{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb9q2_QZgdNk"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mPT0ipYE28wL",
    "outputId": "4352663d-20eb-4080-a83e-bf6b97183bf4"
   },
   "outputs": [],
   "source": [
    "# # ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading_pair_trading_Prices import StockPairTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent, DRLEnsembleAgentOne\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "cd002c5d-2490-4947-9bd3-2b0696cb0f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AVGO']\n"
     ]
    }
   ],
   "source": [
    "DOW_30_TICKER = ['A','AVGO']\n",
    "print(DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "743f675b-6126-44ea-bf39-7b3333d15044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (6126, 8)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = '2010-04-01'\n",
    "TRAIN_END_DATE = '2021-01-01'\n",
    "TEST_START_DATE = '2021-01-01'\n",
    "TEST_END_DATE = '2022-06-01'\n",
    "\n",
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TEST_END_DATE,\n",
    "                     ticker_list = DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GiRuFOTOtj1Y",
    "outputId": "632ce1e6-ad27-4f50-fec7-0ca27c8e3c96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A       3063\n",
       "AVGO    3063\n",
       "Name: tic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DSw4ZEzVtj1Z",
    "outputId": "0015b377-84ec-4a6d-ac4e-e138c2c9bac8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>531.539978</td>\n",
       "      <td>554.570007</td>\n",
       "      <td>527.719971</td>\n",
       "      <td>537.109436</td>\n",
       "      <td>3974300</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>124.919998</td>\n",
       "      <td>130.770004</td>\n",
       "      <td>124.489998</td>\n",
       "      <td>130.094025</td>\n",
       "      <td>2698800</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>562.090027</td>\n",
       "      <td>585.460022</td>\n",
       "      <td>560.010010</td>\n",
       "      <td>568.926819</td>\n",
       "      <td>3730100</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>130.070007</td>\n",
       "      <td>126.720001</td>\n",
       "      <td>127.114464</td>\n",
       "      <td>3403100</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>584.500000</td>\n",
       "      <td>587.030029</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>565.854309</td>\n",
       "      <td>3000900</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close   volume  \\\n",
       "6121  2022-05-26  531.539978  554.570007  527.719971  537.109436  3974300   \n",
       "6122  2022-05-27  124.919998  130.770004  124.489998  130.094025  2698800   \n",
       "6123  2022-05-27  562.090027  585.460022  560.010010  568.926819  3730100   \n",
       "6124  2022-05-31  128.910004  130.070007  126.720001  127.114464  3403100   \n",
       "6125  2022-05-31  584.500000  587.030029  576.000000  565.854309  3000900   \n",
       "\n",
       "       tic  day  \n",
       "6121  AVGO    3  \n",
       "6122     A    4  \n",
       "6123  AVGO    4  \n",
       "6124     A    1  \n",
       "6125  AVGO    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "42781af6-4cee-4277-8a00-cf46052f991c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6126, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "59c51c93-f786-469b-c008-4e4416a041b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>24.706724</td>\n",
       "      <td>24.942776</td>\n",
       "      <td>24.499285</td>\n",
       "      <td>22.442749</td>\n",
       "      <td>3105098</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>20.090000</td>\n",
       "      <td>15.103760</td>\n",
       "      <td>324600</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>24.742489</td>\n",
       "      <td>24.921316</td>\n",
       "      <td>24.706724</td>\n",
       "      <td>22.618134</td>\n",
       "      <td>3731961</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>19.790001</td>\n",
       "      <td>14.926939</td>\n",
       "      <td>612000</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>24.778255</td>\n",
       "      <td>24.814020</td>\n",
       "      <td>24.620888</td>\n",
       "      <td>22.449242</td>\n",
       "      <td>3499054</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close   volume   tic  day\n",
       "0  2010-04-01  24.706724  24.942776  24.499285  22.442749  3105098     A    3\n",
       "1  2010-04-01  20.690001  20.799999  20.090000  15.103760   324600  AVGO    3\n",
       "2  2010-04-05  24.742489  24.921316  24.706724  22.618134  3731961     A    0\n",
       "3  2010-04-05  20.690001  20.700001  19.790001  14.926939   612000  AVGO    0\n",
       "4  2010-04-06  24.778255  24.814020  24.620888  22.449242  3499054     A    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2vryMsdNL9H",
    "outputId": "dff3babf-4aba-44dd-ad61-8845df60243e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcNyXa7RNPrF",
    "outputId": "fd13ad85-36fd-4a55-9084-dbf807bbeb02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A       3063\n",
       "AVGO    3063\n",
       "Name: tic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kM5bH9uroCeg"
   },
   "outputs": [],
   "source": [
    "#  INDICATORS = ['macd',\n",
    "#                'rsi_30',\n",
    "#                'cci_30',\n",
    "#                'dx_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgXfBcjxtj1a",
    "outputId": "aa687295-c857-4366-d9af-96ea233c6463",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)\n",
    "processed = processed.copy()\n",
    "processed = processed.fillna(0)\n",
    "processed = processed.replace(np.inf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "grvhGJJII3Xn",
    "outputId": "6dd919fa-032b-4180-adf4-1f732777cedc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A       3063\n",
       "AVGO    3063\n",
       "Name: tic, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.tic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "0194749d-62ec-420f-9b54-492873c266a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 2, State Space: 21\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 10_000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgentOne(df=processed,\n",
    "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window,\n",
    "                 seed=106,\n",
    "                 **env_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.005,\n",
    "                    'learning_rate': 0.001\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 10_000,\n",
    "                      \"learning_rate\": 0.0005,\n",
    "                      \"batch_size\": 64\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 500_000, \n",
    "                 'ppo' : 0, \n",
    "                 'ddpg' : 0\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1lyCECstj1e",
    "outputId": "b2a1cfbc-ced9-4d06-dd9a-4300845e1113",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  18.962641042223694\n",
      "======Model training from:  2010-04-01 to  2021-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_126_1\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 108          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.85        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0853      |\n",
      "|    reward             | -0.045984533 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 158         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.9        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.0425     |\n",
      "|    reward             | 0.042183142 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000675    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 193         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.249      |\n",
      "|    reward             | -0.13565633 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.031       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 205        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.9       |\n",
      "|    explained_variance | -0.488     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.274     |\n",
      "|    reward             | 0.06592125 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.0364     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.91     |\n",
      "|    explained_variance | 0.109     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 0.0291    |\n",
      "|    reward             | 1.0136185 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 229           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -2.95         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | 0.0889        |\n",
      "|    reward             | -0.0067863218 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000826      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 233           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -2.97         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.0851       |\n",
      "|    reward             | 0.00047894102 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 0.000523      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 241           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.02         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | -0.000523     |\n",
      "|    reward             | -0.0031694274 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.000154      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 249          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.06        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.0221       |\n",
      "|    reward             | -0.012883858 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 6.56e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 254           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.12         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | -0.0632       |\n",
      "|    reward             | -0.0016744827 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 0.000442      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 256          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.15        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.187       |\n",
      "|    reward             | -0.015388765 |\n",
      "|    std                | 1.17         |\n",
      "|    value_loss         | 0.00275      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 259          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.2         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.177       |\n",
      "|    reward             | -0.008018765 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 0.00305      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 260        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.23      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 0.0313     |\n",
      "|    reward             | 0.06703259 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 0.000625   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 260         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.25       |\n",
      "|    explained_variance | 0.683       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0337      |\n",
      "|    reward             | -0.03005923 |\n",
      "|    std                | 1.23        |\n",
      "|    value_loss         | 0.000999    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 263        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.29      |\n",
      "|    explained_variance | 0.327      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -0.191     |\n",
      "|    reward             | 0.82920456 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.00644    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 262         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.3        |\n",
      "|    explained_variance | -0.0237     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -0.415      |\n",
      "|    reward             | -0.18189566 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.0273      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 264         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.34       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0284      |\n",
      "|    reward             | -0.01913887 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 0.000522    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 263           |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 34            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.39         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | -0.0275       |\n",
      "|    reward             | -0.0037686753 |\n",
      "|    std                | 1.32          |\n",
      "|    value_loss         | 8.24e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 265         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.43       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.051      |\n",
      "|    reward             | 0.017010512 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.000514    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 266         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -0.032      |\n",
      "|    reward             | 0.013128453 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 265          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 39           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.51        |\n",
      "|    explained_variance | -1.05        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.0685      |\n",
      "|    reward             | -0.007120976 |\n",
      "|    std                | 1.4          |\n",
      "|    value_loss         | 0.000411     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 267         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.55       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -0.201      |\n",
      "|    reward             | 0.060498364 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.00329     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 269         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.57       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.226       |\n",
      "|    reward             | -0.03302132 |\n",
      "|    std                | 1.44        |\n",
      "|    value_loss         | 0.00544     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 269        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 44         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.59      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | -0.0554    |\n",
      "|    reward             | 0.10681471 |\n",
      "|    std                | 1.46       |\n",
      "|    value_loss         | 0.00265    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 270        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.58      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -1.02      |\n",
      "|    reward             | 0.19964926 |\n",
      "|    std                | 1.45       |\n",
      "|    value_loss         | 0.0767     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 271         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.58       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | -2.4        |\n",
      "|    reward             | -0.29291093 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 0.399       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 270         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.58       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 3.73        |\n",
      "|    reward             | -0.61789465 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -244852.40\n",
      "total_reward: -254852.40\n",
      "total_cost: 43.33\n",
      "total_trades: 5414\n",
      "Sharpe: -0.403\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 271         |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.6        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | -0.101      |\n",
      "|    reward             | 0.001760011 |\n",
      "|    std                | 1.47        |\n",
      "|    value_loss         | 0.00192     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 273        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.63      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -0.0771    |\n",
      "|    reward             | 0.04027939 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 0.00152    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 273         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.66       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | 0.194       |\n",
      "|    reward             | -0.07879799 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.00873     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 274          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.7         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -0.458       |\n",
      "|    reward             | -0.020788375 |\n",
      "|    std                | 1.54         |\n",
      "|    value_loss         | 0.0293       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 276        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.72      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -0.351     |\n",
      "|    reward             | 0.05122148 |\n",
      "|    std                | 1.56       |\n",
      "|    value_loss         | 0.0131     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 276         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.74       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -0.0238     |\n",
      "|    reward             | 0.009848752 |\n",
      "|    std                | 1.57        |\n",
      "|    value_loss         | 0.000181    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 278          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 61           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.77        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | 0.0294       |\n",
      "|    reward             | -0.005551641 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 0.000285     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.8      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | -0.116    |\n",
      "|    reward             | 0.0154957 |\n",
      "|    std                | 1.62      |\n",
      "|    value_loss         | 0.0016    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 279         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.85       |\n",
      "|    explained_variance | -0.356      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.276      |\n",
      "|    reward             | 0.024302145 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 0.00655     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 280        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.89      |\n",
      "|    explained_variance | -0.432     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -0.0415    |\n",
      "|    reward             | 0.06181902 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 0.00217    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 280         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.94       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -0.243      |\n",
      "|    reward             | 0.035082206 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 0.00442     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 280          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.97        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.0149       |\n",
      "|    reward             | -0.019288972 |\n",
      "|    std                | 1.77         |\n",
      "|    value_loss         | 0.000681     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 280          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.99        |\n",
      "|    explained_variance | 0.526        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.0854       |\n",
      "|    reward             | -0.013135816 |\n",
      "|    std                | 1.78         |\n",
      "|    value_loss         | 0.000807     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 280         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.01       |\n",
      "|    explained_variance | -1.88       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 1.21        |\n",
      "|    reward             | 0.071921475 |\n",
      "|    std                | 1.8         |\n",
      "|    value_loss         | 0.104       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 279         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.04       |\n",
      "|    explained_variance | 0.385       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | -1.04       |\n",
      "|    reward             | -0.31007403 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 0.0716      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 278         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.07       |\n",
      "|    explained_variance | 0.35        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | 0.426       |\n",
      "|    reward             | 0.091175206 |\n",
      "|    std                | 1.85        |\n",
      "|    value_loss         | 0.0432      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 279          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 78           |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.09        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.00933      |\n",
      "|    reward             | -0.021629926 |\n",
      "|    std                | 1.88         |\n",
      "|    value_loss         | 4.74e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 278           |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 80            |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.1          |\n",
      "|    explained_variance | -0.499        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | 0.0161        |\n",
      "|    reward             | -0.0061178072 |\n",
      "|    std                | 1.88          |\n",
      "|    value_loss         | 0.000404      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 279          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 82           |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.13        |\n",
      "|    explained_variance | -1.33        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -0.118       |\n",
      "|    reward             | -0.052305043 |\n",
      "|    std                | 1.91         |\n",
      "|    value_loss         | 0.00395      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 279          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.16        |\n",
      "|    explained_variance | 0.452        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | -0.288       |\n",
      "|    reward             | -0.057364643 |\n",
      "|    std                | 1.94         |\n",
      "|    value_loss         | 0.00954      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 279         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.18       |\n",
      "|    explained_variance | -0.538      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 1.17        |\n",
      "|    reward             | -0.12769154 |\n",
      "|    std                | 1.96        |\n",
      "|    value_loss         | 0.131       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 278           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 87            |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.19         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.0291       |\n",
      "|    reward             | -0.0032934798 |\n",
      "|    std                | 1.97          |\n",
      "|    value_loss         | 7.22e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 279          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.22        |\n",
      "|    explained_variance | 0.747        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 0.0461       |\n",
      "|    reward             | -0.010345252 |\n",
      "|    std                | 2            |\n",
      "|    value_loss         | 0.00047      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 280         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.23       |\n",
      "|    explained_variance | 9.51e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 0.244       |\n",
      "|    reward             | 0.008581065 |\n",
      "|    std                | 2.02        |\n",
      "|    value_loss         | 0.00349     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 280         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.29       |\n",
      "|    explained_variance | -0.0578     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | 0.184       |\n",
      "|    reward             | 0.018917467 |\n",
      "|    std                | 2.07        |\n",
      "|    value_loss         | 0.004       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 281         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.3        |\n",
      "|    explained_variance | -0.0289     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | 0.264       |\n",
      "|    reward             | -0.03877292 |\n",
      "|    std                | 2.08        |\n",
      "|    value_loss         | 0.00573     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 281          |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.29        |\n",
      "|    explained_variance | -1.52        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | -1.5         |\n",
      "|    reward             | -0.061630428 |\n",
      "|    std                | 2.07         |\n",
      "|    value_loss         | 0.15         |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -35853.01\n",
      "total_reward: -45853.01\n",
      "total_cost: 24.38\n",
      "total_trades: 5414\n",
      "Sharpe: -0.341\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 281          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.31        |\n",
      "|    explained_variance | 0.0809       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 0.25         |\n",
      "|    reward             | -0.016967576 |\n",
      "|    std                | 2.1          |\n",
      "|    value_loss         | 0.0056       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.35        |\n",
      "|    explained_variance | 0.612        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | 0.371        |\n",
      "|    reward             | -0.053033322 |\n",
      "|    std                | 2.13         |\n",
      "|    value_loss         | 0.00986      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 281          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.37        |\n",
      "|    explained_variance | 0.0447       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.486        |\n",
      "|    reward             | -0.022960505 |\n",
      "|    std                | 2.16         |\n",
      "|    value_loss         | 0.0452       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.4        |\n",
      "|    explained_variance | 0.073       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -1.35       |\n",
      "|    reward             | 0.106211394 |\n",
      "|    std                | 2.19        |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.42       |\n",
      "|    explained_variance | 0.479       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -1.76       |\n",
      "|    reward             | 0.048762657 |\n",
      "|    std                | 2.22        |\n",
      "|    value_loss         | 0.202       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 106          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.42        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.0141      |\n",
      "|    reward             | -0.007215255 |\n",
      "|    std                | 2.21         |\n",
      "|    value_loss         | 1.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.43        |\n",
      "|    explained_variance | 3.93e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | 0.133        |\n",
      "|    reward             | -0.013921942 |\n",
      "|    std                | 2.23         |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.45       |\n",
      "|    explained_variance | 0.891       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | -0.0975     |\n",
      "|    reward             | 0.019196246 |\n",
      "|    std                | 2.25        |\n",
      "|    value_loss         | 0.00064     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.45        |\n",
      "|    explained_variance | -0.133       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | 0.204        |\n",
      "|    reward             | -0.036448903 |\n",
      "|    std                | 2.25         |\n",
      "|    value_loss         | 0.00277      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 112          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.46        |\n",
      "|    explained_variance | 0.215        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | 0.642        |\n",
      "|    reward             | -0.038977757 |\n",
      "|    std                | 2.26         |\n",
      "|    value_loss         | 0.0359       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -0.36       |\n",
      "|    reward             | 0.005320032 |\n",
      "|    std                | 2.27        |\n",
      "|    value_loss         | 0.00529     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 282           |\n",
      "|    iterations         | 6600          |\n",
      "|    time_elapsed       | 116           |\n",
      "|    total_timesteps    | 33000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.5          |\n",
      "|    explained_variance | 0.274         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 6599          |\n",
      "|    policy_loss        | -0.0543       |\n",
      "|    reward             | -0.0026712506 |\n",
      "|    std                | 2.3           |\n",
      "|    value_loss         | 0.000577      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.54        |\n",
      "|    explained_variance | 0.328        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | -0.0502      |\n",
      "|    reward             | -0.016364796 |\n",
      "|    std                | 2.35         |\n",
      "|    value_loss         | 0.000189     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.59       |\n",
      "|    explained_variance | -0.0502     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -0.034      |\n",
      "|    reward             | 0.003217335 |\n",
      "|    std                | 2.41        |\n",
      "|    value_loss         | 0.000523    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 121        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | 0.589      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -0.565     |\n",
      "|    reward             | 0.10266462 |\n",
      "|    std                | 2.44       |\n",
      "|    value_loss         | 0.0146     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 284         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.64       |\n",
      "|    explained_variance | 0.603       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | 0.707       |\n",
      "|    reward             | 0.061439503 |\n",
      "|    std                | 2.48        |\n",
      "|    value_loss         | 0.0137      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.67        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | -0.0789      |\n",
      "|    reward             | -0.008598861 |\n",
      "|    std                | 2.51         |\n",
      "|    value_loss         | 0.00159      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.7        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | 0.0435      |\n",
      "|    reward             | 0.003385861 |\n",
      "|    std                | 2.55        |\n",
      "|    value_loss         | 0.000125    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.74       |\n",
      "|    explained_variance | -32.2       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 0.0825      |\n",
      "|    reward             | -0.02961309 |\n",
      "|    std                | 2.6         |\n",
      "|    value_loss         | 0.000525    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 130        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.78      |\n",
      "|    explained_variance | 0.00321    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | -0.135     |\n",
      "|    reward             | 0.01597247 |\n",
      "|    std                | 2.65       |\n",
      "|    value_loss         | 0.000971   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.83       |\n",
      "|    explained_variance | 0.847       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | 0.0495      |\n",
      "|    reward             | 0.046346165 |\n",
      "|    std                | 2.72        |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.86        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.0404       |\n",
      "|    reward             | 0.0042694146 |\n",
      "|    std                | 2.77         |\n",
      "|    value_loss         | 0.000139     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 7700          |\n",
      "|    time_elapsed       | 135           |\n",
      "|    total_timesteps    | 38500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.92         |\n",
      "|    explained_variance | -0.387        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7699          |\n",
      "|    policy_loss        | -0.169        |\n",
      "|    reward             | -0.0074100355 |\n",
      "|    std                | 2.85          |\n",
      "|    value_loss         | 0.00136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 7800          |\n",
      "|    time_elapsed       | 137           |\n",
      "|    total_timesteps    | 39000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.96         |\n",
      "|    explained_variance | -0.166        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7799          |\n",
      "|    policy_loss        | 0.0645        |\n",
      "|    reward             | -0.0017301112 |\n",
      "|    std                | 2.9           |\n",
      "|    value_loss         | 0.000506      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.99       |\n",
      "|    explained_variance | 0.246       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | -0.0741     |\n",
      "|    reward             | 0.003806835 |\n",
      "|    std                | 2.96        |\n",
      "|    value_loss         | 0.000379    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 141           |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.01         |\n",
      "|    explained_variance | 0.0188        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | 0.109         |\n",
      "|    reward             | -0.0076256706 |\n",
      "|    std                | 2.99          |\n",
      "|    value_loss         | 0.000795      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | -0.000207   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 0.334       |\n",
      "|    reward             | 0.021242442 |\n",
      "|    std                | 3.01        |\n",
      "|    value_loss         | 0.00266     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 1376.96\n",
      "total_reward: -8623.04\n",
      "total_cost: 38.38\n",
      "total_trades: 5414\n",
      "Sharpe: 0.311\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | 0.311      |\n",
      "|    reward             | 0.03888224 |\n",
      "|    std                | 3.06       |\n",
      "|    value_loss         | 0.00643    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.08        |\n",
      "|    explained_variance | 0.00476      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.164       |\n",
      "|    reward             | -0.004711804 |\n",
      "|    std                | 3.09         |\n",
      "|    value_loss         | 0.00164      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.1        |\n",
      "|    explained_variance | -0.954      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 0.0481      |\n",
      "|    reward             | 0.011660237 |\n",
      "|    std                | 3.13        |\n",
      "|    value_loss         | 0.000581    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 149          |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.13        |\n",
      "|    explained_variance | 0.473        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | 0.0737       |\n",
      "|    reward             | 0.0008949061 |\n",
      "|    std                | 3.17         |\n",
      "|    value_loss         | 0.000451     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 284         |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.17       |\n",
      "|    explained_variance | 0.11        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | -0.279      |\n",
      "|    reward             | 0.013914214 |\n",
      "|    std                | 3.23        |\n",
      "|    value_loss         | 0.0064      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 284           |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 152           |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.2          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | -0.116        |\n",
      "|    reward             | -0.0104462765 |\n",
      "|    std                | 3.28          |\n",
      "|    value_loss         | 0.000595      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 154          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.25        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.249       |\n",
      "|    reward             | 0.0016070413 |\n",
      "|    std                | 3.37         |\n",
      "|    value_loss         | 0.00342      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 156           |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.29         |\n",
      "|    explained_variance | -2.62e-06     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | -0.216        |\n",
      "|    reward             | -0.0019507884 |\n",
      "|    std                | 3.44          |\n",
      "|    value_loss         | 0.00185       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.31       |\n",
      "|    explained_variance | -1.06       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | 0.217       |\n",
      "|    reward             | 0.004486523 |\n",
      "|    std                | 3.46        |\n",
      "|    value_loss         | 0.00209     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.34        |\n",
      "|    explained_variance | -0.238       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.317       |\n",
      "|    reward             | 0.0028972032 |\n",
      "|    std                | 3.52         |\n",
      "|    value_loss         | 0.00375      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 162        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.37      |\n",
      "|    explained_variance | -4.39e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -0.149     |\n",
      "|    reward             | 0.08662218 |\n",
      "|    std                | 3.57       |\n",
      "|    value_loss         | 0.0026     |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 283            |\n",
      "|    iterations         | 9300           |\n",
      "|    time_elapsed       | 164            |\n",
      "|    total_timesteps    | 46500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.41          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 9299           |\n",
      "|    policy_loss        | -0.0297        |\n",
      "|    reward             | -0.00023532953 |\n",
      "|    std                | 3.65           |\n",
      "|    value_loss         | 0.000189       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.44       |\n",
      "|    explained_variance | -0.0111     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 0.0948      |\n",
      "|    reward             | -0.01892584 |\n",
      "|    std                | 3.71        |\n",
      "|    value_loss         | 0.000322    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 9500          |\n",
      "|    time_elapsed       | 167           |\n",
      "|    total_timesteps    | 47500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.51         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 9499          |\n",
      "|    policy_loss        | 0.0719        |\n",
      "|    reward             | 0.00018100576 |\n",
      "|    std                | 3.83          |\n",
      "|    value_loss         | 0.000263      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.58       |\n",
      "|    explained_variance | 0.343       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 0.0703      |\n",
      "|    reward             | 0.014192054 |\n",
      "|    std                | 3.98        |\n",
      "|    value_loss         | 0.000276    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.65       |\n",
      "|    explained_variance | 0.831       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 0.13        |\n",
      "|    reward             | 0.017614506 |\n",
      "|    std                | 4.12        |\n",
      "|    value_loss         | 0.000454    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -0.236      |\n",
      "|    reward             | -0.03982586 |\n",
      "|    std                | 4.21        |\n",
      "|    value_loss         | 0.00184     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.72        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | 0.0188       |\n",
      "|    reward             | -0.012064288 |\n",
      "|    std                | 4.25         |\n",
      "|    value_loss         | 5e-05        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 10000        |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 50000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.78        |\n",
      "|    explained_variance | -5.72e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9999         |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | -0.034220193 |\n",
      "|    std                | 4.37         |\n",
      "|    value_loss         | 0.00152      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 10100       |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 50500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.82       |\n",
      "|    explained_variance | 0.279       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | 0.131       |\n",
      "|    reward             | 0.004680378 |\n",
      "|    std                | 4.47        |\n",
      "|    value_loss         | 0.000619    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 282        |\n",
      "|    iterations         | 10200      |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 51000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0.669      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10199      |\n",
      "|    policy_loss        | 0.019      |\n",
      "|    reward             | 0.05838807 |\n",
      "|    std                | 4.55       |\n",
      "|    value_loss         | 0.000318   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 10300       |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 51500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -0.0874     |\n",
      "|    reward             | -0.03577824 |\n",
      "|    std                | 4.62        |\n",
      "|    value_loss         | 0.000685    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 10400       |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 52000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.91       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -0.143      |\n",
      "|    reward             | 0.008510771 |\n",
      "|    std                | 4.68        |\n",
      "|    value_loss         | 0.000952    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 282           |\n",
      "|    iterations         | 10500         |\n",
      "|    time_elapsed       | 185           |\n",
      "|    total_timesteps    | 52500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.95         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10499         |\n",
      "|    policy_loss        | -0.0956       |\n",
      "|    reward             | -0.0053994874 |\n",
      "|    std                | 4.77          |\n",
      "|    value_loss         | 0.000313      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 10600        |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 53000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.01        |\n",
      "|    explained_variance | -1.34        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10599        |\n",
      "|    policy_loss        | -0.114       |\n",
      "|    reward             | -0.008889906 |\n",
      "|    std                | 4.91         |\n",
      "|    value_loss         | 0.000452     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 10700        |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 53500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.08        |\n",
      "|    explained_variance | 0.359        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | -0.0498      |\n",
      "|    reward             | -0.010535231 |\n",
      "|    std                | 5.11         |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 10800       |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 54000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.15       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | -0.182      |\n",
      "|    reward             | 0.008978806 |\n",
      "|    std                | 5.26        |\n",
      "|    value_loss         | 0.000824    |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -7429.50\n",
      "total_reward: -17429.50\n",
      "total_cost: 511.87\n",
      "total_trades: 5414\n",
      "Sharpe: 0.028\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 10900       |\n",
      "|    time_elapsed       | 192         |\n",
      "|    total_timesteps    | 54500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.19       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | 0.371       |\n",
      "|    reward             | 0.022075595 |\n",
      "|    std                | 5.36        |\n",
      "|    value_loss         | 0.00536     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 282           |\n",
      "|    iterations         | 11000         |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 55000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.22         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10999         |\n",
      "|    policy_loss        | 0.0959        |\n",
      "|    reward             | -0.0031793888 |\n",
      "|    std                | 5.46          |\n",
      "|    value_loss         | 0.000241      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 282            |\n",
      "|    iterations         | 11100          |\n",
      "|    time_elapsed       | 196            |\n",
      "|    total_timesteps    | 55500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.27          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 11099          |\n",
      "|    policy_loss        | 0.0541         |\n",
      "|    reward             | -6.1442915e-05 |\n",
      "|    std                | 5.58           |\n",
      "|    value_loss         | 8.31e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 282           |\n",
      "|    iterations         | 11200         |\n",
      "|    time_elapsed       | 198           |\n",
      "|    total_timesteps    | 56000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.34         |\n",
      "|    explained_variance | -0.0858       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11199         |\n",
      "|    policy_loss        | 0.0312        |\n",
      "|    reward             | -0.0007182785 |\n",
      "|    std                | 5.8           |\n",
      "|    value_loss         | 7.48e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 11300        |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 56500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.38        |\n",
      "|    explained_variance | -0.215       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | 0.00945      |\n",
      "|    reward             | 0.0060074283 |\n",
      "|    std                | 5.92         |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 11400        |\n",
      "|    time_elapsed       | 201          |\n",
      "|    total_timesteps    | 57000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.47        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11399        |\n",
      "|    policy_loss        | -0.467       |\n",
      "|    reward             | 0.0005780857 |\n",
      "|    std                | 6.17         |\n",
      "|    value_loss         | 0.00621      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 11500       |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 57500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.49       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 0.3         |\n",
      "|    reward             | 0.005207333 |\n",
      "|    std                | 6.24        |\n",
      "|    value_loss         | 0.00277     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 11600        |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 58000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.52        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | 0.111        |\n",
      "|    reward             | 0.0014002144 |\n",
      "|    std                | 6.35         |\n",
      "|    value_loss         | 0.000272     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 11700       |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 58500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.59       |\n",
      "|    explained_variance | -16.3       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | 0.208       |\n",
      "|    reward             | 0.004905736 |\n",
      "|    std                | 6.57        |\n",
      "|    value_loss         | 0.00167     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 11800        |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 59000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.64        |\n",
      "|    explained_variance | 0.111        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | 0.00545      |\n",
      "|    reward             | -0.009624341 |\n",
      "|    std                | 6.75         |\n",
      "|    value_loss         | 0.000375     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 11900        |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 59500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.71        |\n",
      "|    explained_variance | 0.0441       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | 0.427        |\n",
      "|    reward             | -0.018880434 |\n",
      "|    std                | 6.97         |\n",
      "|    value_loss         | 0.00578      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 282           |\n",
      "|    iterations         | 12000         |\n",
      "|    time_elapsed       | 212           |\n",
      "|    total_timesteps    | 60000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.73         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11999         |\n",
      "|    policy_loss        | 0.19          |\n",
      "|    reward             | -0.0060150553 |\n",
      "|    std                | 7.03          |\n",
      "|    value_loss         | 0.00397       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 12100         |\n",
      "|    time_elapsed       | 213           |\n",
      "|    total_timesteps    | 60500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.76         |\n",
      "|    explained_variance | -0.0561       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12099         |\n",
      "|    policy_loss        | 0.0584        |\n",
      "|    reward             | -0.0013090383 |\n",
      "|    std                | 7.13          |\n",
      "|    value_loss         | 0.000309      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 282           |\n",
      "|    iterations         | 12200         |\n",
      "|    time_elapsed       | 215           |\n",
      "|    total_timesteps    | 61000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.8          |\n",
      "|    explained_variance | -0.872        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12199         |\n",
      "|    policy_loss        | -0.211        |\n",
      "|    reward             | -0.0065550753 |\n",
      "|    std                | 7.3           |\n",
      "|    value_loss         | 0.0013        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 12300        |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 61500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.85        |\n",
      "|    explained_variance | -0.0356      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | 0.2          |\n",
      "|    reward             | -0.021574417 |\n",
      "|    std                | 7.48         |\n",
      "|    value_loss         | 0.00155      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 12400        |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 62000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.9         |\n",
      "|    explained_variance | 0.17         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12399        |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | -0.029259255 |\n",
      "|    std                | 7.68         |\n",
      "|    value_loss         | 0.000908     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 12500        |\n",
      "|    time_elapsed       | 220          |\n",
      "|    total_timesteps    | 62500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.94        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | 0.0348       |\n",
      "|    reward             | -0.012037611 |\n",
      "|    std                | 7.8          |\n",
      "|    value_loss         | 0.000707     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 12600         |\n",
      "|    time_elapsed       | 222           |\n",
      "|    total_timesteps    | 63000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.97         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12599         |\n",
      "|    policy_loss        | 0.00914       |\n",
      "|    reward             | -0.0075526247 |\n",
      "|    std                | 7.93          |\n",
      "|    value_loss         | 8.72e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 12700       |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 63500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.01       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -0.0664     |\n",
      "|    reward             | 0.014400023 |\n",
      "|    std                | 8.11        |\n",
      "|    value_loss         | 0.000152    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 12800        |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 64000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.07        |\n",
      "|    explained_variance | -0.892       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12799        |\n",
      "|    policy_loss        | -0.0236      |\n",
      "|    reward             | -0.015733818 |\n",
      "|    std                | 8.35         |\n",
      "|    value_loss         | 3.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 12900        |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 64500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.13        |\n",
      "|    explained_variance | 0.456        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | 0.332        |\n",
      "|    reward             | 0.0059874123 |\n",
      "|    std                | 8.6          |\n",
      "|    value_loss         | 0.002        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 282         |\n",
      "|    iterations         | 13000       |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 65000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.18       |\n",
      "|    explained_variance | -1.13       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | 1.16        |\n",
      "|    reward             | -0.04283798 |\n",
      "|    std                | 8.84        |\n",
      "|    value_loss         | 0.0345      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 13100        |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 65500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.27        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13099        |\n",
      "|    policy_loss        | 0.0736       |\n",
      "|    reward             | -0.010536498 |\n",
      "|    std                | 9.21         |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 282          |\n",
      "|    iterations         | 13200        |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 66000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.31        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | 0.111        |\n",
      "|    reward             | 0.0040919255 |\n",
      "|    std                | 9.4          |\n",
      "|    value_loss         | 0.000345     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 13300         |\n",
      "|    time_elapsed       | 234           |\n",
      "|    total_timesteps    | 66500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.38         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13299         |\n",
      "|    policy_loss        | -0.0907       |\n",
      "|    reward             | -0.0060056043 |\n",
      "|    std                | 9.73          |\n",
      "|    value_loss         | 0.000262      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 282        |\n",
      "|    iterations         | 13400      |\n",
      "|    time_elapsed       | 236        |\n",
      "|    total_timesteps    | 67000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.46      |\n",
      "|    explained_variance | -6.74      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13399      |\n",
      "|    policy_loss        | 0.082      |\n",
      "|    reward             | 0.00821136 |\n",
      "|    std                | 10.1       |\n",
      "|    value_loss         | 0.000267   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 13500        |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 67500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.5         |\n",
      "|    explained_variance | -0.433       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | 1.14         |\n",
      "|    reward             | -0.033982784 |\n",
      "|    std                | 10.3         |\n",
      "|    value_loss         | 0.0255       |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11483.11\n",
      "total_reward: -21483.11\n",
      "total_cost: 456.65\n",
      "total_trades: 5414\n",
      "Sharpe: -0.027\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.53       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | 0.651       |\n",
      "|    reward             | -0.06860328 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.00808     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 13700         |\n",
      "|    time_elapsed       | 241           |\n",
      "|    total_timesteps    | 68500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.57         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13699         |\n",
      "|    policy_loss        | -0.462        |\n",
      "|    reward             | -0.0032843917 |\n",
      "|    std                | 10.7          |\n",
      "|    value_loss         | 0.00413       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 13800       |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 69000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.6        |\n",
      "|    explained_variance | -0.78       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | 0.0754      |\n",
      "|    reward             | 0.010777623 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.000178    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 13900         |\n",
      "|    time_elapsed       | 245           |\n",
      "|    total_timesteps    | 69500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.66         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13899         |\n",
      "|    policy_loss        | 0.0125        |\n",
      "|    reward             | -0.0072523863 |\n",
      "|    std                | 11.2          |\n",
      "|    value_loss         | 0.000564      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 14000      |\n",
      "|    time_elapsed       | 247        |\n",
      "|    total_timesteps    | 70000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.7       |\n",
      "|    explained_variance | -0.0688    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13999      |\n",
      "|    policy_loss        | 0.581      |\n",
      "|    reward             | 0.03763391 |\n",
      "|    std                | 11.4       |\n",
      "|    value_loss         | 0.00677    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 14100       |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 70500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.72       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | -0.332      |\n",
      "|    reward             | 0.019377964 |\n",
      "|    std                | 11.6        |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 283            |\n",
      "|    iterations         | 14200          |\n",
      "|    time_elapsed       | 250            |\n",
      "|    total_timesteps    | 71000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.76          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 14199          |\n",
      "|    policy_loss        | -0.453         |\n",
      "|    reward             | -0.00094288954 |\n",
      "|    std                | 11.8           |\n",
      "|    value_loss         | 0.0048         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 14300       |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 71500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.8        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | 0.396       |\n",
      "|    reward             | -0.01294732 |\n",
      "|    std                | 12          |\n",
      "|    value_loss         | 0.00365     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 14400       |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 72000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.81       |\n",
      "|    explained_variance | -0.000247   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | 0.117       |\n",
      "|    reward             | 0.006096935 |\n",
      "|    std                | 12.1        |\n",
      "|    value_loss         | 0.000234    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 14500        |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 72500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.84        |\n",
      "|    explained_variance | 0.0452       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | 0.616        |\n",
      "|    reward             | -0.015320075 |\n",
      "|    std                | 12.2         |\n",
      "|    value_loss         | 0.0255       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 14600        |\n",
      "|    time_elapsed       | 257          |\n",
      "|    total_timesteps    | 73000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.85        |\n",
      "|    explained_variance | -0.00034     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | 0.457        |\n",
      "|    reward             | -0.039932538 |\n",
      "|    std                | 12.3         |\n",
      "|    value_loss         | 0.00403      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | 0.445       |\n",
      "|    reward             | 0.024804346 |\n",
      "|    std                | 12.5        |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 14800        |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 74000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.91        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14799        |\n",
      "|    policy_loss        | -0.0381      |\n",
      "|    reward             | -0.007635091 |\n",
      "|    std                | 12.7         |\n",
      "|    value_loss         | 2.76e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 14900        |\n",
      "|    time_elapsed       | 262          |\n",
      "|    total_timesteps    | 74500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.99        |\n",
      "|    explained_variance | 0.774        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | 0.0823       |\n",
      "|    reward             | -0.021750212 |\n",
      "|    std                | 13.2         |\n",
      "|    value_loss         | 0.000164     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 15000       |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 75000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.03       |\n",
      "|    explained_variance | 0.492       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | 0.0193      |\n",
      "|    reward             | 0.017882314 |\n",
      "|    std                | 13.5        |\n",
      "|    value_loss         | 1.92e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | 0.0114      |\n",
      "|    reward             | 0.010483185 |\n",
      "|    std                | 14          |\n",
      "|    value_loss         | 0.000311    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 15200        |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 76000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.13        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15199        |\n",
      "|    policy_loss        | -0.232       |\n",
      "|    reward             | -0.014397933 |\n",
      "|    std                | 14.2         |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 15300         |\n",
      "|    time_elapsed       | 269           |\n",
      "|    total_timesteps    | 76500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.17         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15299         |\n",
      "|    policy_loss        | -0.211        |\n",
      "|    reward             | -0.0035817977 |\n",
      "|    std                | 14.5          |\n",
      "|    value_loss         | 0.000706      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 15400        |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 77000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.23        |\n",
      "|    explained_variance | 1.87e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15399        |\n",
      "|    policy_loss        | -0.0814      |\n",
      "|    reward             | -0.007506628 |\n",
      "|    std                | 14.9         |\n",
      "|    value_loss         | 0.000134     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 283           |\n",
      "|    iterations         | 15500         |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 77500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.27         |\n",
      "|    explained_variance | 0.444         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15499         |\n",
      "|    policy_loss        | 0.0324        |\n",
      "|    reward             | -0.0013634145 |\n",
      "|    std                | 15.3          |\n",
      "|    value_loss         | 4.81e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 15600        |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 78000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.34        |\n",
      "|    explained_variance | 0.696        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | 0.102        |\n",
      "|    reward             | -0.026886757 |\n",
      "|    std                | 15.8         |\n",
      "|    value_loss         | 0.000175     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.39        |\n",
      "|    explained_variance | -0.15        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | -0.272       |\n",
      "|    reward             | -0.011848884 |\n",
      "|    std                | 16.2         |\n",
      "|    value_loss         | 0.00208      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 283          |\n",
      "|    iterations         | 15800        |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 79000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.41        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | -0.457       |\n",
      "|    reward             | -0.031832725 |\n",
      "|    std                | 16.3         |\n",
      "|    value_loss         | 0.00314      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 15900       |\n",
      "|    time_elapsed       | 280         |\n",
      "|    total_timesteps    | 79500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.42       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | 0.995       |\n",
      "|    reward             | 0.004631982 |\n",
      "|    std                | 16.4        |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 283       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 282       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.46     |\n",
      "|    explained_variance | -0.256    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | -0.925    |\n",
      "|    reward             | -0.218377 |\n",
      "|    std                | 16.7      |\n",
      "|    value_loss         | 0.0306    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 16100      |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 80500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.46      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16099      |\n",
      "|    policy_loss        | -1.95      |\n",
      "|    reward             | 0.53728914 |\n",
      "|    std                | 16.7       |\n",
      "|    value_loss         | 0.0463     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 16200       |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 81000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16199       |\n",
      "|    policy_loss        | -1.05       |\n",
      "|    reward             | -0.30608323 |\n",
      "|    std                | 17          |\n",
      "|    value_loss         | 0.113       |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -293369.59\n",
      "total_reward: -303369.59\n",
      "total_cost: 123.03\n",
      "total_trades: 5414\n",
      "Sharpe: 0.265\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 283         |\n",
      "|    iterations         | 16300       |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 81500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.5        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | -0.0548     |\n",
      "|    reward             | 0.013271649 |\n",
      "|    std                | 17.1        |\n",
      "|    value_loss         | 9.43e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 16400        |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 82000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.53        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16399        |\n",
      "|    policy_loss        | 0.188        |\n",
      "|    reward             | -0.009933415 |\n",
      "|    std                | 17.3         |\n",
      "|    value_loss         | 0.00043      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 284           |\n",
      "|    iterations         | 16500         |\n",
      "|    time_elapsed       | 290           |\n",
      "|    total_timesteps    | 82500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.57         |\n",
      "|    explained_variance | 0.349         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 16499         |\n",
      "|    policy_loss        | 0.143         |\n",
      "|    reward             | -0.0009760613 |\n",
      "|    std                | 17.7          |\n",
      "|    value_loss         | 0.000512      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 16600        |\n",
      "|    time_elapsed       | 292          |\n",
      "|    total_timesteps    | 83000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.64        |\n",
      "|    explained_variance | -0.00038     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16599        |\n",
      "|    policy_loss        | 0.12         |\n",
      "|    reward             | 0.0013539691 |\n",
      "|    std                | 18.3         |\n",
      "|    value_loss         | 0.000284     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.69        |\n",
      "|    explained_variance | -1.32        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | 0.00254      |\n",
      "|    reward             | -0.010633922 |\n",
      "|    std                | 18.8         |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 16800        |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 84000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.75        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | 0.108        |\n",
      "|    reward             | -0.038316082 |\n",
      "|    std                | 19.3         |\n",
      "|    value_loss         | 0.000867     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 16900        |\n",
      "|    time_elapsed       | 296          |\n",
      "|    total_timesteps    | 84500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.76        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | 0.884        |\n",
      "|    reward             | -0.029816646 |\n",
      "|    std                | 19.5         |\n",
      "|    value_loss         | 0.0126       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 284         |\n",
      "|    iterations         | 17000       |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 85000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.78       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | 0.000672    |\n",
      "|    reward             | 0.002366327 |\n",
      "|    std                | 19.6        |\n",
      "|    value_loss         | 0.00023     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 284           |\n",
      "|    iterations         | 17100         |\n",
      "|    time_elapsed       | 300           |\n",
      "|    total_timesteps    | 85500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.79         |\n",
      "|    explained_variance | 0.419         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | -0.135        |\n",
      "|    reward             | -0.0049667093 |\n",
      "|    std                | 19.7          |\n",
      "|    value_loss         | 0.000565      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 17200        |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 86000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.82        |\n",
      "|    explained_variance | 0.0943       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | 0.731        |\n",
      "|    reward             | -0.061544366 |\n",
      "|    std                | 20           |\n",
      "|    value_loss         | 0.00922      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 284         |\n",
      "|    iterations         | 17300       |\n",
      "|    time_elapsed       | 303         |\n",
      "|    total_timesteps    | 86500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.87       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | 0.266       |\n",
      "|    reward             | 0.057287928 |\n",
      "|    std                | 20.6        |\n",
      "|    value_loss         | 0.00485     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 17400        |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 87000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.91        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17399        |\n",
      "|    policy_loss        | 1.17         |\n",
      "|    reward             | -0.086023696 |\n",
      "|    std                | 20.9         |\n",
      "|    value_loss         | 0.019        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 17500        |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 87500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.95        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17499        |\n",
      "|    policy_loss        | -0.151       |\n",
      "|    reward             | 0.0021109604 |\n",
      "|    std                | 21.4         |\n",
      "|    value_loss         | 0.000346     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 17600       |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 88000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.97       |\n",
      "|    explained_variance | -0.467      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17599       |\n",
      "|    policy_loss        | 0.168       |\n",
      "|    reward             | 0.022134796 |\n",
      "|    std                | 21.6        |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 284         |\n",
      "|    iterations         | 17700       |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 88500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.99       |\n",
      "|    explained_variance | 0.124       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | 0.0146      |\n",
      "|    reward             | 0.002831681 |\n",
      "|    std                | 21.7        |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 284         |\n",
      "|    iterations         | 17800       |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 89000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.04       |\n",
      "|    explained_variance | -0.00278    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | -0.29       |\n",
      "|    reward             | 0.025932034 |\n",
      "|    std                | 22.4        |\n",
      "|    value_loss         | 0.00194     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 17900        |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 89500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.06        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17899        |\n",
      "|    policy_loss        | -0.117       |\n",
      "|    reward             | -0.018334307 |\n",
      "|    std                | 22.6         |\n",
      "|    value_loss         | 0.000367     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 284       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 315       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -0.137    |\n",
      "|    reward             | 0.0186867 |\n",
      "|    std                | 22.8      |\n",
      "|    value_loss         | 0.000854  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 284         |\n",
      "|    iterations         | 18100       |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 90500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | 0.157       |\n",
      "|    reward             | 0.010939059 |\n",
      "|    std                | 23.3        |\n",
      "|    value_loss         | 0.000572    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 18200        |\n",
      "|    time_elapsed       | 319          |\n",
      "|    total_timesteps    | 91000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.14        |\n",
      "|    explained_variance | -0.121       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18199        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | -0.009320906 |\n",
      "|    std                | 23.5         |\n",
      "|    value_loss         | 0.000475     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 18300       |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 91500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.19       |\n",
      "|    explained_variance | -0.083      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | -0.636      |\n",
      "|    reward             | 0.013782052 |\n",
      "|    std                | 24.1        |\n",
      "|    value_loss         | 0.00588     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 18400       |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 92000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.22       |\n",
      "|    explained_variance | -0.142      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | -0.501      |\n",
      "|    reward             | 0.062366687 |\n",
      "|    std                | 24.4        |\n",
      "|    value_loss         | 0.00628     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 18500       |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 92500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.26       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | -0.801      |\n",
      "|    reward             | -0.00755079 |\n",
      "|    std                | 24.8        |\n",
      "|    value_loss         | 0.00933     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 18600       |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 93000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.3        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | -0.162      |\n",
      "|    reward             | 0.007004588 |\n",
      "|    std                | 25.4        |\n",
      "|    value_loss         | 0.000607    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 18700       |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 93500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.34       |\n",
      "|    explained_variance | 2.24e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18699       |\n",
      "|    policy_loss        | -0.409      |\n",
      "|    reward             | 0.014904104 |\n",
      "|    std                | 25.9        |\n",
      "|    value_loss         | 0.00237     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 18800        |\n",
      "|    time_elapsed       | 329          |\n",
      "|    total_timesteps    | 94000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.39        |\n",
      "|    explained_variance | -0.0271      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18799        |\n",
      "|    policy_loss        | -0.571       |\n",
      "|    reward             | -0.026291614 |\n",
      "|    std                | 26.6         |\n",
      "|    value_loss         | 0.00521      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 18900        |\n",
      "|    time_elapsed       | 330          |\n",
      "|    total_timesteps    | 94500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.46        |\n",
      "|    explained_variance | -0.0734      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18899        |\n",
      "|    policy_loss        | 0.651        |\n",
      "|    reward             | -0.043985672 |\n",
      "|    std                | 27.6         |\n",
      "|    value_loss         | 0.00491      |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -73631.77\n",
      "total_reward: -83631.77\n",
      "total_cost: 100.77\n",
      "total_trades: 5414\n",
      "Sharpe: 0.489\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 19000        |\n",
      "|    time_elapsed       | 332          |\n",
      "|    total_timesteps    | 95000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.49        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18999        |\n",
      "|    policy_loss        | -0.399       |\n",
      "|    reward             | -0.011977857 |\n",
      "|    std                | 27.9         |\n",
      "|    value_loss         | 0.00196      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 19100        |\n",
      "|    time_elapsed       | 334          |\n",
      "|    total_timesteps    | 95500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.52        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19099        |\n",
      "|    policy_loss        | 0.0813       |\n",
      "|    reward             | 0.0027511306 |\n",
      "|    std                | 28.4         |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 19200       |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 96000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.56       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19199       |\n",
      "|    policy_loss        | 0.0425      |\n",
      "|    reward             | -0.00901197 |\n",
      "|    std                | 29          |\n",
      "|    value_loss         | 7.51e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 19300         |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 96500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.62         |\n",
      "|    explained_variance | 0.631         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19299         |\n",
      "|    policy_loss        | -0.0978       |\n",
      "|    reward             | -0.0019043792 |\n",
      "|    std                | 29.8          |\n",
      "|    value_loss         | 9.8e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 19400       |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 97000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | -0.173      |\n",
      "|    reward             | 0.002103372 |\n",
      "|    std                | 31.1        |\n",
      "|    value_loss         | 0.000355    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 19500        |\n",
      "|    time_elapsed       | 342          |\n",
      "|    total_timesteps    | 97500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.76        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19499        |\n",
      "|    policy_loss        | 0.0361       |\n",
      "|    reward             | -0.019236896 |\n",
      "|    std                | 32           |\n",
      "|    value_loss         | 2.88e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 19600        |\n",
      "|    time_elapsed       | 343          |\n",
      "|    total_timesteps    | 98000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.8         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19599        |\n",
      "|    policy_loss        | 0.196        |\n",
      "|    reward             | -0.016511854 |\n",
      "|    std                | 32.8         |\n",
      "|    value_loss         | 0.000418     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 19700        |\n",
      "|    time_elapsed       | 345          |\n",
      "|    total_timesteps    | 98500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.85        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19699        |\n",
      "|    policy_loss        | -0.102       |\n",
      "|    reward             | -0.020366995 |\n",
      "|    std                | 33.6         |\n",
      "|    value_loss         | 0.000172     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 19800       |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 99000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | -0.0104     |\n",
      "|    reward             | 0.009214594 |\n",
      "|    std                | 34.6        |\n",
      "|    value_loss         | 2.77e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 19900         |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 99500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19899         |\n",
      "|    policy_loss        | 0.191         |\n",
      "|    reward             | -0.0012134585 |\n",
      "|    std                | 36.1          |\n",
      "|    value_loss         | 0.000567      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 20000        |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 100000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0.184        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19999        |\n",
      "|    policy_loss        | 0.462        |\n",
      "|    reward             | -0.019291544 |\n",
      "|    std                | 37.3         |\n",
      "|    value_loss         | 0.00329      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 20100      |\n",
      "|    time_elapsed       | 352        |\n",
      "|    total_timesteps    | 100500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20099      |\n",
      "|    policy_loss        | 0.315      |\n",
      "|    reward             | 0.07529452 |\n",
      "|    std                | 38.4       |\n",
      "|    value_loss         | 0.00143    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 20200       |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 101000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20199       |\n",
      "|    policy_loss        | 0.193       |\n",
      "|    reward             | 0.024490122 |\n",
      "|    std                | 38.4        |\n",
      "|    value_loss         | 0.00757     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 20300      |\n",
      "|    time_elapsed       | 356        |\n",
      "|    total_timesteps    | 101500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20299      |\n",
      "|    policy_loss        | -3.17      |\n",
      "|    reward             | 0.27738047 |\n",
      "|    std                | 38.8       |\n",
      "|    value_loss         | 0.211      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 20400      |\n",
      "|    time_elapsed       | 357        |\n",
      "|    total_timesteps    | 102000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.2      |\n",
      "|    explained_variance | -0.00136   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20399      |\n",
      "|    policy_loss        | -1.86      |\n",
      "|    reward             | 0.23083572 |\n",
      "|    std                | 39.5       |\n",
      "|    value_loss         | 0.0469     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 20500       |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 102500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | 0.019       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20499       |\n",
      "|    policy_loss        | 9.23        |\n",
      "|    reward             | 0.016462475 |\n",
      "|    std                | 40.2        |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 284          |\n",
      "|    iterations         | 20600        |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 103000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20599        |\n",
      "|    policy_loss        | 1.73         |\n",
      "|    reward             | -0.025093015 |\n",
      "|    std                | 40.4         |\n",
      "|    value_loss         | 0.0281       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 20700       |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 103500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20699       |\n",
      "|    policy_loss        | -0.484      |\n",
      "|    reward             | 0.014898455 |\n",
      "|    std                | 40.7        |\n",
      "|    value_loss         | 0.00246     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 20800        |\n",
      "|    time_elapsed       | 364          |\n",
      "|    total_timesteps    | 104000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20799        |\n",
      "|    policy_loss        | 0.0709       |\n",
      "|    reward             | -0.015439964 |\n",
      "|    std                | 41.1         |\n",
      "|    value_loss         | 0.000206     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 20900        |\n",
      "|    time_elapsed       | 366          |\n",
      "|    total_timesteps    | 104500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0.015        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20899        |\n",
      "|    policy_loss        | -0.669       |\n",
      "|    reward             | -0.007927917 |\n",
      "|    std                | 42           |\n",
      "|    value_loss         | 0.00474      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 21000        |\n",
      "|    time_elapsed       | 368          |\n",
      "|    total_timesteps    | 105000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0.703        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | -0.655       |\n",
      "|    reward             | -0.011084301 |\n",
      "|    std                | 42.6         |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 21100      |\n",
      "|    time_elapsed       | 369        |\n",
      "|    total_timesteps    | 105500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21099      |\n",
      "|    policy_loss        | -0.567     |\n",
      "|    reward             | 0.07667485 |\n",
      "|    std                | 43.7       |\n",
      "|    value_loss         | 0.00346    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 21200      |\n",
      "|    time_elapsed       | 371        |\n",
      "|    total_timesteps    | 106000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21199      |\n",
      "|    policy_loss        | -0.41      |\n",
      "|    reward             | 0.01989607 |\n",
      "|    std                | 44.4       |\n",
      "|    value_loss         | 0.00245    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 21300       |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 106500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21299       |\n",
      "|    policy_loss        | 0.0553      |\n",
      "|    reward             | -0.01747007 |\n",
      "|    std                | 45.2        |\n",
      "|    value_loss         | 2.92e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 21400       |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 107000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21399       |\n",
      "|    policy_loss        | 0.23        |\n",
      "|    reward             | 0.016543208 |\n",
      "|    std                | 46.2        |\n",
      "|    value_loss         | 0.000602    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 285            |\n",
      "|    iterations         | 21500          |\n",
      "|    time_elapsed       | 376            |\n",
      "|    total_timesteps    | 107500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -10.5          |\n",
      "|    explained_variance | -0.127         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 21499          |\n",
      "|    policy_loss        | 0.197          |\n",
      "|    reward             | -0.00069316744 |\n",
      "|    std                | 47             |\n",
      "|    value_loss         | 0.00035        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 21600        |\n",
      "|    time_elapsed       | 378          |\n",
      "|    total_timesteps    | 108000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21599        |\n",
      "|    policy_loss        | 0.0476       |\n",
      "|    reward             | -0.002185891 |\n",
      "|    std                | 48.4         |\n",
      "|    value_loss         | 0.000115     |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12122.68\n",
      "total_reward: -22122.68\n",
      "total_cost: 361.87\n",
      "total_trades: 5414\n",
      "Sharpe: 0.344\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 21700       |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 108500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21699       |\n",
      "|    policy_loss        | -0.0385     |\n",
      "|    reward             | -0.03198386 |\n",
      "|    std                | 49.9        |\n",
      "|    value_loss         | 0.000327    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 21800       |\n",
      "|    time_elapsed       | 381         |\n",
      "|    total_timesteps    | 109000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21799       |\n",
      "|    policy_loss        | 0.0104      |\n",
      "|    reward             | -0.00797893 |\n",
      "|    std                | 51.6        |\n",
      "|    value_loss         | 1.41e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 21900      |\n",
      "|    time_elapsed       | 383        |\n",
      "|    total_timesteps    | 109500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21899      |\n",
      "|    policy_loss        | 0.141      |\n",
      "|    reward             | 0.01679544 |\n",
      "|    std                | 52.8       |\n",
      "|    value_loss         | 0.000204   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 385        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21999      |\n",
      "|    policy_loss        | -0.0795    |\n",
      "|    reward             | 0.02157366 |\n",
      "|    std                | 54.8       |\n",
      "|    value_loss         | 7.14e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 22100         |\n",
      "|    time_elapsed       | 386           |\n",
      "|    total_timesteps    | 110500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.9         |\n",
      "|    explained_variance | -0.11         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22099         |\n",
      "|    policy_loss        | 0.0154        |\n",
      "|    reward             | -0.0011881383 |\n",
      "|    std                | 57.1          |\n",
      "|    value_loss         | 0.00019       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 22200         |\n",
      "|    time_elapsed       | 388           |\n",
      "|    total_timesteps    | 111000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11           |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22199         |\n",
      "|    policy_loss        | 0.0805        |\n",
      "|    reward             | -0.0068915603 |\n",
      "|    std                | 59.7          |\n",
      "|    value_loss         | 0.000232      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 22300       |\n",
      "|    time_elapsed       | 390         |\n",
      "|    total_timesteps    | 111500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22299       |\n",
      "|    policy_loss        | -0.0401     |\n",
      "|    reward             | 0.013027929 |\n",
      "|    std                | 60.9        |\n",
      "|    value_loss         | 0.000656    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 22400       |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 112000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22399       |\n",
      "|    policy_loss        | 0.164       |\n",
      "|    reward             | -0.04930095 |\n",
      "|    std                | 61.3        |\n",
      "|    value_loss         | 0.000846    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 22500      |\n",
      "|    time_elapsed       | 393        |\n",
      "|    total_timesteps    | 112500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | -0.431     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22499      |\n",
      "|    policy_loss        | -1.28      |\n",
      "|    reward             | 0.11095836 |\n",
      "|    std                | 62.3       |\n",
      "|    value_loss         | 0.0145     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 22600       |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 113000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0.0532      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22599       |\n",
      "|    policy_loss        | 1.3         |\n",
      "|    reward             | -0.09604598 |\n",
      "|    std                | 63.4        |\n",
      "|    value_loss         | 0.0151      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 22700       |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 113500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22699       |\n",
      "|    policy_loss        | -0.372      |\n",
      "|    reward             | -0.13745148 |\n",
      "|    std                | 64.1        |\n",
      "|    value_loss         | 0.00306     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 22800       |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 114000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22799       |\n",
      "|    policy_loss        | 0.0994      |\n",
      "|    reward             | 0.021497404 |\n",
      "|    std                | 63.8        |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 22900        |\n",
      "|    time_elapsed       | 400          |\n",
      "|    total_timesteps    | 114500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22899        |\n",
      "|    policy_loss        | -0.0708      |\n",
      "|    reward             | -0.010940598 |\n",
      "|    std                | 65.2         |\n",
      "|    value_loss         | 5.77e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23000        |\n",
      "|    time_elapsed       | 402          |\n",
      "|    total_timesteps    | 115000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22999        |\n",
      "|    policy_loss        | 0.0425       |\n",
      "|    reward             | -0.006967491 |\n",
      "|    std                | 66.9         |\n",
      "|    value_loss         | 6.7e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23100        |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 115500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23099        |\n",
      "|    policy_loss        | -0.0518      |\n",
      "|    reward             | 0.0031320672 |\n",
      "|    std                | 69           |\n",
      "|    value_loss         | 2.53e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23200        |\n",
      "|    time_elapsed       | 405          |\n",
      "|    total_timesteps    | 116000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | -0.0524      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23199        |\n",
      "|    policy_loss        | 0.259        |\n",
      "|    reward             | -0.011581756 |\n",
      "|    std                | 71.5         |\n",
      "|    value_loss         | 0.000532     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 23300       |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 116500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23299       |\n",
      "|    policy_loss        | -0.734      |\n",
      "|    reward             | 0.024904206 |\n",
      "|    std                | 74.2        |\n",
      "|    value_loss         | 0.00526     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23400        |\n",
      "|    time_elapsed       | 409          |\n",
      "|    total_timesteps    | 117000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23399        |\n",
      "|    policy_loss        | -0.331       |\n",
      "|    reward             | 0.0024727702 |\n",
      "|    std                | 76           |\n",
      "|    value_loss         | 0.00151      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23500        |\n",
      "|    time_elapsed       | 411          |\n",
      "|    total_timesteps    | 117500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23499        |\n",
      "|    policy_loss        | -0.0934      |\n",
      "|    reward             | 0.0028412715 |\n",
      "|    std                | 78           |\n",
      "|    value_loss         | 6.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23600        |\n",
      "|    time_elapsed       | 413          |\n",
      "|    total_timesteps    | 118000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 1.37e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23599        |\n",
      "|    policy_loss        | -0.0847      |\n",
      "|    reward             | -0.003695433 |\n",
      "|    std                | 79.7         |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23700        |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 118500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | -5.05        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23699        |\n",
      "|    policy_loss        | -0.0392      |\n",
      "|    reward             | -0.010215087 |\n",
      "|    std                | 82.8         |\n",
      "|    value_loss         | 0.000161     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 23800        |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 119000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23799        |\n",
      "|    policy_loss        | -0.226       |\n",
      "|    reward             | 0.0046624844 |\n",
      "|    std                | 86.5         |\n",
      "|    value_loss         | 0.000572     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 23900      |\n",
      "|    time_elapsed       | 418        |\n",
      "|    total_timesteps    | 119500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.8      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23899      |\n",
      "|    policy_loss        | 1.04       |\n",
      "|    reward             | 0.01909878 |\n",
      "|    std                | 88.4       |\n",
      "|    value_loss         | 0.0123     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 24000       |\n",
      "|    time_elapsed       | 419         |\n",
      "|    total_timesteps    | 120000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23999       |\n",
      "|    policy_loss        | -0.0516     |\n",
      "|    reward             | 0.010316227 |\n",
      "|    std                | 90.9        |\n",
      "|    value_loss         | 6.77e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 24100        |\n",
      "|    time_elapsed       | 421          |\n",
      "|    total_timesteps    | 120500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0.000125     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24099        |\n",
      "|    policy_loss        | -0.0265      |\n",
      "|    reward             | -0.017873136 |\n",
      "|    std                | 93.2         |\n",
      "|    value_loss         | 5.74e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 24200       |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 121000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24199       |\n",
      "|    policy_loss        | 0.167       |\n",
      "|    reward             | 0.003014434 |\n",
      "|    std                | 96.8        |\n",
      "|    value_loss         | 0.000212    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 24300       |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 121500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | -0.336      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24299       |\n",
      "|    policy_loss        | -0.136      |\n",
      "|    reward             | 0.014399944 |\n",
      "|    std                | 102         |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11209.15\n",
      "total_reward: -21209.15\n",
      "total_cost: 403.38\n",
      "total_trades: 5414\n",
      "Sharpe: -0.275\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 24400       |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 122000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24399       |\n",
      "|    policy_loss        | 0.0148      |\n",
      "|    reward             | 0.011238547 |\n",
      "|    std                | 106         |\n",
      "|    value_loss         | 0.000572    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 24500         |\n",
      "|    time_elapsed       | 428           |\n",
      "|    total_timesteps    | 122500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24499         |\n",
      "|    policy_loss        | 0.36          |\n",
      "|    reward             | -3.521973e-05 |\n",
      "|    std                | 107           |\n",
      "|    value_loss         | 0.00118       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 24600     |\n",
      "|    time_elapsed       | 430       |\n",
      "|    total_timesteps    | 123000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 24599     |\n",
      "|    policy_loss        | 2.04      |\n",
      "|    reward             | 0.5343635 |\n",
      "|    std                | 108       |\n",
      "|    value_loss         | 0.0352    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 24700       |\n",
      "|    time_elapsed       | 432         |\n",
      "|    total_timesteps    | 123500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.0676      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | -1.06       |\n",
      "|    reward             | -0.21071269 |\n",
      "|    std                | 108         |\n",
      "|    value_loss         | 0.0142      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 24800      |\n",
      "|    time_elapsed       | 433        |\n",
      "|    total_timesteps    | 124000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24799      |\n",
      "|    policy_loss        | -4.49      |\n",
      "|    reward             | -0.1475615 |\n",
      "|    std                | 108        |\n",
      "|    value_loss         | 0.185      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 24900       |\n",
      "|    time_elapsed       | 435         |\n",
      "|    total_timesteps    | 124500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.0452      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24899       |\n",
      "|    policy_loss        | 3.63        |\n",
      "|    reward             | -0.24626666 |\n",
      "|    std                | 108         |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | 1.44         |\n",
      "|    reward             | -0.021697972 |\n",
      "|    std                | 109          |\n",
      "|    value_loss         | 0.0144       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 25100         |\n",
      "|    time_elapsed       | 439           |\n",
      "|    total_timesteps    | 125500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 25099         |\n",
      "|    policy_loss        | -0.544        |\n",
      "|    reward             | -0.0040997835 |\n",
      "|    std                | 109           |\n",
      "|    value_loss         | 0.00177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 25200         |\n",
      "|    time_elapsed       | 440           |\n",
      "|    total_timesteps    | 126000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.2         |\n",
      "|    explained_variance | 0.612         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 25199         |\n",
      "|    policy_loss        | -0.835        |\n",
      "|    reward             | -0.0031925114 |\n",
      "|    std                | 110           |\n",
      "|    value_loss         | 0.00453       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 25300       |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 126500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | 0.482       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25299       |\n",
      "|    policy_loss        | -0.313      |\n",
      "|    reward             | 0.041190736 |\n",
      "|    std                | 112         |\n",
      "|    value_loss         | 0.000809    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 25400        |\n",
      "|    time_elapsed       | 443          |\n",
      "|    total_timesteps    | 127000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | -0.0133      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25399        |\n",
      "|    policy_loss        | -0.066       |\n",
      "|    reward             | -0.013925167 |\n",
      "|    std                | 114          |\n",
      "|    value_loss         | 0.000831     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 25500        |\n",
      "|    time_elapsed       | 445          |\n",
      "|    total_timesteps    | 127500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25499        |\n",
      "|    policy_loss        | -0.596       |\n",
      "|    reward             | -0.003647464 |\n",
      "|    std                | 115          |\n",
      "|    value_loss         | 0.00231      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 25600       |\n",
      "|    time_elapsed       | 447         |\n",
      "|    total_timesteps    | 128000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25599       |\n",
      "|    policy_loss        | 0.0706      |\n",
      "|    reward             | 0.021082606 |\n",
      "|    std                | 118         |\n",
      "|    value_loss         | 9.56e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 286            |\n",
      "|    iterations         | 25700          |\n",
      "|    time_elapsed       | 449            |\n",
      "|    total_timesteps    | 128500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -12.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 25699          |\n",
      "|    policy_loss        | -0.0958        |\n",
      "|    reward             | -3.6241287e-05 |\n",
      "|    std                | 121            |\n",
      "|    value_loss         | 0.000111       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 25800        |\n",
      "|    time_elapsed       | 451          |\n",
      "|    total_timesteps    | 129000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.4        |\n",
      "|    explained_variance | -0.689       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25799        |\n",
      "|    policy_loss        | -0.0289      |\n",
      "|    reward             | 0.0001443965 |\n",
      "|    std                | 123          |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 25900        |\n",
      "|    time_elapsed       | 453          |\n",
      "|    total_timesteps    | 129500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -4.82        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25899        |\n",
      "|    policy_loss        | -0.0467      |\n",
      "|    reward             | 0.0018558557 |\n",
      "|    std                | 127          |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 26000        |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 130000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25999        |\n",
      "|    policy_loss        | -0.185       |\n",
      "|    reward             | -0.007357494 |\n",
      "|    std                | 131          |\n",
      "|    value_loss         | 0.000548     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 26100        |\n",
      "|    time_elapsed       | 456          |\n",
      "|    total_timesteps    | 130500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26099        |\n",
      "|    policy_loss        | 0.2          |\n",
      "|    reward             | 0.0052017584 |\n",
      "|    std                | 135          |\n",
      "|    value_loss         | 0.000437     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 26200         |\n",
      "|    time_elapsed       | 458           |\n",
      "|    total_timesteps    | 131000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 26199         |\n",
      "|    policy_loss        | 0.358         |\n",
      "|    reward             | -0.0036805356 |\n",
      "|    std                | 139           |\n",
      "|    value_loss         | 0.00109       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 26300        |\n",
      "|    time_elapsed       | 460          |\n",
      "|    total_timesteps    | 131500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26299        |\n",
      "|    policy_loss        | 0.0295       |\n",
      "|    reward             | 0.0018275686 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 2.53e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 26400         |\n",
      "|    time_elapsed       | 462           |\n",
      "|    total_timesteps    | 132000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 26399         |\n",
      "|    policy_loss        | 0.188         |\n",
      "|    reward             | -0.0003733185 |\n",
      "|    std                | 151           |\n",
      "|    value_loss         | 0.000281      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 26500       |\n",
      "|    time_elapsed       | 464         |\n",
      "|    total_timesteps    | 132500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26499       |\n",
      "|    policy_loss        | -0.773      |\n",
      "|    reward             | 0.010624088 |\n",
      "|    std                | 158         |\n",
      "|    value_loss         | 0.00398     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 26600        |\n",
      "|    time_elapsed       | 465          |\n",
      "|    total_timesteps    | 133000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26599        |\n",
      "|    policy_loss        | -0.097       |\n",
      "|    reward             | -0.023391452 |\n",
      "|    std                | 163          |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | 0.176        |\n",
      "|    reward             | -0.008906071 |\n",
      "|    std                | 166          |\n",
      "|    value_loss         | 0.000223     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 26800       |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 134000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26799       |\n",
      "|    policy_loss        | 0.193       |\n",
      "|    reward             | 0.010294894 |\n",
      "|    std                | 172         |\n",
      "|    value_loss         | 0.000276    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 26900         |\n",
      "|    time_elapsed       | 470           |\n",
      "|    total_timesteps    | 134500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 26899         |\n",
      "|    policy_loss        | 0.0366        |\n",
      "|    reward             | -0.0034849658 |\n",
      "|    std                | 178           |\n",
      "|    value_loss         | 1.09e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 27000        |\n",
      "|    time_elapsed       | 472          |\n",
      "|    total_timesteps    | 135000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0.876        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26999        |\n",
      "|    policy_loss        | 0.139        |\n",
      "|    reward             | -0.024614455 |\n",
      "|    std                | 185          |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -9913.35\n",
      "total_reward: -19913.35\n",
      "total_cost: 522.74\n",
      "total_trades: 5414\n",
      "Sharpe: 0.170\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 27100       |\n",
      "|    time_elapsed       | 474         |\n",
      "|    total_timesteps    | 135500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27099       |\n",
      "|    policy_loss        | -0.822      |\n",
      "|    reward             | 0.038073268 |\n",
      "|    std                | 192         |\n",
      "|    value_loss         | 0.00988     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 27200      |\n",
      "|    time_elapsed       | 476        |\n",
      "|    total_timesteps    | 136000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27199      |\n",
      "|    policy_loss        | -0.565     |\n",
      "|    reward             | 0.11288732 |\n",
      "|    std                | 194        |\n",
      "|    value_loss         | 0.00371    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 27300      |\n",
      "|    time_elapsed       | 478        |\n",
      "|    total_timesteps    | 136500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27299      |\n",
      "|    policy_loss        | 0.37       |\n",
      "|    reward             | -0.0387224 |\n",
      "|    std                | 199        |\n",
      "|    value_loss         | 0.000913   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 27400        |\n",
      "|    time_elapsed       | 479          |\n",
      "|    total_timesteps    | 137000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -0.195       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27399        |\n",
      "|    policy_loss        | 0.246        |\n",
      "|    reward             | -0.019830827 |\n",
      "|    std                | 202          |\n",
      "|    value_loss         | 0.000375     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 27500        |\n",
      "|    time_elapsed       | 481          |\n",
      "|    total_timesteps    | 137500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -0.0293      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27499        |\n",
      "|    policy_loss        | -0.357       |\n",
      "|    reward             | -0.018199028 |\n",
      "|    std                | 206          |\n",
      "|    value_loss         | 0.00362      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 27600        |\n",
      "|    time_elapsed       | 483          |\n",
      "|    total_timesteps    | 138000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0.225        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27599        |\n",
      "|    policy_loss        | 0.0569       |\n",
      "|    reward             | 0.0074289786 |\n",
      "|    std                | 210          |\n",
      "|    value_loss         | 0.00063      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 27700      |\n",
      "|    time_elapsed       | 484        |\n",
      "|    total_timesteps    | 138500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27699      |\n",
      "|    policy_loss        | -0.629     |\n",
      "|    reward             | 0.12236699 |\n",
      "|    std                | 212        |\n",
      "|    value_loss         | 0.00333    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 27800     |\n",
      "|    time_elapsed       | 486       |\n",
      "|    total_timesteps    | 139000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 27799     |\n",
      "|    policy_loss        | 1.34      |\n",
      "|    reward             | -0.064355 |\n",
      "|    std                | 214       |\n",
      "|    value_loss         | 0.0105    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 27900       |\n",
      "|    time_elapsed       | 487         |\n",
      "|    total_timesteps    | 139500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27899       |\n",
      "|    policy_loss        | 0.84        |\n",
      "|    reward             | -0.04407535 |\n",
      "|    std                | 215         |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 28000       |\n",
      "|    time_elapsed       | 489         |\n",
      "|    total_timesteps    | 140000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0.0885      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27999       |\n",
      "|    policy_loss        | -1.97       |\n",
      "|    reward             | -0.09677617 |\n",
      "|    std                | 215         |\n",
      "|    value_loss         | 0.0352      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 28100      |\n",
      "|    time_elapsed       | 491        |\n",
      "|    total_timesteps    | 140500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28099      |\n",
      "|    policy_loss        | 8.47       |\n",
      "|    reward             | 0.31776053 |\n",
      "|    std                | 216        |\n",
      "|    value_loss         | 0.415      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 28200        |\n",
      "|    time_elapsed       | 492          |\n",
      "|    total_timesteps    | 141000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28199        |\n",
      "|    policy_loss        | 0.161        |\n",
      "|    reward             | -0.011512236 |\n",
      "|    std                | 217          |\n",
      "|    value_loss         | 0.0003       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 28300        |\n",
      "|    time_elapsed       | 494          |\n",
      "|    total_timesteps    | 141500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28299        |\n",
      "|    policy_loss        | -0.186       |\n",
      "|    reward             | -0.012006715 |\n",
      "|    std                | 219          |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 28400        |\n",
      "|    time_elapsed       | 495          |\n",
      "|    total_timesteps    | 142000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28399        |\n",
      "|    policy_loss        | -0.442       |\n",
      "|    reward             | 0.0119792335 |\n",
      "|    std                | 221          |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 28500        |\n",
      "|    time_elapsed       | 497          |\n",
      "|    total_timesteps    | 142500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | -0.334       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28499        |\n",
      "|    policy_loss        | 0.207        |\n",
      "|    reward             | -0.008003242 |\n",
      "|    std                | 227          |\n",
      "|    value_loss         | 0.000278     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 28600      |\n",
      "|    time_elapsed       | 499        |\n",
      "|    total_timesteps    | 143000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | -1.54      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28599      |\n",
      "|    policy_loss        | -0.00889   |\n",
      "|    reward             | -0.0179195 |\n",
      "|    std                | 231        |\n",
      "|    value_loss         | 0.000292   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 28700         |\n",
      "|    time_elapsed       | 501           |\n",
      "|    total_timesteps    | 143500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28699         |\n",
      "|    policy_loss        | 0.00928       |\n",
      "|    reward             | -0.0052589565 |\n",
      "|    std                | 239           |\n",
      "|    value_loss         | 9.01e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 28800        |\n",
      "|    time_elapsed       | 503          |\n",
      "|    total_timesteps    | 144000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28799        |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | 0.0029727165 |\n",
      "|    std                | 246          |\n",
      "|    value_loss         | 0.00015      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 28900         |\n",
      "|    time_elapsed       | 505           |\n",
      "|    total_timesteps    | 144500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28899         |\n",
      "|    policy_loss        | -0.237        |\n",
      "|    reward             | -0.0011291071 |\n",
      "|    std                | 250           |\n",
      "|    value_loss         | 0.000377      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 507         |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28999       |\n",
      "|    policy_loss        | -0.158      |\n",
      "|    reward             | 0.013414546 |\n",
      "|    std                | 260         |\n",
      "|    value_loss         | 0.000362    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 29100       |\n",
      "|    time_elapsed       | 509         |\n",
      "|    total_timesteps    | 145500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -0.505      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29099       |\n",
      "|    policy_loss        | 0.337       |\n",
      "|    reward             | -0.01843999 |\n",
      "|    std                | 271         |\n",
      "|    value_loss         | 0.000617    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 29200        |\n",
      "|    time_elapsed       | 511          |\n",
      "|    total_timesteps    | 146000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0.597        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29199        |\n",
      "|    policy_loss        | 0.264        |\n",
      "|    reward             | 0.0015737592 |\n",
      "|    std                | 284          |\n",
      "|    value_loss         | 0.000352     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 29300       |\n",
      "|    time_elapsed       | 512         |\n",
      "|    total_timesteps    | 146500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29299       |\n",
      "|    policy_loss        | -0.0438     |\n",
      "|    reward             | 0.051578842 |\n",
      "|    std                | 290         |\n",
      "|    value_loss         | 0.00241     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 29400       |\n",
      "|    time_elapsed       | 514         |\n",
      "|    total_timesteps    | 147000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29399       |\n",
      "|    policy_loss        | 1.23        |\n",
      "|    reward             | -0.02068547 |\n",
      "|    std                | 287         |\n",
      "|    value_loss         | 0.00877     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 29500      |\n",
      "|    time_elapsed       | 516        |\n",
      "|    total_timesteps    | 147500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29499      |\n",
      "|    policy_loss        | -0.693     |\n",
      "|    reward             | 0.03216523 |\n",
      "|    std                | 294        |\n",
      "|    value_loss         | 0.00291    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 29600       |\n",
      "|    time_elapsed       | 518         |\n",
      "|    total_timesteps    | 148000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -0.863      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29599       |\n",
      "|    policy_loss        | 2.49        |\n",
      "|    reward             | 0.011938995 |\n",
      "|    std                | 297         |\n",
      "|    value_loss         | 0.0359      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 29700        |\n",
      "|    time_elapsed       | 519          |\n",
      "|    total_timesteps    | 148500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29699        |\n",
      "|    policy_loss        | -3.63        |\n",
      "|    reward             | -0.121330634 |\n",
      "|    std                | 295          |\n",
      "|    value_loss         | 0.0705       |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -249654.96\n",
      "total_reward: -259654.96\n",
      "total_cost: 105.12\n",
      "total_trades: 5414\n",
      "Sharpe: -0.019\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 29800         |\n",
      "|    time_elapsed       | 521           |\n",
      "|    total_timesteps    | 149000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29799         |\n",
      "|    policy_loss        | 0.0802        |\n",
      "|    reward             | -0.0066669206 |\n",
      "|    std                | 291           |\n",
      "|    value_loss         | 0.00153       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 29900        |\n",
      "|    time_elapsed       | 523          |\n",
      "|    total_timesteps    | 149500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29899        |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | 0.0033502919 |\n",
      "|    std                | 292          |\n",
      "|    value_loss         | 0.000495     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 30000        |\n",
      "|    time_elapsed       | 524          |\n",
      "|    total_timesteps    | 150000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29999        |\n",
      "|    policy_loss        | 0.0412       |\n",
      "|    reward             | -0.005746612 |\n",
      "|    std                | 297          |\n",
      "|    value_loss         | 0.000125     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0.687       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30099       |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.011836217 |\n",
      "|    std                | 298         |\n",
      "|    value_loss         | 6.98e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 30200         |\n",
      "|    time_elapsed       | 527           |\n",
      "|    total_timesteps    | 151000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | -0.254        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30199         |\n",
      "|    policy_loss        | 0.261         |\n",
      "|    reward             | -0.0042701187 |\n",
      "|    std                | 307           |\n",
      "|    value_loss         | 0.000515      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 30300        |\n",
      "|    time_elapsed       | 529          |\n",
      "|    total_timesteps    | 151500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30299        |\n",
      "|    policy_loss        | -1.38        |\n",
      "|    reward             | -0.040960405 |\n",
      "|    std                | 313          |\n",
      "|    value_loss         | 0.0111       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 30400       |\n",
      "|    time_elapsed       | 531         |\n",
      "|    total_timesteps    | 152000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30399       |\n",
      "|    policy_loss        | -0.843      |\n",
      "|    reward             | -0.17970406 |\n",
      "|    std                | 314         |\n",
      "|    value_loss         | 0.0161      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 30500       |\n",
      "|    time_elapsed       | 532         |\n",
      "|    total_timesteps    | 152500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30499       |\n",
      "|    policy_loss        | -0.954      |\n",
      "|    reward             | -0.04732843 |\n",
      "|    std                | 319         |\n",
      "|    value_loss         | 0.00509     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 30600      |\n",
      "|    time_elapsed       | 534        |\n",
      "|    total_timesteps    | 153000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30599      |\n",
      "|    policy_loss        | 2.21       |\n",
      "|    reward             | 0.13778903 |\n",
      "|    std                | 321        |\n",
      "|    value_loss         | 0.0294     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 30700      |\n",
      "|    time_elapsed       | 536        |\n",
      "|    total_timesteps    | 153500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30699      |\n",
      "|    policy_loss        | -1.62      |\n",
      "|    reward             | 0.13251215 |\n",
      "|    std                | 323        |\n",
      "|    value_loss         | 0.0632     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 30800      |\n",
      "|    time_elapsed       | 538        |\n",
      "|    total_timesteps    | 154000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30799      |\n",
      "|    policy_loss        | 2.28       |\n",
      "|    reward             | 0.05871084 |\n",
      "|    std                | 323        |\n",
      "|    value_loss         | 0.0306     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 30900        |\n",
      "|    time_elapsed       | 539          |\n",
      "|    total_timesteps    | 154500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30899        |\n",
      "|    policy_loss        | 0.3          |\n",
      "|    reward             | -0.009738036 |\n",
      "|    std                | 323          |\n",
      "|    value_loss         | 0.000481     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 31000       |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 155000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30999       |\n",
      "|    policy_loss        | 0.252       |\n",
      "|    reward             | 0.013182559 |\n",
      "|    std                | 327         |\n",
      "|    value_loss         | 0.000501    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 31100        |\n",
      "|    time_elapsed       | 543          |\n",
      "|    total_timesteps    | 155500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31099        |\n",
      "|    policy_loss        | 0.254        |\n",
      "|    reward             | -0.015602586 |\n",
      "|    std                | 333          |\n",
      "|    value_loss         | 0.000392     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 31200       |\n",
      "|    time_elapsed       | 545         |\n",
      "|    total_timesteps    | 156000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31199       |\n",
      "|    policy_loss        | 0.097       |\n",
      "|    reward             | 0.021484196 |\n",
      "|    std                | 338         |\n",
      "|    value_loss         | 4.63e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 31300        |\n",
      "|    time_elapsed       | 546          |\n",
      "|    total_timesteps    | 156500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31299        |\n",
      "|    policy_loss        | 0.0783       |\n",
      "|    reward             | 0.0066347015 |\n",
      "|    std                | 350          |\n",
      "|    value_loss         | 4.61e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 31400         |\n",
      "|    time_elapsed       | 548           |\n",
      "|    total_timesteps    | 157000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | 0.791         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31399         |\n",
      "|    policy_loss        | 0.169         |\n",
      "|    reward             | -0.0062859403 |\n",
      "|    std                | 360           |\n",
      "|    value_loss         | 0.000165      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 31500       |\n",
      "|    time_elapsed       | 550         |\n",
      "|    total_timesteps    | 157500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31499       |\n",
      "|    policy_loss        | 0.747       |\n",
      "|    reward             | 0.014480311 |\n",
      "|    std                | 371         |\n",
      "|    value_loss         | 0.00356     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 31600         |\n",
      "|    time_elapsed       | 552           |\n",
      "|    total_timesteps    | 158000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31599         |\n",
      "|    policy_loss        | 0.0692        |\n",
      "|    reward             | -0.0077693327 |\n",
      "|    std                | 380           |\n",
      "|    value_loss         | 0.000135      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 31700        |\n",
      "|    time_elapsed       | 553          |\n",
      "|    total_timesteps    | 158500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31699        |\n",
      "|    policy_loss        | -0.328       |\n",
      "|    reward             | 0.0042526457 |\n",
      "|    std                | 390          |\n",
      "|    value_loss         | 0.000801     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 31800        |\n",
      "|    time_elapsed       | 555          |\n",
      "|    total_timesteps    | 159000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0.164        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31799        |\n",
      "|    policy_loss        | -0.0609      |\n",
      "|    reward             | -0.004184677 |\n",
      "|    std                | 405          |\n",
      "|    value_loss         | 6.15e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 31900         |\n",
      "|    time_elapsed       | 557           |\n",
      "|    total_timesteps    | 159500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.9         |\n",
      "|    explained_variance | -0.856        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31899         |\n",
      "|    policy_loss        | -0.138        |\n",
      "|    reward             | -0.0070130867 |\n",
      "|    std                | 423           |\n",
      "|    value_loss         | 0.000144      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 32000       |\n",
      "|    time_elapsed       | 558         |\n",
      "|    total_timesteps    | 160000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31999       |\n",
      "|    policy_loss        | 0.0935      |\n",
      "|    reward             | -0.01498881 |\n",
      "|    std                | 432         |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 32100         |\n",
      "|    time_elapsed       | 560           |\n",
      "|    total_timesteps    | 160500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32099         |\n",
      "|    policy_loss        | -0.0211       |\n",
      "|    reward             | -0.0058807074 |\n",
      "|    std                | 446           |\n",
      "|    value_loss         | 6.72e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 32200        |\n",
      "|    time_elapsed       | 562          |\n",
      "|    total_timesteps    | 161000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32199        |\n",
      "|    policy_loss        | -0.102       |\n",
      "|    reward             | -0.006636448 |\n",
      "|    std                | 461          |\n",
      "|    value_loss         | 8.61e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 32300         |\n",
      "|    time_elapsed       | 564           |\n",
      "|    total_timesteps    | 161500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32299         |\n",
      "|    policy_loss        | -0.0553       |\n",
      "|    reward             | 0.00046511056 |\n",
      "|    std                | 483           |\n",
      "|    value_loss         | 4.25e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 32400       |\n",
      "|    time_elapsed       | 565         |\n",
      "|    total_timesteps    | 162000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32399       |\n",
      "|    policy_loss        | -0.147      |\n",
      "|    reward             | 0.013623441 |\n",
      "|    std                | 500         |\n",
      "|    value_loss         | 0.000132    |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -9206.03\n",
      "total_reward: -19206.03\n",
      "total_cost: 562.49\n",
      "total_trades: 5414\n",
      "Sharpe: -0.218\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 32500       |\n",
      "|    time_elapsed       | 567         |\n",
      "|    total_timesteps    | 162500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32499       |\n",
      "|    policy_loss        | -0.038      |\n",
      "|    reward             | 0.024711486 |\n",
      "|    std                | 521         |\n",
      "|    value_loss         | 4.63e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 32600       |\n",
      "|    time_elapsed       | 569         |\n",
      "|    total_timesteps    | 163000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32599       |\n",
      "|    policy_loss        | -0.0643     |\n",
      "|    reward             | 0.016613921 |\n",
      "|    std                | 537         |\n",
      "|    value_loss         | 9.42e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 32700        |\n",
      "|    time_elapsed       | 570          |\n",
      "|    total_timesteps    | 163500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32699        |\n",
      "|    policy_loss        | 0.268        |\n",
      "|    reward             | -0.010617649 |\n",
      "|    std                | 554          |\n",
      "|    value_loss         | 0.000488     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 32800        |\n",
      "|    time_elapsed       | 572          |\n",
      "|    total_timesteps    | 164000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32799        |\n",
      "|    policy_loss        | 0.0962       |\n",
      "|    reward             | 0.0059017125 |\n",
      "|    std                | 576          |\n",
      "|    value_loss         | 7.89e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 32900        |\n",
      "|    time_elapsed       | 574          |\n",
      "|    total_timesteps    | 164500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | -0.0265      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32899        |\n",
      "|    policy_loss        | -0.051       |\n",
      "|    reward             | 0.0016413842 |\n",
      "|    std                | 600          |\n",
      "|    value_loss         | 0.000125     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 33000        |\n",
      "|    time_elapsed       | 575          |\n",
      "|    total_timesteps    | 165000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.00039      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32999        |\n",
      "|    policy_loss        | -0.962       |\n",
      "|    reward             | -0.042858675 |\n",
      "|    std                | 621          |\n",
      "|    value_loss         | 0.00626      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 33100         |\n",
      "|    time_elapsed       | 577           |\n",
      "|    total_timesteps    | 165500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33099         |\n",
      "|    policy_loss        | 0.144         |\n",
      "|    reward             | -0.0015383291 |\n",
      "|    std                | 642           |\n",
      "|    value_loss         | 0.000248      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 33200       |\n",
      "|    time_elapsed       | 579         |\n",
      "|    total_timesteps    | 166000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33199       |\n",
      "|    policy_loss        | -0.216      |\n",
      "|    reward             | 0.011513171 |\n",
      "|    std                | 666         |\n",
      "|    value_loss         | 0.000238    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 33300         |\n",
      "|    time_elapsed       | 581           |\n",
      "|    total_timesteps    | 166500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33299         |\n",
      "|    policy_loss        | -0.0313       |\n",
      "|    reward             | -0.0073396745 |\n",
      "|    std                | 686           |\n",
      "|    value_loss         | 4.08e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 33400         |\n",
      "|    time_elapsed       | 582           |\n",
      "|    total_timesteps    | 167000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 0.112         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33399         |\n",
      "|    policy_loss        | -0.0794       |\n",
      "|    reward             | -0.0020281293 |\n",
      "|    std                | 713           |\n",
      "|    value_loss         | 0.000127      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 33500        |\n",
      "|    time_elapsed       | 584          |\n",
      "|    total_timesteps    | 167500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | -5.55        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33499        |\n",
      "|    policy_loss        | 0.176        |\n",
      "|    reward             | -0.011110717 |\n",
      "|    std                | 740          |\n",
      "|    value_loss         | 0.00018      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 33600       |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 168000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33599       |\n",
      "|    policy_loss        | 0.146       |\n",
      "|    reward             | 0.008282351 |\n",
      "|    std                | 769         |\n",
      "|    value_loss         | 0.000233    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 33700         |\n",
      "|    time_elapsed       | 588           |\n",
      "|    total_timesteps    | 168500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33699         |\n",
      "|    policy_loss        | 0.0968        |\n",
      "|    reward             | -0.0036464175 |\n",
      "|    std                | 785           |\n",
      "|    value_loss         | 8.8e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 33800         |\n",
      "|    time_elapsed       | 589           |\n",
      "|    total_timesteps    | 169000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33799         |\n",
      "|    policy_loss        | -0.0573       |\n",
      "|    reward             | -0.0018894768 |\n",
      "|    std                | 812           |\n",
      "|    value_loss         | 1.96e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 33900        |\n",
      "|    time_elapsed       | 591          |\n",
      "|    total_timesteps    | 169500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33899        |\n",
      "|    policy_loss        | -0.0314      |\n",
      "|    reward             | -0.007602304 |\n",
      "|    std                | 841          |\n",
      "|    value_loss         | 2.76e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 34000       |\n",
      "|    time_elapsed       | 593         |\n",
      "|    total_timesteps    | 170000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | -0.534      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33999       |\n",
      "|    policy_loss        | 0.119       |\n",
      "|    reward             | 0.007825105 |\n",
      "|    std                | 863         |\n",
      "|    value_loss         | 9.63e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 34100         |\n",
      "|    time_elapsed       | 595           |\n",
      "|    total_timesteps    | 170500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34099         |\n",
      "|    policy_loss        | 0.0945        |\n",
      "|    reward             | -0.0030150956 |\n",
      "|    std                | 902           |\n",
      "|    value_loss         | 0.000126      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 34200      |\n",
      "|    time_elapsed       | 597        |\n",
      "|    total_timesteps    | 171000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34199      |\n",
      "|    policy_loss        | -1.78      |\n",
      "|    reward             | 0.09352531 |\n",
      "|    std                | 929        |\n",
      "|    value_loss         | 0.0156     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 34300      |\n",
      "|    time_elapsed       | 598        |\n",
      "|    total_timesteps    | 171500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34299      |\n",
      "|    policy_loss        | -0.4       |\n",
      "|    reward             | 0.01841157 |\n",
      "|    std                | 941        |\n",
      "|    value_loss         | 0.00244    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 34400      |\n",
      "|    time_elapsed       | 600        |\n",
      "|    total_timesteps    | 172000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0.00678    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34399      |\n",
      "|    policy_loss        | 1.85       |\n",
      "|    reward             | 0.03356152 |\n",
      "|    std                | 941        |\n",
      "|    value_loss         | 0.0256     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 34500      |\n",
      "|    time_elapsed       | 601        |\n",
      "|    total_timesteps    | 172500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0.269      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34499      |\n",
      "|    policy_loss        | 0.486      |\n",
      "|    reward             | -0.1967381 |\n",
      "|    std                | 947        |\n",
      "|    value_loss         | 0.00388    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 34600      |\n",
      "|    time_elapsed       | 603        |\n",
      "|    total_timesteps    | 173000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0.796      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34599      |\n",
      "|    policy_loss        | 1.78       |\n",
      "|    reward             | 0.30407494 |\n",
      "|    std                | 945        |\n",
      "|    value_loss         | 0.0145     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 34700       |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 173500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34699       |\n",
      "|    policy_loss        | -0.31       |\n",
      "|    reward             | -0.01780631 |\n",
      "|    std                | 954         |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 34800      |\n",
      "|    time_elapsed       | 607        |\n",
      "|    total_timesteps    | 174000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34799      |\n",
      "|    policy_loss        | 0.687      |\n",
      "|    reward             | 0.00649259 |\n",
      "|    std                | 968        |\n",
      "|    value_loss         | 0.00311    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 34900        |\n",
      "|    time_elapsed       | 609          |\n",
      "|    total_timesteps    | 174500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34899        |\n",
      "|    policy_loss        | 0.712        |\n",
      "|    reward             | -0.044837356 |\n",
      "|    std                | 967          |\n",
      "|    value_loss         | 0.00317      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 35000        |\n",
      "|    time_elapsed       | 611          |\n",
      "|    total_timesteps    | 175000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0.376        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34999        |\n",
      "|    policy_loss        | 0.351        |\n",
      "|    reward             | -0.014621478 |\n",
      "|    std                | 982          |\n",
      "|    value_loss         | 0.00211      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 35100       |\n",
      "|    time_elapsed       | 613         |\n",
      "|    total_timesteps    | 175500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0.434       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | -0.712      |\n",
      "|    reward             | -0.11153355 |\n",
      "|    std                | 999         |\n",
      "|    value_loss         | 0.00249     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 35200       |\n",
      "|    time_elapsed       | 615         |\n",
      "|    total_timesteps    | 176000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35199       |\n",
      "|    policy_loss        | -1.27       |\n",
      "|    reward             | 0.053241685 |\n",
      "|    std                | 1e+03       |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -60539.97\n",
      "total_reward: -70539.97\n",
      "total_cost: 97.80\n",
      "total_trades: 5414\n",
      "Sharpe: 0.405\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 35300      |\n",
      "|    time_elapsed       | 617        |\n",
      "|    total_timesteps    | 176500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35299      |\n",
      "|    policy_loss        | -0.0377    |\n",
      "|    reward             | -0.0541169 |\n",
      "|    std                | 1e+03      |\n",
      "|    value_loss         | 0.00106    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 35400        |\n",
      "|    time_elapsed       | 618          |\n",
      "|    total_timesteps    | 177000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35399        |\n",
      "|    policy_loss        | 0.475        |\n",
      "|    reward             | -0.063797824 |\n",
      "|    std                | 1.01e+03     |\n",
      "|    value_loss         | 0.00506      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 35500      |\n",
      "|    time_elapsed       | 620        |\n",
      "|    total_timesteps    | 177500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 0.184      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35499      |\n",
      "|    policy_loss        | 5.67       |\n",
      "|    reward             | 0.16778144 |\n",
      "|    std                | 1.01e+03   |\n",
      "|    value_loss         | 0.186      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 35600      |\n",
      "|    time_elapsed       | 622        |\n",
      "|    total_timesteps    | 178000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35599      |\n",
      "|    policy_loss        | 11.1       |\n",
      "|    reward             | -0.4258214 |\n",
      "|    std                | 1.01e+03   |\n",
      "|    value_loss         | 0.529      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 35700      |\n",
      "|    time_elapsed       | 623        |\n",
      "|    total_timesteps    | 178500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35699      |\n",
      "|    policy_loss        | 9.5        |\n",
      "|    reward             | 0.24046618 |\n",
      "|    std                | 1.02e+03   |\n",
      "|    value_loss         | 0.409      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 35800         |\n",
      "|    time_elapsed       | 626           |\n",
      "|    total_timesteps    | 179000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 35799         |\n",
      "|    policy_loss        | -1.8          |\n",
      "|    reward             | -0.0029877329 |\n",
      "|    std                | 1.03e+03      |\n",
      "|    value_loss         | 0.0146        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 35900       |\n",
      "|    time_elapsed       | 628         |\n",
      "|    total_timesteps    | 179500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35899       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | 0.065875605 |\n",
      "|    std                | 1.05e+03    |\n",
      "|    value_loss         | 0.0147      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 36000       |\n",
      "|    time_elapsed       | 630         |\n",
      "|    total_timesteps    | 180000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | -3.54       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35999       |\n",
      "|    policy_loss        | -0.71       |\n",
      "|    reward             | -0.02082148 |\n",
      "|    std                | 1.06e+03    |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 36100        |\n",
      "|    time_elapsed       | 631          |\n",
      "|    total_timesteps    | 180500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0.0171       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36099        |\n",
      "|    policy_loss        | 0.263        |\n",
      "|    reward             | -0.046285294 |\n",
      "|    std                | 1.08e+03     |\n",
      "|    value_loss         | 0.0004       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 36200        |\n",
      "|    time_elapsed       | 633          |\n",
      "|    total_timesteps    | 181000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0.268        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36199        |\n",
      "|    policy_loss        | 0.334        |\n",
      "|    reward             | 0.0075929905 |\n",
      "|    std                | 1.1e+03      |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 285           |\n",
      "|    iterations         | 36300         |\n",
      "|    time_elapsed       | 635           |\n",
      "|    total_timesteps    | 181500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 36299         |\n",
      "|    policy_loss        | 2.25          |\n",
      "|    reward             | -0.0018298422 |\n",
      "|    std                | 1.12e+03      |\n",
      "|    value_loss         | 0.0247        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 36400        |\n",
      "|    time_elapsed       | 637          |\n",
      "|    total_timesteps    | 182000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36399        |\n",
      "|    policy_loss        | -0.989       |\n",
      "|    reward             | -0.016265582 |\n",
      "|    std                | 1.14e+03     |\n",
      "|    value_loss         | 0.00438      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 36500       |\n",
      "|    time_elapsed       | 639         |\n",
      "|    total_timesteps    | 182500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36499       |\n",
      "|    policy_loss        | 0.146       |\n",
      "|    reward             | 0.035532385 |\n",
      "|    std                | 1.16e+03    |\n",
      "|    value_loss         | 0.00109     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 36600       |\n",
      "|    time_elapsed       | 640         |\n",
      "|    total_timesteps    | 183000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | -0.157      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36599       |\n",
      "|    policy_loss        | 2.81        |\n",
      "|    reward             | 0.117854856 |\n",
      "|    std                | 1.19e+03    |\n",
      "|    value_loss         | 0.0282      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 36700       |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 183500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36699       |\n",
      "|    policy_loss        | -6.27       |\n",
      "|    reward             | -0.09983114 |\n",
      "|    std                | 1.2e+03     |\n",
      "|    value_loss         | 0.168       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 36800      |\n",
      "|    time_elapsed       | 644        |\n",
      "|    total_timesteps    | 184000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 36799      |\n",
      "|    policy_loss        | -9.27      |\n",
      "|    reward             | 0.11758416 |\n",
      "|    std                | 1.2e+03    |\n",
      "|    value_loss         | 0.334      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 36900       |\n",
      "|    time_elapsed       | 646         |\n",
      "|    total_timesteps    | 184500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36899       |\n",
      "|    policy_loss        | 4.65        |\n",
      "|    reward             | -0.13508461 |\n",
      "|    std                | 1.21e+03    |\n",
      "|    value_loss         | 0.102       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 285          |\n",
      "|    iterations         | 37000        |\n",
      "|    time_elapsed       | 648          |\n",
      "|    total_timesteps    | 185000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36999        |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | -0.045150492 |\n",
      "|    std                | 1.23e+03     |\n",
      "|    value_loss         | 0.00581      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 37100      |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 185500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37099      |\n",
      "|    policy_loss        | 0.726      |\n",
      "|    reward             | 0.29743576 |\n",
      "|    std                | 1.22e+03   |\n",
      "|    value_loss         | 0.00742    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 37200       |\n",
      "|    time_elapsed       | 651         |\n",
      "|    total_timesteps    | 186000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37199       |\n",
      "|    policy_loss        | 0.205       |\n",
      "|    reward             | -0.11901232 |\n",
      "|    std                | 1.21e+03    |\n",
      "|    value_loss         | 0.00672     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 37300       |\n",
      "|    time_elapsed       | 653         |\n",
      "|    total_timesteps    | 186500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0.179       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37299       |\n",
      "|    policy_loss        | 18.4        |\n",
      "|    reward             | 0.024078935 |\n",
      "|    std                | 1.21e+03    |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 37400      |\n",
      "|    time_elapsed       | 654        |\n",
      "|    total_timesteps    | 187000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37399      |\n",
      "|    policy_loss        | -0.415     |\n",
      "|    reward             | 0.07408941 |\n",
      "|    std                | 1.22e+03   |\n",
      "|    value_loss         | 0.00154    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 37500       |\n",
      "|    time_elapsed       | 656         |\n",
      "|    total_timesteps    | 187500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37499       |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | 0.031986345 |\n",
      "|    std                | 1.23e+03    |\n",
      "|    value_loss         | 0.00528     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 37600      |\n",
      "|    time_elapsed       | 658        |\n",
      "|    total_timesteps    | 188000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37599      |\n",
      "|    policy_loss        | 2.91       |\n",
      "|    reward             | 0.08770455 |\n",
      "|    std                | 1.24e+03   |\n",
      "|    value_loss         | 0.131      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 37700      |\n",
      "|    time_elapsed       | 659        |\n",
      "|    total_timesteps    | 188500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.1      |\n",
      "|    explained_variance | -0.00218   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37699      |\n",
      "|    policy_loss        | -4.9       |\n",
      "|    reward             | 0.05191797 |\n",
      "|    std                | 1.24e+03   |\n",
      "|    value_loss         | 0.0925     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 37800      |\n",
      "|    time_elapsed       | 661        |\n",
      "|    total_timesteps    | 189000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37799      |\n",
      "|    policy_loss        | 0.483      |\n",
      "|    reward             | 0.15321405 |\n",
      "|    std                | 1.25e+03   |\n",
      "|    value_loss         | 0.00375    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 37900       |\n",
      "|    time_elapsed       | 662         |\n",
      "|    total_timesteps    | 189500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37899       |\n",
      "|    policy_loss        | -5.22       |\n",
      "|    reward             | -0.16169569 |\n",
      "|    std                | 1.25e+03    |\n",
      "|    value_loss         | 0.185       |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -233991.30\n",
      "total_reward: -243991.30\n",
      "total_cost: 107.82\n",
      "total_trades: 5414\n",
      "Sharpe: 0.546\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 38000       |\n",
      "|    time_elapsed       | 664         |\n",
      "|    total_timesteps    | 190000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37999       |\n",
      "|    policy_loss        | -0.461      |\n",
      "|    reward             | 0.026144363 |\n",
      "|    std                | 1.25e+03    |\n",
      "|    value_loss         | 0.000804    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 38100         |\n",
      "|    time_elapsed       | 665           |\n",
      "|    total_timesteps    | 190500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38099         |\n",
      "|    policy_loss        | -1.01         |\n",
      "|    reward             | -0.0028408496 |\n",
      "|    std                | 1.27e+03      |\n",
      "|    value_loss         | 0.00377       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 38200       |\n",
      "|    time_elapsed       | 667         |\n",
      "|    total_timesteps    | 191000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38199       |\n",
      "|    policy_loss        | 0.367       |\n",
      "|    reward             | 0.006082534 |\n",
      "|    std                | 1.29e+03    |\n",
      "|    value_loss         | 0.000434    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 286           |\n",
      "|    iterations         | 38300         |\n",
      "|    time_elapsed       | 668           |\n",
      "|    total_timesteps    | 191500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.2         |\n",
      "|    explained_variance | -0.0981       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38299         |\n",
      "|    policy_loss        | 0.31          |\n",
      "|    reward             | -0.0021691688 |\n",
      "|    std                | 1.32e+03      |\n",
      "|    value_loss         | 0.000603      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 38400        |\n",
      "|    time_elapsed       | 670          |\n",
      "|    total_timesteps    | 192000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | -0.533       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38399        |\n",
      "|    policy_loss        | -0.105       |\n",
      "|    reward             | -0.006562023 |\n",
      "|    std                | 1.35e+03     |\n",
      "|    value_loss         | 9.83e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 38500       |\n",
      "|    time_elapsed       | 671         |\n",
      "|    total_timesteps    | 192500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38499       |\n",
      "|    policy_loss        | -0.0361     |\n",
      "|    reward             | -0.07150921 |\n",
      "|    std                | 1.38e+03    |\n",
      "|    value_loss         | 0.0166      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 38600        |\n",
      "|    time_elapsed       | 673          |\n",
      "|    total_timesteps    | 193000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38599        |\n",
      "|    policy_loss        | 1.97         |\n",
      "|    reward             | -0.033280466 |\n",
      "|    std                | 1.4e+03      |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 286         |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 674         |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | -2.74       |\n",
      "|    reward             | -0.01922296 |\n",
      "|    std                | 1.42e+03    |\n",
      "|    value_loss         | 0.0421      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 286          |\n",
      "|    iterations         | 38800        |\n",
      "|    time_elapsed       | 676          |\n",
      "|    total_timesteps    | 194000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38799        |\n",
      "|    policy_loss        | 0.821        |\n",
      "|    reward             | -0.087162174 |\n",
      "|    std                | 1.43e+03     |\n",
      "|    value_loss         | 0.00361      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 38900       |\n",
      "|    time_elapsed       | 677         |\n",
      "|    total_timesteps    | 194500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38899       |\n",
      "|    policy_loss        | -4.67       |\n",
      "|    reward             | -0.09179069 |\n",
      "|    std                | 1.46e+03    |\n",
      "|    value_loss         | 0.0805      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 39000      |\n",
      "|    time_elapsed       | 678        |\n",
      "|    total_timesteps    | 195000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 38999      |\n",
      "|    policy_loss        | 0.566      |\n",
      "|    reward             | 0.03804411 |\n",
      "|    std                | 1.45e+03   |\n",
      "|    value_loss         | 0.00232    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 39100       |\n",
      "|    time_elapsed       | 680         |\n",
      "|    total_timesteps    | 195500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39099       |\n",
      "|    policy_loss        | 2.34        |\n",
      "|    reward             | 0.007997651 |\n",
      "|    std                | 1.47e+03    |\n",
      "|    value_loss         | 0.0219      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 39200     |\n",
      "|    time_elapsed       | 681       |\n",
      "|    total_timesteps    | 196000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -17.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 39199     |\n",
      "|    policy_loss        | -0.945    |\n",
      "|    reward             | 0.0370778 |\n",
      "|    std                | 1.49e+03  |\n",
      "|    value_loss         | 0.00333   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 39300       |\n",
      "|    time_elapsed       | 683         |\n",
      "|    total_timesteps    | 196500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | -0.0103     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39299       |\n",
      "|    policy_loss        | -0.423      |\n",
      "|    reward             | 0.016254492 |\n",
      "|    std                | 1.51e+03    |\n",
      "|    value_loss         | 0.000954    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 39400       |\n",
      "|    time_elapsed       | 684         |\n",
      "|    total_timesteps    | 197000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | -0.0368     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39399       |\n",
      "|    policy_loss        | -1.21       |\n",
      "|    reward             | -0.02992723 |\n",
      "|    std                | 1.54e+03    |\n",
      "|    value_loss         | 0.00706     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 287          |\n",
      "|    iterations         | 39500        |\n",
      "|    time_elapsed       | 686          |\n",
      "|    total_timesteps    | 197500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | -4.77e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39499        |\n",
      "|    policy_loss        | 0.321        |\n",
      "|    reward             | -0.047101073 |\n",
      "|    std                | 1.57e+03     |\n",
      "|    value_loss         | 0.00818      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 287         |\n",
      "|    iterations         | 39600       |\n",
      "|    time_elapsed       | 687         |\n",
      "|    total_timesteps    | 198000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39599       |\n",
      "|    policy_loss        | -0.813      |\n",
      "|    reward             | -0.03505569 |\n",
      "|    std                | 1.59e+03    |\n",
      "|    value_loss         | 0.00646     |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 288             |\n",
      "|    iterations         | 39700           |\n",
      "|    time_elapsed       | 689             |\n",
      "|    total_timesteps    | 198500          |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -17.6           |\n",
      "|    explained_variance | 0               |\n",
      "|    learning_rate      | 0.001           |\n",
      "|    n_updates          | 39699           |\n",
      "|    policy_loss        | 0.531           |\n",
      "|    reward             | -1.29541695e-05 |\n",
      "|    std                | 1.62e+03        |\n",
      "|    value_loss         | 0.00139         |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 288          |\n",
      "|    iterations         | 39800        |\n",
      "|    time_elapsed       | 690          |\n",
      "|    total_timesteps    | 199000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | -23.7        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39799        |\n",
      "|    policy_loss        | -2.03        |\n",
      "|    reward             | 0.0098660905 |\n",
      "|    std                | 1.63e+03     |\n",
      "|    value_loss         | 0.0216       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 288          |\n",
      "|    iterations         | 39900        |\n",
      "|    time_elapsed       | 692          |\n",
      "|    total_timesteps    | 199500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39899        |\n",
      "|    policy_loss        | 1.63         |\n",
      "|    reward             | -0.055854626 |\n",
      "|    std                | 1.64e+03     |\n",
      "|    value_loss         | 0.0101       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 40000      |\n",
      "|    time_elapsed       | 693        |\n",
      "|    total_timesteps    | 200000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.7      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39999      |\n",
      "|    policy_loss        | -2.4       |\n",
      "|    reward             | 0.16078433 |\n",
      "|    std                | 1.66e+03   |\n",
      "|    value_loss         | 0.0272     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 288           |\n",
      "|    iterations         | 40100         |\n",
      "|    time_elapsed       | 695           |\n",
      "|    total_timesteps    | 200500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40099         |\n",
      "|    policy_loss        | 0.217         |\n",
      "|    reward             | -0.0045924406 |\n",
      "|    std                | 1.7e+03       |\n",
      "|    value_loss         | 0.000267      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 288          |\n",
      "|    iterations         | 40200        |\n",
      "|    time_elapsed       | 696          |\n",
      "|    total_timesteps    | 201000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40199        |\n",
      "|    policy_loss        | 0.338        |\n",
      "|    reward             | -0.010187815 |\n",
      "|    std                | 1.73e+03     |\n",
      "|    value_loss         | 0.000708     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 288           |\n",
      "|    iterations         | 40300         |\n",
      "|    time_elapsed       | 698           |\n",
      "|    total_timesteps    | 201500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40299         |\n",
      "|    policy_loss        | -0.615        |\n",
      "|    reward             | -0.0027709135 |\n",
      "|    std                | 1.76e+03      |\n",
      "|    value_loss         | 0.00188       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 288          |\n",
      "|    iterations         | 40400        |\n",
      "|    time_elapsed       | 699          |\n",
      "|    total_timesteps    | 202000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40399        |\n",
      "|    policy_loss        | -0.0596      |\n",
      "|    reward             | -0.014200054 |\n",
      "|    std                | 1.82e+03     |\n",
      "|    value_loss         | 3.98e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 288         |\n",
      "|    iterations         | 40500       |\n",
      "|    time_elapsed       | 700         |\n",
      "|    total_timesteps    | 202500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40499       |\n",
      "|    policy_loss        | -0.463      |\n",
      "|    reward             | 0.026219191 |\n",
      "|    std                | 1.83e+03    |\n",
      "|    value_loss         | 0.000918    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 40600      |\n",
      "|    time_elapsed       | 702        |\n",
      "|    total_timesteps    | 203000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.9      |\n",
      "|    explained_variance | 0.268      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40599      |\n",
      "|    policy_loss        | -1.18      |\n",
      "|    reward             | 0.02547602 |\n",
      "|    std                | 1.87e+03   |\n",
      "|    value_loss         | 0.00457    |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -34805.61\n",
      "total_reward: -44805.61\n",
      "total_cost: 92.95\n",
      "total_trades: 5414\n",
      "Sharpe: -0.100\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 40700      |\n",
      "|    time_elapsed       | 703        |\n",
      "|    total_timesteps    | 203500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40699      |\n",
      "|    policy_loss        | -3.43      |\n",
      "|    reward             | 0.15458861 |\n",
      "|    std                | 1.9e+03    |\n",
      "|    value_loss         | 0.0317     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 40800      |\n",
      "|    time_elapsed       | 705        |\n",
      "|    total_timesteps    | 204000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40799      |\n",
      "|    policy_loss        | -0.523     |\n",
      "|    reward             | 0.01161473 |\n",
      "|    std                | 1.92e+03   |\n",
      "|    value_loss         | 0.00171    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 289          |\n",
      "|    iterations         | 40900        |\n",
      "|    time_elapsed       | 706          |\n",
      "|    total_timesteps    | 204500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | -0.629       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40899        |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | -0.020866184 |\n",
      "|    std                | 1.95e+03     |\n",
      "|    value_loss         | 0.000305     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 41000      |\n",
      "|    time_elapsed       | 708        |\n",
      "|    total_timesteps    | 205000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18        |\n",
      "|    explained_variance | 0.398      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40999      |\n",
      "|    policy_loss        | -0.232     |\n",
      "|    reward             | 0.03116525 |\n",
      "|    std                | 1.98e+03   |\n",
      "|    value_loss         | 0.000337   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 289            |\n",
      "|    iterations         | 41100          |\n",
      "|    time_elapsed       | 709            |\n",
      "|    total_timesteps    | 205500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.1          |\n",
      "|    explained_variance | 0.0597         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 41099          |\n",
      "|    policy_loss        | -0.0299        |\n",
      "|    reward             | -0.00038615015 |\n",
      "|    std                | 2.03e+03       |\n",
      "|    value_loss         | 0.00137        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 289         |\n",
      "|    iterations         | 41200       |\n",
      "|    time_elapsed       | 711         |\n",
      "|    total_timesteps    | 206000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41199       |\n",
      "|    policy_loss        | 0.119       |\n",
      "|    reward             | -0.00878285 |\n",
      "|    std                | 2.08e+03    |\n",
      "|    value_loss         | 0.000735    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 289          |\n",
      "|    iterations         | 41300        |\n",
      "|    time_elapsed       | 713          |\n",
      "|    total_timesteps    | 206500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41299        |\n",
      "|    policy_loss        | 0.455        |\n",
      "|    reward             | -0.042811833 |\n",
      "|    std                | 2.1e+03      |\n",
      "|    value_loss         | 0.00171      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 289          |\n",
      "|    iterations         | 41400        |\n",
      "|    time_elapsed       | 714          |\n",
      "|    total_timesteps    | 207000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41399        |\n",
      "|    policy_loss        | 0.0154       |\n",
      "|    reward             | 0.0053093494 |\n",
      "|    std                | 2.11e+03     |\n",
      "|    value_loss         | 0.0052       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 289         |\n",
      "|    iterations         | 41500       |\n",
      "|    time_elapsed       | 716         |\n",
      "|    total_timesteps    | 207500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0.439       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41499       |\n",
      "|    policy_loss        | -4.4        |\n",
      "|    reward             | -0.08086825 |\n",
      "|    std                | 2.14e+03    |\n",
      "|    value_loss         | 0.0816      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 41600      |\n",
      "|    time_elapsed       | 717        |\n",
      "|    total_timesteps    | 208000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 41599      |\n",
      "|    policy_loss        | 5.92       |\n",
      "|    reward             | 0.17361067 |\n",
      "|    std                | 2.16e+03   |\n",
      "|    value_loss         | 0.17       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 41700      |\n",
      "|    time_elapsed       | 719        |\n",
      "|    total_timesteps    | 208500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.2      |\n",
      "|    explained_variance | 0.000795   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 41699      |\n",
      "|    policy_loss        | -5.23      |\n",
      "|    reward             | 0.35483038 |\n",
      "|    std                | 2.17e+03   |\n",
      "|    value_loss         | 0.144      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 289         |\n",
      "|    iterations         | 41800       |\n",
      "|    time_elapsed       | 720         |\n",
      "|    total_timesteps    | 209000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41799       |\n",
      "|    policy_loss        | 0.0823      |\n",
      "|    reward             | 0.013814021 |\n",
      "|    std                | 2.18e+03    |\n",
      "|    value_loss         | 0.000145    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 290         |\n",
      "|    iterations         | 41900       |\n",
      "|    time_elapsed       | 722         |\n",
      "|    total_timesteps    | 209500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41899       |\n",
      "|    policy_loss        | 0.214       |\n",
      "|    reward             | -0.00614411 |\n",
      "|    std                | 2.21e+03    |\n",
      "|    value_loss         | 0.000345    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 42000        |\n",
      "|    time_elapsed       | 723          |\n",
      "|    total_timesteps    | 210000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41999        |\n",
      "|    policy_loss        | -0.95        |\n",
      "|    reward             | -0.008930445 |\n",
      "|    std                | 2.26e+03     |\n",
      "|    value_loss         | 0.00288      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 42100        |\n",
      "|    time_elapsed       | 725          |\n",
      "|    total_timesteps    | 210500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | -11.4        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42099        |\n",
      "|    policy_loss        | 0.263        |\n",
      "|    reward             | 0.0039491164 |\n",
      "|    std                | 2.26e+03     |\n",
      "|    value_loss         | 0.00419      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 42200        |\n",
      "|    time_elapsed       | 726          |\n",
      "|    total_timesteps    | 211000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0.246        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42199        |\n",
      "|    policy_loss        | -0.246       |\n",
      "|    reward             | 0.0006870853 |\n",
      "|    std                | 2.32e+03     |\n",
      "|    value_loss         | 0.000273     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 42300        |\n",
      "|    time_elapsed       | 728          |\n",
      "|    total_timesteps    | 211500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42299        |\n",
      "|    policy_loss        | -0.65        |\n",
      "|    reward             | -0.010778536 |\n",
      "|    std                | 2.37e+03     |\n",
      "|    value_loss         | 0.00252      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 290         |\n",
      "|    iterations         | 42400       |\n",
      "|    time_elapsed       | 729         |\n",
      "|    total_timesteps    | 212000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42399       |\n",
      "|    policy_loss        | -0.459      |\n",
      "|    reward             | -0.01956353 |\n",
      "|    std                | 2.37e+03    |\n",
      "|    value_loss         | 0.000987    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 42500        |\n",
      "|    time_elapsed       | 731          |\n",
      "|    total_timesteps    | 212500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0.491        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42499        |\n",
      "|    policy_loss        | 0.0826       |\n",
      "|    reward             | 0.0033968436 |\n",
      "|    std                | 2.43e+03     |\n",
      "|    value_loss         | 6.38e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 290           |\n",
      "|    iterations         | 42600         |\n",
      "|    time_elapsed       | 732           |\n",
      "|    total_timesteps    | 213000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42599         |\n",
      "|    policy_loss        | 0.569         |\n",
      "|    reward             | -0.0012788522 |\n",
      "|    std                | 2.5e+03       |\n",
      "|    value_loss         | 0.00127       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 290        |\n",
      "|    iterations         | 42700      |\n",
      "|    time_elapsed       | 734        |\n",
      "|    total_timesteps    | 213500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42699      |\n",
      "|    policy_loss        | -0.0447    |\n",
      "|    reward             | 0.03733512 |\n",
      "|    std                | 2.54e+03   |\n",
      "|    value_loss         | 0.00015    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 290          |\n",
      "|    iterations         | 42800        |\n",
      "|    time_elapsed       | 735          |\n",
      "|    total_timesteps    | 214000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42799        |\n",
      "|    policy_loss        | 0.915        |\n",
      "|    reward             | -0.015580121 |\n",
      "|    std                | 2.58e+03     |\n",
      "|    value_loss         | 0.00525      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 736         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42899       |\n",
      "|    policy_loss        | 1.57        |\n",
      "|    reward             | 0.032874748 |\n",
      "|    std                | 2.62e+03    |\n",
      "|    value_loss         | 0.00767     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 291          |\n",
      "|    iterations         | 43000        |\n",
      "|    time_elapsed       | 738          |\n",
      "|    total_timesteps    | 215000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42999        |\n",
      "|    policy_loss        | 0.371        |\n",
      "|    reward             | -0.062796965 |\n",
      "|    std                | 2.66e+03     |\n",
      "|    value_loss         | 0.000732     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 43100       |\n",
      "|    time_elapsed       | 739         |\n",
      "|    total_timesteps    | 215500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0.00133     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43099       |\n",
      "|    policy_loss        | 1.8         |\n",
      "|    reward             | -0.15520084 |\n",
      "|    std                | 2.66e+03    |\n",
      "|    value_loss         | 0.0188      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 43200       |\n",
      "|    time_elapsed       | 741         |\n",
      "|    total_timesteps    | 216000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43199       |\n",
      "|    policy_loss        | 0.507       |\n",
      "|    reward             | 0.017670188 |\n",
      "|    std                | 2.67e+03    |\n",
      "|    value_loss         | 0.0146      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 43300       |\n",
      "|    time_elapsed       | 742         |\n",
      "|    total_timesteps    | 216500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | -10.3       |\n",
      "|    reward             | -0.19544223 |\n",
      "|    std                | 2.68e+03    |\n",
      "|    value_loss         | 0.531       |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -231196.89\n",
      "total_reward: -241196.89\n",
      "total_cost: 102.18\n",
      "total_trades: 5414\n",
      "Sharpe: -0.370\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 43400       |\n",
      "|    time_elapsed       | 744         |\n",
      "|    total_timesteps    | 217000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43399       |\n",
      "|    policy_loss        | -1.83       |\n",
      "|    reward             | 0.041516148 |\n",
      "|    std                | 2.69e+03    |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 291         |\n",
      "|    iterations         | 43500       |\n",
      "|    time_elapsed       | 745         |\n",
      "|    total_timesteps    | 217500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43499       |\n",
      "|    policy_loss        | -0.109      |\n",
      "|    reward             | 0.006272556 |\n",
      "|    std                | 2.72e+03    |\n",
      "|    value_loss         | 6.65e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 291          |\n",
      "|    iterations         | 43600        |\n",
      "|    time_elapsed       | 747          |\n",
      "|    total_timesteps    | 218000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43599        |\n",
      "|    policy_loss        | 0.157        |\n",
      "|    reward             | -0.038559653 |\n",
      "|    std                | 2.77e+03     |\n",
      "|    value_loss         | 8.78e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 291          |\n",
      "|    iterations         | 43700        |\n",
      "|    time_elapsed       | 748          |\n",
      "|    total_timesteps    | 218500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | -89.4        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43699        |\n",
      "|    policy_loss        | 3.29         |\n",
      "|    reward             | -0.003309253 |\n",
      "|    std                | 2.83e+03     |\n",
      "|    value_loss         | 0.0401       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 291          |\n",
      "|    iterations         | 43800        |\n",
      "|    time_elapsed       | 750          |\n",
      "|    total_timesteps    | 219000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | -3.46e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43799        |\n",
      "|    policy_loss        | -0.249       |\n",
      "|    reward             | -0.014785256 |\n",
      "|    std                | 2.89e+03     |\n",
      "|    value_loss         | 0.000287     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 292          |\n",
      "|    iterations         | 43900        |\n",
      "|    time_elapsed       | 751          |\n",
      "|    total_timesteps    | 219500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43899        |\n",
      "|    policy_loss        | -1.22        |\n",
      "|    reward             | -0.008105644 |\n",
      "|    std                | 2.96e+03     |\n",
      "|    value_loss         | 0.00443      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 292          |\n",
      "|    iterations         | 44000        |\n",
      "|    time_elapsed       | 752          |\n",
      "|    total_timesteps    | 220000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43999        |\n",
      "|    policy_loss        | 0.49         |\n",
      "|    reward             | -0.056454517 |\n",
      "|    std                | 3.04e+03     |\n",
      "|    value_loss         | 0.00116      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 292          |\n",
      "|    iterations         | 44100        |\n",
      "|    time_elapsed       | 754          |\n",
      "|    total_timesteps    | 220500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44099        |\n",
      "|    policy_loss        | -1.83        |\n",
      "|    reward             | -0.036353447 |\n",
      "|    std                | 3.1e+03      |\n",
      "|    value_loss         | 0.0107       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 292         |\n",
      "|    iterations         | 44200       |\n",
      "|    time_elapsed       | 755         |\n",
      "|    total_timesteps    | 221000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | 0.0631      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44199       |\n",
      "|    policy_loss        | 0.609       |\n",
      "|    reward             | 0.008344608 |\n",
      "|    std                | 3.14e+03    |\n",
      "|    value_loss         | 0.00189     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 292         |\n",
      "|    iterations         | 44300       |\n",
      "|    time_elapsed       | 757         |\n",
      "|    total_timesteps    | 221500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 5.96e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44299       |\n",
      "|    policy_loss        | 2.88        |\n",
      "|    reward             | 0.011746051 |\n",
      "|    std                | 3.22e+03    |\n",
      "|    value_loss         | 0.0247      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 292         |\n",
      "|    iterations         | 44400       |\n",
      "|    time_elapsed       | 758         |\n",
      "|    total_timesteps    | 222000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44399       |\n",
      "|    policy_loss        | 0.229       |\n",
      "|    reward             | 0.008256647 |\n",
      "|    std                | 3.32e+03    |\n",
      "|    value_loss         | 0.00194     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 292         |\n",
      "|    iterations         | 44500       |\n",
      "|    time_elapsed       | 760         |\n",
      "|    total_timesteps    | 222500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44499       |\n",
      "|    policy_loss        | -0.446      |\n",
      "|    reward             | 0.010614847 |\n",
      "|    std                | 3.36e+03    |\n",
      "|    value_loss         | 0.000993    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 292            |\n",
      "|    iterations         | 44600          |\n",
      "|    time_elapsed       | 761            |\n",
      "|    total_timesteps    | 223000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.1          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 44599          |\n",
      "|    policy_loss        | 0.0334         |\n",
      "|    reward             | -0.00046729966 |\n",
      "|    std                | 3.42e+03       |\n",
      "|    value_loss         | 0.000159       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 292           |\n",
      "|    iterations         | 44700         |\n",
      "|    time_elapsed       | 763           |\n",
      "|    total_timesteps    | 223500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 44699         |\n",
      "|    policy_loss        | 0.258         |\n",
      "|    reward             | -0.0030568177 |\n",
      "|    std                | 3.48e+03      |\n",
      "|    value_loss         | 0.000237      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 292          |\n",
      "|    iterations         | 44800        |\n",
      "|    time_elapsed       | 764          |\n",
      "|    total_timesteps    | 224000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0.135        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44799        |\n",
      "|    policy_loss        | -0.00684     |\n",
      "|    reward             | 0.0004201477 |\n",
      "|    std                | 3.57e+03     |\n",
      "|    value_loss         | 8.82e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 292          |\n",
      "|    iterations         | 44900        |\n",
      "|    time_elapsed       | 766          |\n",
      "|    total_timesteps    | 224500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44899        |\n",
      "|    policy_loss        | -0.0759      |\n",
      "|    reward             | -0.012466676 |\n",
      "|    std                | 3.66e+03     |\n",
      "|    value_loss         | 4.59e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 293         |\n",
      "|    iterations         | 45000       |\n",
      "|    time_elapsed       | 767         |\n",
      "|    total_timesteps    | 225000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44999       |\n",
      "|    policy_loss        | 1.48        |\n",
      "|    reward             | 0.118145615 |\n",
      "|    std                | 3.71e+03    |\n",
      "|    value_loss         | 0.0199      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 293          |\n",
      "|    iterations         | 45100        |\n",
      "|    time_elapsed       | 769          |\n",
      "|    total_timesteps    | 225500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45099        |\n",
      "|    policy_loss        | -0.00173     |\n",
      "|    reward             | -0.030390354 |\n",
      "|    std                | 3.76e+03     |\n",
      "|    value_loss         | 0.0022       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 293         |\n",
      "|    iterations         | 45200       |\n",
      "|    time_elapsed       | 770         |\n",
      "|    total_timesteps    | 226000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45199       |\n",
      "|    policy_loss        | -1.55       |\n",
      "|    reward             | -0.07464124 |\n",
      "|    std                | 3.81e+03    |\n",
      "|    value_loss         | 0.0077      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 293        |\n",
      "|    iterations         | 45300      |\n",
      "|    time_elapsed       | 772        |\n",
      "|    total_timesteps    | 226500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45299      |\n",
      "|    policy_loss        | 0.368      |\n",
      "|    reward             | 0.16117524 |\n",
      "|    std                | 3.83e+03   |\n",
      "|    value_loss         | 0.00189    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 293         |\n",
      "|    iterations         | 45400       |\n",
      "|    time_elapsed       | 773         |\n",
      "|    total_timesteps    | 227000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45399       |\n",
      "|    policy_loss        | -5.47       |\n",
      "|    reward             | -0.09568282 |\n",
      "|    std                | 3.82e+03    |\n",
      "|    value_loss         | 0.101       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 293          |\n",
      "|    iterations         | 45500        |\n",
      "|    time_elapsed       | 774          |\n",
      "|    total_timesteps    | 227500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45499        |\n",
      "|    policy_loss        | 3.75         |\n",
      "|    reward             | -0.024948945 |\n",
      "|    std                | 3.83e+03     |\n",
      "|    value_loss         | 0.0453       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 293        |\n",
      "|    iterations         | 45600      |\n",
      "|    time_elapsed       | 776        |\n",
      "|    total_timesteps    | 228000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45599      |\n",
      "|    policy_loss        | -0.583     |\n",
      "|    reward             | 0.14261808 |\n",
      "|    std                | 3.88e+03   |\n",
      "|    value_loss         | 0.00636    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 293          |\n",
      "|    iterations         | 45700        |\n",
      "|    time_elapsed       | 778          |\n",
      "|    total_timesteps    | 228500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45699        |\n",
      "|    policy_loss        | 1.38         |\n",
      "|    reward             | -0.045730993 |\n",
      "|    std                | 3.89e+03     |\n",
      "|    value_loss         | 0.0134       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 293          |\n",
      "|    iterations         | 45800        |\n",
      "|    time_elapsed       | 779          |\n",
      "|    total_timesteps    | 229000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45799        |\n",
      "|    policy_loss        | 3.5          |\n",
      "|    reward             | -0.037005495 |\n",
      "|    std                | 3.95e+03     |\n",
      "|    value_loss         | 0.0573       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 293        |\n",
      "|    iterations         | 45900      |\n",
      "|    time_elapsed       | 781        |\n",
      "|    total_timesteps    | 229500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.4      |\n",
      "|    explained_variance | 0.326      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45899      |\n",
      "|    policy_loss        | -7.29      |\n",
      "|    reward             | 0.16811414 |\n",
      "|    std                | 3.96e+03   |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 293         |\n",
      "|    iterations         | 46000       |\n",
      "|    time_elapsed       | 782         |\n",
      "|    total_timesteps    | 230000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45999       |\n",
      "|    policy_loss        | -6.86       |\n",
      "|    reward             | -0.39716035 |\n",
      "|    std                | 3.94e+03    |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -242279.75\n",
      "total_reward: -252279.75\n",
      "total_cost: 104.99\n",
      "total_trades: 5414\n",
      "Sharpe: -0.230\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 293        |\n",
      "|    iterations         | 46100      |\n",
      "|    time_elapsed       | 784        |\n",
      "|    total_timesteps    | 230500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46099      |\n",
      "|    policy_loss        | -1.34      |\n",
      "|    reward             | 0.04175305 |\n",
      "|    std                | 3.93e+03   |\n",
      "|    value_loss         | 0.00568    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 293          |\n",
      "|    iterations         | 46200        |\n",
      "|    time_elapsed       | 785          |\n",
      "|    total_timesteps    | 231000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46199        |\n",
      "|    policy_loss        | -0.106       |\n",
      "|    reward             | -0.013459912 |\n",
      "|    std                | 3.94e+03     |\n",
      "|    value_loss         | 8.79e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 294           |\n",
      "|    iterations         | 46300         |\n",
      "|    time_elapsed       | 787           |\n",
      "|    total_timesteps    | 231500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.4         |\n",
      "|    explained_variance | -29.9         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 46299         |\n",
      "|    policy_loss        | -0.168        |\n",
      "|    reward             | -0.0037055362 |\n",
      "|    std                | 4.01e+03      |\n",
      "|    value_loss         | 0.000771      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 46400        |\n",
      "|    time_elapsed       | 788          |\n",
      "|    total_timesteps    | 232000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46399        |\n",
      "|    policy_loss        | 0.543        |\n",
      "|    reward             | 0.0030002778 |\n",
      "|    std                | 4.08e+03     |\n",
      "|    value_loss         | 0.000876     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 46500        |\n",
      "|    time_elapsed       | 790          |\n",
      "|    total_timesteps    | 232500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46499        |\n",
      "|    policy_loss        | -0.38        |\n",
      "|    reward             | -0.015703725 |\n",
      "|    std                | 4.12e+03     |\n",
      "|    value_loss         | 0.00093      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 294         |\n",
      "|    iterations         | 46600       |\n",
      "|    time_elapsed       | 791         |\n",
      "|    total_timesteps    | 233000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46599       |\n",
      "|    policy_loss        | -0.996      |\n",
      "|    reward             | 0.020999413 |\n",
      "|    std                | 4.21e+03    |\n",
      "|    value_loss         | 0.00294     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 294         |\n",
      "|    iterations         | 46700       |\n",
      "|    time_elapsed       | 793         |\n",
      "|    total_timesteps    | 233500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46699       |\n",
      "|    policy_loss        | 0.0139      |\n",
      "|    reward             | 0.008428703 |\n",
      "|    std                | 4.28e+03    |\n",
      "|    value_loss         | 3.8e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 46800        |\n",
      "|    time_elapsed       | 794          |\n",
      "|    total_timesteps    | 234000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46799        |\n",
      "|    policy_loss        | 0.186        |\n",
      "|    reward             | -0.017752014 |\n",
      "|    std                | 4.35e+03     |\n",
      "|    value_loss         | 9.92e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 294           |\n",
      "|    iterations         | 46900         |\n",
      "|    time_elapsed       | 796           |\n",
      "|    total_timesteps    | 234500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 46899         |\n",
      "|    policy_loss        | 0.288         |\n",
      "|    reward             | -0.0053544804 |\n",
      "|    std                | 4.44e+03      |\n",
      "|    value_loss         | 0.000227      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 47000        |\n",
      "|    time_elapsed       | 797          |\n",
      "|    total_timesteps    | 235000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | -0.144       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46999        |\n",
      "|    policy_loss        | 0.318        |\n",
      "|    reward             | -0.009199366 |\n",
      "|    std                | 4.63e+03     |\n",
      "|    value_loss         | 0.000391     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 47100        |\n",
      "|    time_elapsed       | 799          |\n",
      "|    total_timesteps    | 235500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47099        |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | -0.004584677 |\n",
      "|    std                | 4.75e+03     |\n",
      "|    value_loss         | 7.43e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 294            |\n",
      "|    iterations         | 47200          |\n",
      "|    time_elapsed       | 800            |\n",
      "|    total_timesteps    | 236000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 47199          |\n",
      "|    policy_loss        | -0.114         |\n",
      "|    reward             | -0.00080087624 |\n",
      "|    std                | 4.83e+03       |\n",
      "|    value_loss         | 0.00309        |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 294        |\n",
      "|    iterations         | 47300      |\n",
      "|    time_elapsed       | 801        |\n",
      "|    total_timesteps    | 236500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47299      |\n",
      "|    policy_loss        | 0.837      |\n",
      "|    reward             | 0.04217121 |\n",
      "|    std                | 4.88e+03   |\n",
      "|    value_loss         | 0.00441    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 294         |\n",
      "|    iterations         | 47400       |\n",
      "|    time_elapsed       | 803         |\n",
      "|    total_timesteps    | 237000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.8       |\n",
      "|    explained_variance | -0.0463     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47399       |\n",
      "|    policy_loss        | -0.552      |\n",
      "|    reward             | -0.25637057 |\n",
      "|    std                | 4.9e+03     |\n",
      "|    value_loss         | 0.00592     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 47500        |\n",
      "|    time_elapsed       | 804          |\n",
      "|    total_timesteps    | 237500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47499        |\n",
      "|    policy_loss        | 1.87         |\n",
      "|    reward             | 0.0009142311 |\n",
      "|    std                | 4.92e+03     |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 295        |\n",
      "|    iterations         | 47600      |\n",
      "|    time_elapsed       | 806        |\n",
      "|    total_timesteps    | 238000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 7.75e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47599      |\n",
      "|    policy_loss        | -2.63      |\n",
      "|    reward             | 0.13677074 |\n",
      "|    std                | 4.87e+03   |\n",
      "|    value_loss         | 0.0606     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 47700        |\n",
      "|    time_elapsed       | 807          |\n",
      "|    total_timesteps    | 238500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47699        |\n",
      "|    policy_loss        | 0.643        |\n",
      "|    reward             | -0.025417384 |\n",
      "|    std                | 4.91e+03     |\n",
      "|    value_loss         | 0.00133      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 295         |\n",
      "|    iterations         | 47800       |\n",
      "|    time_elapsed       | 809         |\n",
      "|    total_timesteps    | 239000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47799       |\n",
      "|    policy_loss        | 0.288       |\n",
      "|    reward             | 0.005228394 |\n",
      "|    std                | 4.94e+03    |\n",
      "|    value_loss         | 0.000251    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 295         |\n",
      "|    iterations         | 47900       |\n",
      "|    time_elapsed       | 810         |\n",
      "|    total_timesteps    | 239500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47899       |\n",
      "|    policy_loss        | -0.199      |\n",
      "|    reward             | 0.004431186 |\n",
      "|    std                | 5e+03       |\n",
      "|    value_loss         | 0.000352    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 295        |\n",
      "|    iterations         | 48000      |\n",
      "|    time_elapsed       | 812        |\n",
      "|    total_timesteps    | 240000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.9      |\n",
      "|    explained_variance | -0.888     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47999      |\n",
      "|    policy_loss        | 0.16       |\n",
      "|    reward             | -0.0037793 |\n",
      "|    std                | 5.12e+03   |\n",
      "|    value_loss         | 7.76e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 295         |\n",
      "|    iterations         | 48100       |\n",
      "|    time_elapsed       | 813         |\n",
      "|    total_timesteps    | 240500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | -4.28       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48099       |\n",
      "|    policy_loss        | 0.618       |\n",
      "|    reward             | 0.011003598 |\n",
      "|    std                | 5.3e+03     |\n",
      "|    value_loss         | 0.00207     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 48200        |\n",
      "|    time_elapsed       | 815          |\n",
      "|    total_timesteps    | 241000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48199        |\n",
      "|    policy_loss        | -0.441       |\n",
      "|    reward             | -0.011451458 |\n",
      "|    std                | 5.44e+03     |\n",
      "|    value_loss         | 0.000595     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 48300        |\n",
      "|    time_elapsed       | 816          |\n",
      "|    total_timesteps    | 241500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48299        |\n",
      "|    policy_loss        | -0.198       |\n",
      "|    reward             | -0.051875114 |\n",
      "|    std                | 5.62e+03     |\n",
      "|    value_loss         | 0.000371     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 295          |\n",
      "|    iterations         | 48400        |\n",
      "|    time_elapsed       | 818          |\n",
      "|    total_timesteps    | 242000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48399        |\n",
      "|    policy_loss        | 0.0354       |\n",
      "|    reward             | -0.027594855 |\n",
      "|    std                | 5.73e+03     |\n",
      "|    value_loss         | 0.000238     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 295        |\n",
      "|    iterations         | 48500      |\n",
      "|    time_elapsed       | 819        |\n",
      "|    total_timesteps    | 242500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | 0.0646     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 48499      |\n",
      "|    policy_loss        | 0.214      |\n",
      "|    reward             | -0.0369918 |\n",
      "|    std                | 5.86e+03   |\n",
      "|    value_loss         | 0.000243   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 48600        |\n",
      "|    time_elapsed       | 820          |\n",
      "|    total_timesteps    | 243000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48599        |\n",
      "|    policy_loss        | -2.39        |\n",
      "|    reward             | -0.013744282 |\n",
      "|    std                | 6.02e+03     |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 296         |\n",
      "|    iterations         | 48700       |\n",
      "|    time_elapsed       | 822         |\n",
      "|    total_timesteps    | 243500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0.0574      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48699       |\n",
      "|    policy_loss        | -0.684      |\n",
      "|    reward             | 0.041600112 |\n",
      "|    std                | 6.1e+03     |\n",
      "|    value_loss         | 0.00156     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -38989.26\n",
      "total_reward: -48989.26\n",
      "total_cost: 75.15\n",
      "total_trades: 5414\n",
      "Sharpe: -0.302\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 48800        |\n",
      "|    time_elapsed       | 823          |\n",
      "|    total_timesteps    | 244000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48799        |\n",
      "|    policy_loss        | 0.794        |\n",
      "|    reward             | 0.0012218977 |\n",
      "|    std                | 6.18e+03     |\n",
      "|    value_loss         | 0.00226      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 48900        |\n",
      "|    time_elapsed       | 825          |\n",
      "|    total_timesteps    | 244500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48899        |\n",
      "|    policy_loss        | 0.887        |\n",
      "|    reward             | -0.036525954 |\n",
      "|    std                | 6.32e+03     |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 296         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 826         |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | 1.37        |\n",
      "|    reward             | 0.022765428 |\n",
      "|    std                | 6.48e+03    |\n",
      "|    value_loss         | 0.00595     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 49100        |\n",
      "|    time_elapsed       | 828          |\n",
      "|    total_timesteps    | 245500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49099        |\n",
      "|    policy_loss        | -1.56        |\n",
      "|    reward             | -0.026204633 |\n",
      "|    std                | 6.45e+03     |\n",
      "|    value_loss         | 0.00644      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 296        |\n",
      "|    iterations         | 49200      |\n",
      "|    time_elapsed       | 829        |\n",
      "|    total_timesteps    | 246000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49199      |\n",
      "|    policy_loss        | -1.39      |\n",
      "|    reward             | 0.01767006 |\n",
      "|    std                | 6.55e+03   |\n",
      "|    value_loss         | 0.00818    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 49300        |\n",
      "|    time_elapsed       | 831          |\n",
      "|    total_timesteps    | 246500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49299        |\n",
      "|    policy_loss        | -0.258       |\n",
      "|    reward             | -0.025788642 |\n",
      "|    std                | 6.54e+03     |\n",
      "|    value_loss         | 0.000442     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 296         |\n",
      "|    iterations         | 49400       |\n",
      "|    time_elapsed       | 832         |\n",
      "|    total_timesteps    | 247000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49399       |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | 0.037843157 |\n",
      "|    std                | 6.66e+03    |\n",
      "|    value_loss         | 0.00267     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 296         |\n",
      "|    iterations         | 49500       |\n",
      "|    time_elapsed       | 833         |\n",
      "|    total_timesteps    | 247500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49499       |\n",
      "|    policy_loss        | 0.292       |\n",
      "|    reward             | 0.009390203 |\n",
      "|    std                | 6.75e+03    |\n",
      "|    value_loss         | 0.00028     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 296          |\n",
      "|    iterations         | 49600        |\n",
      "|    time_elapsed       | 835          |\n",
      "|    total_timesteps    | 248000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | 0.05         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | -0.00579     |\n",
      "|    reward             | -0.025221137 |\n",
      "|    std                | 6.89e+03     |\n",
      "|    value_loss         | 1.48e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 296         |\n",
      "|    iterations         | 49700       |\n",
      "|    time_elapsed       | 836         |\n",
      "|    total_timesteps    | 248500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | 0.396       |\n",
      "|    reward             | 0.044014074 |\n",
      "|    std                | 7e+03       |\n",
      "|    value_loss         | 0.000492    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 49800       |\n",
      "|    time_elapsed       | 838         |\n",
      "|    total_timesteps    | 249000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49799       |\n",
      "|    policy_loss        | 1.86        |\n",
      "|    reward             | 0.046056174 |\n",
      "|    std                | 7.19e+03    |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 297        |\n",
      "|    iterations         | 49900      |\n",
      "|    time_elapsed       | 839        |\n",
      "|    total_timesteps    | 249500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49899      |\n",
      "|    policy_loss        | 0.107      |\n",
      "|    reward             | 0.02423476 |\n",
      "|    std                | 7.35e+03   |\n",
      "|    value_loss         | 0.00158    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 50000       |\n",
      "|    time_elapsed       | 841         |\n",
      "|    total_timesteps    | 250000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49999       |\n",
      "|    policy_loss        | -0.209      |\n",
      "|    reward             | 0.003643175 |\n",
      "|    std                | 7.52e+03    |\n",
      "|    value_loss         | 0.000124    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 50100       |\n",
      "|    time_elapsed       | 842         |\n",
      "|    total_timesteps    | 250500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50099       |\n",
      "|    policy_loss        | 0.981       |\n",
      "|    reward             | 0.034740604 |\n",
      "|    std                | 7.76e+03    |\n",
      "|    value_loss         | 0.00284     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 50200       |\n",
      "|    time_elapsed       | 844         |\n",
      "|    total_timesteps    | 251000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | -0.719      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50199       |\n",
      "|    policy_loss        | 0.0963      |\n",
      "|    reward             | 0.008951644 |\n",
      "|    std                | 7.95e+03    |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 297          |\n",
      "|    iterations         | 50300        |\n",
      "|    time_elapsed       | 845          |\n",
      "|    total_timesteps    | 251500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50299        |\n",
      "|    policy_loss        | -0.0235      |\n",
      "|    reward             | 0.0020204468 |\n",
      "|    std                | 8.29e+03     |\n",
      "|    value_loss         | 7.22e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 297          |\n",
      "|    iterations         | 50400        |\n",
      "|    time_elapsed       | 847          |\n",
      "|    total_timesteps    | 252000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50399        |\n",
      "|    policy_loss        | -1.27        |\n",
      "|    reward             | -0.016756056 |\n",
      "|    std                | 8.48e+03     |\n",
      "|    value_loss         | 0.00422      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 50500       |\n",
      "|    time_elapsed       | 848         |\n",
      "|    total_timesteps    | 252500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50499       |\n",
      "|    policy_loss        | 0.25        |\n",
      "|    reward             | 0.049258627 |\n",
      "|    std                | 8.66e+03    |\n",
      "|    value_loss         | 0.000321    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 297          |\n",
      "|    iterations         | 50600        |\n",
      "|    time_elapsed       | 850          |\n",
      "|    total_timesteps    | 253000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50599        |\n",
      "|    policy_loss        | -0.14        |\n",
      "|    reward             | -0.014308442 |\n",
      "|    std                | 8.86e+03     |\n",
      "|    value_loss         | 0.000627     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 50700       |\n",
      "|    time_elapsed       | 851         |\n",
      "|    total_timesteps    | 253500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0.149       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50699       |\n",
      "|    policy_loss        | -0.5        |\n",
      "|    reward             | 0.006330606 |\n",
      "|    std                | 9.02e+03    |\n",
      "|    value_loss         | 0.000669    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 50800       |\n",
      "|    time_elapsed       | 853         |\n",
      "|    total_timesteps    | 254000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.1       |\n",
      "|    explained_variance | 1.98e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50799       |\n",
      "|    policy_loss        | -0.799      |\n",
      "|    reward             | 0.013585521 |\n",
      "|    std                | 9.3e+03     |\n",
      "|    value_loss         | 0.00627     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 297        |\n",
      "|    iterations         | 50900      |\n",
      "|    time_elapsed       | 854        |\n",
      "|    total_timesteps    | 254500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.1      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50899      |\n",
      "|    policy_loss        | -2.74      |\n",
      "|    reward             | 0.04207988 |\n",
      "|    std                | 9.56e+03   |\n",
      "|    value_loss         | 0.0198     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 51000       |\n",
      "|    time_elapsed       | 856         |\n",
      "|    total_timesteps    | 255000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50999       |\n",
      "|    policy_loss        | 0.238       |\n",
      "|    reward             | -0.04132581 |\n",
      "|    std                | 9.7e+03     |\n",
      "|    value_loss         | 0.00115     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 297          |\n",
      "|    iterations         | 51100        |\n",
      "|    time_elapsed       | 857          |\n",
      "|    total_timesteps    | 255500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51099        |\n",
      "|    policy_loss        | -0.224       |\n",
      "|    reward             | -0.032839555 |\n",
      "|    std                | 9.81e+03     |\n",
      "|    value_loss         | 0.000579     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 297        |\n",
      "|    iterations         | 51200      |\n",
      "|    time_elapsed       | 859        |\n",
      "|    total_timesteps    | 256000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51199      |\n",
      "|    policy_loss        | -2.77      |\n",
      "|    reward             | 0.09340979 |\n",
      "|    std                | 1.01e+04   |\n",
      "|    value_loss         | 0.0242     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 298        |\n",
      "|    iterations         | 51300      |\n",
      "|    time_elapsed       | 860        |\n",
      "|    total_timesteps    | 256500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | 0.164      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51299      |\n",
      "|    policy_loss        | -3.54      |\n",
      "|    reward             | 0.18113062 |\n",
      "|    std                | 1.03e+04   |\n",
      "|    value_loss         | 0.0327     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 298        |\n",
      "|    iterations         | 51400      |\n",
      "|    time_elapsed       | 862        |\n",
      "|    total_timesteps    | 257000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51399      |\n",
      "|    policy_loss        | 3.57       |\n",
      "|    reward             | 0.07788487 |\n",
      "|    std                | 1.04e+04   |\n",
      "|    value_loss         | 0.0789     |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -223746.55\n",
      "total_reward: -233746.55\n",
      "total_cost: 107.97\n",
      "total_trades: 5414\n",
      "Sharpe: 0.339\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 863         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | -0.0572     |\n",
      "|    reward             | 0.004994989 |\n",
      "|    std                | 1.04e+04    |\n",
      "|    value_loss         | 0.000559    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 51600       |\n",
      "|    time_elapsed       | 865         |\n",
      "|    total_timesteps    | 258000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51599       |\n",
      "|    policy_loss        | -0.424      |\n",
      "|    reward             | -0.00331037 |\n",
      "|    std                | 1.07e+04    |\n",
      "|    value_loss         | 0.000486    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 51700       |\n",
      "|    time_elapsed       | 866         |\n",
      "|    total_timesteps    | 258500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | -0.989      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51699       |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | 0.020783452 |\n",
      "|    std                | 1.08e+04    |\n",
      "|    value_loss         | 0.00802     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 298          |\n",
      "|    iterations         | 51800        |\n",
      "|    time_elapsed       | 867          |\n",
      "|    total_timesteps    | 259000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51799        |\n",
      "|    policy_loss        | -0.491       |\n",
      "|    reward             | -0.026870955 |\n",
      "|    std                | 1.11e+04     |\n",
      "|    value_loss         | 0.000682     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 51900       |\n",
      "|    time_elapsed       | 869         |\n",
      "|    total_timesteps    | 259500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51899       |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | 0.025995586 |\n",
      "|    std                | 1.13e+04    |\n",
      "|    value_loss         | 0.000256    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 298        |\n",
      "|    iterations         | 52000      |\n",
      "|    time_elapsed       | 870        |\n",
      "|    total_timesteps    | 260000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51999      |\n",
      "|    policy_loss        | -0.382     |\n",
      "|    reward             | 0.07116352 |\n",
      "|    std                | 1.14e+04   |\n",
      "|    value_loss         | 0.0023     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 298          |\n",
      "|    iterations         | 52100        |\n",
      "|    time_elapsed       | 872          |\n",
      "|    total_timesteps    | 260500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52099        |\n",
      "|    policy_loss        | 0.424        |\n",
      "|    reward             | 0.0046407855 |\n",
      "|    std                | 1.16e+04     |\n",
      "|    value_loss         | 0.000396     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 52200       |\n",
      "|    time_elapsed       | 873         |\n",
      "|    total_timesteps    | 261000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52199       |\n",
      "|    policy_loss        | -0.0972     |\n",
      "|    reward             | -0.00880872 |\n",
      "|    std                | 1.18e+04    |\n",
      "|    value_loss         | 0.000207    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 52300       |\n",
      "|    time_elapsed       | 875         |\n",
      "|    total_timesteps    | 261500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52299       |\n",
      "|    policy_loss        | 0.158       |\n",
      "|    reward             | 0.011201527 |\n",
      "|    std                | 1.21e+04    |\n",
      "|    value_loss         | 6.95e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 298           |\n",
      "|    iterations         | 52400         |\n",
      "|    time_elapsed       | 876           |\n",
      "|    total_timesteps    | 262000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.7         |\n",
      "|    explained_variance | -1.91         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 52399         |\n",
      "|    policy_loss        | 0.0142        |\n",
      "|    reward             | -0.0030608894 |\n",
      "|    std                | 1.25e+04      |\n",
      "|    value_loss         | 0.000145      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 298          |\n",
      "|    iterations         | 52500        |\n",
      "|    time_elapsed       | 878          |\n",
      "|    total_timesteps    | 262500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | 0.0391       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52499        |\n",
      "|    policy_loss        | -0.14        |\n",
      "|    reward             | 0.0018763961 |\n",
      "|    std                | 1.29e+04     |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 298         |\n",
      "|    iterations         | 52600       |\n",
      "|    time_elapsed       | 879         |\n",
      "|    total_timesteps    | 263000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52599       |\n",
      "|    policy_loss        | -0.144      |\n",
      "|    reward             | 0.013606541 |\n",
      "|    std                | 1.32e+04    |\n",
      "|    value_loss         | 0.000504    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 52700       |\n",
      "|    time_elapsed       | 881         |\n",
      "|    total_timesteps    | 263500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52699       |\n",
      "|    policy_loss        | -0.534      |\n",
      "|    reward             | -0.00968525 |\n",
      "|    std                | 1.37e+04    |\n",
      "|    value_loss         | 0.000719    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 52800       |\n",
      "|    time_elapsed       | 882         |\n",
      "|    total_timesteps    | 264000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 0.154       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52799       |\n",
      "|    policy_loss        | 1.28        |\n",
      "|    reward             | 0.004372796 |\n",
      "|    std                | 1.39e+04    |\n",
      "|    value_loss         | 0.00385     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 884         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | -0.522      |\n",
      "|    reward             | 0.044429023 |\n",
      "|    std                | 1.42e+04    |\n",
      "|    value_loss         | 0.000894    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 53000        |\n",
      "|    time_elapsed       | 885          |\n",
      "|    total_timesteps    | 265000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | 0.297        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52999        |\n",
      "|    policy_loss        | -0.534       |\n",
      "|    reward             | -0.025259687 |\n",
      "|    std                | 1.46e+04     |\n",
      "|    value_loss         | 0.00213      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 53100        |\n",
      "|    time_elapsed       | 886          |\n",
      "|    total_timesteps    | 265500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53099        |\n",
      "|    policy_loss        | 1.45         |\n",
      "|    reward             | -0.014793584 |\n",
      "|    std                | 1.48e+04     |\n",
      "|    value_loss         | 0.00493      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 299        |\n",
      "|    iterations         | 53200      |\n",
      "|    time_elapsed       | 888        |\n",
      "|    total_timesteps    | 266000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53199      |\n",
      "|    policy_loss        | -0.159     |\n",
      "|    reward             | 0.04403552 |\n",
      "|    std                | 1.51e+04   |\n",
      "|    value_loss         | 0.000142   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 53300        |\n",
      "|    time_elapsed       | 889          |\n",
      "|    total_timesteps    | 266500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53299        |\n",
      "|    policy_loss        | -2.14        |\n",
      "|    reward             | -0.003982014 |\n",
      "|    std                | 1.53e+04     |\n",
      "|    value_loss         | 0.00922      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 53400       |\n",
      "|    time_elapsed       | 891         |\n",
      "|    total_timesteps    | 267000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53399       |\n",
      "|    policy_loss        | 0.391       |\n",
      "|    reward             | 0.008086875 |\n",
      "|    std                | 1.54e+04    |\n",
      "|    value_loss         | 0.00046     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 53500       |\n",
      "|    time_elapsed       | 892         |\n",
      "|    total_timesteps    | 267500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0.0806      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53499       |\n",
      "|    policy_loss        | 0.673       |\n",
      "|    reward             | -0.04860182 |\n",
      "|    std                | 1.55e+04    |\n",
      "|    value_loss         | 0.00132     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 53600       |\n",
      "|    time_elapsed       | 894         |\n",
      "|    total_timesteps    | 268000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53599       |\n",
      "|    policy_loss        | 0.306       |\n",
      "|    reward             | -0.02059042 |\n",
      "|    std                | 1.56e+04    |\n",
      "|    value_loss         | 0.00225     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 53700        |\n",
      "|    time_elapsed       | 895          |\n",
      "|    total_timesteps    | 268500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53699        |\n",
      "|    policy_loss        | 0.383        |\n",
      "|    reward             | -0.014719518 |\n",
      "|    std                | 1.57e+04     |\n",
      "|    value_loss         | 0.00306      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 299         |\n",
      "|    iterations         | 53800       |\n",
      "|    time_elapsed       | 897         |\n",
      "|    total_timesteps    | 269000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53799       |\n",
      "|    policy_loss        | 0.19        |\n",
      "|    reward             | 0.019987294 |\n",
      "|    std                | 1.61e+04    |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 53900        |\n",
      "|    time_elapsed       | 898          |\n",
      "|    total_timesteps    | 269500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53899        |\n",
      "|    policy_loss        | 0.00158      |\n",
      "|    reward             | 0.0066829566 |\n",
      "|    std                | 1.64e+04     |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 54000        |\n",
      "|    time_elapsed       | 900          |\n",
      "|    total_timesteps    | 270000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | -0.851       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53999        |\n",
      "|    policy_loss        | 0.0538       |\n",
      "|    reward             | -0.013495793 |\n",
      "|    std                | 1.69e+04     |\n",
      "|    value_loss         | 4.59e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 54100        |\n",
      "|    time_elapsed       | 901          |\n",
      "|    total_timesteps    | 270500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54099        |\n",
      "|    policy_loss        | -0.12        |\n",
      "|    reward             | -0.002390782 |\n",
      "|    std                | 1.73e+04     |\n",
      "|    value_loss         | 9.52e-05     |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11533.67\n",
      "total_reward: -21533.67\n",
      "total_cost: 453.08\n",
      "total_trades: 5414\n",
      "Sharpe: 0.357\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 54200        |\n",
      "|    time_elapsed       | 903          |\n",
      "|    total_timesteps    | 271000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54199        |\n",
      "|    policy_loss        | 0.0793       |\n",
      "|    reward             | -0.011559513 |\n",
      "|    std                | 1.81e+04     |\n",
      "|    value_loss         | 2.82e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 300           |\n",
      "|    iterations         | 54300         |\n",
      "|    time_elapsed       | 904           |\n",
      "|    total_timesteps    | 271500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54299         |\n",
      "|    policy_loss        | -0.471        |\n",
      "|    reward             | -0.0068757962 |\n",
      "|    std                | 1.85e+04      |\n",
      "|    value_loss         | 0.00064       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 54400        |\n",
      "|    time_elapsed       | 906          |\n",
      "|    total_timesteps    | 272000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54399        |\n",
      "|    policy_loss        | 0.0828       |\n",
      "|    reward             | -0.012421815 |\n",
      "|    std                | 1.91e+04     |\n",
      "|    value_loss         | 2.87e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 300         |\n",
      "|    iterations         | 54500       |\n",
      "|    time_elapsed       | 907         |\n",
      "|    total_timesteps    | 272500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54499       |\n",
      "|    policy_loss        | 0.0528      |\n",
      "|    reward             | 0.006422434 |\n",
      "|    std                | 1.99e+04    |\n",
      "|    value_loss         | 2.28e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 54600        |\n",
      "|    time_elapsed       | 909          |\n",
      "|    total_timesteps    | 273000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54599        |\n",
      "|    policy_loss        | 0.672        |\n",
      "|    reward             | -0.007226602 |\n",
      "|    std                | 2.08e+04     |\n",
      "|    value_loss         | 0.00094      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 300         |\n",
      "|    iterations         | 54700       |\n",
      "|    time_elapsed       | 910         |\n",
      "|    total_timesteps    | 273500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54699       |\n",
      "|    policy_loss        | 0.343       |\n",
      "|    reward             | 0.014089682 |\n",
      "|    std                | 2.12e+04    |\n",
      "|    value_loss         | 0.000307    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 300        |\n",
      "|    iterations         | 54800      |\n",
      "|    time_elapsed       | 912        |\n",
      "|    total_timesteps    | 274000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54799      |\n",
      "|    policy_loss        | 1.03       |\n",
      "|    reward             | 0.03026091 |\n",
      "|    std                | 2.15e+04   |\n",
      "|    value_loss         | 0.00588    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 300        |\n",
      "|    iterations         | 54900      |\n",
      "|    time_elapsed       | 913        |\n",
      "|    total_timesteps    | 274500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54899      |\n",
      "|    policy_loss        | -0.786     |\n",
      "|    reward             | -0.0457889 |\n",
      "|    std                | 2.18e+04   |\n",
      "|    value_loss         | 0.00183    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 300         |\n",
      "|    iterations         | 55000       |\n",
      "|    time_elapsed       | 915         |\n",
      "|    total_timesteps    | 275000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54999       |\n",
      "|    policy_loss        | -1.32       |\n",
      "|    reward             | 0.061547585 |\n",
      "|    std                | 2.24e+04    |\n",
      "|    value_loss         | 0.0049      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 300        |\n",
      "|    iterations         | 55100      |\n",
      "|    time_elapsed       | 917        |\n",
      "|    total_timesteps    | 275500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55099      |\n",
      "|    policy_loss        | 0.598      |\n",
      "|    reward             | 0.09133584 |\n",
      "|    std                | 2.26e+04   |\n",
      "|    value_loss         | 0.00234    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 300         |\n",
      "|    iterations         | 55200       |\n",
      "|    time_elapsed       | 918         |\n",
      "|    total_timesteps    | 276000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55199       |\n",
      "|    policy_loss        | 2.58        |\n",
      "|    reward             | -0.08966365 |\n",
      "|    std                | 2.26e+04    |\n",
      "|    value_loss         | 0.0364      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 300         |\n",
      "|    iterations         | 55300       |\n",
      "|    time_elapsed       | 919         |\n",
      "|    total_timesteps    | 276500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55299       |\n",
      "|    policy_loss        | -0.898      |\n",
      "|    reward             | 0.025020251 |\n",
      "|    std                | 2.25e+04    |\n",
      "|    value_loss         | 0.00191     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 55400        |\n",
      "|    time_elapsed       | 921          |\n",
      "|    total_timesteps    | 277000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55399        |\n",
      "|    policy_loss        | -0.279       |\n",
      "|    reward             | -0.008481078 |\n",
      "|    std                | 2.27e+04     |\n",
      "|    value_loss         | 0.000189     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 300           |\n",
      "|    iterations         | 55500         |\n",
      "|    time_elapsed       | 922           |\n",
      "|    total_timesteps    | 277500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.9         |\n",
      "|    explained_variance | -0.000435     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55499         |\n",
      "|    policy_loss        | -0.135        |\n",
      "|    reward             | -0.0077565033 |\n",
      "|    std                | 2.31e+04      |\n",
      "|    value_loss         | 8.31e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 300            |\n",
      "|    iterations         | 55600          |\n",
      "|    time_elapsed       | 924            |\n",
      "|    total_timesteps    | 278000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -23            |\n",
      "|    explained_variance | 0.0713         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 55599          |\n",
      "|    policy_loss        | -0.207         |\n",
      "|    reward             | -0.00045338972 |\n",
      "|    std                | 2.37e+04       |\n",
      "|    value_loss         | 0.000141       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 55700        |\n",
      "|    time_elapsed       | 925          |\n",
      "|    total_timesteps    | 278500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55699        |\n",
      "|    policy_loss        | 0.35         |\n",
      "|    reward             | -0.011704842 |\n",
      "|    std                | 2.43e+04     |\n",
      "|    value_loss         | 0.000337     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 55800        |\n",
      "|    time_elapsed       | 927          |\n",
      "|    total_timesteps    | 279000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55799        |\n",
      "|    policy_loss        | -0.332       |\n",
      "|    reward             | 0.0101651335 |\n",
      "|    std                | 2.5e+04      |\n",
      "|    value_loss         | 0.000392     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 55900        |\n",
      "|    time_elapsed       | 928          |\n",
      "|    total_timesteps    | 279500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55899        |\n",
      "|    policy_loss        | 0.895        |\n",
      "|    reward             | -0.022259522 |\n",
      "|    std                | 2.56e+04     |\n",
      "|    value_loss         | 0.00178      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 301           |\n",
      "|    iterations         | 56000         |\n",
      "|    time_elapsed       | 930           |\n",
      "|    total_timesteps    | 280000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55999         |\n",
      "|    policy_loss        | -0.619        |\n",
      "|    reward             | -0.0012381268 |\n",
      "|    std                | 2.6e+04       |\n",
      "|    value_loss         | 0.000923      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 301           |\n",
      "|    iterations         | 56100         |\n",
      "|    time_elapsed       | 931           |\n",
      "|    total_timesteps    | 280500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.2         |\n",
      "|    explained_variance | -0.102        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56099         |\n",
      "|    policy_loss        | 0.831         |\n",
      "|    reward             | -0.0074841417 |\n",
      "|    std                | 2.68e+04      |\n",
      "|    value_loss         | 0.00268       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 56200        |\n",
      "|    time_elapsed       | 933          |\n",
      "|    total_timesteps    | 281000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56199        |\n",
      "|    policy_loss        | 0.554        |\n",
      "|    reward             | 0.0010037117 |\n",
      "|    std                | 2.75e+04     |\n",
      "|    value_loss         | 0.00103      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 56300        |\n",
      "|    time_elapsed       | 934          |\n",
      "|    total_timesteps    | 281500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56299        |\n",
      "|    policy_loss        | -1.39        |\n",
      "|    reward             | -0.014353408 |\n",
      "|    std                | 2.83e+04     |\n",
      "|    value_loss         | 0.00477      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 56400        |\n",
      "|    time_elapsed       | 936          |\n",
      "|    total_timesteps    | 282000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56399        |\n",
      "|    policy_loss        | -0.887       |\n",
      "|    reward             | -0.030937815 |\n",
      "|    std                | 2.85e+04     |\n",
      "|    value_loss         | 0.00817      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 56500       |\n",
      "|    time_elapsed       | 937         |\n",
      "|    total_timesteps    | 282500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56499       |\n",
      "|    policy_loss        | -0.233      |\n",
      "|    reward             | 0.016692385 |\n",
      "|    std                | 2.87e+04    |\n",
      "|    value_loss         | 0.000487    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 56600       |\n",
      "|    time_elapsed       | 939         |\n",
      "|    total_timesteps    | 283000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56599       |\n",
      "|    policy_loss        | -8.26       |\n",
      "|    reward             | -0.37033713 |\n",
      "|    std                | 2.95e+04    |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 56700       |\n",
      "|    time_elapsed       | 940         |\n",
      "|    total_timesteps    | 283500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56699       |\n",
      "|    policy_loss        | -2.7        |\n",
      "|    reward             | -0.27937654 |\n",
      "|    std                | 2.94e+04    |\n",
      "|    value_loss         | 0.0391      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 56800        |\n",
      "|    time_elapsed       | 941          |\n",
      "|    total_timesteps    | 284000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0.25         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56799        |\n",
      "|    policy_loss        | -13.2        |\n",
      "|    reward             | -0.028196204 |\n",
      "|    std                | 2.94e+04     |\n",
      "|    value_loss         | 0.351        |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -237438.90\n",
      "total_reward: -247438.90\n",
      "total_cost: 102.06\n",
      "total_trades: 5414\n",
      "Sharpe: -0.075\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 56900       |\n",
      "|    time_elapsed       | 943         |\n",
      "|    total_timesteps    | 284500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56899       |\n",
      "|    policy_loss        | 0.989       |\n",
      "|    reward             | 0.011923862 |\n",
      "|    std                | 2.95e+04    |\n",
      "|    value_loss         | 0.00212     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 301        |\n",
      "|    iterations         | 57000      |\n",
      "|    time_elapsed       | 945        |\n",
      "|    total_timesteps    | 285000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56999      |\n",
      "|    policy_loss        | -1.09      |\n",
      "|    reward             | 0.01361255 |\n",
      "|    std                | 2.99e+04   |\n",
      "|    value_loss         | 0.00249    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 57100       |\n",
      "|    time_elapsed       | 946         |\n",
      "|    total_timesteps    | 285500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57099       |\n",
      "|    policy_loss        | -0.824      |\n",
      "|    reward             | 0.029387014 |\n",
      "|    std                | 3.04e+04    |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 57200        |\n",
      "|    time_elapsed       | 948          |\n",
      "|    total_timesteps    | 286000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57199        |\n",
      "|    policy_loss        | 0.604        |\n",
      "|    reward             | -0.019659074 |\n",
      "|    std                | 3.07e+04     |\n",
      "|    value_loss         | 0.00079      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 57300       |\n",
      "|    time_elapsed       | 949         |\n",
      "|    total_timesteps    | 286500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | 0.602       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57299       |\n",
      "|    policy_loss        | 0.588       |\n",
      "|    reward             | 0.016498104 |\n",
      "|    std                | 3.15e+04    |\n",
      "|    value_loss         | 0.00117     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 57400        |\n",
      "|    time_elapsed       | 951          |\n",
      "|    total_timesteps    | 287000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57399        |\n",
      "|    policy_loss        | 0.285        |\n",
      "|    reward             | 0.0102938535 |\n",
      "|    std                | 3.17e+04     |\n",
      "|    value_loss         | 0.000309     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 57500        |\n",
      "|    time_elapsed       | 952          |\n",
      "|    total_timesteps    | 287500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57499        |\n",
      "|    policy_loss        | -3.21        |\n",
      "|    reward             | -0.017645117 |\n",
      "|    std                | 3.17e+04     |\n",
      "|    value_loss         | 0.0192       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 301       |\n",
      "|    iterations         | 57600     |\n",
      "|    time_elapsed       | 954       |\n",
      "|    total_timesteps    | 288000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 57599     |\n",
      "|    policy_loss        | 0.725     |\n",
      "|    reward             | 0.0384414 |\n",
      "|    std                | 3.18e+04  |\n",
      "|    value_loss         | 0.00109   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 301        |\n",
      "|    iterations         | 57700      |\n",
      "|    time_elapsed       | 955        |\n",
      "|    total_timesteps    | 288500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57699      |\n",
      "|    policy_loss        | -0.413     |\n",
      "|    reward             | 0.19678764 |\n",
      "|    std                | 3.23e+04   |\n",
      "|    value_loss         | 0.00137    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 57800       |\n",
      "|    time_elapsed       | 956         |\n",
      "|    total_timesteps    | 289000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57799       |\n",
      "|    policy_loss        | 2.65        |\n",
      "|    reward             | -0.44631767 |\n",
      "|    std                | 3.25e+04    |\n",
      "|    value_loss         | 0.0154      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 302       |\n",
      "|    iterations         | 57900     |\n",
      "|    time_elapsed       | 958       |\n",
      "|    total_timesteps    | 289500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.6     |\n",
      "|    explained_variance | 0.0709    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 57899     |\n",
      "|    policy_loss        | -0.392    |\n",
      "|    reward             | 0.0688338 |\n",
      "|    std                | 3.23e+04  |\n",
      "|    value_loss         | 0.0407    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 58000        |\n",
      "|    time_elapsed       | 959          |\n",
      "|    total_timesteps    | 290000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57999        |\n",
      "|    policy_loss        | 1.16         |\n",
      "|    reward             | -0.041076615 |\n",
      "|    std                | 3.23e+04     |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 58100       |\n",
      "|    time_elapsed       | 961         |\n",
      "|    total_timesteps    | 290500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58099       |\n",
      "|    policy_loss        | -0.383      |\n",
      "|    reward             | 0.025239779 |\n",
      "|    std                | 3.26e+04    |\n",
      "|    value_loss         | 0.000642    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 58200        |\n",
      "|    time_elapsed       | 962          |\n",
      "|    total_timesteps    | 291000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | -3.35        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58199        |\n",
      "|    policy_loss        | -0.883       |\n",
      "|    reward             | -0.017113062 |\n",
      "|    std                | 3.3e+04      |\n",
      "|    value_loss         | 0.00188      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 58300        |\n",
      "|    time_elapsed       | 964          |\n",
      "|    total_timesteps    | 291500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | -0.547       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58299        |\n",
      "|    policy_loss        | 0.98         |\n",
      "|    reward             | -0.011532147 |\n",
      "|    std                | 3.38e+04     |\n",
      "|    value_loss         | 0.00204      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 58400        |\n",
      "|    time_elapsed       | 965          |\n",
      "|    total_timesteps    | 292000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 0.000208     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58399        |\n",
      "|    policy_loss        | 0.698        |\n",
      "|    reward             | -0.010073492 |\n",
      "|    std                | 3.42e+04     |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 58500       |\n",
      "|    time_elapsed       | 967         |\n",
      "|    total_timesteps    | 292500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58499       |\n",
      "|    policy_loss        | 0.646       |\n",
      "|    reward             | 0.020674005 |\n",
      "|    std                | 3.43e+04    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 58600       |\n",
      "|    time_elapsed       | 968         |\n",
      "|    total_timesteps    | 293000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58599       |\n",
      "|    policy_loss        | 1.79        |\n",
      "|    reward             | 0.017065547 |\n",
      "|    std                | 3.53e+04    |\n",
      "|    value_loss         | 0.00751     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 58700      |\n",
      "|    time_elapsed       | 970        |\n",
      "|    total_timesteps    | 293500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 58699      |\n",
      "|    policy_loss        | -0.623     |\n",
      "|    reward             | 0.00937154 |\n",
      "|    std                | 3.59e+04   |\n",
      "|    value_loss         | 0.00102    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 302           |\n",
      "|    iterations         | 58800         |\n",
      "|    time_elapsed       | 971           |\n",
      "|    total_timesteps    | 294000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.8         |\n",
      "|    explained_variance | 0.471         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58799         |\n",
      "|    policy_loss        | 0.411         |\n",
      "|    reward             | -0.0013140885 |\n",
      "|    std                | 3.66e+04      |\n",
      "|    value_loss         | 0.000401      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 58900       |\n",
      "|    time_elapsed       | 973         |\n",
      "|    total_timesteps    | 294500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | 0.208       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58899       |\n",
      "|    policy_loss        | 0.545       |\n",
      "|    reward             | 0.012472526 |\n",
      "|    std                | 3.73e+04    |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 59000       |\n",
      "|    time_elapsed       | 974         |\n",
      "|    total_timesteps    | 295000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | 0.00189     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58999       |\n",
      "|    policy_loss        | 0.408       |\n",
      "|    reward             | -0.09828554 |\n",
      "|    std                | 3.82e+04    |\n",
      "|    value_loss         | 0.00313     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 59100       |\n",
      "|    time_elapsed       | 976         |\n",
      "|    total_timesteps    | 295500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59099       |\n",
      "|    policy_loss        | 6.06        |\n",
      "|    reward             | 0.010653925 |\n",
      "|    std                | 3.92e+04    |\n",
      "|    value_loss         | 0.0813      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 302            |\n",
      "|    iterations         | 59200          |\n",
      "|    time_elapsed       | 978            |\n",
      "|    total_timesteps    | 296000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -24            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 59199          |\n",
      "|    policy_loss        | -0.414         |\n",
      "|    reward             | -0.00056047726 |\n",
      "|    std                | 3.98e+04       |\n",
      "|    value_loss         | 0.00178        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 59300       |\n",
      "|    time_elapsed       | 979         |\n",
      "|    total_timesteps    | 296500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59299       |\n",
      "|    policy_loss        | 1.1         |\n",
      "|    reward             | 0.026667697 |\n",
      "|    std                | 4.02e+04    |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 59400       |\n",
      "|    time_elapsed       | 981         |\n",
      "|    total_timesteps    | 297000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0.294       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59399       |\n",
      "|    policy_loss        | 3.31        |\n",
      "|    reward             | -0.15026017 |\n",
      "|    std                | 4.03e+04    |\n",
      "|    value_loss         | 0.0452      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 59500      |\n",
      "|    time_elapsed       | 982        |\n",
      "|    total_timesteps    | 297500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59499      |\n",
      "|    policy_loss        | 0.45       |\n",
      "|    reward             | 0.24662958 |\n",
      "|    std                | 4.03e+04   |\n",
      "|    value_loss         | 0.00667    |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -239048.04\n",
      "total_reward: -249048.04\n",
      "total_cost: 101.90\n",
      "total_trades: 5414\n",
      "Sharpe: -0.282\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 59600        |\n",
      "|    time_elapsed       | 984          |\n",
      "|    total_timesteps    | 298000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59599        |\n",
      "|    policy_loss        | 0.324        |\n",
      "|    reward             | 0.0047821268 |\n",
      "|    std                | 4.03e+04     |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 59700        |\n",
      "|    time_elapsed       | 985          |\n",
      "|    total_timesteps    | 298500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59699        |\n",
      "|    policy_loss        | -0.289       |\n",
      "|    reward             | -0.011371463 |\n",
      "|    std                | 4.06e+04     |\n",
      "|    value_loss         | 0.000177     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 302           |\n",
      "|    iterations         | 59800         |\n",
      "|    time_elapsed       | 987           |\n",
      "|    total_timesteps    | 299000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59799         |\n",
      "|    policy_loss        | -0.636        |\n",
      "|    reward             | -0.0007870578 |\n",
      "|    std                | 4.13e+04      |\n",
      "|    value_loss         | 0.00104       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 59900       |\n",
      "|    time_elapsed       | 988         |\n",
      "|    total_timesteps    | 299500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59899       |\n",
      "|    policy_loss        | 0.0817      |\n",
      "|    reward             | 0.002845414 |\n",
      "|    std                | 4.23e+04    |\n",
      "|    value_loss         | 2.63e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 60000        |\n",
      "|    time_elapsed       | 990          |\n",
      "|    total_timesteps    | 300000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0.544        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59999        |\n",
      "|    policy_loss        | -0.319       |\n",
      "|    reward             | -0.005706021 |\n",
      "|    std                | 4.33e+04     |\n",
      "|    value_loss         | 0.000185     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 60100        |\n",
      "|    time_elapsed       | 991          |\n",
      "|    total_timesteps    | 300500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60099        |\n",
      "|    policy_loss        | 0.195        |\n",
      "|    reward             | 0.0019332153 |\n",
      "|    std                | 4.46e+04     |\n",
      "|    value_loss         | 8.94e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 60200        |\n",
      "|    time_elapsed       | 993          |\n",
      "|    total_timesteps    | 301000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60199        |\n",
      "|    policy_loss        | 0.772        |\n",
      "|    reward             | 0.0024706733 |\n",
      "|    std                | 4.55e+04     |\n",
      "|    value_loss         | 0.00167      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 303           |\n",
      "|    iterations         | 60300         |\n",
      "|    time_elapsed       | 994           |\n",
      "|    total_timesteps    | 301500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60299         |\n",
      "|    policy_loss        | -0.0177       |\n",
      "|    reward             | -0.0018772881 |\n",
      "|    std                | 4.67e+04      |\n",
      "|    value_loss         | 2.08e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 60400       |\n",
      "|    time_elapsed       | 996         |\n",
      "|    total_timesteps    | 302000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60399       |\n",
      "|    policy_loss        | -0.349      |\n",
      "|    reward             | 0.010232872 |\n",
      "|    std                | 4.84e+04    |\n",
      "|    value_loss         | 0.000266    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 303            |\n",
      "|    iterations         | 60500          |\n",
      "|    time_elapsed       | 997            |\n",
      "|    total_timesteps    | 302500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -24.5          |\n",
      "|    explained_variance | -3.1           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 60499          |\n",
      "|    policy_loss        | 0.0127         |\n",
      "|    reward             | -0.00085050275 |\n",
      "|    std                | 5.01e+04       |\n",
      "|    value_loss         | 1.07e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 60600        |\n",
      "|    time_elapsed       | 998          |\n",
      "|    total_timesteps    | 303000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60599        |\n",
      "|    policy_loss        | 0.256        |\n",
      "|    reward             | -0.002339157 |\n",
      "|    std                | 5.22e+04     |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 60700        |\n",
      "|    time_elapsed       | 1000         |\n",
      "|    total_timesteps    | 303500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60699        |\n",
      "|    policy_loss        | -0.105       |\n",
      "|    reward             | 0.0029789526 |\n",
      "|    std                | 5.37e+04     |\n",
      "|    value_loss         | 0.000279     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 60800        |\n",
      "|    time_elapsed       | 1001         |\n",
      "|    total_timesteps    | 304000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60799        |\n",
      "|    policy_loss        | -0.455       |\n",
      "|    reward             | -0.010414051 |\n",
      "|    std                | 5.44e+04     |\n",
      "|    value_loss         | 0.000362     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 60900       |\n",
      "|    time_elapsed       | 1003        |\n",
      "|    total_timesteps    | 304500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60899       |\n",
      "|    policy_loss        | 0.721       |\n",
      "|    reward             | 0.007503516 |\n",
      "|    std                | 5.59e+04    |\n",
      "|    value_loss         | 0.000923    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 61000        |\n",
      "|    time_elapsed       | 1004         |\n",
      "|    total_timesteps    | 305000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.8        |\n",
      "|    explained_variance | 0.00868      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60999        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | -0.014804645 |\n",
      "|    std                | 5.78e+04     |\n",
      "|    value_loss         | 3.65e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 61100       |\n",
      "|    time_elapsed       | 1006        |\n",
      "|    total_timesteps    | 305500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 0.168       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61099       |\n",
      "|    policy_loss        | -0.0658     |\n",
      "|    reward             | 0.042564243 |\n",
      "|    std                | 6.03e+04    |\n",
      "|    value_loss         | 0.000294    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 303           |\n",
      "|    iterations         | 61200         |\n",
      "|    time_elapsed       | 1007          |\n",
      "|    total_timesteps    | 306000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61199         |\n",
      "|    policy_loss        | -0.635        |\n",
      "|    reward             | -0.0032759805 |\n",
      "|    std                | 6.29e+04      |\n",
      "|    value_loss         | 0.000728      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 61300       |\n",
      "|    time_elapsed       | 1009        |\n",
      "|    total_timesteps    | 306500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61299       |\n",
      "|    policy_loss        | -1.42       |\n",
      "|    reward             | 0.004913106 |\n",
      "|    std                | 6.4e+04     |\n",
      "|    value_loss         | 0.00386     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 61400        |\n",
      "|    time_elapsed       | 1010         |\n",
      "|    total_timesteps    | 307000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61399        |\n",
      "|    policy_loss        | 0.821        |\n",
      "|    reward             | -0.016362764 |\n",
      "|    std                | 6.53e+04     |\n",
      "|    value_loss         | 0.00114      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 61500        |\n",
      "|    time_elapsed       | 1012         |\n",
      "|    total_timesteps    | 307500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0.0703       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61499        |\n",
      "|    policy_loss        | -1.33        |\n",
      "|    reward             | -0.032106433 |\n",
      "|    std                | 6.62e+04     |\n",
      "|    value_loss         | 0.00293      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 61600        |\n",
      "|    time_elapsed       | 1013         |\n",
      "|    total_timesteps    | 308000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61599        |\n",
      "|    policy_loss        | 1            |\n",
      "|    reward             | 0.0028069383 |\n",
      "|    std                | 6.72e+04     |\n",
      "|    value_loss         | 0.00174      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 303        |\n",
      "|    iterations         | 61700      |\n",
      "|    time_elapsed       | 1015       |\n",
      "|    total_timesteps    | 308500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | 0.194      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61699      |\n",
      "|    policy_loss        | 4.05       |\n",
      "|    reward             | 0.07150231 |\n",
      "|    std                | 6.84e+04   |\n",
      "|    value_loss         | 0.0294     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 303        |\n",
      "|    iterations         | 61800      |\n",
      "|    time_elapsed       | 1016       |\n",
      "|    total_timesteps    | 309000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61799      |\n",
      "|    policy_loss        | 1.58       |\n",
      "|    reward             | 0.11821017 |\n",
      "|    std                | 6.88e+04   |\n",
      "|    value_loss         | 0.00406    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 303           |\n",
      "|    iterations         | 61900         |\n",
      "|    time_elapsed       | 1018          |\n",
      "|    total_timesteps    | 309500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61899         |\n",
      "|    policy_loss        | -0.258        |\n",
      "|    reward             | -0.0060260114 |\n",
      "|    std                | 7e+04         |\n",
      "|    value_loss         | 0.000544      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 62000        |\n",
      "|    time_elapsed       | 1019         |\n",
      "|    total_timesteps    | 310000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | -0.00566     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61999        |\n",
      "|    policy_loss        | -0.348       |\n",
      "|    reward             | -0.036283314 |\n",
      "|    std                | 7.15e+04     |\n",
      "|    value_loss         | 0.000857     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 62100       |\n",
      "|    time_elapsed       | 1020        |\n",
      "|    total_timesteps    | 310500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.2       |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62099       |\n",
      "|    policy_loss        | -0.547      |\n",
      "|    reward             | -0.03474897 |\n",
      "|    std                | 7.33e+04    |\n",
      "|    value_loss         | 0.000608    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 62200       |\n",
      "|    time_elapsed       | 1022        |\n",
      "|    total_timesteps    | 311000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62199       |\n",
      "|    policy_loss        | 0.183       |\n",
      "|    reward             | 0.037752178 |\n",
      "|    std                | 7.44e+04    |\n",
      "|    value_loss         | 0.000326    |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -55953.22\n",
      "total_reward: -65953.22\n",
      "total_cost: 95.25\n",
      "total_trades: 5414\n",
      "Sharpe: 0.341\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 304        |\n",
      "|    iterations         | 62300      |\n",
      "|    time_elapsed       | 1023       |\n",
      "|    total_timesteps    | 311500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 62299      |\n",
      "|    policy_loss        | 0.686      |\n",
      "|    reward             | 0.02815912 |\n",
      "|    std                | 7.48e+04   |\n",
      "|    value_loss         | 0.00139    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 62400        |\n",
      "|    time_elapsed       | 1025         |\n",
      "|    total_timesteps    | 312000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62399        |\n",
      "|    policy_loss        | 0.809        |\n",
      "|    reward             | -0.022283234 |\n",
      "|    std                | 7.63e+04     |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 304        |\n",
      "|    iterations         | 62500      |\n",
      "|    time_elapsed       | 1026       |\n",
      "|    total_timesteps    | 312500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 62499      |\n",
      "|    policy_loss        | 0.421      |\n",
      "|    reward             | 0.02098638 |\n",
      "|    std                | 7.75e+04   |\n",
      "|    value_loss         | 0.000335   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 62600        |\n",
      "|    time_elapsed       | 1028         |\n",
      "|    total_timesteps    | 313000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62599        |\n",
      "|    policy_loss        | -0.0316      |\n",
      "|    reward             | -0.011923544 |\n",
      "|    std                | 7.91e+04     |\n",
      "|    value_loss         | 0.000353     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 62700       |\n",
      "|    time_elapsed       | 1029        |\n",
      "|    total_timesteps    | 313500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | 0.103       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62699       |\n",
      "|    policy_loss        | 0.408       |\n",
      "|    reward             | -0.00605655 |\n",
      "|    std                | 8.14e+04    |\n",
      "|    value_loss         | 0.000365    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 62800        |\n",
      "|    time_elapsed       | 1031         |\n",
      "|    total_timesteps    | 314000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62799        |\n",
      "|    policy_loss        | 0.509        |\n",
      "|    reward             | 0.0049585206 |\n",
      "|    std                | 8.52e+04     |\n",
      "|    value_loss         | 0.000402     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 62900       |\n",
      "|    time_elapsed       | 1032        |\n",
      "|    total_timesteps    | 314500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62899       |\n",
      "|    policy_loss        | -3.74       |\n",
      "|    reward             | 0.040110026 |\n",
      "|    std                | 8.6e+04     |\n",
      "|    value_loss         | 0.0207      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 63000        |\n",
      "|    time_elapsed       | 1034         |\n",
      "|    total_timesteps    | 315000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62999        |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | -0.014890242 |\n",
      "|    std                | 8.74e+04     |\n",
      "|    value_loss         | 0.000216     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 63100       |\n",
      "|    time_elapsed       | 1035        |\n",
      "|    total_timesteps    | 315500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0.0564      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63099       |\n",
      "|    policy_loss        | 0.615       |\n",
      "|    reward             | 0.003218105 |\n",
      "|    std                | 8.97e+04    |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 63200       |\n",
      "|    time_elapsed       | 1037        |\n",
      "|    total_timesteps    | 316000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.7       |\n",
      "|    explained_variance | 0.355       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63199       |\n",
      "|    policy_loss        | 0.265       |\n",
      "|    reward             | 0.013442797 |\n",
      "|    std                | 9.15e+04    |\n",
      "|    value_loss         | 0.00133     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 63300       |\n",
      "|    time_elapsed       | 1038        |\n",
      "|    total_timesteps    | 316500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63299       |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    reward             | -0.06461499 |\n",
      "|    std                | 9.29e+04    |\n",
      "|    value_loss         | 0.00612     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 63400       |\n",
      "|    time_elapsed       | 1039        |\n",
      "|    total_timesteps    | 317000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63399       |\n",
      "|    policy_loss        | 0.464       |\n",
      "|    reward             | 0.009461972 |\n",
      "|    std                | 9.46e+04    |\n",
      "|    value_loss         | 0.000365    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 63500        |\n",
      "|    time_elapsed       | 1041         |\n",
      "|    total_timesteps    | 317500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63499        |\n",
      "|    policy_loss        | 0.347        |\n",
      "|    reward             | -0.025026765 |\n",
      "|    std                | 9.63e+04     |\n",
      "|    value_loss         | 0.000313     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 304           |\n",
      "|    iterations         | 63600         |\n",
      "|    time_elapsed       | 1043          |\n",
      "|    total_timesteps    | 318000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63599         |\n",
      "|    policy_loss        | -0.517        |\n",
      "|    reward             | -0.0016412062 |\n",
      "|    std                | 9.88e+04      |\n",
      "|    value_loss         | 0.00053       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 63700        |\n",
      "|    time_elapsed       | 1044         |\n",
      "|    total_timesteps    | 318500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63699        |\n",
      "|    policy_loss        | 0.0733       |\n",
      "|    reward             | 0.0005472937 |\n",
      "|    std                | 1.03e+05     |\n",
      "|    value_loss         | 1.64e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 63800       |\n",
      "|    time_elapsed       | 1046        |\n",
      "|    total_timesteps    | 319000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | 0.000161    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63799       |\n",
      "|    policy_loss        | 0.533       |\n",
      "|    reward             | 0.010056713 |\n",
      "|    std                | 1.07e+05    |\n",
      "|    value_loss         | 0.000593    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 63900        |\n",
      "|    time_elapsed       | 1047         |\n",
      "|    total_timesteps    | 319500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63899        |\n",
      "|    policy_loss        | 0.225        |\n",
      "|    reward             | -0.010847232 |\n",
      "|    std                | 1.11e+05     |\n",
      "|    value_loss         | 0.00015      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 64000       |\n",
      "|    time_elapsed       | 1049        |\n",
      "|    total_timesteps    | 320000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63999       |\n",
      "|    policy_loss        | -2.37       |\n",
      "|    reward             | 0.011371092 |\n",
      "|    std                | 1.12e+05    |\n",
      "|    value_loss         | 0.0164      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 64100        |\n",
      "|    time_elapsed       | 1050         |\n",
      "|    total_timesteps    | 320500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64099        |\n",
      "|    policy_loss        | -0.166       |\n",
      "|    reward             | -0.044149943 |\n",
      "|    std                | 1.14e+05     |\n",
      "|    value_loss         | 0.000683     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 64200     |\n",
      "|    time_elapsed       | 1052      |\n",
      "|    total_timesteps    | 321000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -26.2     |\n",
      "|    explained_variance | -0.274    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 64199     |\n",
      "|    policy_loss        | 9.06      |\n",
      "|    reward             | 0.3011591 |\n",
      "|    std                | 1.16e+05  |\n",
      "|    value_loss         | 0.164     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 64300        |\n",
      "|    time_elapsed       | 1053         |\n",
      "|    total_timesteps    | 321500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0.536        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64299        |\n",
      "|    policy_loss        | 4.07         |\n",
      "|    reward             | -0.030816276 |\n",
      "|    std                | 1.17e+05     |\n",
      "|    value_loss         | 0.0277       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 305        |\n",
      "|    iterations         | 64400      |\n",
      "|    time_elapsed       | 1055       |\n",
      "|    total_timesteps    | 322000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64399      |\n",
      "|    policy_loss        | 4.5        |\n",
      "|    reward             | 0.41660064 |\n",
      "|    std                | 1.17e+05   |\n",
      "|    value_loss         | 0.0395     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 64500       |\n",
      "|    time_elapsed       | 1056        |\n",
      "|    total_timesteps    | 322500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64499       |\n",
      "|    policy_loss        | 1.56        |\n",
      "|    reward             | 0.015683975 |\n",
      "|    std                | 1.16e+05    |\n",
      "|    value_loss         | 0.0144      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 64600        |\n",
      "|    time_elapsed       | 1057         |\n",
      "|    total_timesteps    | 323000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64599        |\n",
      "|    policy_loss        | -0.283       |\n",
      "|    reward             | -0.012634653 |\n",
      "|    std                | 1.18e+05     |\n",
      "|    value_loss         | 0.00132      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 64700       |\n",
      "|    time_elapsed       | 1059        |\n",
      "|    total_timesteps    | 323500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64699       |\n",
      "|    policy_loss        | 5.33        |\n",
      "|    reward             | -0.08955723 |\n",
      "|    std                | 1.19e+05    |\n",
      "|    value_loss         | 0.0525      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 64800         |\n",
      "|    time_elapsed       | 1060          |\n",
      "|    total_timesteps    | 324000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.2         |\n",
      "|    explained_variance | 0.558         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64799         |\n",
      "|    policy_loss        | -1.13         |\n",
      "|    reward             | -0.0076154093 |\n",
      "|    std                | 1.2e+05       |\n",
      "|    value_loss         | 0.00619       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 64900     |\n",
      "|    time_elapsed       | 1062      |\n",
      "|    total_timesteps    | 324500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -26.2     |\n",
      "|    explained_variance | 0.708     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 64899     |\n",
      "|    policy_loss        | 1.57      |\n",
      "|    reward             | 0.0698988 |\n",
      "|    std                | 1.2e+05   |\n",
      "|    value_loss         | 0.00788   |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -235257.77\n",
      "total_reward: -245257.77\n",
      "total_cost: 104.85\n",
      "total_trades: 5414\n",
      "Sharpe: 0.217\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 305        |\n",
      "|    iterations         | 65000      |\n",
      "|    time_elapsed       | 1063       |\n",
      "|    total_timesteps    | 325000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64999      |\n",
      "|    policy_loss        | 2.91       |\n",
      "|    reward             | 0.08356125 |\n",
      "|    std                | 1.2e+05    |\n",
      "|    value_loss         | 0.0161     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 65100       |\n",
      "|    time_elapsed       | 1065        |\n",
      "|    total_timesteps    | 325500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65099       |\n",
      "|    policy_loss        | 0.417       |\n",
      "|    reward             | -0.03889309 |\n",
      "|    std                | 1.21e+05    |\n",
      "|    value_loss         | 0.00126     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 305        |\n",
      "|    iterations         | 65200      |\n",
      "|    time_elapsed       | 1066       |\n",
      "|    total_timesteps    | 326000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65199      |\n",
      "|    policy_loss        | -1.59      |\n",
      "|    reward             | 0.06265128 |\n",
      "|    std                | 1.22e+05   |\n",
      "|    value_loss         | 0.00673    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 65300       |\n",
      "|    time_elapsed       | 1068        |\n",
      "|    total_timesteps    | 326500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | -9.54e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65299       |\n",
      "|    policy_loss        | 4.37        |\n",
      "|    reward             | 0.057892576 |\n",
      "|    std                | 1.22e+05    |\n",
      "|    value_loss         | 0.0418      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 305        |\n",
      "|    iterations         | 65400      |\n",
      "|    time_elapsed       | 1069       |\n",
      "|    total_timesteps    | 327000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.3      |\n",
      "|    explained_variance | 5.72e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65399      |\n",
      "|    policy_loss        | 4.14       |\n",
      "|    reward             | 0.04083499 |\n",
      "|    std                | 1.23e+05   |\n",
      "|    value_loss         | 0.0315     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 65500       |\n",
      "|    time_elapsed       | 1071        |\n",
      "|    total_timesteps    | 327500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65499       |\n",
      "|    policy_loss        | -6.55       |\n",
      "|    reward             | -0.18864493 |\n",
      "|    std                | 1.24e+05    |\n",
      "|    value_loss         | 0.251       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 65600       |\n",
      "|    time_elapsed       | 1072        |\n",
      "|    total_timesteps    | 328000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65599       |\n",
      "|    policy_loss        | -0.542      |\n",
      "|    reward             | -0.01463478 |\n",
      "|    std                | 1.25e+05    |\n",
      "|    value_loss         | 0.000882    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 65700        |\n",
      "|    time_elapsed       | 1074         |\n",
      "|    total_timesteps    | 328500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65699        |\n",
      "|    policy_loss        | -0.459       |\n",
      "|    reward             | 0.0073541915 |\n",
      "|    std                | 1.25e+05     |\n",
      "|    value_loss         | 0.000526     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 65800       |\n",
      "|    time_elapsed       | 1075        |\n",
      "|    total_timesteps    | 329000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65799       |\n",
      "|    policy_loss        | 2.33        |\n",
      "|    reward             | 0.014317893 |\n",
      "|    std                | 1.27e+05    |\n",
      "|    value_loss         | 0.0151      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 65900        |\n",
      "|    time_elapsed       | 1077         |\n",
      "|    total_timesteps    | 329500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0.253        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65899        |\n",
      "|    policy_loss        | 1.24         |\n",
      "|    reward             | -0.066693105 |\n",
      "|    std                | 1.29e+05     |\n",
      "|    value_loss         | 0.00366      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 66000         |\n",
      "|    time_elapsed       | 1078          |\n",
      "|    total_timesteps    | 330000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.4         |\n",
      "|    explained_variance | 0.311         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 65999         |\n",
      "|    policy_loss        | -5.53         |\n",
      "|    reward             | -0.0017399292 |\n",
      "|    std                | 1.3e+05       |\n",
      "|    value_loss         | 0.0431        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 66100        |\n",
      "|    time_elapsed       | 1080         |\n",
      "|    total_timesteps    | 330500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66099        |\n",
      "|    policy_loss        | -2.57        |\n",
      "|    reward             | -0.038059458 |\n",
      "|    std                | 1.31e+05     |\n",
      "|    value_loss         | 0.013        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 305        |\n",
      "|    iterations         | 66200      |\n",
      "|    time_elapsed       | 1081       |\n",
      "|    total_timesteps    | 331000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66199      |\n",
      "|    policy_loss        | 1.23       |\n",
      "|    reward             | 0.09684872 |\n",
      "|    std                | 1.31e+05   |\n",
      "|    value_loss         | 0.00496    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 66300        |\n",
      "|    time_elapsed       | 1083         |\n",
      "|    total_timesteps    | 331500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66299        |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.094922565 |\n",
      "|    std                | 1.32e+05     |\n",
      "|    value_loss         | 0.00358      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 66400        |\n",
      "|    time_elapsed       | 1084         |\n",
      "|    total_timesteps    | 332000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 0.0675       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66399        |\n",
      "|    policy_loss        | 7.04         |\n",
      "|    reward             | -0.025636835 |\n",
      "|    std                | 1.34e+05     |\n",
      "|    value_loss         | 0.0779       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 66500      |\n",
      "|    time_elapsed       | 1085       |\n",
      "|    total_timesteps    | 332500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.5      |\n",
      "|    explained_variance | 6.56e-06   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66499      |\n",
      "|    policy_loss        | -5.74      |\n",
      "|    reward             | -0.7779116 |\n",
      "|    std                | 1.35e+05   |\n",
      "|    value_loss         | 0.0722     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 66600      |\n",
      "|    time_elapsed       | 1087       |\n",
      "|    total_timesteps    | 333000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.5      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66599      |\n",
      "|    policy_loss        | -9.97      |\n",
      "|    reward             | -0.8090876 |\n",
      "|    std                | 1.37e+05   |\n",
      "|    value_loss         | 0.152      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 66700       |\n",
      "|    time_elapsed       | 1088        |\n",
      "|    total_timesteps    | 333500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66699       |\n",
      "|    policy_loss        | 0.568       |\n",
      "|    reward             | 0.004089825 |\n",
      "|    std                | 1.36e+05    |\n",
      "|    value_loss         | 0.00181     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 66800       |\n",
      "|    time_elapsed       | 1090        |\n",
      "|    total_timesteps    | 334000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66799       |\n",
      "|    policy_loss        | -0.187      |\n",
      "|    reward             | 0.022721272 |\n",
      "|    std                | 1.38e+05    |\n",
      "|    value_loss         | 0.000362    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 66900       |\n",
      "|    time_elapsed       | 1091        |\n",
      "|    total_timesteps    | 334500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | -0.341      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66899       |\n",
      "|    policy_loss        | -0.397      |\n",
      "|    reward             | 0.022206783 |\n",
      "|    std                | 1.4e+05     |\n",
      "|    value_loss         | 0.000387    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 67000         |\n",
      "|    time_elapsed       | 1093          |\n",
      "|    total_timesteps    | 335000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66999         |\n",
      "|    policy_loss        | -0.879        |\n",
      "|    reward             | -0.0059970017 |\n",
      "|    std                | 1.42e+05      |\n",
      "|    value_loss         | 0.00386       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 67100        |\n",
      "|    time_elapsed       | 1094         |\n",
      "|    total_timesteps    | 335500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67099        |\n",
      "|    policy_loss        | -0.576       |\n",
      "|    reward             | -0.054946903 |\n",
      "|    std                | 1.44e+05     |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 67200        |\n",
      "|    time_elapsed       | 1096         |\n",
      "|    total_timesteps    | 336000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67199        |\n",
      "|    policy_loss        | 0.522        |\n",
      "|    reward             | -0.010910059 |\n",
      "|    std                | 1.45e+05     |\n",
      "|    value_loss         | 0.000435     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 67300        |\n",
      "|    time_elapsed       | 1097         |\n",
      "|    total_timesteps    | 336500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67299        |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | 0.0019193809 |\n",
      "|    std                | 1.48e+05     |\n",
      "|    value_loss         | 5.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 67400        |\n",
      "|    time_elapsed       | 1099         |\n",
      "|    total_timesteps    | 337000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67399        |\n",
      "|    policy_loss        | -0.188       |\n",
      "|    reward             | -0.001137833 |\n",
      "|    std                | 1.53e+05     |\n",
      "|    value_loss         | 0.000355     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 67500        |\n",
      "|    time_elapsed       | 1100         |\n",
      "|    total_timesteps    | 337500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67499        |\n",
      "|    policy_loss        | 0.213        |\n",
      "|    reward             | 0.0058858097 |\n",
      "|    std                | 1.57e+05     |\n",
      "|    value_loss         | 7.24e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 67600        |\n",
      "|    time_elapsed       | 1102         |\n",
      "|    total_timesteps    | 338000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67599        |\n",
      "|    policy_loss        | -0.226       |\n",
      "|    reward             | -0.021501483 |\n",
      "|    std                | 1.64e+05     |\n",
      "|    value_loss         | 0.000418     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2707, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -7978.25\n",
      "total_reward: -17978.25\n",
      "total_cost: 601.60\n",
      "total_trades: 5414\n",
      "Sharpe: -0.061\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 67700         |\n",
      "|    time_elapsed       | 1103          |\n",
      "|    total_timesteps    | 338500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 67699         |\n",
      "|    policy_loss        | 0.163         |\n",
      "|    reward             | -0.0064279265 |\n",
      "|    std                | 1.68e+05      |\n",
      "|    value_loss         | 8.27e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 67800        |\n",
      "|    time_elapsed       | 1104         |\n",
      "|    total_timesteps    | 339000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67799        |\n",
      "|    policy_loss        | -0.568       |\n",
      "|    reward             | -0.034396086 |\n",
      "|    std                | 1.72e+05     |\n",
      "|    value_loss         | 0.000973     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 67900       |\n",
      "|    time_elapsed       | 1106        |\n",
      "|    total_timesteps    | 339500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67899       |\n",
      "|    policy_loss        | -0.00405    |\n",
      "|    reward             | 0.019542411 |\n",
      "|    std                | 1.76e+05    |\n",
      "|    value_loss         | 0.000158    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 68000      |\n",
      "|    time_elapsed       | 1108       |\n",
      "|    total_timesteps    | 340000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27        |\n",
      "|    explained_variance | -2.28e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67999      |\n",
      "|    policy_loss        | -0.471     |\n",
      "|    reward             | -0.0297219 |\n",
      "|    std                | 1.8e+05    |\n",
      "|    value_loss         | 0.00121    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 68100       |\n",
      "|    time_elapsed       | 1109        |\n",
      "|    total_timesteps    | 340500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68099       |\n",
      "|    policy_loss        | -0.767      |\n",
      "|    reward             | 0.015695225 |\n",
      "|    std                | 1.82e+05    |\n",
      "|    value_loss         | 0.00189     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 68200     |\n",
      "|    time_elapsed       | 1111      |\n",
      "|    total_timesteps    | 341000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 68199     |\n",
      "|    policy_loss        | -1.45     |\n",
      "|    reward             | 0.2976874 |\n",
      "|    std                | 1.82e+05  |\n",
      "|    value_loss         | 0.0115    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 68300        |\n",
      "|    time_elapsed       | 1112         |\n",
      "|    total_timesteps    | 341500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68299        |\n",
      "|    policy_loss        | 2.32         |\n",
      "|    reward             | -0.020652935 |\n",
      "|    std                | 1.84e+05     |\n",
      "|    value_loss         | 0.00894      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 68400        |\n",
      "|    time_elapsed       | 1114         |\n",
      "|    total_timesteps    | 342000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68399        |\n",
      "|    policy_loss        | -1.19        |\n",
      "|    reward             | 0.0019652143 |\n",
      "|    std                | 1.83e+05     |\n",
      "|    value_loss         | 0.00283      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 68500        |\n",
      "|    time_elapsed       | 1115         |\n",
      "|    total_timesteps    | 342500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | 0.583        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68499        |\n",
      "|    policy_loss        | -0.251       |\n",
      "|    reward             | -0.003936429 |\n",
      "|    std                | 1.86e+05     |\n",
      "|    value_loss         | 0.000155     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 68600        |\n",
      "|    time_elapsed       | 1117         |\n",
      "|    total_timesteps    | 343000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | -0.788       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68599        |\n",
      "|    policy_loss        | -0.0254      |\n",
      "|    reward             | -0.020473406 |\n",
      "|    std                | 1.91e+05     |\n",
      "|    value_loss         | 8.87e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 68700         |\n",
      "|    time_elapsed       | 1118          |\n",
      "|    total_timesteps    | 343500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68699         |\n",
      "|    policy_loss        | -0.553        |\n",
      "|    reward             | -0.0016787201 |\n",
      "|    std                | 1.97e+05      |\n",
      "|    value_loss         | 0.000645      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 68800        |\n",
      "|    time_elapsed       | 1120         |\n",
      "|    total_timesteps    | 344000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68799        |\n",
      "|    policy_loss        | -1.12        |\n",
      "|    reward             | -0.026708312 |\n",
      "|    std                | 2e+05        |\n",
      "|    value_loss         | 0.00236      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 68900        |\n",
      "|    time_elapsed       | 1121         |\n",
      "|    total_timesteps    | 344500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68899        |\n",
      "|    policy_loss        | -0.735       |\n",
      "|    reward             | -0.007606177 |\n",
      "|    std                | 2.04e+05     |\n",
      "|    value_loss         | 0.000744     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 69000       |\n",
      "|    time_elapsed       | 1123        |\n",
      "|    total_timesteps    | 345000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68999       |\n",
      "|    policy_loss        | 0.0351      |\n",
      "|    reward             | 0.008982182 |\n",
      "|    std                | 2.08e+05    |\n",
      "|    value_loss         | 1.51e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 69100         |\n",
      "|    time_elapsed       | 1124          |\n",
      "|    total_timesteps    | 345500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.4         |\n",
      "|    explained_variance | 0.151         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 69099         |\n",
      "|    policy_loss        | -0.339        |\n",
      "|    reward             | -0.0033522905 |\n",
      "|    std                | 2.13e+05      |\n",
      "|    value_loss         | 0.000213      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 69200      |\n",
      "|    time_elapsed       | 1126       |\n",
      "|    total_timesteps    | 346000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.4      |\n",
      "|    explained_variance | 0.559      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69199      |\n",
      "|    policy_loss        | -0.255     |\n",
      "|    reward             | 0.02502147 |\n",
      "|    std                | 2.2e+05    |\n",
      "|    value_loss         | 8.41e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 69300        |\n",
      "|    time_elapsed       | 1127         |\n",
      "|    total_timesteps    | 346500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69299        |\n",
      "|    policy_loss        | -0.154       |\n",
      "|    reward             | -0.009574655 |\n",
      "|    std                | 2.28e+05     |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 69400       |\n",
      "|    time_elapsed       | 1129        |\n",
      "|    total_timesteps    | 347000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69399       |\n",
      "|    policy_loss        | 0.101       |\n",
      "|    reward             | -0.01723977 |\n",
      "|    std                | 2.35e+05    |\n",
      "|    value_loss         | 0.000426    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 69500        |\n",
      "|    time_elapsed       | 1130         |\n",
      "|    total_timesteps    | 347500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69499        |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | -0.004034526 |\n",
      "|    std                | 2.42e+05     |\n",
      "|    value_loss         | 6.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 69600        |\n",
      "|    time_elapsed       | 1132         |\n",
      "|    total_timesteps    | 348000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69599        |\n",
      "|    policy_loss        | -0.485       |\n",
      "|    reward             | 0.0144408615 |\n",
      "|    std                | 2.53e+05     |\n",
      "|    value_loss         | 0.000471     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 69700       |\n",
      "|    time_elapsed       | 1133        |\n",
      "|    total_timesteps    | 348500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.8       |\n",
      "|    explained_variance | 0.0235      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69699       |\n",
      "|    policy_loss        | -0.0982     |\n",
      "|    reward             | 0.004393045 |\n",
      "|    std                | 2.64e+05    |\n",
      "|    value_loss         | 6.71e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 69800        |\n",
      "|    time_elapsed       | 1135         |\n",
      "|    total_timesteps    | 349000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | -0.375       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69799        |\n",
      "|    policy_loss        | 0.142        |\n",
      "|    reward             | -0.004970453 |\n",
      "|    std                | 2.78e+05     |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 69900      |\n",
      "|    time_elapsed       | 1136       |\n",
      "|    total_timesteps    | 349500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.9      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69899      |\n",
      "|    policy_loss        | -2.12      |\n",
      "|    reward             | 0.08298416 |\n",
      "|    std                | 2.79e+05   |\n",
      "|    value_loss         | 0.00645    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 70000        |\n",
      "|    time_elapsed       | 1138         |\n",
      "|    total_timesteps    | 350000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69999        |\n",
      "|    policy_loss        | 2.34         |\n",
      "|    reward             | -0.039515216 |\n",
      "|    std                | 2.83e+05     |\n",
      "|    value_loss         | 0.00858      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 70100      |\n",
      "|    time_elapsed       | 1139       |\n",
      "|    total_timesteps    | 350500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 70099      |\n",
      "|    policy_loss        | -0.477     |\n",
      "|    reward             | 0.10728235 |\n",
      "|    std                | 2.86e+05   |\n",
      "|    value_loss         | 0.00264    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 70200      |\n",
      "|    time_elapsed       | 1141       |\n",
      "|    total_timesteps    | 351000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28        |\n",
      "|    explained_variance | -0.0154    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 70199      |\n",
      "|    policy_loss        | -5.87      |\n",
      "|    reward             | 0.16831979 |\n",
      "|    std                | 2.87e+05   |\n",
      "|    value_loss         | 0.0481     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 70300       |\n",
      "|    time_elapsed       | 1142        |\n",
      "|    total_timesteps    | 351500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 0.174       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70299       |\n",
      "|    policy_loss        | -11.4       |\n",
      "|    reward             | -0.25601348 |\n",
      "|    std                | 2.87e+05    |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 70400     |\n",
      "|    time_elapsed       | 1144      |\n",
      "|    total_timesteps    | 352000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 5.44e-05  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 70399     |\n",
      "|    policy_loss        | 30        |\n",
      "|    reward             | -0.542634 |\n",
      "|    std                | 2.92e+05  |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -226608.26\n",
      "total_reward: -236608.26\n",
      "total_cost: 105.00\n",
      "total_trades: 5414\n",
      "Sharpe: -0.371\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 70500        |\n",
      "|    time_elapsed       | 1145         |\n",
      "|    total_timesteps    | 352500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70499        |\n",
      "|    policy_loss        | -1.14        |\n",
      "|    reward             | 0.0031163641 |\n",
      "|    std                | 2.96e+05     |\n",
      "|    value_loss         | 0.00356      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 70600       |\n",
      "|    time_elapsed       | 1146        |\n",
      "|    total_timesteps    | 353000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70599       |\n",
      "|    policy_loss        | -0.415      |\n",
      "|    reward             | 0.031180441 |\n",
      "|    std                | 3e+05       |\n",
      "|    value_loss         | 0.000806    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 70700        |\n",
      "|    time_elapsed       | 1148         |\n",
      "|    total_timesteps    | 353500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | -0.0645      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70699        |\n",
      "|    policy_loss        | 0.398        |\n",
      "|    reward             | -0.010295045 |\n",
      "|    std                | 3.07e+05     |\n",
      "|    value_loss         | 0.000642     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 70800        |\n",
      "|    time_elapsed       | 1149         |\n",
      "|    total_timesteps    | 354000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0.374        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70799        |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.012765372 |\n",
      "|    std                | 3.12e+05     |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 70900        |\n",
      "|    time_elapsed       | 1151         |\n",
      "|    total_timesteps    | 354500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70899        |\n",
      "|    policy_loss        | -0.455       |\n",
      "|    reward             | -0.008628907 |\n",
      "|    std                | 3.19e+05     |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 71000       |\n",
      "|    time_elapsed       | 1152        |\n",
      "|    total_timesteps    | 355000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70999       |\n",
      "|    policy_loss        | -0.556      |\n",
      "|    reward             | 0.020198304 |\n",
      "|    std                | 3.27e+05    |\n",
      "|    value_loss         | 0.00119     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 71100         |\n",
      "|    time_elapsed       | 1154          |\n",
      "|    total_timesteps    | 355500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71099         |\n",
      "|    policy_loss        | 0.31          |\n",
      "|    reward             | -0.0077797687 |\n",
      "|    std                | 3.35e+05      |\n",
      "|    value_loss         | 0.000436      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 71200       |\n",
      "|    time_elapsed       | 1155        |\n",
      "|    total_timesteps    | 356000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | -0.0563     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71199       |\n",
      "|    policy_loss        | -0.617      |\n",
      "|    reward             | 0.020937322 |\n",
      "|    std                | 3.36e+05    |\n",
      "|    value_loss         | 0.000812    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 71300        |\n",
      "|    time_elapsed       | 1157         |\n",
      "|    total_timesteps    | 356500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71299        |\n",
      "|    policy_loss        | -1.28        |\n",
      "|    reward             | 0.0060225893 |\n",
      "|    std                | 3.43e+05     |\n",
      "|    value_loss         | 0.0021       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 71400       |\n",
      "|    time_elapsed       | 1158        |\n",
      "|    total_timesteps    | 357000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | 0.0252      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71399       |\n",
      "|    policy_loss        | 0.989       |\n",
      "|    reward             | 0.018595962 |\n",
      "|    std                | 3.44e+05    |\n",
      "|    value_loss         | 0.00181     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 71500       |\n",
      "|    time_elapsed       | 1160        |\n",
      "|    total_timesteps    | 357500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71499       |\n",
      "|    policy_loss        | -2.22       |\n",
      "|    reward             | 0.063110605 |\n",
      "|    std                | 3.45e+05    |\n",
      "|    value_loss         | 0.00651     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 71600       |\n",
      "|    time_elapsed       | 1161        |\n",
      "|    total_timesteps    | 358000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71599       |\n",
      "|    policy_loss        | -0.334      |\n",
      "|    reward             | -0.05253122 |\n",
      "|    std                | 3.48e+05    |\n",
      "|    value_loss         | 0.000522    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 71700        |\n",
      "|    time_elapsed       | 1163         |\n",
      "|    total_timesteps    | 358500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71699        |\n",
      "|    policy_loss        | 0.459        |\n",
      "|    reward             | -0.006172051 |\n",
      "|    std                | 3.56e+05     |\n",
      "|    value_loss         | 0.000449     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 71800        |\n",
      "|    time_elapsed       | 1164         |\n",
      "|    total_timesteps    | 359000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71799        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | 0.0051773703 |\n",
      "|    std                | 3.61e+05     |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 308        |\n",
      "|    iterations         | 71900      |\n",
      "|    time_elapsed       | 1166       |\n",
      "|    total_timesteps    | 359500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.5      |\n",
      "|    explained_variance | 0.407      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71899      |\n",
      "|    policy_loss        | -0.986     |\n",
      "|    reward             | 0.08519025 |\n",
      "|    std                | 3.67e+05   |\n",
      "|    value_loss         | 0.00164    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 72000        |\n",
      "|    time_elapsed       | 1167         |\n",
      "|    total_timesteps    | 360000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71999        |\n",
      "|    policy_loss        | 1.9          |\n",
      "|    reward             | -0.017788125 |\n",
      "|    std                | 3.7e+05      |\n",
      "|    value_loss         | 0.00747      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 72100       |\n",
      "|    time_elapsed       | 1169        |\n",
      "|    total_timesteps    | 360500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72099       |\n",
      "|    policy_loss        | 0.519       |\n",
      "|    reward             | 0.033934373 |\n",
      "|    std                | 3.74e+05    |\n",
      "|    value_loss         | 0.00158     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 72200       |\n",
      "|    time_elapsed       | 1170        |\n",
      "|    total_timesteps    | 361000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72199       |\n",
      "|    policy_loss        | 0.394       |\n",
      "|    reward             | 0.008622882 |\n",
      "|    std                | 3.82e+05    |\n",
      "|    value_loss         | 0.000556    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 72300       |\n",
      "|    time_elapsed       | 1172        |\n",
      "|    total_timesteps    | 361500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.6       |\n",
      "|    explained_variance | 0.00912     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72299       |\n",
      "|    policy_loss        | 1.79        |\n",
      "|    reward             | -0.03410553 |\n",
      "|    std                | 3.9e+05     |\n",
      "|    value_loss         | 0.00542     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 72400        |\n",
      "|    time_elapsed       | 1173         |\n",
      "|    total_timesteps    | 362000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0.044        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72399        |\n",
      "|    policy_loss        | -1.81        |\n",
      "|    reward             | -0.023238013 |\n",
      "|    std                | 3.92e+05     |\n",
      "|    value_loss         | 0.00752      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 72500        |\n",
      "|    time_elapsed       | 1175         |\n",
      "|    total_timesteps    | 362500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72499        |\n",
      "|    policy_loss        | 7.4          |\n",
      "|    reward             | -0.033830132 |\n",
      "|    std                | 3.9e+05      |\n",
      "|    value_loss         | 0.0752       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 72600       |\n",
      "|    time_elapsed       | 1176        |\n",
      "|    total_timesteps    | 363000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72599       |\n",
      "|    policy_loss        | -0.994      |\n",
      "|    reward             | 0.027806599 |\n",
      "|    std                | 3.97e+05    |\n",
      "|    value_loss         | 0.00139     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 72700       |\n",
      "|    time_elapsed       | 1178        |\n",
      "|    total_timesteps    | 363500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72699       |\n",
      "|    policy_loss        | -0.213      |\n",
      "|    reward             | -0.01217032 |\n",
      "|    std                | 4.01e+05    |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 72800        |\n",
      "|    time_elapsed       | 1179         |\n",
      "|    total_timesteps    | 364000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72799        |\n",
      "|    policy_loss        | 0.104        |\n",
      "|    reward             | -0.019392928 |\n",
      "|    std                | 4.07e+05     |\n",
      "|    value_loss         | 0.000135     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 72900         |\n",
      "|    time_elapsed       | 1181          |\n",
      "|    total_timesteps    | 364500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.7         |\n",
      "|    explained_variance | 0.203         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 72899         |\n",
      "|    policy_loss        | 0.737         |\n",
      "|    reward             | 0.00045062028 |\n",
      "|    std                | 4.15e+05      |\n",
      "|    value_loss         | 0.00125       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 73000        |\n",
      "|    time_elapsed       | 1182         |\n",
      "|    total_timesteps    | 365000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0.356        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72999        |\n",
      "|    policy_loss        | 0.106        |\n",
      "|    reward             | -0.037233416 |\n",
      "|    std                | 4.25e+05     |\n",
      "|    value_loss         | 8.53e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 73100        |\n",
      "|    time_elapsed       | 1184         |\n",
      "|    total_timesteps    | 365500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73099        |\n",
      "|    policy_loss        | -2.48        |\n",
      "|    reward             | -0.071331285 |\n",
      "|    std                | 4.3e+05      |\n",
      "|    value_loss         | 0.00811      |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -32222.86\n",
      "total_reward: -42222.86\n",
      "total_cost: 92.77\n",
      "total_trades: 5414\n",
      "Sharpe: 0.325\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 73200         |\n",
      "|    time_elapsed       | 1185          |\n",
      "|    total_timesteps    | 366000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73199         |\n",
      "|    policy_loss        | 1.67          |\n",
      "|    reward             | -0.0010221696 |\n",
      "|    std                | 4.37e+05      |\n",
      "|    value_loss         | 0.00382       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 73300       |\n",
      "|    time_elapsed       | 1187        |\n",
      "|    total_timesteps    | 366500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73299       |\n",
      "|    policy_loss        | -0.262      |\n",
      "|    reward             | 0.001676991 |\n",
      "|    std                | 4.47e+05    |\n",
      "|    value_loss         | 0.000268    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 73400       |\n",
      "|    time_elapsed       | 1188        |\n",
      "|    total_timesteps    | 367000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73399       |\n",
      "|    policy_loss        | 0.406       |\n",
      "|    reward             | 0.009109953 |\n",
      "|    std                | 4.6e+05     |\n",
      "|    value_loss         | 0.000281    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 73500         |\n",
      "|    time_elapsed       | 1189          |\n",
      "|    total_timesteps    | 367500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29           |\n",
      "|    explained_variance | -0.134        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73499         |\n",
      "|    policy_loss        | -0.125        |\n",
      "|    reward             | 0.00048395788 |\n",
      "|    std                | 4.75e+05      |\n",
      "|    value_loss         | 0.000125      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 308            |\n",
      "|    iterations         | 73600          |\n",
      "|    time_elapsed       | 1191           |\n",
      "|    total_timesteps    | 368000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 73599          |\n",
      "|    policy_loss        | -0.414         |\n",
      "|    reward             | -0.00016132431 |\n",
      "|    std                | 4.95e+05       |\n",
      "|    value_loss         | 0.000198       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 73700       |\n",
      "|    time_elapsed       | 1192        |\n",
      "|    total_timesteps    | 368500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73699       |\n",
      "|    policy_loss        | -0.0905     |\n",
      "|    reward             | 0.023071049 |\n",
      "|    std                | 5.11e+05    |\n",
      "|    value_loss         | 5.92e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 73800       |\n",
      "|    time_elapsed       | 1194        |\n",
      "|    total_timesteps    | 369000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73799       |\n",
      "|    policy_loss        | -0.247      |\n",
      "|    reward             | -0.01892366 |\n",
      "|    std                | 5.11e+05    |\n",
      "|    value_loss         | 0.000353    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 73900        |\n",
      "|    time_elapsed       | 1195         |\n",
      "|    total_timesteps    | 369500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73899        |\n",
      "|    policy_loss        | 0.319        |\n",
      "|    reward             | 0.0023036064 |\n",
      "|    std                | 5.19e+05     |\n",
      "|    value_loss         | 0.0019       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 74000         |\n",
      "|    time_elapsed       | 1197          |\n",
      "|    total_timesteps    | 370000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.2         |\n",
      "|    explained_variance | 0.28          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73999         |\n",
      "|    policy_loss        | -1.1          |\n",
      "|    reward             | -0.0045736353 |\n",
      "|    std                | 5.26e+05      |\n",
      "|    value_loss         | 0.00262       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 74100       |\n",
      "|    time_elapsed       | 1198        |\n",
      "|    total_timesteps    | 370500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | 0.201       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74099       |\n",
      "|    policy_loss        | 2.92        |\n",
      "|    reward             | -0.12312052 |\n",
      "|    std                | 5.31e+05    |\n",
      "|    value_loss         | 0.0494      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 74200        |\n",
      "|    time_elapsed       | 1200         |\n",
      "|    total_timesteps    | 371000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0.000773     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74199        |\n",
      "|    policy_loss        | -3.99        |\n",
      "|    reward             | 0.0008586451 |\n",
      "|    std                | 5.41e+05     |\n",
      "|    value_loss         | 0.0223       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 74300        |\n",
      "|    time_elapsed       | 1201         |\n",
      "|    total_timesteps    | 371500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74299        |\n",
      "|    policy_loss        | 0.454        |\n",
      "|    reward             | -0.027990822 |\n",
      "|    std                | 5.47e+05     |\n",
      "|    value_loss         | 0.0004       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 74400        |\n",
      "|    time_elapsed       | 1203         |\n",
      "|    total_timesteps    | 372000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74399        |\n",
      "|    policy_loss        | 0.423        |\n",
      "|    reward             | -0.032625478 |\n",
      "|    std                | 5.55e+05     |\n",
      "|    value_loss         | 0.000649     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 74500       |\n",
      "|    time_elapsed       | 1204        |\n",
      "|    total_timesteps    | 372500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.3       |\n",
      "|    explained_variance | 0.418       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74499       |\n",
      "|    policy_loss        | -1.54       |\n",
      "|    reward             | 0.027884694 |\n",
      "|    std                | 5.61e+05    |\n",
      "|    value_loss         | 0.00354     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 74600      |\n",
      "|    time_elapsed       | 1205       |\n",
      "|    total_timesteps    | 373000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.3      |\n",
      "|    explained_variance | 0.268      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74599      |\n",
      "|    policy_loss        | -4.68      |\n",
      "|    reward             | 0.14169092 |\n",
      "|    std                | 5.71e+05   |\n",
      "|    value_loss         | 0.0277     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 74700       |\n",
      "|    time_elapsed       | 1207        |\n",
      "|    total_timesteps    | 373500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74699       |\n",
      "|    policy_loss        | 5.01        |\n",
      "|    reward             | -0.29448152 |\n",
      "|    std                | 5.85e+05    |\n",
      "|    value_loss         | 0.0411      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 74800      |\n",
      "|    time_elapsed       | 1208       |\n",
      "|    total_timesteps    | 374000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74799      |\n",
      "|    policy_loss        | -2.03      |\n",
      "|    reward             | -0.0176477 |\n",
      "|    std                | 5.87e+05   |\n",
      "|    value_loss         | 0.0211     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 74900       |\n",
      "|    time_elapsed       | 1210        |\n",
      "|    total_timesteps    | 374500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74899       |\n",
      "|    policy_loss        | 1.39        |\n",
      "|    reward             | 0.009977767 |\n",
      "|    std                | 5.9e+05     |\n",
      "|    value_loss         | 0.00274     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 75000       |\n",
      "|    time_elapsed       | 1211        |\n",
      "|    total_timesteps    | 375000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.4       |\n",
      "|    explained_variance | 0.0607      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74999       |\n",
      "|    policy_loss        | -3.88       |\n",
      "|    reward             | -0.48763892 |\n",
      "|    std                | 5.97e+05    |\n",
      "|    value_loss         | 0.0306      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 75100      |\n",
      "|    time_elapsed       | 1212       |\n",
      "|    total_timesteps    | 375500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75099      |\n",
      "|    policy_loss        | -8.52      |\n",
      "|    reward             | 0.15716746 |\n",
      "|    std                | 5.95e+05   |\n",
      "|    value_loss         | 0.0939     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 75200     |\n",
      "|    time_elapsed       | 1214      |\n",
      "|    total_timesteps    | 376000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 0.437     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 75199     |\n",
      "|    policy_loss        | 8.67      |\n",
      "|    reward             | 0.3253866 |\n",
      "|    std                | 5.9e+05   |\n",
      "|    value_loss         | 0.126     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 75300        |\n",
      "|    time_elapsed       | 1215         |\n",
      "|    total_timesteps    | 376500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75299        |\n",
      "|    policy_loss        | 3.06         |\n",
      "|    reward             | 0.0070696976 |\n",
      "|    std                | 5.94e+05     |\n",
      "|    value_loss         | 0.0157       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 75400       |\n",
      "|    time_elapsed       | 1217        |\n",
      "|    total_timesteps    | 377000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | 1.84        |\n",
      "|    reward             | -0.06803612 |\n",
      "|    std                | 6e+05       |\n",
      "|    value_loss         | 0.00951     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 75500      |\n",
      "|    time_elapsed       | 1218       |\n",
      "|    total_timesteps    | 377500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75499      |\n",
      "|    policy_loss        | -2.21      |\n",
      "|    reward             | 0.03647979 |\n",
      "|    std                | 6.09e+05   |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 75600       |\n",
      "|    time_elapsed       | 1220        |\n",
      "|    total_timesteps    | 378000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 0.56        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75599       |\n",
      "|    policy_loss        | -0.596      |\n",
      "|    reward             | 0.033132114 |\n",
      "|    std                | 6.07e+05    |\n",
      "|    value_loss         | 0.00214     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 75700        |\n",
      "|    time_elapsed       | 1221         |\n",
      "|    total_timesteps    | 378500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75699        |\n",
      "|    policy_loss        | 4.77         |\n",
      "|    reward             | -0.020976072 |\n",
      "|    std                | 6.14e+05     |\n",
      "|    value_loss         | 0.0524       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 75800       |\n",
      "|    time_elapsed       | 1223        |\n",
      "|    total_timesteps    | 379000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 0.00249     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75799       |\n",
      "|    policy_loss        | 2.68        |\n",
      "|    reward             | -0.20492792 |\n",
      "|    std                | 6.1e+05     |\n",
      "|    value_loss         | 0.0296      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -236207.25\n",
      "total_reward: -246207.25\n",
      "total_cost: 108.16\n",
      "total_trades: 5414\n",
      "Sharpe: 0.395\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 75900       |\n",
      "|    time_elapsed       | 1224        |\n",
      "|    total_timesteps    | 379500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75899       |\n",
      "|    policy_loss        | 0.99        |\n",
      "|    reward             | 0.051299285 |\n",
      "|    std                | 6.13e+05    |\n",
      "|    value_loss         | 0.00361     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 76000         |\n",
      "|    time_elapsed       | 1226          |\n",
      "|    total_timesteps    | 380000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75999         |\n",
      "|    policy_loss        | -0.635        |\n",
      "|    reward             | -0.0015071745 |\n",
      "|    std                | 6.22e+05      |\n",
      "|    value_loss         | 0.000684      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 76100        |\n",
      "|    time_elapsed       | 1227         |\n",
      "|    total_timesteps    | 380500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76099        |\n",
      "|    policy_loss        | -0.0825      |\n",
      "|    reward             | 0.0069406335 |\n",
      "|    std                | 6.33e+05     |\n",
      "|    value_loss         | 5.06e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 309            |\n",
      "|    iterations         | 76200          |\n",
      "|    time_elapsed       | 1229           |\n",
      "|    total_timesteps    | 381000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.6          |\n",
      "|    explained_variance | -69.6          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 76199          |\n",
      "|    policy_loss        | -2.59          |\n",
      "|    reward             | -0.00039039928 |\n",
      "|    std                | 6.48e+05       |\n",
      "|    value_loss         | 0.00847        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 76300        |\n",
      "|    time_elapsed       | 1230         |\n",
      "|    total_timesteps    | 381500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.6        |\n",
      "|    explained_variance | 0.524        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76299        |\n",
      "|    policy_loss        | 0.211        |\n",
      "|    reward             | 0.0054967036 |\n",
      "|    std                | 6.59e+05     |\n",
      "|    value_loss         | 0.000159     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 310            |\n",
      "|    iterations         | 76400          |\n",
      "|    time_elapsed       | 1232           |\n",
      "|    total_timesteps    | 382000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 76399          |\n",
      "|    policy_loss        | 0.0629         |\n",
      "|    reward             | -0.00074526866 |\n",
      "|    std                | 6.7e+05        |\n",
      "|    value_loss         | 4.18e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76500       |\n",
      "|    time_elapsed       | 1233        |\n",
      "|    total_timesteps    | 382500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76499       |\n",
      "|    policy_loss        | -0.636      |\n",
      "|    reward             | 0.000517629 |\n",
      "|    std                | 6.85e+05    |\n",
      "|    value_loss         | 0.000571    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 76600         |\n",
      "|    time_elapsed       | 1235          |\n",
      "|    total_timesteps    | 383000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 76599         |\n",
      "|    policy_loss        | -0.217        |\n",
      "|    reward             | -0.0034470786 |\n",
      "|    std                | 7.03e+05      |\n",
      "|    value_loss         | 6.31e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76700       |\n",
      "|    time_elapsed       | 1236        |\n",
      "|    total_timesteps    | 383500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76699       |\n",
      "|    policy_loss        | 0.167       |\n",
      "|    reward             | 0.004606439 |\n",
      "|    std                | 7.18e+05    |\n",
      "|    value_loss         | 9.03e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 76800        |\n",
      "|    time_elapsed       | 1238         |\n",
      "|    total_timesteps    | 384000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76799        |\n",
      "|    policy_loss        | -0.974       |\n",
      "|    reward             | 0.0032338493 |\n",
      "|    std                | 7.44e+05     |\n",
      "|    value_loss         | 0.001        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76900       |\n",
      "|    time_elapsed       | 1239        |\n",
      "|    total_timesteps    | 384500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76899       |\n",
      "|    policy_loss        | -0.418      |\n",
      "|    reward             | 0.025276765 |\n",
      "|    std                | 7.78e+05    |\n",
      "|    value_loss         | 0.000365    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77000        |\n",
      "|    time_elapsed       | 1241         |\n",
      "|    total_timesteps    | 385000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76999        |\n",
      "|    policy_loss        | -0.503       |\n",
      "|    reward             | -0.015198464 |\n",
      "|    std                | 8.01e+05     |\n",
      "|    value_loss         | 0.000497     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77100        |\n",
      "|    time_elapsed       | 1242         |\n",
      "|    total_timesteps    | 385500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77099        |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | -0.043292686 |\n",
      "|    std                | 8.12e+05     |\n",
      "|    value_loss         | 0.00176      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77200        |\n",
      "|    time_elapsed       | 1244         |\n",
      "|    total_timesteps    | 386000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77199        |\n",
      "|    policy_loss        | 3.33         |\n",
      "|    reward             | 0.0028655792 |\n",
      "|    std                | 8.16e+05     |\n",
      "|    value_loss         | 0.0179       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 77300       |\n",
      "|    time_elapsed       | 1245        |\n",
      "|    total_timesteps    | 386500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0.177       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77299       |\n",
      "|    policy_loss        | 3.21        |\n",
      "|    reward             | 0.058885697 |\n",
      "|    std                | 8.23e+05    |\n",
      "|    value_loss         | 0.0153      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 77400      |\n",
      "|    time_elapsed       | 1247       |\n",
      "|    total_timesteps    | 387000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.1      |\n",
      "|    explained_variance | 0.287      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77399      |\n",
      "|    policy_loss        | 2.77       |\n",
      "|    reward             | 0.10214132 |\n",
      "|    std                | 8.15e+05   |\n",
      "|    value_loss         | 0.0142     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77500        |\n",
      "|    time_elapsed       | 1248         |\n",
      "|    total_timesteps    | 387500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77499        |\n",
      "|    policy_loss        | -0.44        |\n",
      "|    reward             | -0.009273765 |\n",
      "|    std                | 8.18e+05     |\n",
      "|    value_loss         | 0.000232     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 77600       |\n",
      "|    time_elapsed       | 1250        |\n",
      "|    total_timesteps    | 388000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77599       |\n",
      "|    policy_loss        | -0.0547     |\n",
      "|    reward             | -0.01107704 |\n",
      "|    std                | 8.36e+05    |\n",
      "|    value_loss         | 3.05e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77700        |\n",
      "|    time_elapsed       | 1251         |\n",
      "|    total_timesteps    | 388500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77699        |\n",
      "|    policy_loss        | -0.159       |\n",
      "|    reward             | -0.010568865 |\n",
      "|    std                | 8.5e+05      |\n",
      "|    value_loss         | 4.57e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 77800         |\n",
      "|    time_elapsed       | 1253          |\n",
      "|    total_timesteps    | 389000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77799         |\n",
      "|    policy_loss        | 0.158         |\n",
      "|    reward             | 0.00039279152 |\n",
      "|    std                | 8.72e+05      |\n",
      "|    value_loss         | 5.99e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77900        |\n",
      "|    time_elapsed       | 1254         |\n",
      "|    total_timesteps    | 389500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | -18.6        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77899        |\n",
      "|    policy_loss        | -0.418       |\n",
      "|    reward             | 0.0079810945 |\n",
      "|    std                | 9.02e+05     |\n",
      "|    value_loss         | 0.000961     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 78000        |\n",
      "|    time_elapsed       | 1256         |\n",
      "|    total_timesteps    | 390000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77999        |\n",
      "|    policy_loss        | -0.773       |\n",
      "|    reward             | -0.040334787 |\n",
      "|    std                | 9.23e+05     |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 78100       |\n",
      "|    time_elapsed       | 1257        |\n",
      "|    total_timesteps    | 390500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78099       |\n",
      "|    policy_loss        | -0.728      |\n",
      "|    reward             | 0.009145209 |\n",
      "|    std                | 9.42e+05    |\n",
      "|    value_loss         | 0.00106     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 78200         |\n",
      "|    time_elapsed       | 1259          |\n",
      "|    total_timesteps    | 391000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 78199         |\n",
      "|    policy_loss        | -0.522        |\n",
      "|    reward             | -0.0048388406 |\n",
      "|    std                | 9.63e+05      |\n",
      "|    value_loss         | 0.000312      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 78300         |\n",
      "|    time_elapsed       | 1260          |\n",
      "|    total_timesteps    | 391500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 78299         |\n",
      "|    policy_loss        | -0.382        |\n",
      "|    reward             | -0.0073931618 |\n",
      "|    std                | 9.95e+05      |\n",
      "|    value_loss         | 0.000178      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 78400        |\n",
      "|    time_elapsed       | 1262         |\n",
      "|    total_timesteps    | 392000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 0.0128       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78399        |\n",
      "|    policy_loss        | -0.395       |\n",
      "|    reward             | -0.009661617 |\n",
      "|    std                | 1.03e+06     |\n",
      "|    value_loss         | 0.000248     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 78500       |\n",
      "|    time_elapsed       | 1263        |\n",
      "|    total_timesteps    | 392500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78499       |\n",
      "|    policy_loss        | -0.786      |\n",
      "|    reward             | 0.008136848 |\n",
      "|    std                | 1.08e+06    |\n",
      "|    value_loss         | 0.000741    |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -10663.24\n",
      "total_reward: -20663.24\n",
      "total_cost: 478.42\n",
      "total_trades: 5414\n",
      "Sharpe: 0.022\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 78600       |\n",
      "|    time_elapsed       | 1265        |\n",
      "|    total_timesteps    | 393000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78599       |\n",
      "|    policy_loss        | 1.49        |\n",
      "|    reward             | 0.021517634 |\n",
      "|    std                | 1.11e+06    |\n",
      "|    value_loss         | 0.00358     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 78700         |\n",
      "|    time_elapsed       | 1266          |\n",
      "|    total_timesteps    | 393500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 78699         |\n",
      "|    policy_loss        | 0.524         |\n",
      "|    reward             | -0.0033478872 |\n",
      "|    std                | 1.14e+06      |\n",
      "|    value_loss         | 0.000328      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 78800        |\n",
      "|    time_elapsed       | 1268         |\n",
      "|    total_timesteps    | 394000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78799        |\n",
      "|    policy_loss        | 0.246        |\n",
      "|    reward             | 4.330421e-05 |\n",
      "|    std                | 1.18e+06     |\n",
      "|    value_loss         | 7.42e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 310            |\n",
      "|    iterations         | 78900          |\n",
      "|    time_elapsed       | 1269           |\n",
      "|    total_timesteps    | 394500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 78899          |\n",
      "|    policy_loss        | -0.271         |\n",
      "|    reward             | -0.00068098755 |\n",
      "|    std                | 1.22e+06       |\n",
      "|    value_loss         | 0.000145       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 79000      |\n",
      "|    time_elapsed       | 1271       |\n",
      "|    total_timesteps    | 395000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.9      |\n",
      "|    explained_variance | -0.945     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78999      |\n",
      "|    policy_loss        | 0.0471     |\n",
      "|    reward             | 0.00525092 |\n",
      "|    std                | 1.28e+06   |\n",
      "|    value_loss         | 0.000156   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 79100         |\n",
      "|    time_elapsed       | 1272          |\n",
      "|    total_timesteps    | 395500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31           |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79099         |\n",
      "|    policy_loss        | -1.23         |\n",
      "|    reward             | -0.0033557732 |\n",
      "|    std                | 1.32e+06      |\n",
      "|    value_loss         | 0.00181       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 1274        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | 0.768       |\n",
      "|    reward             | 0.002429493 |\n",
      "|    std                | 1.35e+06    |\n",
      "|    value_loss         | 0.000666    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 79300        |\n",
      "|    time_elapsed       | 1275         |\n",
      "|    total_timesteps    | 396500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79299        |\n",
      "|    policy_loss        | 0.512        |\n",
      "|    reward             | 0.0014056603 |\n",
      "|    std                | 1.38e+06     |\n",
      "|    value_loss         | 0.000305     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 79400        |\n",
      "|    time_elapsed       | 1277         |\n",
      "|    total_timesteps    | 397000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79399        |\n",
      "|    policy_loss        | -0.283       |\n",
      "|    reward             | 0.0053289915 |\n",
      "|    std                | 1.41e+06     |\n",
      "|    value_loss         | 0.000186     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 79500        |\n",
      "|    time_elapsed       | 1278         |\n",
      "|    total_timesteps    | 397500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.2        |\n",
      "|    explained_variance | 0.0197       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79499        |\n",
      "|    policy_loss        | -0.0722      |\n",
      "|    reward             | -0.006251222 |\n",
      "|    std                | 1.46e+06     |\n",
      "|    value_loss         | 0.00024      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 79600       |\n",
      "|    time_elapsed       | 1280        |\n",
      "|    total_timesteps    | 398000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0.0155      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79599       |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | -0.01180621 |\n",
      "|    std                | 1.51e+06    |\n",
      "|    value_loss         | 0.00258     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 79700         |\n",
      "|    time_elapsed       | 1281          |\n",
      "|    total_timesteps    | 398500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79699         |\n",
      "|    policy_loss        | 0.248         |\n",
      "|    reward             | -0.0034178176 |\n",
      "|    std                | 1.55e+06      |\n",
      "|    value_loss         | 0.0007        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 79800      |\n",
      "|    time_elapsed       | 1283       |\n",
      "|    total_timesteps    | 399000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79799      |\n",
      "|    policy_loss        | 0.302      |\n",
      "|    reward             | 7.7497e-05 |\n",
      "|    std                | 1.59e+06   |\n",
      "|    value_loss         | 0.000234   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 79900         |\n",
      "|    time_elapsed       | 1284          |\n",
      "|    total_timesteps    | 399500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79899         |\n",
      "|    policy_loss        | -1.11         |\n",
      "|    reward             | -0.0059690326 |\n",
      "|    std                | 1.64e+06      |\n",
      "|    value_loss         | 0.00129       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 80000        |\n",
      "|    time_elapsed       | 1286         |\n",
      "|    total_timesteps    | 400000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | -0.00107     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79999        |\n",
      "|    policy_loss        | 0.42         |\n",
      "|    reward             | -0.009922714 |\n",
      "|    std                | 1.69e+06     |\n",
      "|    value_loss         | 0.000291     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 80100        |\n",
      "|    time_elapsed       | 1287         |\n",
      "|    total_timesteps    | 400500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.6        |\n",
      "|    explained_variance | 0.0343       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80099        |\n",
      "|    policy_loss        | -0.13        |\n",
      "|    reward             | -0.011966394 |\n",
      "|    std                | 1.75e+06     |\n",
      "|    value_loss         | 3.24e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 80200       |\n",
      "|    time_elapsed       | 1289        |\n",
      "|    total_timesteps    | 401000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80199       |\n",
      "|    policy_loss        | -0.438      |\n",
      "|    reward             | -0.04924266 |\n",
      "|    std                | 1.8e+06     |\n",
      "|    value_loss         | 0.00076     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 80300         |\n",
      "|    time_elapsed       | 1290          |\n",
      "|    total_timesteps    | 401500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80299         |\n",
      "|    policy_loss        | -0.0841       |\n",
      "|    reward             | -0.0114147505 |\n",
      "|    std                | 1.82e+06      |\n",
      "|    value_loss         | 4.71e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 80400       |\n",
      "|    time_elapsed       | 1292        |\n",
      "|    total_timesteps    | 402000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0.111       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80399       |\n",
      "|    policy_loss        | -0.794      |\n",
      "|    reward             | 0.041880477 |\n",
      "|    std                | 1.87e+06    |\n",
      "|    value_loss         | 0.000824    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 80500       |\n",
      "|    time_elapsed       | 1293        |\n",
      "|    total_timesteps    | 402500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80499       |\n",
      "|    policy_loss        | -0.42       |\n",
      "|    reward             | -0.04575946 |\n",
      "|    std                | 1.9e+06     |\n",
      "|    value_loss         | 0.000233    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 80600      |\n",
      "|    time_elapsed       | 1295       |\n",
      "|    total_timesteps    | 403000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.8      |\n",
      "|    explained_variance | 6.43e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80599      |\n",
      "|    policy_loss        | -1.77      |\n",
      "|    reward             | 0.02628489 |\n",
      "|    std                | 1.93e+06   |\n",
      "|    value_loss         | 0.00642    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 80700        |\n",
      "|    time_elapsed       | 1296         |\n",
      "|    total_timesteps    | 403500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | -0.0122      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80699        |\n",
      "|    policy_loss        | 11.6         |\n",
      "|    reward             | -0.035957947 |\n",
      "|    std                | 1.93e+06     |\n",
      "|    value_loss         | 0.287        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 80800        |\n",
      "|    time_elapsed       | 1298         |\n",
      "|    total_timesteps    | 404000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80799        |\n",
      "|    policy_loss        | 0.462        |\n",
      "|    reward             | -0.017339202 |\n",
      "|    std                | 1.96e+06     |\n",
      "|    value_loss         | 0.000344     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 80900        |\n",
      "|    time_elapsed       | 1299         |\n",
      "|    total_timesteps    | 404500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80899        |\n",
      "|    policy_loss        | 0.56         |\n",
      "|    reward             | 0.0046280823 |\n",
      "|    std                | 2e+06        |\n",
      "|    value_loss         | 0.000439     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 81000         |\n",
      "|    time_elapsed       | 1301          |\n",
      "|    total_timesteps    | 405000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80999         |\n",
      "|    policy_loss        | -0.367        |\n",
      "|    reward             | -0.0064094304 |\n",
      "|    std                | 2.07e+06      |\n",
      "|    value_loss         | 0.000215      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 81100       |\n",
      "|    time_elapsed       | 1302        |\n",
      "|    total_timesteps    | 405500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | 0.049       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81099       |\n",
      "|    policy_loss        | 0.0772      |\n",
      "|    reward             | 0.009164593 |\n",
      "|    std                | 2.14e+06    |\n",
      "|    value_loss         | 1.78e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 81200        |\n",
      "|    time_elapsed       | 1304         |\n",
      "|    total_timesteps    | 406000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | -2.86e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81199        |\n",
      "|    policy_loss        | 2.99         |\n",
      "|    reward             | -0.019354116 |\n",
      "|    std                | 2.26e+06     |\n",
      "|    value_loss         | 0.00968      |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12374.34\n",
      "total_reward: -22374.34\n",
      "total_cost: 427.92\n",
      "total_trades: 5414\n",
      "Sharpe: 0.052\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 81300       |\n",
      "|    time_elapsed       | 1306        |\n",
      "|    total_timesteps    | 406500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81299       |\n",
      "|    policy_loss        | 2.81        |\n",
      "|    reward             | -0.07337278 |\n",
      "|    std                | 2.31e+06    |\n",
      "|    value_loss         | 0.00958     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 81400       |\n",
      "|    time_elapsed       | 1307        |\n",
      "|    total_timesteps    | 407000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81399       |\n",
      "|    policy_loss        | -1.84       |\n",
      "|    reward             | -0.00963722 |\n",
      "|    std                | 2.36e+06    |\n",
      "|    value_loss         | 0.00334     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 81500        |\n",
      "|    time_elapsed       | 1309         |\n",
      "|    total_timesteps    | 407500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 0.0461       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81499        |\n",
      "|    policy_loss        | 0.381        |\n",
      "|    reward             | 0.0035760833 |\n",
      "|    std                | 2.4e+06      |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 81600         |\n",
      "|    time_elapsed       | 1311          |\n",
      "|    total_timesteps    | 408000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81599         |\n",
      "|    policy_loss        | 0.372         |\n",
      "|    reward             | -0.0053462354 |\n",
      "|    std                | 2.45e+06      |\n",
      "|    value_loss         | 0.000538      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 81700       |\n",
      "|    time_elapsed       | 1313        |\n",
      "|    total_timesteps    | 408500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0.0453      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81699       |\n",
      "|    policy_loss        | 5.82        |\n",
      "|    reward             | 0.027637772 |\n",
      "|    std                | 2.51e+06    |\n",
      "|    value_loss         | 0.0351      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 81800         |\n",
      "|    time_elapsed       | 1314          |\n",
      "|    total_timesteps    | 409000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81799         |\n",
      "|    policy_loss        | -1.39         |\n",
      "|    reward             | -0.0008424332 |\n",
      "|    std                | 2.52e+06      |\n",
      "|    value_loss         | 0.00197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 81900         |\n",
      "|    time_elapsed       | 1316          |\n",
      "|    total_timesteps    | 409500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81899         |\n",
      "|    policy_loss        | -1.71         |\n",
      "|    reward             | 0.00045586244 |\n",
      "|    std                | 2.53e+06      |\n",
      "|    value_loss         | 0.004         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 82000        |\n",
      "|    time_elapsed       | 1318         |\n",
      "|    total_timesteps    | 410000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81999        |\n",
      "|    policy_loss        | 2.39         |\n",
      "|    reward             | -0.018895756 |\n",
      "|    std                | 2.59e+06     |\n",
      "|    value_loss         | 0.00785      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 82100       |\n",
      "|    time_elapsed       | 1319        |\n",
      "|    total_timesteps    | 410500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82099       |\n",
      "|    policy_loss        | 0.798       |\n",
      "|    reward             | 0.014519558 |\n",
      "|    std                | 2.62e+06    |\n",
      "|    value_loss         | 0.000666    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 82200       |\n",
      "|    time_elapsed       | 1321        |\n",
      "|    total_timesteps    | 411000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 0.00469     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82199       |\n",
      "|    policy_loss        | 5.7         |\n",
      "|    reward             | -0.01765671 |\n",
      "|    std                | 2.66e+06    |\n",
      "|    value_loss         | 0.1         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 82300        |\n",
      "|    time_elapsed       | 1323         |\n",
      "|    total_timesteps    | 411500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 0.175        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82299        |\n",
      "|    policy_loss        | 3.3          |\n",
      "|    reward             | -0.067614526 |\n",
      "|    std                | 2.65e+06     |\n",
      "|    value_loss         | 0.0116       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 82400      |\n",
      "|    time_elapsed       | 1324       |\n",
      "|    total_timesteps    | 412000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 82399      |\n",
      "|    policy_loss        | 0.816      |\n",
      "|    reward             | 0.02527998 |\n",
      "|    std                | 2.66e+06   |\n",
      "|    value_loss         | 0.000809   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 82500        |\n",
      "|    time_elapsed       | 1326         |\n",
      "|    total_timesteps    | 412500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82499        |\n",
      "|    policy_loss        | -0.00118     |\n",
      "|    reward             | -0.006465621 |\n",
      "|    std                | 2.71e+06     |\n",
      "|    value_loss         | 1.06e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 82600        |\n",
      "|    time_elapsed       | 1328         |\n",
      "|    total_timesteps    | 413000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82599        |\n",
      "|    policy_loss        | 0.462        |\n",
      "|    reward             | -0.019962387 |\n",
      "|    std                | 2.8e+06      |\n",
      "|    value_loss         | 0.00032      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 82700       |\n",
      "|    time_elapsed       | 1329        |\n",
      "|    total_timesteps    | 413500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | -0.166      |\n",
      "|    reward             | 0.011338505 |\n",
      "|    std                | 2.91e+06    |\n",
      "|    value_loss         | 3.51e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 82800       |\n",
      "|    time_elapsed       | 1331        |\n",
      "|    total_timesteps    | 414000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | -0.041      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82799       |\n",
      "|    policy_loss        | 0.0296      |\n",
      "|    reward             | 0.004710513 |\n",
      "|    std                | 3.02e+06    |\n",
      "|    value_loss         | 6.57e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 82900         |\n",
      "|    time_elapsed       | 1332          |\n",
      "|    total_timesteps    | 414500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.8         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82899         |\n",
      "|    policy_loss        | 0.742         |\n",
      "|    reward             | -0.0043191267 |\n",
      "|    std                | 3.16e+06      |\n",
      "|    value_loss         | 0.0021        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 83000       |\n",
      "|    time_elapsed       | 1334        |\n",
      "|    total_timesteps    | 415000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82999       |\n",
      "|    policy_loss        | -1.75       |\n",
      "|    reward             | -0.01540635 |\n",
      "|    std                | 3.18e+06    |\n",
      "|    value_loss         | 0.00348     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 83100        |\n",
      "|    time_elapsed       | 1335         |\n",
      "|    total_timesteps    | 415500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83099        |\n",
      "|    policy_loss        | -0.483       |\n",
      "|    reward             | -0.019201238 |\n",
      "|    std                | 3.23e+06     |\n",
      "|    value_loss         | 0.000354     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 83200        |\n",
      "|    time_elapsed       | 1337         |\n",
      "|    total_timesteps    | 416000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | 0.0237       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83199        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | 0.0002622345 |\n",
      "|    std                | 3.33e+06     |\n",
      "|    value_loss         | 0.000402     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 83300        |\n",
      "|    time_elapsed       | 1338         |\n",
      "|    total_timesteps    | 416500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83299        |\n",
      "|    policy_loss        | 3.55         |\n",
      "|    reward             | -0.040485755 |\n",
      "|    std                | 3.39e+06     |\n",
      "|    value_loss         | 0.0172       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 83400       |\n",
      "|    time_elapsed       | 1340        |\n",
      "|    total_timesteps    | 417000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0.0423      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83399       |\n",
      "|    policy_loss        | -3.82       |\n",
      "|    reward             | -0.07339774 |\n",
      "|    std                | 3.38e+06    |\n",
      "|    value_loss         | 0.0339      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 83500        |\n",
      "|    time_elapsed       | 1341         |\n",
      "|    total_timesteps    | 417500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83499        |\n",
      "|    policy_loss        | -0.957       |\n",
      "|    reward             | -0.018955505 |\n",
      "|    std                | 3.43e+06     |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 83600        |\n",
      "|    time_elapsed       | 1343         |\n",
      "|    total_timesteps    | 418000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33          |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83599        |\n",
      "|    policy_loss        | 2.08         |\n",
      "|    reward             | 0.0035238224 |\n",
      "|    std                | 3.51e+06     |\n",
      "|    value_loss         | 0.006        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 83700       |\n",
      "|    time_elapsed       | 1344        |\n",
      "|    total_timesteps    | 418500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83699       |\n",
      "|    policy_loss        | -1.09       |\n",
      "|    reward             | -0.07719692 |\n",
      "|    std                | 3.56e+06    |\n",
      "|    value_loss         | 0.00262     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 83800      |\n",
      "|    time_elapsed       | 1346       |\n",
      "|    total_timesteps    | 419000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83799      |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | 0.18896623 |\n",
      "|    std                | 3.64e+06   |\n",
      "|    value_loss         | 0.00512    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 83900       |\n",
      "|    time_elapsed       | 1347        |\n",
      "|    total_timesteps    | 419500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83899       |\n",
      "|    policy_loss        | -1.72       |\n",
      "|    reward             | -0.11185232 |\n",
      "|    std                | 3.63e+06    |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -111493.08\n",
      "total_reward: -121493.08\n",
      "total_cost: 107.57\n",
      "total_trades: 5414\n",
      "Sharpe: 0.542\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 84000       |\n",
      "|    time_elapsed       | 1349        |\n",
      "|    total_timesteps    | 420000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83999       |\n",
      "|    policy_loss        | -0.292      |\n",
      "|    reward             | 0.013390036 |\n",
      "|    std                | 3.65e+06    |\n",
      "|    value_loss         | 0.00018     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 84100         |\n",
      "|    time_elapsed       | 1350          |\n",
      "|    total_timesteps    | 420500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84099         |\n",
      "|    policy_loss        | 0.657         |\n",
      "|    reward             | -0.0103277955 |\n",
      "|    std                | 3.68e+06      |\n",
      "|    value_loss         | 0.000483      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 84200         |\n",
      "|    time_elapsed       | 1352          |\n",
      "|    total_timesteps    | 421000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84199         |\n",
      "|    policy_loss        | 0.411         |\n",
      "|    reward             | -0.0013798871 |\n",
      "|    std                | 3.72e+06      |\n",
      "|    value_loss         | 0.000541      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 84300        |\n",
      "|    time_elapsed       | 1354         |\n",
      "|    total_timesteps    | 421500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.2        |\n",
      "|    explained_variance | 0.524        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84299        |\n",
      "|    policy_loss        | 0.23         |\n",
      "|    reward             | 0.0016250011 |\n",
      "|    std                | 3.85e+06     |\n",
      "|    value_loss         | 9.59e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 84400        |\n",
      "|    time_elapsed       | 1355         |\n",
      "|    total_timesteps    | 422000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.2        |\n",
      "|    explained_variance | 0.455        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84399        |\n",
      "|    policy_loss        | -0.691       |\n",
      "|    reward             | -0.011020101 |\n",
      "|    std                | 3.96e+06     |\n",
      "|    value_loss         | 0.000557     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 84500        |\n",
      "|    time_elapsed       | 1357         |\n",
      "|    total_timesteps    | 422500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84499        |\n",
      "|    policy_loss        | 2.45         |\n",
      "|    reward             | -0.050476193 |\n",
      "|    std                | 4.05e+06     |\n",
      "|    value_loss         | 0.00995      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 84600        |\n",
      "|    time_elapsed       | 1358         |\n",
      "|    total_timesteps    | 423000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84599        |\n",
      "|    policy_loss        | 5.66         |\n",
      "|    reward             | -0.009601614 |\n",
      "|    std                | 4.15e+06     |\n",
      "|    value_loss         | 0.0306       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 84700        |\n",
      "|    time_elapsed       | 1360         |\n",
      "|    total_timesteps    | 423500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84699        |\n",
      "|    policy_loss        | -0.202       |\n",
      "|    reward             | -0.006578827 |\n",
      "|    std                | 4.21e+06     |\n",
      "|    value_loss         | 0.000203     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 84800         |\n",
      "|    time_elapsed       | 1361          |\n",
      "|    total_timesteps    | 424000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.4         |\n",
      "|    explained_variance | 0.0824        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84799         |\n",
      "|    policy_loss        | -0.476        |\n",
      "|    reward             | -0.0023093207 |\n",
      "|    std                | 4.29e+06      |\n",
      "|    value_loss         | 0.000249      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 84900         |\n",
      "|    time_elapsed       | 1363          |\n",
      "|    total_timesteps    | 424500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.4         |\n",
      "|    explained_variance | -0.0771       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84899         |\n",
      "|    policy_loss        | 1.26          |\n",
      "|    reward             | -0.0021976228 |\n",
      "|    std                | 4.4e+06       |\n",
      "|    value_loss         | 0.00634       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 85000      |\n",
      "|    time_elapsed       | 1364       |\n",
      "|    total_timesteps    | 425000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84999      |\n",
      "|    policy_loss        | -0.508     |\n",
      "|    reward             | 0.03127643 |\n",
      "|    std                | 4.53e+06   |\n",
      "|    value_loss         | 0.000976   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 85100        |\n",
      "|    time_elapsed       | 1366         |\n",
      "|    total_timesteps    | 425500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85099        |\n",
      "|    policy_loss        | 1.87         |\n",
      "|    reward             | -0.043231808 |\n",
      "|    std                | 4.61e+06     |\n",
      "|    value_loss         | 0.0036       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 85200        |\n",
      "|    time_elapsed       | 1368         |\n",
      "|    total_timesteps    | 426000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85199        |\n",
      "|    policy_loss        | -0.376       |\n",
      "|    reward             | 0.0031708716 |\n",
      "|    std                | 4.7e+06      |\n",
      "|    value_loss         | 0.000169     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 85300       |\n",
      "|    time_elapsed       | 1369        |\n",
      "|    total_timesteps    | 426500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85299       |\n",
      "|    policy_loss        | -0.00149    |\n",
      "|    reward             | 0.008719793 |\n",
      "|    std                | 4.85e+06    |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 311            |\n",
      "|    iterations         | 85400          |\n",
      "|    time_elapsed       | 1370           |\n",
      "|    total_timesteps    | 427000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -33.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 85399          |\n",
      "|    policy_loss        | 0.0714         |\n",
      "|    reward             | -0.00051462115 |\n",
      "|    std                | 5e+06          |\n",
      "|    value_loss         | 8.32e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 85500        |\n",
      "|    time_elapsed       | 1372         |\n",
      "|    total_timesteps    | 427500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | -0.0749      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85499        |\n",
      "|    policy_loss        | -0.203       |\n",
      "|    reward             | 0.0018560634 |\n",
      "|    std                | 5.22e+06     |\n",
      "|    value_loss         | 6.17e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 85600        |\n",
      "|    time_elapsed       | 1374         |\n",
      "|    total_timesteps    | 428000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85599        |\n",
      "|    policy_loss        | -0.629       |\n",
      "|    reward             | -0.020743534 |\n",
      "|    std                | 5.43e+06     |\n",
      "|    value_loss         | 0.00053      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 85700       |\n",
      "|    time_elapsed       | 1375        |\n",
      "|    total_timesteps    | 428500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.9       |\n",
      "|    explained_variance | 2.98e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85699       |\n",
      "|    policy_loss        | -0.624      |\n",
      "|    reward             | 0.021397918 |\n",
      "|    std                | 5.54e+06    |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 85800       |\n",
      "|    time_elapsed       | 1377        |\n",
      "|    total_timesteps    | 429000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85799       |\n",
      "|    policy_loss        | 0.633       |\n",
      "|    reward             | 0.012227952 |\n",
      "|    std                | 5.63e+06    |\n",
      "|    value_loss         | 0.000699    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 85900        |\n",
      "|    time_elapsed       | 1379         |\n",
      "|    total_timesteps    | 429500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.9        |\n",
      "|    explained_variance | 0.157        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85899        |\n",
      "|    policy_loss        | 0.564        |\n",
      "|    reward             | -0.012848216 |\n",
      "|    std                | 5.71e+06     |\n",
      "|    value_loss         | 0.0006       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 86000      |\n",
      "|    time_elapsed       | 1380       |\n",
      "|    total_timesteps    | 430000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34        |\n",
      "|    explained_variance | -0.0464    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85999      |\n",
      "|    policy_loss        | -3.11      |\n",
      "|    reward             | 0.01782235 |\n",
      "|    std                | 5.85e+06   |\n",
      "|    value_loss         | 0.00948    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 86100      |\n",
      "|    time_elapsed       | 1382       |\n",
      "|    total_timesteps    | 430500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34        |\n",
      "|    explained_variance | -0.0376    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86099      |\n",
      "|    policy_loss        | -2.53      |\n",
      "|    reward             | 0.07514492 |\n",
      "|    std                | 5.91e+06   |\n",
      "|    value_loss         | 0.00986    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 311           |\n",
      "|    iterations         | 86200         |\n",
      "|    time_elapsed       | 1383          |\n",
      "|    total_timesteps    | 431000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86199         |\n",
      "|    policy_loss        | -4.94         |\n",
      "|    reward             | -0.0058591445 |\n",
      "|    std                | 5.95e+06      |\n",
      "|    value_loss         | 0.0235        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 86300       |\n",
      "|    time_elapsed       | 1384        |\n",
      "|    total_timesteps    | 431500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86299       |\n",
      "|    policy_loss        | -1.51       |\n",
      "|    reward             | 0.031205563 |\n",
      "|    std                | 6.04e+06    |\n",
      "|    value_loss         | 0.00352     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 86400       |\n",
      "|    time_elapsed       | 1386        |\n",
      "|    total_timesteps    | 432000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.1       |\n",
      "|    explained_variance | 2.38e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86399       |\n",
      "|    policy_loss        | -5.3        |\n",
      "|    reward             | 0.035660774 |\n",
      "|    std                | 6.16e+06    |\n",
      "|    value_loss         | 0.0271      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 86500       |\n",
      "|    time_elapsed       | 1387        |\n",
      "|    total_timesteps    | 432500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.1       |\n",
      "|    explained_variance | 2.15e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86499       |\n",
      "|    policy_loss        | -7.46       |\n",
      "|    reward             | -0.10113407 |\n",
      "|    std                | 6.23e+06    |\n",
      "|    value_loss         | 0.0653      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 86600       |\n",
      "|    time_elapsed       | 1389        |\n",
      "|    total_timesteps    | 433000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.1       |\n",
      "|    explained_variance | -4.29e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86599       |\n",
      "|    policy_loss        | 8.26        |\n",
      "|    reward             | -0.17361726 |\n",
      "|    std                | 6.28e+06    |\n",
      "|    value_loss         | 0.0619      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -240512.89\n",
      "total_reward: -250512.89\n",
      "total_cost: 108.00\n",
      "total_trades: 5414\n",
      "Sharpe: -0.066\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 86700        |\n",
      "|    time_elapsed       | 1390         |\n",
      "|    total_timesteps    | 433500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86699        |\n",
      "|    policy_loss        | -5.08        |\n",
      "|    reward             | -0.059815392 |\n",
      "|    std                | 6.33e+06     |\n",
      "|    value_loss         | 0.0282       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 86800        |\n",
      "|    time_elapsed       | 1392         |\n",
      "|    total_timesteps    | 434000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86799        |\n",
      "|    policy_loss        | 0.774        |\n",
      "|    reward             | -0.002389306 |\n",
      "|    std                | 6.35e+06     |\n",
      "|    value_loss         | 0.00229      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 86900        |\n",
      "|    time_elapsed       | 1393         |\n",
      "|    total_timesteps    | 434500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86899        |\n",
      "|    policy_loss        | -0.688       |\n",
      "|    reward             | -0.077661105 |\n",
      "|    std                | 6.43e+06     |\n",
      "|    value_loss         | 0.00342      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 87000      |\n",
      "|    time_elapsed       | 1395       |\n",
      "|    total_timesteps    | 435000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86999      |\n",
      "|    policy_loss        | -15.4      |\n",
      "|    reward             | 0.15886787 |\n",
      "|    std                | 6.52e+06   |\n",
      "|    value_loss         | 0.24       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 87100      |\n",
      "|    time_elapsed       | 1396       |\n",
      "|    total_timesteps    | 435500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87099      |\n",
      "|    policy_loss        | -12.2      |\n",
      "|    reward             | 0.01928276 |\n",
      "|    std                | 6.52e+06   |\n",
      "|    value_loss         | 0.143      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1398        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.2       |\n",
      "|    explained_variance | 0.0539      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | 2.2         |\n",
      "|    reward             | -0.07321597 |\n",
      "|    std                | 6.6e+06     |\n",
      "|    value_loss         | 0.006       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 87300        |\n",
      "|    time_elapsed       | 1399         |\n",
      "|    total_timesteps    | 436500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87299        |\n",
      "|    policy_loss        | 3.54         |\n",
      "|    reward             | -0.061430562 |\n",
      "|    std                | 6.65e+06     |\n",
      "|    value_loss         | 0.0115       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 87400       |\n",
      "|    time_elapsed       | 1401        |\n",
      "|    total_timesteps    | 437000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87399       |\n",
      "|    policy_loss        | -1.43       |\n",
      "|    reward             | -0.14209343 |\n",
      "|    std                | 6.69e+06    |\n",
      "|    value_loss         | 0.00424     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 87500      |\n",
      "|    time_elapsed       | 1402       |\n",
      "|    total_timesteps    | 437500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.3      |\n",
      "|    explained_variance | -5.36e-06  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87499      |\n",
      "|    policy_loss        | 0.327      |\n",
      "|    reward             | 0.05053071 |\n",
      "|    std                | 6.74e+06   |\n",
      "|    value_loss         | 0.00218    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 87600       |\n",
      "|    time_elapsed       | 1404        |\n",
      "|    total_timesteps    | 438000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87599       |\n",
      "|    policy_loss        | 3.26        |\n",
      "|    reward             | 0.043331455 |\n",
      "|    std                | 6.84e+06    |\n",
      "|    value_loss         | 0.192       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 87700       |\n",
      "|    time_elapsed       | 1405        |\n",
      "|    total_timesteps    | 438500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87699       |\n",
      "|    policy_loss        | 82.5        |\n",
      "|    reward             | -0.26231772 |\n",
      "|    std                | 6.9e+06     |\n",
      "|    value_loss         | 7.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 87800       |\n",
      "|    time_elapsed       | 1407        |\n",
      "|    total_timesteps    | 439000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87799       |\n",
      "|    policy_loss        | 0.64        |\n",
      "|    reward             | 0.035116926 |\n",
      "|    std                | 6.93e+06    |\n",
      "|    value_loss         | 0.000503    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 311         |\n",
      "|    iterations         | 87900       |\n",
      "|    time_elapsed       | 1408        |\n",
      "|    total_timesteps    | 439500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87899       |\n",
      "|    policy_loss        | 0.473       |\n",
      "|    reward             | 0.012109071 |\n",
      "|    std                | 7.03e+06    |\n",
      "|    value_loss         | 0.00122     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 88000      |\n",
      "|    time_elapsed       | 1410       |\n",
      "|    total_timesteps    | 440000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.4      |\n",
      "|    explained_variance | -0.0537    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87999      |\n",
      "|    policy_loss        | 1.8        |\n",
      "|    reward             | 0.05044695 |\n",
      "|    std                | 7.16e+06   |\n",
      "|    value_loss         | 0.00514    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 88100       |\n",
      "|    time_elapsed       | 1411        |\n",
      "|    total_timesteps    | 440500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.4       |\n",
      "|    explained_variance | -0.00194    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88099       |\n",
      "|    policy_loss        | -1.86       |\n",
      "|    reward             | 0.039615124 |\n",
      "|    std                | 7.21e+06    |\n",
      "|    value_loss         | 0.00342     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 88200        |\n",
      "|    time_elapsed       | 1413         |\n",
      "|    total_timesteps    | 441000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.4        |\n",
      "|    explained_variance | 0.094        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88199        |\n",
      "|    policy_loss        | 6.76         |\n",
      "|    reward             | 0.0012202957 |\n",
      "|    std                | 7.2e+06      |\n",
      "|    value_loss         | 0.0535       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 88300        |\n",
      "|    time_elapsed       | 1415         |\n",
      "|    total_timesteps    | 441500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88299        |\n",
      "|    policy_loss        | 5.28         |\n",
      "|    reward             | -0.024109842 |\n",
      "|    std                | 7.32e+06     |\n",
      "|    value_loss         | 0.0242       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 88400       |\n",
      "|    time_elapsed       | 1416        |\n",
      "|    total_timesteps    | 442000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88399       |\n",
      "|    policy_loss        | -0.922      |\n",
      "|    reward             | 0.009036032 |\n",
      "|    std                | 7.45e+06    |\n",
      "|    value_loss         | 0.000902    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 88500        |\n",
      "|    time_elapsed       | 1418         |\n",
      "|    total_timesteps    | 442500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88499        |\n",
      "|    policy_loss        | 0.0826       |\n",
      "|    reward             | -0.017986638 |\n",
      "|    std                | 7.53e+06     |\n",
      "|    value_loss         | 0.000156     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 88600       |\n",
      "|    time_elapsed       | 1419        |\n",
      "|    total_timesteps    | 443000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.6       |\n",
      "|    explained_variance | 0.372       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88599       |\n",
      "|    policy_loss        | -1.73       |\n",
      "|    reward             | -0.01556552 |\n",
      "|    std                | 7.71e+06    |\n",
      "|    value_loss         | 0.00277     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 88700        |\n",
      "|    time_elapsed       | 1421         |\n",
      "|    total_timesteps    | 443500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.6        |\n",
      "|    explained_variance | -1.92e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88699        |\n",
      "|    policy_loss        | -4.79        |\n",
      "|    reward             | -0.048317622 |\n",
      "|    std                | 7.79e+06     |\n",
      "|    value_loss         | 0.0207       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 88800       |\n",
      "|    time_elapsed       | 1422        |\n",
      "|    total_timesteps    | 444000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.6       |\n",
      "|    explained_variance | 0.12        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88799       |\n",
      "|    policy_loss        | -0.631      |\n",
      "|    reward             | 0.077602394 |\n",
      "|    std                | 7.91e+06    |\n",
      "|    value_loss         | 0.00207     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 88900         |\n",
      "|    time_elapsed       | 1424          |\n",
      "|    total_timesteps    | 444500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88899         |\n",
      "|    policy_loss        | -1.23         |\n",
      "|    reward             | -0.0053634774 |\n",
      "|    std                | 7.93e+06      |\n",
      "|    value_loss         | 0.00256       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 89000       |\n",
      "|    time_elapsed       | 1426        |\n",
      "|    total_timesteps    | 445000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88999       |\n",
      "|    policy_loss        | 0.0207      |\n",
      "|    reward             | -0.05226736 |\n",
      "|    std                | 8.05e+06    |\n",
      "|    value_loss         | 0.000118    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 89100      |\n",
      "|    time_elapsed       | 1427       |\n",
      "|    total_timesteps    | 445500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.7      |\n",
      "|    explained_variance | 0.506      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89099      |\n",
      "|    policy_loss        | 2.68       |\n",
      "|    reward             | 0.07728726 |\n",
      "|    std                | 8.15e+06   |\n",
      "|    value_loss         | 0.00702    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 89200        |\n",
      "|    time_elapsed       | 1429         |\n",
      "|    total_timesteps    | 446000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.7        |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89199        |\n",
      "|    policy_loss        | 3.88         |\n",
      "|    reward             | 0.0051792925 |\n",
      "|    std                | 8.28e+06     |\n",
      "|    value_loss         | 0.0151       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 89300        |\n",
      "|    time_elapsed       | 1430         |\n",
      "|    total_timesteps    | 446500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89299        |\n",
      "|    policy_loss        | 0.752        |\n",
      "|    reward             | -0.024539664 |\n",
      "|    std                | 8.32e+06     |\n",
      "|    value_loss         | 0.011        |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -103788.63\n",
      "total_reward: -113788.63\n",
      "total_cost: 101.69\n",
      "total_trades: 5414\n",
      "Sharpe: -0.300\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 89400       |\n",
      "|    time_elapsed       | 1432        |\n",
      "|    total_timesteps    | 447000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89399       |\n",
      "|    policy_loss        | -0.413      |\n",
      "|    reward             | -0.05829012 |\n",
      "|    std                | 8.35e+06    |\n",
      "|    value_loss         | 0.000479    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 89500        |\n",
      "|    time_elapsed       | 1433         |\n",
      "|    total_timesteps    | 447500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89499        |\n",
      "|    policy_loss        | 0.00304      |\n",
      "|    reward             | -0.008632699 |\n",
      "|    std                | 8.41e+06     |\n",
      "|    value_loss         | 1.34e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 89600       |\n",
      "|    time_elapsed       | 1435        |\n",
      "|    total_timesteps    | 448000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89599       |\n",
      "|    policy_loss        | 0.478       |\n",
      "|    reward             | 0.017803172 |\n",
      "|    std                | 8.58e+06    |\n",
      "|    value_loss         | 0.00023     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 89700       |\n",
      "|    time_elapsed       | 1437        |\n",
      "|    total_timesteps    | 448500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89699       |\n",
      "|    policy_loss        | -0.235      |\n",
      "|    reward             | 0.019676575 |\n",
      "|    std                | 8.81e+06    |\n",
      "|    value_loss         | 6.39e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 89800         |\n",
      "|    time_elapsed       | 1438          |\n",
      "|    total_timesteps    | 449000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.9         |\n",
      "|    explained_variance | -0.155        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89799         |\n",
      "|    policy_loss        | 0.035         |\n",
      "|    reward             | -0.0012455796 |\n",
      "|    std                | 9.02e+06      |\n",
      "|    value_loss         | 0.000207      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 89900        |\n",
      "|    time_elapsed       | 1440         |\n",
      "|    total_timesteps    | 449500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89899        |\n",
      "|    policy_loss        | 0.348        |\n",
      "|    reward             | -0.009767938 |\n",
      "|    std                | 9.24e+06     |\n",
      "|    value_loss         | 0.000406     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 90000       |\n",
      "|    time_elapsed       | 1441        |\n",
      "|    total_timesteps    | 450000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89999       |\n",
      "|    policy_loss        | 0.184       |\n",
      "|    reward             | 0.023912076 |\n",
      "|    std                | 9.3e+06     |\n",
      "|    value_loss         | 0.00165     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 90100        |\n",
      "|    time_elapsed       | 1443         |\n",
      "|    total_timesteps    | 450500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90099        |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | -0.112152256 |\n",
      "|    std                | 9.38e+06     |\n",
      "|    value_loss         | 0.00328      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 90200      |\n",
      "|    time_elapsed       | 1444       |\n",
      "|    total_timesteps    | 451000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35        |\n",
      "|    explained_variance | -2.84e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90199      |\n",
      "|    policy_loss        | -13.7      |\n",
      "|    reward             | 0.36905304 |\n",
      "|    std                | 9.6e+06    |\n",
      "|    value_loss         | 0.157      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 1446        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35         |\n",
      "|    explained_variance | 0.174       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | 10.5        |\n",
      "|    reward             | -0.33915296 |\n",
      "|    std                | 9.72e+06    |\n",
      "|    value_loss         | 0.101       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 90400      |\n",
      "|    time_elapsed       | 1448       |\n",
      "|    total_timesteps    | 452000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35        |\n",
      "|    explained_variance | 7.75e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90399      |\n",
      "|    policy_loss        | -3.83      |\n",
      "|    reward             | -0.4853243 |\n",
      "|    std                | 9.8e+06    |\n",
      "|    value_loss         | 0.0339     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 90500      |\n",
      "|    time_elapsed       | 1449       |\n",
      "|    total_timesteps    | 452500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90499      |\n",
      "|    policy_loss        | 0.422      |\n",
      "|    reward             | 0.02573354 |\n",
      "|    std                | 9.81e+06   |\n",
      "|    value_loss         | 0.000303   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 90600       |\n",
      "|    time_elapsed       | 1451        |\n",
      "|    total_timesteps    | 453000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90599       |\n",
      "|    policy_loss        | -0.212      |\n",
      "|    reward             | -0.01134805 |\n",
      "|    std                | 9.89e+06    |\n",
      "|    value_loss         | 6.06e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 90700        |\n",
      "|    time_elapsed       | 1452         |\n",
      "|    total_timesteps    | 453500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90699        |\n",
      "|    policy_loss        | 0.123        |\n",
      "|    reward             | -0.007842598 |\n",
      "|    std                | 1.01e+07     |\n",
      "|    value_loss         | 7.98e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 90800        |\n",
      "|    time_elapsed       | 1454         |\n",
      "|    total_timesteps    | 454000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | -43.7        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90799        |\n",
      "|    policy_loss        | 0.0811       |\n",
      "|    reward             | 0.0038643447 |\n",
      "|    std                | 1.03e+07     |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 90900        |\n",
      "|    time_elapsed       | 1455         |\n",
      "|    total_timesteps    | 454500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90899        |\n",
      "|    policy_loss        | 0.532        |\n",
      "|    reward             | -0.014002576 |\n",
      "|    std                | 1.04e+07     |\n",
      "|    value_loss         | 0.000301     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 91000       |\n",
      "|    time_elapsed       | 1456        |\n",
      "|    total_timesteps    | 455000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90999       |\n",
      "|    policy_loss        | -1.94       |\n",
      "|    reward             | 0.043089334 |\n",
      "|    std                | 1.07e+07    |\n",
      "|    value_loss         | 0.00364     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 91100       |\n",
      "|    time_elapsed       | 1458        |\n",
      "|    total_timesteps    | 455500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91099       |\n",
      "|    policy_loss        | -1.61       |\n",
      "|    reward             | 0.017624367 |\n",
      "|    std                | 1.1e+07     |\n",
      "|    value_loss         | 0.0044      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 91200        |\n",
      "|    time_elapsed       | 1459         |\n",
      "|    total_timesteps    | 456000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91199        |\n",
      "|    policy_loss        | -0.357       |\n",
      "|    reward             | 0.0028364686 |\n",
      "|    std                | 1.12e+07     |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 91300       |\n",
      "|    time_elapsed       | 1461        |\n",
      "|    total_timesteps    | 456500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.3       |\n",
      "|    explained_variance | 0.559       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91299       |\n",
      "|    policy_loss        | -0.508      |\n",
      "|    reward             | -0.01533622 |\n",
      "|    std                | 1.14e+07    |\n",
      "|    value_loss         | 0.000345    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 91400        |\n",
      "|    time_elapsed       | 1462         |\n",
      "|    total_timesteps    | 457000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.4        |\n",
      "|    explained_variance | -0.0126      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91399        |\n",
      "|    policy_loss        | -1.57        |\n",
      "|    reward             | -0.046412576 |\n",
      "|    std                | 1.16e+07     |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 91500      |\n",
      "|    time_elapsed       | 1464       |\n",
      "|    total_timesteps    | 457500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.4      |\n",
      "|    explained_variance | 0.0227     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91499      |\n",
      "|    policy_loss        | -3.87      |\n",
      "|    reward             | 0.03622111 |\n",
      "|    std                | 1.18e+07   |\n",
      "|    value_loss         | 0.0148     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 91600      |\n",
      "|    time_elapsed       | 1465       |\n",
      "|    total_timesteps    | 458000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91599      |\n",
      "|    policy_loss        | 2.59       |\n",
      "|    reward             | 0.02035628 |\n",
      "|    std                | 1.18e+07   |\n",
      "|    value_loss         | 0.0147     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 91700       |\n",
      "|    time_elapsed       | 1467        |\n",
      "|    total_timesteps    | 458500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91699       |\n",
      "|    policy_loss        | -0.171      |\n",
      "|    reward             | 0.020263359 |\n",
      "|    std                | 1.19e+07    |\n",
      "|    value_loss         | 0.000115    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 91800        |\n",
      "|    time_elapsed       | 1469         |\n",
      "|    total_timesteps    | 459000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91799        |\n",
      "|    policy_loss        | 0.137        |\n",
      "|    reward             | -0.031031827 |\n",
      "|    std                | 1.22e+07     |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 91900       |\n",
      "|    time_elapsed       | 1470        |\n",
      "|    total_timesteps    | 459500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91899       |\n",
      "|    policy_loss        | 1.42        |\n",
      "|    reward             | 0.014278189 |\n",
      "|    std                | 1.25e+07    |\n",
      "|    value_loss         | 0.00163     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 92000     |\n",
      "|    time_elapsed       | 1472      |\n",
      "|    total_timesteps    | 460000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.6     |\n",
      "|    explained_variance | 0.0232    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 91999     |\n",
      "|    policy_loss        | -2.13     |\n",
      "|    reward             | 0.0620899 |\n",
      "|    std                | 1.28e+07  |\n",
      "|    value_loss         | 0.00436   |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -39355.97\n",
      "total_reward: -49355.97\n",
      "total_cost: 92.94\n",
      "total_trades: 5414\n",
      "Sharpe: 0.582\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 92100      |\n",
      "|    time_elapsed       | 1473       |\n",
      "|    total_timesteps    | 460500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92099      |\n",
      "|    policy_loss        | -0.624     |\n",
      "|    reward             | -0.0131914 |\n",
      "|    std                | 1.29e+07   |\n",
      "|    value_loss         | 0.000428   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 92200        |\n",
      "|    time_elapsed       | 1475         |\n",
      "|    total_timesteps    | 461000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92199        |\n",
      "|    policy_loss        | 0.14         |\n",
      "|    reward             | 0.0048481245 |\n",
      "|    std                | 1.32e+07     |\n",
      "|    value_loss         | 1.76e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 92300       |\n",
      "|    time_elapsed       | 1476        |\n",
      "|    total_timesteps    | 461500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92299       |\n",
      "|    policy_loss        | 0.311       |\n",
      "|    reward             | 0.049375854 |\n",
      "|    std                | 1.34e+07    |\n",
      "|    value_loss         | 0.000159    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 92400        |\n",
      "|    time_elapsed       | 1478         |\n",
      "|    total_timesteps    | 462000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92399        |\n",
      "|    policy_loss        | -0.282       |\n",
      "|    reward             | -0.010864852 |\n",
      "|    std                | 1.39e+07     |\n",
      "|    value_loss         | 7.47e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 92500        |\n",
      "|    time_elapsed       | 1479         |\n",
      "|    total_timesteps    | 462500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | -0.0254      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92499        |\n",
      "|    policy_loss        | -0.365       |\n",
      "|    reward             | -0.008087743 |\n",
      "|    std                | 1.45e+07     |\n",
      "|    value_loss         | 0.000199     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 92600        |\n",
      "|    time_elapsed       | 1481         |\n",
      "|    total_timesteps    | 463000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92599        |\n",
      "|    policy_loss        | 0.423        |\n",
      "|    reward             | -0.012380272 |\n",
      "|    std                | 1.5e+07      |\n",
      "|    value_loss         | 0.000166     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 92700       |\n",
      "|    time_elapsed       | 1482        |\n",
      "|    total_timesteps    | 463500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92699       |\n",
      "|    policy_loss        | 0.797       |\n",
      "|    reward             | -0.00669384 |\n",
      "|    std                | 1.56e+07    |\n",
      "|    value_loss         | 0.000512    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 92800         |\n",
      "|    time_elapsed       | 1484          |\n",
      "|    total_timesteps    | 464000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 92799         |\n",
      "|    policy_loss        | -0.669        |\n",
      "|    reward             | 0.00014031697 |\n",
      "|    std                | 1.61e+07      |\n",
      "|    value_loss         | 0.000352      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 92900        |\n",
      "|    time_elapsed       | 1485         |\n",
      "|    total_timesteps    | 464500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92899        |\n",
      "|    policy_loss        | -0.348       |\n",
      "|    reward             | -0.001710668 |\n",
      "|    std                | 1.68e+07     |\n",
      "|    value_loss         | 0.000233     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 93000      |\n",
      "|    time_elapsed       | 1487       |\n",
      "|    total_timesteps    | 465000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92999      |\n",
      "|    policy_loss        | -0.216     |\n",
      "|    reward             | 0.01176941 |\n",
      "|    std                | 1.75e+07   |\n",
      "|    value_loss         | 5.31e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 93100         |\n",
      "|    time_elapsed       | 1489          |\n",
      "|    total_timesteps    | 465500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 93099         |\n",
      "|    policy_loss        | 0.0298        |\n",
      "|    reward             | -0.0028416885 |\n",
      "|    std                | 1.83e+07      |\n",
      "|    value_loss         | 3.37e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 93200        |\n",
      "|    time_elapsed       | 1490         |\n",
      "|    total_timesteps    | 466000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93199        |\n",
      "|    policy_loss        | -5.87        |\n",
      "|    reward             | -0.021700665 |\n",
      "|    std                | 1.9e+07      |\n",
      "|    value_loss         | 0.029        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 93300       |\n",
      "|    time_elapsed       | 1492        |\n",
      "|    total_timesteps    | 466500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93299       |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | 0.058981888 |\n",
      "|    std                | 1.92e+07    |\n",
      "|    value_loss         | 0.00273     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 93400       |\n",
      "|    time_elapsed       | 1494        |\n",
      "|    total_timesteps    | 467000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93399       |\n",
      "|    policy_loss        | -0.795      |\n",
      "|    reward             | -0.05565641 |\n",
      "|    std                | 1.93e+07    |\n",
      "|    value_loss         | 0.0131      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 93500       |\n",
      "|    time_elapsed       | 1495        |\n",
      "|    total_timesteps    | 467500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.4       |\n",
      "|    explained_variance | 0.000112    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93499       |\n",
      "|    policy_loss        | -4.58       |\n",
      "|    reward             | -0.02191626 |\n",
      "|    std                | 1.98e+07    |\n",
      "|    value_loss         | 0.101       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 93600       |\n",
      "|    time_elapsed       | 1497        |\n",
      "|    total_timesteps    | 468000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93599       |\n",
      "|    policy_loss        | -18.1       |\n",
      "|    reward             | 0.088059485 |\n",
      "|    std                | 2.03e+07    |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 93700       |\n",
      "|    time_elapsed       | 1498        |\n",
      "|    total_timesteps    | 468500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93699       |\n",
      "|    policy_loss        | 0.543       |\n",
      "|    reward             | -0.01812334 |\n",
      "|    std                | 2.04e+07    |\n",
      "|    value_loss         | 0.000988    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 93800       |\n",
      "|    time_elapsed       | 1500        |\n",
      "|    total_timesteps    | 469000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93799       |\n",
      "|    policy_loss        | 0.803       |\n",
      "|    reward             | 0.011864179 |\n",
      "|    std                | 2.06e+07    |\n",
      "|    value_loss         | 0.00131     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 93900        |\n",
      "|    time_elapsed       | 1502         |\n",
      "|    total_timesteps    | 469500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93899        |\n",
      "|    policy_loss        | 2.77         |\n",
      "|    reward             | -0.005140543 |\n",
      "|    std                | 2.09e+07     |\n",
      "|    value_loss         | 0.00784      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 94000       |\n",
      "|    time_elapsed       | 1503        |\n",
      "|    total_timesteps    | 470000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93999       |\n",
      "|    policy_loss        | 0.286       |\n",
      "|    reward             | 0.006170042 |\n",
      "|    std                | 2.12e+07    |\n",
      "|    value_loss         | 0.000245    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 94100       |\n",
      "|    time_elapsed       | 1505        |\n",
      "|    total_timesteps    | 470500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.6       |\n",
      "|    explained_variance | 0.108       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94099       |\n",
      "|    policy_loss        | 2.58        |\n",
      "|    reward             | 0.003747854 |\n",
      "|    std                | 2.16e+07    |\n",
      "|    value_loss         | 0.00579     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 94200       |\n",
      "|    time_elapsed       | 1507        |\n",
      "|    total_timesteps    | 471000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94199       |\n",
      "|    policy_loss        | -9.23       |\n",
      "|    reward             | 0.042078413 |\n",
      "|    std                | 2.19e+07    |\n",
      "|    value_loss         | 0.0781      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 94300       |\n",
      "|    time_elapsed       | 1508        |\n",
      "|    total_timesteps    | 471500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94299       |\n",
      "|    policy_loss        | -0.318      |\n",
      "|    reward             | -0.02929425 |\n",
      "|    std                | 2.23e+07    |\n",
      "|    value_loss         | 0.000143    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 94400        |\n",
      "|    time_elapsed       | 1510         |\n",
      "|    total_timesteps    | 472000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94399        |\n",
      "|    policy_loss        | 0.452        |\n",
      "|    reward             | -0.009262659 |\n",
      "|    std                | 2.27e+07     |\n",
      "|    value_loss         | 0.000184     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 94500       |\n",
      "|    time_elapsed       | 1511        |\n",
      "|    total_timesteps    | 472500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94499       |\n",
      "|    policy_loss        | 0.482       |\n",
      "|    reward             | 0.009477091 |\n",
      "|    std                | 2.34e+07    |\n",
      "|    value_loss         | 0.000284    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 94600         |\n",
      "|    time_elapsed       | 1513          |\n",
      "|    total_timesteps    | 473000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.8         |\n",
      "|    explained_variance | -1.74e+03     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 94599         |\n",
      "|    policy_loss        | 1.93          |\n",
      "|    reward             | -0.0036664493 |\n",
      "|    std                | 2.41e+07      |\n",
      "|    value_loss         | 0.00616       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 94700        |\n",
      "|    time_elapsed       | 1514         |\n",
      "|    total_timesteps    | 473500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.8        |\n",
      "|    explained_variance | 0.194        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94699        |\n",
      "|    policy_loss        | 0.617        |\n",
      "|    reward             | -0.017932363 |\n",
      "|    std                | 2.42e+07     |\n",
      "|    value_loss         | 0.000358     |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 175\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -10227.03\n",
      "total_reward: -20227.03\n",
      "total_cost: 485.39\n",
      "total_trades: 5414\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 94800       |\n",
      "|    time_elapsed       | 1516        |\n",
      "|    total_timesteps    | 474000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94799       |\n",
      "|    policy_loss        | -2.33       |\n",
      "|    reward             | 0.037551086 |\n",
      "|    std                | 2.49e+07    |\n",
      "|    value_loss         | 0.00963     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 94900      |\n",
      "|    time_elapsed       | 1517       |\n",
      "|    total_timesteps    | 474500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94899      |\n",
      "|    policy_loss        | -1.63      |\n",
      "|    reward             | 0.10976503 |\n",
      "|    std                | 2.52e+07   |\n",
      "|    value_loss         | 0.00336    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 95000        |\n",
      "|    time_elapsed       | 1519         |\n",
      "|    total_timesteps    | 475000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94999        |\n",
      "|    policy_loss        | 0.733        |\n",
      "|    reward             | -0.025590278 |\n",
      "|    std                | 2.56e+07     |\n",
      "|    value_loss         | 0.00048      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 95100        |\n",
      "|    time_elapsed       | 1521         |\n",
      "|    total_timesteps    | 475500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95099        |\n",
      "|    policy_loss        | 0.457        |\n",
      "|    reward             | -0.011934008 |\n",
      "|    std                | 2.6e+07      |\n",
      "|    value_loss         | 0.000176     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 95200        |\n",
      "|    time_elapsed       | 1522         |\n",
      "|    total_timesteps    | 476000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37          |\n",
      "|    explained_variance | 0.25         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95199        |\n",
      "|    policy_loss        | -0.56        |\n",
      "|    reward             | -0.012146484 |\n",
      "|    std                | 2.68e+07     |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 95300       |\n",
      "|    time_elapsed       | 1524        |\n",
      "|    total_timesteps    | 476500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37         |\n",
      "|    explained_variance | 0.291       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95299       |\n",
      "|    policy_loss        | -0.174      |\n",
      "|    reward             | 0.009952295 |\n",
      "|    std                | 2.7e+07     |\n",
      "|    value_loss         | 0.000299    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 95400       |\n",
      "|    time_elapsed       | 1526        |\n",
      "|    total_timesteps    | 477000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95399       |\n",
      "|    policy_loss        | -1.05       |\n",
      "|    reward             | 0.061704412 |\n",
      "|    std                | 2.7e+07     |\n",
      "|    value_loss         | 0.00131     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 95500       |\n",
      "|    time_elapsed       | 1527        |\n",
      "|    total_timesteps    | 477500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95499       |\n",
      "|    policy_loss        | 1.64        |\n",
      "|    reward             | -0.02705469 |\n",
      "|    std                | 2.75e+07    |\n",
      "|    value_loss         | 0.00219     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 95600        |\n",
      "|    time_elapsed       | 1529         |\n",
      "|    total_timesteps    | 478000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.1        |\n",
      "|    explained_variance | -0.00122     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95599        |\n",
      "|    policy_loss        | -0.243       |\n",
      "|    reward             | -0.007977372 |\n",
      "|    std                | 2.78e+07     |\n",
      "|    value_loss         | 0.000973     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 95700        |\n",
      "|    time_elapsed       | 1530         |\n",
      "|    total_timesteps    | 478500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.1        |\n",
      "|    explained_variance | -0.673       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95699        |\n",
      "|    policy_loss        | -0.153       |\n",
      "|    reward             | -0.022193162 |\n",
      "|    std                | 2.82e+07     |\n",
      "|    value_loss         | 0.00228      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 95800      |\n",
      "|    time_elapsed       | 1532       |\n",
      "|    total_timesteps    | 479000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.1      |\n",
      "|    explained_variance | 0.381      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95799      |\n",
      "|    policy_loss        | 3.47       |\n",
      "|    reward             | 0.08987463 |\n",
      "|    std                | 2.82e+07   |\n",
      "|    value_loss         | 0.00974    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 95900         |\n",
      "|    time_elapsed       | 1533          |\n",
      "|    total_timesteps    | 479500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95899         |\n",
      "|    policy_loss        | 0.0387        |\n",
      "|    reward             | -0.0068234173 |\n",
      "|    std                | 2.83e+07      |\n",
      "|    value_loss         | 8.79e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 96000         |\n",
      "|    time_elapsed       | 1535          |\n",
      "|    total_timesteps    | 480000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95999         |\n",
      "|    policy_loss        | -0.31         |\n",
      "|    reward             | -0.0089180395 |\n",
      "|    std                | 2.88e+07      |\n",
      "|    value_loss         | 0.000103      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 312        |\n",
      "|    iterations         | 96100      |\n",
      "|    time_elapsed       | 1536       |\n",
      "|    total_timesteps    | 480500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96099      |\n",
      "|    policy_loss        | -1.22      |\n",
      "|    reward             | 0.01353237 |\n",
      "|    std                | 2.95e+07   |\n",
      "|    value_loss         | 0.00138    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 96200        |\n",
      "|    time_elapsed       | 1538         |\n",
      "|    total_timesteps    | 481000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96199        |\n",
      "|    policy_loss        | 0.551        |\n",
      "|    reward             | -0.008560238 |\n",
      "|    std                | 3.05e+07     |\n",
      "|    value_loss         | 0.000239     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 96300        |\n",
      "|    time_elapsed       | 1539         |\n",
      "|    total_timesteps    | 481500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96299        |\n",
      "|    policy_loss        | -0.716       |\n",
      "|    reward             | -0.017850792 |\n",
      "|    std                | 3.15e+07     |\n",
      "|    value_loss         | 0.000473     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 96400         |\n",
      "|    time_elapsed       | 1541          |\n",
      "|    total_timesteps    | 482000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.4         |\n",
      "|    explained_variance | -0.673        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96399         |\n",
      "|    policy_loss        | 0.18          |\n",
      "|    reward             | -0.0035079124 |\n",
      "|    std                | 3.28e+07      |\n",
      "|    value_loss         | 0.000123      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 312           |\n",
      "|    iterations         | 96500         |\n",
      "|    time_elapsed       | 1542          |\n",
      "|    total_timesteps    | 482500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96499         |\n",
      "|    policy_loss        | 0.237         |\n",
      "|    reward             | -0.0032194941 |\n",
      "|    std                | 3.41e+07      |\n",
      "|    value_loss         | 0.000192      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 96600       |\n",
      "|    time_elapsed       | 1543        |\n",
      "|    total_timesteps    | 483000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96599       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | -0.00422252 |\n",
      "|    std                | 3.46e+07    |\n",
      "|    value_loss         | 0.00152     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 96700       |\n",
      "|    time_elapsed       | 1545        |\n",
      "|    total_timesteps    | 483500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0.0545      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96699       |\n",
      "|    policy_loss        | -0.722      |\n",
      "|    reward             | 0.020721858 |\n",
      "|    std                | 3.54e+07    |\n",
      "|    value_loss         | 0.000953    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 96800       |\n",
      "|    time_elapsed       | 1546        |\n",
      "|    total_timesteps    | 484000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0.4         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96799       |\n",
      "|    policy_loss        | 2.64        |\n",
      "|    reward             | -0.06864136 |\n",
      "|    std                | 3.61e+07    |\n",
      "|    value_loss         | 0.00568     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 96900       |\n",
      "|    time_elapsed       | 1548        |\n",
      "|    total_timesteps    | 484500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0.454       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96899       |\n",
      "|    policy_loss        | 2.82        |\n",
      "|    reward             | 0.004258783 |\n",
      "|    std                | 3.6e+07     |\n",
      "|    value_loss         | 0.00605     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 97000       |\n",
      "|    time_elapsed       | 1550        |\n",
      "|    total_timesteps    | 485000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96999       |\n",
      "|    policy_loss        | 0.178       |\n",
      "|    reward             | 0.026549652 |\n",
      "|    std                | 3.63e+07    |\n",
      "|    value_loss         | 0.000874    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 97100        |\n",
      "|    time_elapsed       | 1551         |\n",
      "|    total_timesteps    | 485500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97099        |\n",
      "|    policy_loss        | 1.44         |\n",
      "|    reward             | -0.008780812 |\n",
      "|    std                | 3.66e+07     |\n",
      "|    value_loss         | 0.00186      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 97200       |\n",
      "|    time_elapsed       | 1553        |\n",
      "|    total_timesteps    | 486000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.7       |\n",
      "|    explained_variance | 0.0679      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97199       |\n",
      "|    policy_loss        | -0.455      |\n",
      "|    reward             | 0.008846958 |\n",
      "|    std                | 3.73e+07    |\n",
      "|    value_loss         | 0.000159    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 97300        |\n",
      "|    time_elapsed       | 1554         |\n",
      "|    total_timesteps    | 486500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97299        |\n",
      "|    policy_loss        | 1.22         |\n",
      "|    reward             | 0.0038102712 |\n",
      "|    std                | 3.81e+07     |\n",
      "|    value_loss         | 0.00126      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 97400        |\n",
      "|    time_elapsed       | 1556         |\n",
      "|    total_timesteps    | 487000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | 0.0921       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97399        |\n",
      "|    policy_loss        | -2.23        |\n",
      "|    reward             | -0.034335602 |\n",
      "|    std                | 3.88e+07     |\n",
      "|    value_loss         | 0.0044       |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 180\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -69719.58\n",
      "total_reward: -79719.58\n",
      "total_cost: 97.86\n",
      "total_trades: 5414\n",
      "Sharpe: -0.397\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 97500        |\n",
      "|    time_elapsed       | 1557         |\n",
      "|    total_timesteps    | 487500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97499        |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.022452798 |\n",
      "|    std                | 3.95e+07     |\n",
      "|    value_loss         | 0.00493      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 97600        |\n",
      "|    time_elapsed       | 1558         |\n",
      "|    total_timesteps    | 488000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97599        |\n",
      "|    policy_loss        | -1.02        |\n",
      "|    reward             | -0.037236862 |\n",
      "|    std                | 3.97e+07     |\n",
      "|    value_loss         | 0.00134      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 97700       |\n",
      "|    time_elapsed       | 1560        |\n",
      "|    total_timesteps    | 488500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97699       |\n",
      "|    policy_loss        | 0.664       |\n",
      "|    reward             | 0.012748474 |\n",
      "|    std                | 4e+07       |\n",
      "|    value_loss         | 0.000344    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 97800     |\n",
      "|    time_elapsed       | 1561      |\n",
      "|    total_timesteps    | 489000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37.8     |\n",
      "|    explained_variance | 0.103     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 97799     |\n",
      "|    policy_loss        | -10.3     |\n",
      "|    reward             | 0.0400164 |\n",
      "|    std                | 4e+07     |\n",
      "|    value_loss         | 0.0934    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 97900        |\n",
      "|    time_elapsed       | 1563         |\n",
      "|    total_timesteps    | 489500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97899        |\n",
      "|    policy_loss        | -7.78        |\n",
      "|    reward             | -0.054071244 |\n",
      "|    std                | 4.04e+07     |\n",
      "|    value_loss         | 0.0683       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98000       |\n",
      "|    time_elapsed       | 1564        |\n",
      "|    total_timesteps    | 490000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97999       |\n",
      "|    policy_loss        | -19.5       |\n",
      "|    reward             | -0.58032614 |\n",
      "|    std                | 4.04e+07    |\n",
      "|    value_loss         | 0.291       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98100       |\n",
      "|    time_elapsed       | 1565        |\n",
      "|    total_timesteps    | 490500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98099       |\n",
      "|    policy_loss        | -1.33       |\n",
      "|    reward             | -0.08664508 |\n",
      "|    std                | 4.08e+07    |\n",
      "|    value_loss         | 0.00445     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 98200        |\n",
      "|    time_elapsed       | 1567         |\n",
      "|    total_timesteps    | 491000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98199        |\n",
      "|    policy_loss        | -1.03        |\n",
      "|    reward             | -0.019462131 |\n",
      "|    std                | 4.11e+07     |\n",
      "|    value_loss         | 0.00083      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98300       |\n",
      "|    time_elapsed       | 1568        |\n",
      "|    total_timesteps    | 491500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98299       |\n",
      "|    policy_loss        | 2.22        |\n",
      "|    reward             | 0.024611454 |\n",
      "|    std                | 4.2e+07     |\n",
      "|    value_loss         | 0.00409     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 98400      |\n",
      "|    time_elapsed       | 1570       |\n",
      "|    total_timesteps    | 492000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.9      |\n",
      "|    explained_variance | 1.61e-06   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98399      |\n",
      "|    policy_loss        | -0.524     |\n",
      "|    reward             | 0.02907307 |\n",
      "|    std                | 4.27e+07   |\n",
      "|    value_loss         | 0.00237    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 98500         |\n",
      "|    time_elapsed       | 1572          |\n",
      "|    total_timesteps    | 492500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.9         |\n",
      "|    explained_variance | 0.545         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 98499         |\n",
      "|    policy_loss        | 0.98          |\n",
      "|    reward             | -0.0040048887 |\n",
      "|    std                | 4.28e+07      |\n",
      "|    value_loss         | 0.00078       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 98600        |\n",
      "|    time_elapsed       | 1573         |\n",
      "|    total_timesteps    | 493000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98599        |\n",
      "|    policy_loss        | 0.438        |\n",
      "|    reward             | -0.026693141 |\n",
      "|    std                | 4.32e+07     |\n",
      "|    value_loss         | 0.000334     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98700       |\n",
      "|    time_elapsed       | 1575        |\n",
      "|    total_timesteps    | 493500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98699       |\n",
      "|    policy_loss        | 1.44        |\n",
      "|    reward             | 0.014799417 |\n",
      "|    std                | 4.39e+07    |\n",
      "|    value_loss         | 0.00224     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 98800        |\n",
      "|    time_elapsed       | 1576         |\n",
      "|    total_timesteps    | 494000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98799        |\n",
      "|    policy_loss        | 1.74         |\n",
      "|    reward             | -0.042474434 |\n",
      "|    std                | 4.47e+07     |\n",
      "|    value_loss         | 0.00237      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 1578       |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.1      |\n",
      "|    explained_variance | -0.416     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98899      |\n",
      "|    policy_loss        | 0.983      |\n",
      "|    reward             | 0.05088626 |\n",
      "|    std                | 4.57e+07   |\n",
      "|    value_loss         | 0.000742   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 99000       |\n",
      "|    time_elapsed       | 1579        |\n",
      "|    total_timesteps    | 495000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98999       |\n",
      "|    policy_loss        | 0.601       |\n",
      "|    reward             | 0.038073134 |\n",
      "|    std                | 4.62e+07    |\n",
      "|    value_loss         | 0.000483    |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 99100    |\n",
      "|    time_elapsed       | 1581     |\n",
      "|    total_timesteps    | 495500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | 0.291    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 99099    |\n",
      "|    policy_loss        | 4.36     |\n",
      "|    reward             | -0.04345 |\n",
      "|    std                | 4.67e+07 |\n",
      "|    value_loss         | 0.0159   |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 99200      |\n",
      "|    time_elapsed       | 1582       |\n",
      "|    total_timesteps    | 496000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99199      |\n",
      "|    policy_loss        | 2.73       |\n",
      "|    reward             | 0.03487129 |\n",
      "|    std                | 4.69e+07   |\n",
      "|    value_loss         | 0.00667    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 99300       |\n",
      "|    time_elapsed       | 1584        |\n",
      "|    total_timesteps    | 496500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99299       |\n",
      "|    policy_loss        | 0.482       |\n",
      "|    reward             | -0.00582384 |\n",
      "|    std                | 4.73e+07    |\n",
      "|    value_loss         | 0.000555    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 99400       |\n",
      "|    time_elapsed       | 1585        |\n",
      "|    total_timesteps    | 497000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.2       |\n",
      "|    explained_variance | 0.131       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99399       |\n",
      "|    policy_loss        | -1.38       |\n",
      "|    reward             | 0.007705992 |\n",
      "|    std                | 4.82e+07    |\n",
      "|    value_loss         | 0.00188     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99500        |\n",
      "|    time_elapsed       | 1587         |\n",
      "|    total_timesteps    | 497500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.2        |\n",
      "|    explained_variance | 0.219        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99499        |\n",
      "|    policy_loss        | 0.177        |\n",
      "|    reward             | -0.009310712 |\n",
      "|    std                | 4.91e+07     |\n",
      "|    value_loss         | 0.000542     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99600        |\n",
      "|    time_elapsed       | 1588         |\n",
      "|    total_timesteps    | 498000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99599        |\n",
      "|    policy_loss        | -0.637       |\n",
      "|    reward             | -0.025271779 |\n",
      "|    std                | 5e+07        |\n",
      "|    value_loss         | 0.000639     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99700        |\n",
      "|    time_elapsed       | 1590         |\n",
      "|    total_timesteps    | 498500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99699        |\n",
      "|    policy_loss        | 0.705        |\n",
      "|    reward             | -0.056033917 |\n",
      "|    std                | 5.04e+07     |\n",
      "|    value_loss         | 0.00269      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99800        |\n",
      "|    time_elapsed       | 1591         |\n",
      "|    total_timesteps    | 499000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99799        |\n",
      "|    policy_loss        | -0.958       |\n",
      "|    reward             | -0.028477235 |\n",
      "|    std                | 5.07e+07     |\n",
      "|    value_loss         | 0.000713     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 99900       |\n",
      "|    time_elapsed       | 1592        |\n",
      "|    total_timesteps    | 499500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99899       |\n",
      "|    policy_loss        | -4.18       |\n",
      "|    reward             | 0.033733305 |\n",
      "|    std                | 5.09e+07    |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 100000        |\n",
      "|    time_elapsed       | 1594          |\n",
      "|    total_timesteps    | 500000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.3         |\n",
      "|    explained_variance | -0.0187       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99999         |\n",
      "|    policy_loss        | -3.01         |\n",
      "|    reward             | -0.0065822867 |\n",
      "|    std                | 5.13e+07      |\n",
      "|    value_loss         | 0.0152        |\n",
      "-----------------------------------------\n",
      "======A2C Validation from:  2021-01-04 to  2021-04-06\n",
      "A2C Sharpe Ratio:  -0.058675181133295215\n",
      "======Best Model Retraining from:  2010-04-01 to  2021-04-06\n",
      "======Trading from:  2021-04-06 to  2021-07-06\n",
      "[[1.00000000e+04 1.29873489e+02 4.58832611e+02 0.00000000e+00\n",
      "  0.00000000e+00 1.74376881e+00 4.65067148e+00 1.28886871e+02\n",
      "  4.69388184e+02 1.16377350e+02 4.13412140e+02 6.06303902e+01\n",
      "  5.49654160e+01 2.25215164e+02 1.10213249e+02 3.74220161e+01\n",
      "  6.06779385e+00 1.21544266e+02 4.39414581e+02 1.22726051e+02\n",
      "  4.38737152e+02]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "turbulence_threshold:  18.962641042223694\n",
      "======Model training from:  2010-04-01 to  2021-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_189_1\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.85        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0853      |\n",
      "|    reward             | -0.045984533 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 294         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.9        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.0425     |\n",
      "|    reward             | 0.042183142 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000675    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.249      |\n",
      "|    reward             | -0.13565633 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.031       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.9       |\n",
      "|    explained_variance | -0.488     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.274     |\n",
      "|    reward             | 0.06592125 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.0364     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 300       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.91     |\n",
      "|    explained_variance | 0.109     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 0.0291    |\n",
      "|    reward             | 1.0136185 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 290        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.93      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 0.0468     |\n",
      "|    reward             | 0.01814403 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.000439   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 295        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 0.179      |\n",
      "|    reward             | 0.04964277 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.00224    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 294          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3           |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | -0.026415188 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 0.00959      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 293          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3           |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | -0.238       |\n",
      "|    reward             | -0.039547037 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 293         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.02       |\n",
      "|    explained_variance | -6.88       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.467       |\n",
      "|    reward             | -0.15078309 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.0407      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 296        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.05      |\n",
      "|    explained_variance | 0.107      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 2.51       |\n",
      "|    reward             | 0.38299677 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 299          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.06        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.425       |\n",
      "|    reward             | -0.020846928 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.0163       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.08        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.198       |\n",
      "|    reward             | -0.037044544 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.00654      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.13      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 0.887      |\n",
      "|    reward             | 0.15419233 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.126      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 303        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.15      |\n",
      "|    explained_variance | 0.512      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 0.427      |\n",
      "|    reward             | 0.14662518 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.0192     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.16       |\n",
      "|    explained_variance | 0.000101    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.113       |\n",
      "|    reward             | 0.022190373 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.00356     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.19       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.0681     |\n",
      "|    reward             | 0.013309299 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.000662    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.21       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 0.0748      |\n",
      "|    reward             | 0.009693455 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 0.000744    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.26        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.13         |\n",
      "|    reward             | -0.031643808 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 0.00212      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.31        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.0248      |\n",
      "|    reward             | 0.0047276653 |\n",
      "|    std                | 1.27         |\n",
      "|    value_loss         | 0.000294     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.36       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -0.159      |\n",
      "|    reward             | 0.028022073 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 0.00218     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.38       |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -0.322      |\n",
      "|    reward             | 0.015161105 |\n",
      "|    std                | 1.31        |\n",
      "|    value_loss         | 0.00851     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.43        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | 0.00561      |\n",
      "|    reward             | 0.0031738319 |\n",
      "|    std                | 1.35         |\n",
      "|    value_loss         | 0.00041      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | -0.0146     |\n",
      "|    reward             | 0.012087634 |\n",
      "|    std                | 1.39        |\n",
      "|    value_loss         | 0.000152    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.53     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -0.118    |\n",
      "|    reward             | 0.0258194 |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 0.00106   |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 313            |\n",
      "|    iterations         | 2600           |\n",
      "|    time_elapsed       | 41             |\n",
      "|    total_timesteps    | 13000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.59          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 2599           |\n",
      "|    policy_loss        | -0.0631        |\n",
      "|    reward             | -0.00035019446 |\n",
      "|    std                | 1.46           |\n",
      "|    value_loss         | 0.000654       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.65        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.0703      |\n",
      "|    reward             | 0.0091348905 |\n",
      "|    std                | 1.5          |\n",
      "|    value_loss         | 0.000769     |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -28111.61\n",
      "total_reward: -38111.61\n",
      "total_cost: 64.31\n",
      "total_trades: 5540\n",
      "Sharpe: 0.474\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.67        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.0658       |\n",
      "|    reward             | -0.012643569 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 0.00049      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.7        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 0.181       |\n",
      "|    reward             | 0.052491874 |\n",
      "|    std                | 1.54        |\n",
      "|    value_loss         | 0.00413     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.74       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | 1.7         |\n",
      "|    reward             | -0.06900871 |\n",
      "|    std                | 1.57        |\n",
      "|    value_loss         | 0.221       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.73      |\n",
      "|    explained_variance | -0.076     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | -0.282     |\n",
      "|    reward             | 0.02403521 |\n",
      "|    std                | 1.57       |\n",
      "|    value_loss         | 0.00724    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.73      |\n",
      "|    explained_variance | -0.573     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -0.199     |\n",
      "|    reward             | 0.09938106 |\n",
      "|    std                | 1.56       |\n",
      "|    value_loss         | 0.00604    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.73     |\n",
      "|    explained_variance | 0.0832    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -0.00324  |\n",
      "|    reward             | 0.4121152 |\n",
      "|    std                | 1.57      |\n",
      "|    value_loss         | 0.0216    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.75        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.129       |\n",
      "|    reward             | -0.013825472 |\n",
      "|    std                | 1.58         |\n",
      "|    value_loss         | 0.00292      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.8        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 0.00976     |\n",
      "|    reward             | -0.01639487 |\n",
      "|    std                | 1.62        |\n",
      "|    value_loss         | 4.47e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.0519     |\n",
      "|    reward             | 0.002228489 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 0.000454    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 58           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.9         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | 0.0839       |\n",
      "|    reward             | -0.011490769 |\n",
      "|    std                | 1.7          |\n",
      "|    value_loss         | 0.000442     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.96        |\n",
      "|    explained_variance | -4.18        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | -0.0455      |\n",
      "|    reward             | -0.005140037 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 0.00426      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 317            |\n",
      "|    iterations         | 3900           |\n",
      "|    time_elapsed       | 61             |\n",
      "|    total_timesteps    | 19500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.01          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 3899           |\n",
      "|    policy_loss        | -0.00197       |\n",
      "|    reward             | -0.00045814743 |\n",
      "|    std                | 1.79           |\n",
      "|    value_loss         | 0.000259       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.04        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.0691       |\n",
      "|    reward             | -0.011721875 |\n",
      "|    std                | 1.83         |\n",
      "|    value_loss         | 0.00041      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 64            |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.1          |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | -0.0133       |\n",
      "|    reward             | -0.0038488489 |\n",
      "|    std                | 1.88          |\n",
      "|    value_loss         | 4.24e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 66            |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.12         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | -0.269        |\n",
      "|    reward             | -0.0046543316 |\n",
      "|    std                | 1.89          |\n",
      "|    value_loss         | 0.00376       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.17       |\n",
      "|    explained_variance | -0.0323     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | 0.335       |\n",
      "|    reward             | 0.010610363 |\n",
      "|    std                | 1.95        |\n",
      "|    value_loss         | 0.00739     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.2        |\n",
      "|    explained_variance | -1.24       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | -0.492      |\n",
      "|    reward             | -0.06828503 |\n",
      "|    std                | 1.98        |\n",
      "|    value_loss         | 0.0166      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.24        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | -0.0371      |\n",
      "|    reward             | 0.0005574305 |\n",
      "|    std                | 2.02         |\n",
      "|    value_loss         | 0.000232     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.27       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -0.0545     |\n",
      "|    reward             | 0.005572739 |\n",
      "|    std                | 2.05        |\n",
      "|    value_loss         | 0.000231    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.32       |\n",
      "|    explained_variance | 4.74e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | 0.119       |\n",
      "|    reward             | 0.017143784 |\n",
      "|    std                | 2.09        |\n",
      "|    value_loss         | 0.00563     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 315      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.35    |\n",
      "|    explained_variance | 0.0176   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.189    |\n",
      "|    reward             | -0.074   |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 0.00468  |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 77            |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.38         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -1.85         |\n",
      "|    reward             | -0.0042839036 |\n",
      "|    std                | 2.17          |\n",
      "|    value_loss         | 0.196         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 79          |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.42       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.139       |\n",
      "|    reward             | 0.029168608 |\n",
      "|    std                | 2.2         |\n",
      "|    value_loss         | 0.000718    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.45       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 0.0344      |\n",
      "|    reward             | 0.028387077 |\n",
      "|    std                | 2.24        |\n",
      "|    value_loss         | 8.67e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 82           |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.48        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | 0.0547       |\n",
      "|    reward             | 0.0091512315 |\n",
      "|    std                | 2.27         |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.53        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.243       |\n",
      "|    reward             | 0.0102559095 |\n",
      "|    std                | 2.33         |\n",
      "|    value_loss         | 0.00442      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.57       |\n",
      "|    explained_variance | -0.037      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.096      |\n",
      "|    reward             | 0.044131212 |\n",
      "|    std                | 2.38        |\n",
      "|    value_loss         | 0.00071     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 5500          |\n",
      "|    time_elapsed       | 86            |\n",
      "|    total_timesteps    | 27500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.61         |\n",
      "|    explained_variance | -0.212        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 5499          |\n",
      "|    policy_loss        | -0.23         |\n",
      "|    reward             | 0.00017694134 |\n",
      "|    std                | 2.43          |\n",
      "|    value_loss         | 0.00555       |\n",
      "-----------------------------------------\n",
      "day: 2770, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -48841.50\n",
      "total_reward: -58841.50\n",
      "total_cost: 95.23\n",
      "total_trades: 5540\n",
      "Sharpe: -0.108\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.66       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | 0.0772      |\n",
      "|    reward             | -0.13379517 |\n",
      "|    std                | 2.48        |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.67       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.159      |\n",
      "|    reward             | 0.025052723 |\n",
      "|    std                | 2.5         |\n",
      "|    value_loss         | 0.00114     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 91          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.71       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -0.474      |\n",
      "|    reward             | -0.07469477 |\n",
      "|    std                | 2.55        |\n",
      "|    value_loss         | 0.0128      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.73        |\n",
      "|    explained_variance | 0.116        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.234        |\n",
      "|    reward             | 0.0060952837 |\n",
      "|    std                | 2.57         |\n",
      "|    value_loss         | 0.00444      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 94         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.73      |\n",
      "|    explained_variance | 0.0309     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | -0.49      |\n",
      "|    reward             | 0.10068077 |\n",
      "|    std                | 2.58       |\n",
      "|    value_loss         | 0.0141     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.72        |\n",
      "|    explained_variance | -2.93        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | 0.213        |\n",
      "|    reward             | -0.024633745 |\n",
      "|    std                | 2.56         |\n",
      "|    value_loss         | 0.00203      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.74       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 0.126       |\n",
      "|    reward             | 0.043571576 |\n",
      "|    std                | 2.58        |\n",
      "|    value_loss         | 0.00121     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.76        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | 0.216        |\n",
      "|    reward             | -0.012507843 |\n",
      "|    std                | 2.61         |\n",
      "|    value_loss         | 0.00269      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.78        |\n",
      "|    explained_variance | -1.6         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -0.0657      |\n",
      "|    reward             | 0.0009230827 |\n",
      "|    std                | 2.64         |\n",
      "|    value_loss         | 0.000445     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.83        |\n",
      "|    explained_variance | -1.35        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 0.0566       |\n",
      "|    reward             | -0.031236323 |\n",
      "|    std                | 2.7          |\n",
      "|    value_loss         | 0.00276      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.88       |\n",
      "|    explained_variance | 0.0291      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.417      |\n",
      "|    reward             | 0.030364132 |\n",
      "|    std                | 2.78        |\n",
      "|    value_loss         | 0.0186      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.9         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 0.105        |\n",
      "|    reward             | 0.0098046465 |\n",
      "|    std                | 2.8          |\n",
      "|    value_loss         | 0.00332      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.91         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | -0.0421       |\n",
      "|    reward             | -0.0040262486 |\n",
      "|    std                | 2.81          |\n",
      "|    value_loss         | 0.000383      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 109          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.93        |\n",
      "|    explained_variance | -0.125       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 0.385        |\n",
      "|    reward             | -0.030424776 |\n",
      "|    std                | 2.84         |\n",
      "|    value_loss         | 0.00818      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.97        |\n",
      "|    explained_variance | 0.0591       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.0711      |\n",
      "|    reward             | -0.004248339 |\n",
      "|    std                | 2.9          |\n",
      "|    value_loss         | 0.000809     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.98      |\n",
      "|    explained_variance | 0.469      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 0.0214     |\n",
      "|    reward             | 0.02466449 |\n",
      "|    std                | 2.92       |\n",
      "|    value_loss         | 0.000577   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | 0.472      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | 0.0176     |\n",
      "|    reward             | 0.28829855 |\n",
      "|    std                | 2.96       |\n",
      "|    value_loss         | 0.00776    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 115           |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.02         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | 0.0447        |\n",
      "|    reward             | -0.0050265808 |\n",
      "|    std                | 2.99          |\n",
      "|    value_loss         | 0.000135      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.06         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | -0.115        |\n",
      "|    reward             | 0.00016615693 |\n",
      "|    std                | 3.04          |\n",
      "|    value_loss         | 0.000684      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 118          |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.1         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | 0.154        |\n",
      "|    reward             | -0.024786202 |\n",
      "|    std                | 3.11         |\n",
      "|    value_loss         | 0.00099      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 120          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.17        |\n",
      "|    explained_variance | -201         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.654        |\n",
      "|    reward             | 0.0062139607 |\n",
      "|    std                | 3.22         |\n",
      "|    value_loss         | 0.0252       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 121          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.2         |\n",
      "|    explained_variance | -1.56        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.157        |\n",
      "|    reward             | -0.012218624 |\n",
      "|    std                | 3.26         |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.23        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.193        |\n",
      "|    reward             | 0.0037891723 |\n",
      "|    std                | 3.3          |\n",
      "|    value_loss         | 0.0018       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 124          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.28        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -0.139       |\n",
      "|    reward             | -0.004299651 |\n",
      "|    std                | 3.39         |\n",
      "|    value_loss         | 0.00109      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.34       |\n",
      "|    explained_variance | 0.178       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -0.103      |\n",
      "|    reward             | 0.016534476 |\n",
      "|    std                | 3.49        |\n",
      "|    value_loss         | 0.00047     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 127          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.41        |\n",
      "|    explained_variance | -23          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | 0.128        |\n",
      "|    reward             | -0.007073709 |\n",
      "|    std                | 3.62         |\n",
      "|    value_loss         | 0.000958     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.46       |\n",
      "|    explained_variance | 3.56e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -0.0617     |\n",
      "|    reward             | -0.01691649 |\n",
      "|    std                | 3.73        |\n",
      "|    value_loss         | 0.000504    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 130          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.53        |\n",
      "|    explained_variance | 0.304        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.00227     |\n",
      "|    reward             | -0.011292025 |\n",
      "|    std                | 3.85         |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -17445.82\n",
      "total_reward: -27445.82\n",
      "total_cost: 240.99\n",
      "total_trades: 5540\n",
      "Sharpe: 0.568\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.6         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.485        |\n",
      "|    reward             | -0.062370006 |\n",
      "|    std                | 4            |\n",
      "|    value_loss         | 0.00749      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 133          |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.65        |\n",
      "|    explained_variance | 0.282        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | -0.0389      |\n",
      "|    reward             | -0.059481937 |\n",
      "|    std                | 4.07         |\n",
      "|    value_loss         | 0.000402     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.69      |\n",
      "|    explained_variance | -20.5      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -0.639     |\n",
      "|    reward             | 0.02035305 |\n",
      "|    std                | 4.15       |\n",
      "|    value_loss         | 0.015      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.72        |\n",
      "|    explained_variance | 6.26e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 0.239        |\n",
      "|    reward             | -0.007310607 |\n",
      "|    std                | 4.24         |\n",
      "|    value_loss         | 0.00174      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 137        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.78      |\n",
      "|    explained_variance | 0.000592   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | -0.173     |\n",
      "|    reward             | 0.01638503 |\n",
      "|    std                | 4.35       |\n",
      "|    value_loss         | 0.00106    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.81       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 0.164       |\n",
      "|    reward             | 0.026108487 |\n",
      "|    std                | 4.41        |\n",
      "|    value_loss         | 0.00119     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.83        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | 0.104        |\n",
      "|    reward             | -0.038368095 |\n",
      "|    std                | 4.46         |\n",
      "|    value_loss         | 0.00059      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 9100          |\n",
      "|    time_elapsed       | 141           |\n",
      "|    total_timesteps    | 45500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.86         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 9099          |\n",
      "|    policy_loss        | -0.14         |\n",
      "|    reward             | -0.0016078727 |\n",
      "|    std                | 4.54          |\n",
      "|    value_loss         | 0.000629      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.91        |\n",
      "|    explained_variance | -0.000434    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.0203       |\n",
      "|    reward             | 0.0007410616 |\n",
      "|    std                | 4.65         |\n",
      "|    value_loss         | 2.18e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 144         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | -21.7       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -0.993      |\n",
      "|    reward             | 0.009306929 |\n",
      "|    std                | 4.72        |\n",
      "|    value_loss         | 0.0229      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 146          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.98        |\n",
      "|    explained_variance | -0.0371      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.0563       |\n",
      "|    reward             | -0.013133166 |\n",
      "|    std                | 4.82         |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -0.041      |\n",
      "|    reward             | 0.011872419 |\n",
      "|    std                | 4.95        |\n",
      "|    value_loss         | 0.000243    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -0.00836    |\n",
      "|    reward             | -0.01211808 |\n",
      "|    std                | 5.05        |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.15       |\n",
      "|    explained_variance | -0.613      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 0.0321      |\n",
      "|    reward             | 0.015996732 |\n",
      "|    std                | 5.24        |\n",
      "|    value_loss         | 0.000146    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 9800          |\n",
      "|    time_elapsed       | 152           |\n",
      "|    total_timesteps    | 49000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.2          |\n",
      "|    explained_variance | -0.0314       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 9799          |\n",
      "|    policy_loss        | 0.0369        |\n",
      "|    reward             | -0.0076073515 |\n",
      "|    std                | 5.38          |\n",
      "|    value_loss         | 6.67e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.26       |\n",
      "|    explained_variance | 0.242       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 0.086       |\n",
      "|    reward             | -0.01067439 |\n",
      "|    std                | 5.54        |\n",
      "|    value_loss         | 0.000388    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.3        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -0.377      |\n",
      "|    reward             | -0.03313696 |\n",
      "|    std                | 5.64        |\n",
      "|    value_loss         | 0.00519     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 10100         |\n",
      "|    time_elapsed       | 157           |\n",
      "|    total_timesteps    | 50500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.34         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10099         |\n",
      "|    policy_loss        | 0.23          |\n",
      "|    reward             | -0.0008894476 |\n",
      "|    std                | 5.77          |\n",
      "|    value_loss         | 0.00164       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 10200        |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 51000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.36        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | -0.124       |\n",
      "|    reward             | -0.022598531 |\n",
      "|    std                | 5.82         |\n",
      "|    value_loss         | 0.000624     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 10300      |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 51500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.36      |\n",
      "|    explained_variance | -0.00473   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10299      |\n",
      "|    policy_loss        | 0.0544     |\n",
      "|    reward             | 0.11376831 |\n",
      "|    std                | 5.83       |\n",
      "|    value_loss         | 0.000171   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 10400       |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 52000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.4        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -0.466      |\n",
      "|    reward             | -0.02278519 |\n",
      "|    std                | 5.92        |\n",
      "|    value_loss         | 0.00581     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 163         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.41       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | -0.283      |\n",
      "|    reward             | -0.03801495 |\n",
      "|    std                | 5.97        |\n",
      "|    value_loss         | 0.00227     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.4        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | -1.23       |\n",
      "|    reward             | 0.059127543 |\n",
      "|    std                | 5.95        |\n",
      "|    value_loss         | 0.055       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 10700        |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 53500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.42        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | -0.197       |\n",
      "|    reward             | 0.0028501654 |\n",
      "|    std                | 6.01         |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 10800      |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 54000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.46      |\n",
      "|    explained_variance | -0.0626    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10799      |\n",
      "|    policy_loss        | 0.818      |\n",
      "|    reward             | 0.06080024 |\n",
      "|    std                | 6.11       |\n",
      "|    value_loss         | 0.0166     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 10900       |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 54500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.47       |\n",
      "|    explained_variance | 0.131       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | 0.921       |\n",
      "|    reward             | 0.049120966 |\n",
      "|    std                | 6.17        |\n",
      "|    value_loss         | 0.0363      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 322       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.47     |\n",
      "|    explained_variance | 0.0032    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -0.617    |\n",
      "|    reward             | 0.4722834 |\n",
      "|    std                | 6.15      |\n",
      "|    value_loss         | 0.0159    |\n",
      "-------------------------------------\n",
      "day: 2770, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -230678.07\n",
      "total_reward: -240678.07\n",
      "total_cost: 104.31\n",
      "total_trades: 5540\n",
      "Sharpe: -0.294\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 11100       |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 55500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.47       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | 0.407       |\n",
      "|    reward             | 0.053196516 |\n",
      "|    std                | 6.15        |\n",
      "|    value_loss         | 0.00625     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 11200       |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 56000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | 0.823       |\n",
      "|    reward             | -0.15839997 |\n",
      "|    std                | 6.21        |\n",
      "|    value_loss         | 0.0236      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 11300       |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 56500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.51       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | 0.555       |\n",
      "|    reward             | 0.098925054 |\n",
      "|    std                | 6.28        |\n",
      "|    value_loss         | 0.00846     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 11400       |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 57000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.52       |\n",
      "|    explained_variance | 0.127       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | 0.533       |\n",
      "|    reward             | -0.06071836 |\n",
      "|    std                | 6.33        |\n",
      "|    value_loss         | 0.0308      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 11500       |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 57500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.54       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 2.55        |\n",
      "|    reward             | -0.10018485 |\n",
      "|    std                | 6.36        |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 11600      |\n",
      "|    time_elapsed       | 179        |\n",
      "|    total_timesteps    | 58000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.56      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11599      |\n",
      "|    policy_loss        | 1.51       |\n",
      "|    reward             | 0.13290498 |\n",
      "|    std                | 6.42       |\n",
      "|    value_loss         | 0.102      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 11700       |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 58500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.57       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | 0.247       |\n",
      "|    reward             | -0.14076827 |\n",
      "|    std                | 6.46        |\n",
      "|    value_loss         | 0.00239     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 11800      |\n",
      "|    time_elapsed       | 182        |\n",
      "|    total_timesteps    | 59000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.58      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11799      |\n",
      "|    policy_loss        | 0.405      |\n",
      "|    reward             | 0.04925309 |\n",
      "|    std                | 6.5        |\n",
      "|    value_loss         | 0.00436    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 11900       |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 59500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.61       |\n",
      "|    explained_variance | 0.0592      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11899       |\n",
      "|    policy_loss        | 1.66        |\n",
      "|    reward             | -0.09522693 |\n",
      "|    std                | 6.6         |\n",
      "|    value_loss         | 0.0821      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 12000        |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 60000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.63        |\n",
      "|    explained_variance | 0.000722     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11999        |\n",
      "|    policy_loss        | 1.65         |\n",
      "|    reward             | -0.021154761 |\n",
      "|    std                | 6.66         |\n",
      "|    value_loss         | 0.0631       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 12100        |\n",
      "|    time_elapsed       | 187          |\n",
      "|    total_timesteps    | 60500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.64        |\n",
      "|    explained_variance | 2.01e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12099        |\n",
      "|    policy_loss        | 2.53         |\n",
      "|    reward             | -0.004504418 |\n",
      "|    std                | 6.71         |\n",
      "|    value_loss         | 0.283        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 12200        |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 61000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.63        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12199        |\n",
      "|    policy_loss        | 0.392        |\n",
      "|    reward             | -0.049900524 |\n",
      "|    std                | 6.66         |\n",
      "|    value_loss         | 0.00514      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 12300       |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 61500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.66       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 0.185       |\n",
      "|    reward             | 0.009119897 |\n",
      "|    std                | 6.77        |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 12400        |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 62000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.7         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12399        |\n",
      "|    policy_loss        | -0.0912      |\n",
      "|    reward             | -0.012666866 |\n",
      "|    std                | 6.9          |\n",
      "|    value_loss         | 0.000786     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 12500        |\n",
      "|    time_elapsed       | 192          |\n",
      "|    total_timesteps    | 62500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.72        |\n",
      "|    explained_variance | -0.707       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | 0.4          |\n",
      "|    reward             | 0.0021004057 |\n",
      "|    std                | 6.99         |\n",
      "|    value_loss         | 0.00399      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 12600        |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 63000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.73        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12599        |\n",
      "|    policy_loss        | 0.174        |\n",
      "|    reward             | -0.051546838 |\n",
      "|    std                | 7.02         |\n",
      "|    value_loss         | 0.000999     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 12700      |\n",
      "|    time_elapsed       | 196        |\n",
      "|    total_timesteps    | 63500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.76      |\n",
      "|    explained_variance | -0.0261    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12699      |\n",
      "|    policy_loss        | -0.291     |\n",
      "|    reward             | 0.13766614 |\n",
      "|    std                | 7.11       |\n",
      "|    value_loss         | 0.00792    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 12800         |\n",
      "|    time_elapsed       | 197           |\n",
      "|    total_timesteps    | 64000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.78         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12799         |\n",
      "|    policy_loss        | 0.0359        |\n",
      "|    reward             | -0.0066492157 |\n",
      "|    std                | 7.19          |\n",
      "|    value_loss         | 7.97e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 12900          |\n",
      "|    time_elapsed       | 199            |\n",
      "|    total_timesteps    | 64500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.81          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 12899          |\n",
      "|    policy_loss        | -0.136         |\n",
      "|    reward             | -0.00018157615 |\n",
      "|    std                | 7.28           |\n",
      "|    value_loss         | 0.000482       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 13000        |\n",
      "|    time_elapsed       | 200          |\n",
      "|    total_timesteps    | 65000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.87        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | -0.0177      |\n",
      "|    reward             | -0.006847803 |\n",
      "|    std                | 7.52         |\n",
      "|    value_loss         | 1.19e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 13100        |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 65500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.95        |\n",
      "|    explained_variance | -3.38        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13099        |\n",
      "|    policy_loss        | -0.0512      |\n",
      "|    reward             | 0.0007948766 |\n",
      "|    std                | 7.82         |\n",
      "|    value_loss         | 6e-05        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 13200       |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 66000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.01       |\n",
      "|    explained_variance | -0.531      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | 0.179       |\n",
      "|    reward             | 0.007527484 |\n",
      "|    std                | 8.09        |\n",
      "|    value_loss         | 0.000845    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 13300       |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 66500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | 0.144       |\n",
      "|    reward             | 0.021387098 |\n",
      "|    std                | 8.16        |\n",
      "|    value_loss         | 0.000521    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 13400        |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 67000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.06        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13399        |\n",
      "|    policy_loss        | -0.486       |\n",
      "|    reward             | 0.0059281616 |\n",
      "|    std                | 8.24         |\n",
      "|    value_loss         | 0.00438      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 13500        |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 67500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.08        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | 0.248        |\n",
      "|    reward             | -0.017153319 |\n",
      "|    std                | 8.33         |\n",
      "|    value_loss         | 0.00126      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 13600        |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 68000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.08        |\n",
      "|    explained_variance | 0.318        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13599        |\n",
      "|    policy_loss        | -0.573       |\n",
      "|    reward             | -0.040710356 |\n",
      "|    std                | 8.34         |\n",
      "|    value_loss         | 0.00536      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 13700       |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 68500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | 4.17e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13699       |\n",
      "|    policy_loss        | 0.355       |\n",
      "|    reward             | 0.011275968 |\n",
      "|    std                | 8.49        |\n",
      "|    value_loss         | 0.00276     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 13800       |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 69000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.14       |\n",
      "|    explained_variance | 0.219       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | 1.41        |\n",
      "|    reward             | 0.095435776 |\n",
      "|    std                | 8.58        |\n",
      "|    value_loss         | 0.0499      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -50916.93\n",
      "total_reward: -60916.93\n",
      "total_cost: 95.67\n",
      "total_trades: 5540\n",
      "Sharpe: 0.428\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 13900       |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 69500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.13       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | -0.205      |\n",
      "|    reward             | 0.035850886 |\n",
      "|    std                | 8.56        |\n",
      "|    value_loss         | 0.000995    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 14000        |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 70000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.17        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13999        |\n",
      "|    policy_loss        | 0.0445       |\n",
      "|    reward             | -0.010868196 |\n",
      "|    std                | 8.75         |\n",
      "|    value_loss         | 5.13e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 14100        |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 70500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.22        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | -0.0928      |\n",
      "|    reward             | -0.012295171 |\n",
      "|    std                | 8.98         |\n",
      "|    value_loss         | 0.000258     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 14200         |\n",
      "|    time_elapsed       | 217           |\n",
      "|    total_timesteps    | 71000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.28         |\n",
      "|    explained_variance | 0.206         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14199         |\n",
      "|    policy_loss        | 0.0292        |\n",
      "|    reward             | -0.0017399125 |\n",
      "|    std                | 9.25          |\n",
      "|    value_loss         | 5.49e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 14300         |\n",
      "|    time_elapsed       | 219           |\n",
      "|    total_timesteps    | 71500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.34         |\n",
      "|    explained_variance | -51           |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14299         |\n",
      "|    policy_loss        | -0.135        |\n",
      "|    reward             | -0.0065712347 |\n",
      "|    std                | 9.52          |\n",
      "|    value_loss         | 0.00287       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 14400       |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 72000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.39       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | -0.0873     |\n",
      "|    reward             | -0.02526762 |\n",
      "|    std                | 9.76        |\n",
      "|    value_loss         | 0.000252    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 14500        |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 72500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.42        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | -0.866       |\n",
      "|    reward             | -0.014791205 |\n",
      "|    std                | 9.92         |\n",
      "|    value_loss         | 0.0231       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 14600        |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 73000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.45        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | -0.368       |\n",
      "|    reward             | -0.049102712 |\n",
      "|    std                | 10.1         |\n",
      "|    value_loss         | 0.00288      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.49       |\n",
      "|    explained_variance | -0.00316    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | 0.691       |\n",
      "|    reward             | 0.020638917 |\n",
      "|    std                | 10.3        |\n",
      "|    value_loss         | 0.0081      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.52       |\n",
      "|    explained_variance | 0.0015      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | 0.262       |\n",
      "|    reward             | 0.015586065 |\n",
      "|    std                | 10.4        |\n",
      "|    value_loss         | 0.00192     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 14900        |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 74500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.51        |\n",
      "|    explained_variance | -4.71        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.029109554 |\n",
      "|    std                | 10.4         |\n",
      "|    value_loss         | 0.000801     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 15000        |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 75000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.55        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14999        |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | -0.004198075 |\n",
      "|    std                | 10.6         |\n",
      "|    value_loss         | 0.000656     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 15100        |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 75500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.56        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15099        |\n",
      "|    policy_loss        | -0.0216      |\n",
      "|    reward             | -0.014985921 |\n",
      "|    std                | 10.7         |\n",
      "|    value_loss         | 2.18e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 15200         |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 76000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.61         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15199         |\n",
      "|    policy_loss        | -0.296        |\n",
      "|    reward             | -0.0074518067 |\n",
      "|    std                | 10.9          |\n",
      "|    value_loss         | 0.00155       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 15300        |\n",
      "|    time_elapsed       | 234          |\n",
      "|    total_timesteps    | 76500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.68        |\n",
      "|    explained_variance | -0.15        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15299        |\n",
      "|    policy_loss        | 0.0167       |\n",
      "|    reward             | 7.416185e-05 |\n",
      "|    std                | 11.3         |\n",
      "|    value_loss         | 3.48e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 15400        |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 77000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.7         |\n",
      "|    explained_variance | -2.8         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15399        |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | -0.006858183 |\n",
      "|    std                | 11.4         |\n",
      "|    value_loss         | 0.000698     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 15500       |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 77500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.74       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15499       |\n",
      "|    policy_loss        | 0.162       |\n",
      "|    reward             | 0.003910486 |\n",
      "|    std                | 11.6        |\n",
      "|    value_loss         | 0.000437    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 15600       |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 78000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.79       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | 0.468       |\n",
      "|    reward             | 0.037745133 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.00484     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 15700         |\n",
      "|    time_elapsed       | 242           |\n",
      "|    total_timesteps    | 78500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.82         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15699         |\n",
      "|    policy_loss        | -0.0456       |\n",
      "|    reward             | -0.0070011513 |\n",
      "|    std                | 12.1          |\n",
      "|    value_loss         | 6.8e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 15800       |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 79000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.87       |\n",
      "|    explained_variance | -0.524      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | -0.503      |\n",
      "|    reward             | 0.043513924 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 0.00562     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 15900         |\n",
      "|    time_elapsed       | 245           |\n",
      "|    total_timesteps    | 79500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.86         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15899         |\n",
      "|    policy_loss        | 0.256         |\n",
      "|    reward             | -0.0040241214 |\n",
      "|    std                | 12.4          |\n",
      "|    value_loss         | 0.00117       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 16000        |\n",
      "|    time_elapsed       | 247          |\n",
      "|    total_timesteps    | 80000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.89        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15999        |\n",
      "|    policy_loss        | 0.995        |\n",
      "|    reward             | -0.029602375 |\n",
      "|    std                | 12.6         |\n",
      "|    value_loss         | 0.0169       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 16100        |\n",
      "|    time_elapsed       | 248          |\n",
      "|    total_timesteps    | 80500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.9         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16099        |\n",
      "|    policy_loss        | -0.0284      |\n",
      "|    reward             | 0.0063721095 |\n",
      "|    std                | 12.6         |\n",
      "|    value_loss         | 0.000293     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 16200       |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 81000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16199       |\n",
      "|    policy_loss        | 0.192       |\n",
      "|    reward             | -0.00582677 |\n",
      "|    std                | 12.9        |\n",
      "|    value_loss         | 0.000691    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 16300       |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 81500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.97       |\n",
      "|    explained_variance | 0.0202      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | 0.254       |\n",
      "|    reward             | 0.026936563 |\n",
      "|    std                | 13.1        |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 16400         |\n",
      "|    time_elapsed       | 253           |\n",
      "|    total_timesteps    | 82000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.99         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 16399         |\n",
      "|    policy_loss        | -0.112        |\n",
      "|    reward             | -0.0054413676 |\n",
      "|    std                | 13.2          |\n",
      "|    value_loss         | 0.00023       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 16500       |\n",
      "|    time_elapsed       | 255         |\n",
      "|    total_timesteps    | 82500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.03       |\n",
      "|    explained_variance | -0.0128     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16499       |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.003882438 |\n",
      "|    std                | 13.5        |\n",
      "|    value_loss         | 0.00083     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 16600       |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 83000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16599       |\n",
      "|    policy_loss        | 0.739       |\n",
      "|    reward             | -0.08606111 |\n",
      "|    std                | 13.9        |\n",
      "|    value_loss         | 0.00791     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -45395.44\n",
      "total_reward: -55395.44\n",
      "total_cost: 88.85\n",
      "total_trades: 5540\n",
      "Sharpe: 0.141\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 258          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.13        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | -0.317       |\n",
      "|    reward             | -0.019024024 |\n",
      "|    std                | 14.2         |\n",
      "|    value_loss         | 0.00284      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 16800        |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 84000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.16        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | -0.0206      |\n",
      "|    reward             | -0.008466418 |\n",
      "|    std                | 14.4         |\n",
      "|    value_loss         | 6.05e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 16900         |\n",
      "|    time_elapsed       | 261           |\n",
      "|    total_timesteps    | 84500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.19         |\n",
      "|    explained_variance | -8.07         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 16899         |\n",
      "|    policy_loss        | 1.84          |\n",
      "|    reward             | -0.0138808405 |\n",
      "|    std                | 14.6          |\n",
      "|    value_loss         | 0.074         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 17000       |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 85000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.22       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | 0.508       |\n",
      "|    reward             | 0.026700534 |\n",
      "|    std                | 14.9        |\n",
      "|    value_loss         | 0.00514     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 17100        |\n",
      "|    time_elapsed       | 264          |\n",
      "|    total_timesteps    | 85500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.23        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17099        |\n",
      "|    policy_loss        | 0.838        |\n",
      "|    reward             | 0.0010422094 |\n",
      "|    std                | 14.9         |\n",
      "|    value_loss         | 0.0117       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 17200      |\n",
      "|    time_elapsed       | 266        |\n",
      "|    total_timesteps    | 86000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17199      |\n",
      "|    policy_loss        | 1.11       |\n",
      "|    reward             | 0.01704299 |\n",
      "|    std                | 15.2       |\n",
      "|    value_loss         | 0.0334     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 17300        |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 86500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.3         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17299        |\n",
      "|    policy_loss        | -0.337       |\n",
      "|    reward             | -0.029249758 |\n",
      "|    std                | 15.4         |\n",
      "|    value_loss         | 0.00216      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 17400      |\n",
      "|    time_elapsed       | 269        |\n",
      "|    total_timesteps    | 87000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17399      |\n",
      "|    policy_loss        | 0.214      |\n",
      "|    reward             | -0.0433666 |\n",
      "|    std                | 15.5       |\n",
      "|    value_loss         | 0.00151    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 17500       |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 87500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.36       |\n",
      "|    explained_variance | 7.33e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | 0.0049      |\n",
      "|    reward             | 0.071739934 |\n",
      "|    std                | 15.9        |\n",
      "|    value_loss         | 0.00605     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 17600      |\n",
      "|    time_elapsed       | 272        |\n",
      "|    total_timesteps    | 88000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.38      |\n",
      "|    explained_variance | 0.0166     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17599      |\n",
      "|    policy_loss        | -2.15      |\n",
      "|    reward             | 0.01586383 |\n",
      "|    std                | 16.1       |\n",
      "|    value_loss         | 0.126      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 17700      |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 88500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17699      |\n",
      "|    policy_loss        | 0.282      |\n",
      "|    reward             | -0.0841831 |\n",
      "|    std                | 16         |\n",
      "|    value_loss         | 0.00798    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 17800       |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 89000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.38       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | 2.14        |\n",
      "|    reward             | 0.010939944 |\n",
      "|    std                | 16          |\n",
      "|    value_loss         | 0.0896      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 17900          |\n",
      "|    time_elapsed       | 277            |\n",
      "|    total_timesteps    | 89500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -8.42          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 17899          |\n",
      "|    policy_loss        | -0.116         |\n",
      "|    reward             | -0.00053592096 |\n",
      "|    std                | 16.3           |\n",
      "|    value_loss         | 0.00172        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 18000       |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 90000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.45       |\n",
      "|    explained_variance | 0.0273      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | 0.439       |\n",
      "|    reward             | 0.024619844 |\n",
      "|    std                | 16.6        |\n",
      "|    value_loss         | 0.00947     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 18100       |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 90500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.48       |\n",
      "|    explained_variance | 0.183       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | 0.875       |\n",
      "|    reward             | -0.14240347 |\n",
      "|    std                | 16.9        |\n",
      "|    value_loss         | 0.0376      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 323       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 281       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.5      |\n",
      "|    explained_variance | 0.0929    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 0.739     |\n",
      "|    reward             | 0.2360242 |\n",
      "|    std                | 17        |\n",
      "|    value_loss         | 0.0119    |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 18300         |\n",
      "|    time_elapsed       | 283           |\n",
      "|    total_timesteps    | 91500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.5          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18299         |\n",
      "|    policy_loss        | -0.492        |\n",
      "|    reward             | -0.0031835062 |\n",
      "|    std                | 17            |\n",
      "|    value_loss         | 0.00425       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 18400        |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 92000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.52        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | -0.313       |\n",
      "|    reward             | -0.017814683 |\n",
      "|    std                | 17.1         |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 18500       |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 92500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.54       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | -0.048      |\n",
      "|    reward             | 0.001155003 |\n",
      "|    std                | 17.4        |\n",
      "|    value_loss         | 4.25e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 18600          |\n",
      "|    time_elapsed       | 288            |\n",
      "|    total_timesteps    | 93000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -8.57          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 18599          |\n",
      "|    policy_loss        | 0.00382        |\n",
      "|    reward             | -0.00041185794 |\n",
      "|    std                | 17.6           |\n",
      "|    value_loss         | 3.29e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 18700         |\n",
      "|    time_elapsed       | 289           |\n",
      "|    total_timesteps    | 93500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.61         |\n",
      "|    explained_variance | -1.17         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18699         |\n",
      "|    policy_loss        | -0.0712       |\n",
      "|    reward             | -0.0065692933 |\n",
      "|    std                | 18            |\n",
      "|    value_loss         | 9.62e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 18800        |\n",
      "|    time_elapsed       | 291          |\n",
      "|    total_timesteps    | 94000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.64        |\n",
      "|    explained_variance | 0.00602      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18799        |\n",
      "|    policy_loss        | 0.0354       |\n",
      "|    reward             | -0.019141858 |\n",
      "|    std                | 18.2         |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.67       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | 0.0467      |\n",
      "|    reward             | 0.019148305 |\n",
      "|    std                | 18.5        |\n",
      "|    value_loss         | 0.00213     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 19000       |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 95000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | -0.449      |\n",
      "|    reward             | 0.019361148 |\n",
      "|    std                | 18.8        |\n",
      "|    value_loss         | 0.00311     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 19100       |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 95500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.73       |\n",
      "|    explained_variance | -6.4        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | 0.344       |\n",
      "|    reward             | 0.014570505 |\n",
      "|    std                | 19.1        |\n",
      "|    value_loss         | 0.00236     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 19200        |\n",
      "|    time_elapsed       | 297          |\n",
      "|    total_timesteps    | 96000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.78        |\n",
      "|    explained_variance | 0.581        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19199        |\n",
      "|    policy_loss        | 0.0944       |\n",
      "|    reward             | -0.009300686 |\n",
      "|    std                | 19.6         |\n",
      "|    value_loss         | 0.000275     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 19300        |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 96500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.82        |\n",
      "|    explained_variance | -1.11        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19299        |\n",
      "|    policy_loss        | 0.111        |\n",
      "|    reward             | -0.004609863 |\n",
      "|    std                | 19.9         |\n",
      "|    value_loss         | 0.00063      |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -48840.95\n",
      "total_reward: -58840.95\n",
      "total_cost: 66.24\n",
      "total_trades: 5540\n",
      "Sharpe: 0.473\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 19400         |\n",
      "|    time_elapsed       | 301           |\n",
      "|    total_timesteps    | 97000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.83         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19399         |\n",
      "|    policy_loss        | -0.319        |\n",
      "|    reward             | -0.0053283926 |\n",
      "|    std                | 20.1          |\n",
      "|    value_loss         | 0.00226       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 19500        |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 97500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.86        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19499        |\n",
      "|    policy_loss        | 0.323        |\n",
      "|    reward             | -0.014293049 |\n",
      "|    std                | 20.3         |\n",
      "|    value_loss         | 0.00161      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 19600          |\n",
      "|    time_elapsed       | 304            |\n",
      "|    total_timesteps    | 98000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -8.89          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 19599          |\n",
      "|    policy_loss        | 0.315          |\n",
      "|    reward             | -0.00079010386 |\n",
      "|    std                | 20.6           |\n",
      "|    value_loss         | 0.0014         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 19700        |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 98500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.94        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19699        |\n",
      "|    policy_loss        | -0.0945      |\n",
      "|    reward             | -0.002947248 |\n",
      "|    std                | 21.2         |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 19800         |\n",
      "|    time_elapsed       | 308           |\n",
      "|    total_timesteps    | 99000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9            |\n",
      "|    explained_variance | -21.2         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19799         |\n",
      "|    policy_loss        | -0.167        |\n",
      "|    reward             | -0.0005097397 |\n",
      "|    std                | 21.8          |\n",
      "|    value_loss         | 0.00145       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 19900        |\n",
      "|    time_elapsed       | 310          |\n",
      "|    total_timesteps    | 99500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.03        |\n",
      "|    explained_variance | -0.534       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19899        |\n",
      "|    policy_loss        | 0.359        |\n",
      "|    reward             | -0.023108298 |\n",
      "|    std                | 22.1         |\n",
      "|    value_loss         | 0.00248      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 0.799       |\n",
      "|    reward             | -0.08992567 |\n",
      "|    std                | 22.5        |\n",
      "|    value_loss         | 0.0118      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 20100      |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 100500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20099      |\n",
      "|    policy_loss        | -0.474     |\n",
      "|    reward             | 0.06406699 |\n",
      "|    std                | 22.9       |\n",
      "|    value_loss         | 0.00435    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 20200       |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 101000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.13       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20199       |\n",
      "|    policy_loss        | -0.724      |\n",
      "|    reward             | -0.09544653 |\n",
      "|    std                | 23.2        |\n",
      "|    value_loss         | 0.00806     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 20300        |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 101500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.14        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20299        |\n",
      "|    policy_loss        | 0.944        |\n",
      "|    reward             | -0.073691405 |\n",
      "|    std                | 23.4         |\n",
      "|    value_loss         | 0.0203       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 20400       |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 102000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.15       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20399       |\n",
      "|    policy_loss        | 1.5         |\n",
      "|    reward             | -0.11832596 |\n",
      "|    std                | 23.5        |\n",
      "|    value_loss         | 0.0531      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 20500     |\n",
      "|    time_elapsed       | 319       |\n",
      "|    total_timesteps    | 102500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.14     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 20499     |\n",
      "|    policy_loss        | -0.567    |\n",
      "|    reward             | 1.5835929 |\n",
      "|    std                | 23.4      |\n",
      "|    value_loss         | 0.187     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 20600       |\n",
      "|    time_elapsed       | 321         |\n",
      "|    total_timesteps    | 103000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20599       |\n",
      "|    policy_loss        | 0.0852      |\n",
      "|    reward             | -0.00842914 |\n",
      "|    std                | 23.8        |\n",
      "|    value_loss         | 0.000619    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 20700        |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 103500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.21        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20699        |\n",
      "|    policy_loss        | 0.194        |\n",
      "|    reward             | -0.013927652 |\n",
      "|    std                | 24.2         |\n",
      "|    value_loss         | 0.00155      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 20800       |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 104000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.24       |\n",
      "|    explained_variance | 0.264       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20799       |\n",
      "|    policy_loss        | -0.0368     |\n",
      "|    reward             | 0.042895235 |\n",
      "|    std                | 24.5        |\n",
      "|    value_loss         | 0.000237    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 20900       |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 104500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.28       |\n",
      "|    explained_variance | 0.236       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20899       |\n",
      "|    policy_loss        | 0.406       |\n",
      "|    reward             | 0.040010866 |\n",
      "|    std                | 25.1        |\n",
      "|    value_loss         | 0.00206     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 21000        |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 105000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.31        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | -0.308       |\n",
      "|    reward             | 0.0014803616 |\n",
      "|    std                | 25.4         |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 21100       |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 105500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.33       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21099       |\n",
      "|    policy_loss        | -0.396      |\n",
      "|    reward             | 0.017224194 |\n",
      "|    std                | 25.6        |\n",
      "|    value_loss         | 0.00158     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 21200       |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 106000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.35       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21199       |\n",
      "|    policy_loss        | 0.0135      |\n",
      "|    reward             | 0.024447052 |\n",
      "|    std                | 26          |\n",
      "|    value_loss         | 0.000331    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 21300        |\n",
      "|    time_elapsed       | 332          |\n",
      "|    total_timesteps    | 106500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.4         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21299        |\n",
      "|    policy_loss        | 0.201        |\n",
      "|    reward             | -0.009632418 |\n",
      "|    std                | 26.6         |\n",
      "|    value_loss         | 0.000475     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 21400      |\n",
      "|    time_elapsed       | 333        |\n",
      "|    total_timesteps    | 107000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.44      |\n",
      "|    explained_variance | -7.15e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21399      |\n",
      "|    policy_loss        | -0.0879    |\n",
      "|    reward             | 0.00434585 |\n",
      "|    std                | 27.1       |\n",
      "|    value_loss         | 0.000163   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 21500       |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 107500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.46       |\n",
      "|    explained_variance | 0.123       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21499       |\n",
      "|    policy_loss        | 0.872       |\n",
      "|    reward             | -0.02257541 |\n",
      "|    std                | 27.5        |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 21600      |\n",
      "|    time_elapsed       | 336        |\n",
      "|    total_timesteps    | 108000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.47      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21599      |\n",
      "|    policy_loss        | -0.845     |\n",
      "|    reward             | 0.07641631 |\n",
      "|    std                | 27.6       |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 21700       |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 108500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.52       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21699       |\n",
      "|    policy_loss        | 0.0914      |\n",
      "|    reward             | 0.010553171 |\n",
      "|    std                | 28.3        |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 21800       |\n",
      "|    time_elapsed       | 339         |\n",
      "|    total_timesteps    | 109000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.54       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21799       |\n",
      "|    policy_loss        | 0.0606      |\n",
      "|    reward             | 0.007361002 |\n",
      "|    std                | 28.6        |\n",
      "|    value_loss         | 4.47e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 21900         |\n",
      "|    time_elapsed       | 341           |\n",
      "|    total_timesteps    | 109500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.6          |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21899         |\n",
      "|    policy_loss        | -0.127        |\n",
      "|    reward             | -0.0002896806 |\n",
      "|    std                | 29.4          |\n",
      "|    value_loss         | 0.000265      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22000        |\n",
      "|    time_elapsed       | 342          |\n",
      "|    total_timesteps    | 110000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.65        |\n",
      "|    explained_variance | -204         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21999        |\n",
      "|    policy_loss        | 0.333        |\n",
      "|    reward             | -0.011804937 |\n",
      "|    std                | 30.1         |\n",
      "|    value_loss         | 0.01         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22100        |\n",
      "|    time_elapsed       | 344          |\n",
      "|    total_timesteps    | 110500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.7         |\n",
      "|    explained_variance | -0.399       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22099        |\n",
      "|    policy_loss        | -0.12        |\n",
      "|    reward             | 0.0005147111 |\n",
      "|    std                | 30.9         |\n",
      "|    value_loss         | 0.000173     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2770, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13727.61\n",
      "total_reward: -23727.61\n",
      "total_cost: 398.65\n",
      "total_trades: 5540\n",
      "Sharpe: -0.373\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 320            |\n",
      "|    iterations         | 22200          |\n",
      "|    time_elapsed       | 345            |\n",
      "|    total_timesteps    | 111000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -9.78          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 22199          |\n",
      "|    policy_loss        | 0.33           |\n",
      "|    reward             | -0.00027623418 |\n",
      "|    std                | 32.1           |\n",
      "|    value_loss         | 0.00151        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 22300       |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 111500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22299       |\n",
      "|    policy_loss        | -0.406      |\n",
      "|    reward             | 0.011691794 |\n",
      "|    std                | 32.8        |\n",
      "|    value_loss         | 0.00186     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 22400       |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 112000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22399       |\n",
      "|    policy_loss        | -0.168      |\n",
      "|    reward             | 0.012902576 |\n",
      "|    std                | 33.5        |\n",
      "|    value_loss         | 0.000389    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22500        |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 112500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.91        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22499        |\n",
      "|    policy_loss        | 0.175        |\n",
      "|    reward             | -0.004684105 |\n",
      "|    std                | 34.3         |\n",
      "|    value_loss         | 0.00039      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22600        |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 113000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.94        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22599        |\n",
      "|    policy_loss        | 0.121        |\n",
      "|    reward             | 0.0067700697 |\n",
      "|    std                | 34.9         |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22700        |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 113500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.99        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22699        |\n",
      "|    policy_loss        | 0.0199       |\n",
      "|    reward             | 0.0038719424 |\n",
      "|    std                | 35.8         |\n",
      "|    value_loss         | 1.8e-05      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 22800      |\n",
      "|    time_elapsed       | 355        |\n",
      "|    total_timesteps    | 114000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22799      |\n",
      "|    policy_loss        | -0.276     |\n",
      "|    reward             | -0.1681336 |\n",
      "|    std                | 36.4       |\n",
      "|    value_loss         | 0.00407    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 22900      |\n",
      "|    time_elapsed       | 357        |\n",
      "|    total_timesteps    | 114500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22899      |\n",
      "|    policy_loss        | -0.154     |\n",
      "|    reward             | 0.01391188 |\n",
      "|    std                | 37.1       |\n",
      "|    value_loss         | 0.000544   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 23000       |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 115000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22999       |\n",
      "|    policy_loss        | -0.597      |\n",
      "|    reward             | -0.10155119 |\n",
      "|    std                | 37          |\n",
      "|    value_loss         | 0.0397      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 23100      |\n",
      "|    time_elapsed       | 360        |\n",
      "|    total_timesteps    | 115500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | -0.0148    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23099      |\n",
      "|    policy_loss        | 5.7        |\n",
      "|    reward             | 0.11680664 |\n",
      "|    std                | 37.4       |\n",
      "|    value_loss         | 0.417      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 23200      |\n",
      "|    time_elapsed       | 362        |\n",
      "|    total_timesteps    | 116000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23199      |\n",
      "|    policy_loss        | 1.96       |\n",
      "|    reward             | 0.17974827 |\n",
      "|    std                | 37.6       |\n",
      "|    value_loss         | 0.0412     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 23300        |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 116500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23299        |\n",
      "|    policy_loss        | 1.23         |\n",
      "|    reward             | -0.062196326 |\n",
      "|    std                | 37.9         |\n",
      "|    value_loss         | 0.0261       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 23400        |\n",
      "|    time_elapsed       | 365          |\n",
      "|    total_timesteps    | 117000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23399        |\n",
      "|    policy_loss        | 0.917        |\n",
      "|    reward             | -0.015651941 |\n",
      "|    std                | 38           |\n",
      "|    value_loss         | 0.0094       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 23500        |\n",
      "|    time_elapsed       | 367          |\n",
      "|    total_timesteps    | 117500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23499        |\n",
      "|    policy_loss        | -3.08        |\n",
      "|    reward             | -0.031986993 |\n",
      "|    std                | 38.3         |\n",
      "|    value_loss         | 0.128        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 23600      |\n",
      "|    time_elapsed       | 368        |\n",
      "|    total_timesteps    | 118000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.2      |\n",
      "|    explained_variance | 0.887      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23599      |\n",
      "|    policy_loss        | 0.345      |\n",
      "|    reward             | 0.16865723 |\n",
      "|    std                | 38.8       |\n",
      "|    value_loss         | 0.00134    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 23700        |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 118500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | -0.123       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23699        |\n",
      "|    policy_loss        | 0.611        |\n",
      "|    reward             | -0.028415428 |\n",
      "|    std                | 39.1         |\n",
      "|    value_loss         | 0.00747      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 23800       |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 119000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | 0.00761     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23799       |\n",
      "|    policy_loss        | 0.536       |\n",
      "|    reward             | -0.11202343 |\n",
      "|    std                | 39.1        |\n",
      "|    value_loss         | 0.0265      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 23900       |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 119500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23899       |\n",
      "|    policy_loss        | 0.393       |\n",
      "|    reward             | 0.016414888 |\n",
      "|    std                | 39.3        |\n",
      "|    value_loss         | 0.00352     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 24000         |\n",
      "|    time_elapsed       | 375           |\n",
      "|    total_timesteps    | 120000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23999         |\n",
      "|    policy_loss        | -0.0134       |\n",
      "|    reward             | -0.0073250146 |\n",
      "|    std                | 39.8          |\n",
      "|    value_loss         | 6.44e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 24100        |\n",
      "|    time_elapsed       | 377          |\n",
      "|    total_timesteps    | 120500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24099        |\n",
      "|    policy_loss        | -0.0121      |\n",
      "|    reward             | 0.0033771615 |\n",
      "|    std                | 40.5         |\n",
      "|    value_loss         | 6.13e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 24200        |\n",
      "|    time_elapsed       | 378          |\n",
      "|    total_timesteps    | 121000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24199        |\n",
      "|    policy_loss        | 0.0794       |\n",
      "|    reward             | -0.008016295 |\n",
      "|    std                | 41.6         |\n",
      "|    value_loss         | 7.28e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 24300        |\n",
      "|    time_elapsed       | 380          |\n",
      "|    total_timesteps    | 121500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | -681         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24299        |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | 0.0033501803 |\n",
      "|    std                | 42.9         |\n",
      "|    value_loss         | 0.00719      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 24400       |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 122000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24399       |\n",
      "|    policy_loss        | -0.0726     |\n",
      "|    reward             | 0.003121814 |\n",
      "|    std                | 43.8        |\n",
      "|    value_loss         | 8.83e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 24500        |\n",
      "|    time_elapsed       | 384          |\n",
      "|    total_timesteps    | 122500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24499        |\n",
      "|    policy_loss        | 0.187        |\n",
      "|    reward             | -0.009981364 |\n",
      "|    std                | 44.9         |\n",
      "|    value_loss         | 0.00046      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 24600         |\n",
      "|    time_elapsed       | 385           |\n",
      "|    total_timesteps    | 123000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24599         |\n",
      "|    policy_loss        | -0.141        |\n",
      "|    reward             | -0.0009620289 |\n",
      "|    std                | 46            |\n",
      "|    value_loss         | 0.000208      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 24700         |\n",
      "|    time_elapsed       | 387           |\n",
      "|    total_timesteps    | 123500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.6         |\n",
      "|    explained_variance | 0.0113        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24699         |\n",
      "|    policy_loss        | 0.196         |\n",
      "|    reward             | -0.0058523878 |\n",
      "|    std                | 47.4          |\n",
      "|    value_loss         | 0.000941      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 24800         |\n",
      "|    time_elapsed       | 388           |\n",
      "|    total_timesteps    | 124000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.6         |\n",
      "|    explained_variance | -0.00315      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24799         |\n",
      "|    policy_loss        | 0.155         |\n",
      "|    reward             | -0.0006655149 |\n",
      "|    std                | 49.2          |\n",
      "|    value_loss         | 0.000329      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 24900         |\n",
      "|    time_elapsed       | 390           |\n",
      "|    total_timesteps    | 124500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24899         |\n",
      "|    policy_loss        | -0.249        |\n",
      "|    reward             | -0.0054175095 |\n",
      "|    std                | 51            |\n",
      "|    value_loss         | 0.000777      |\n",
      "-----------------------------------------\n",
      "day: 2770, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12028.11\n",
      "total_reward: -22028.11\n",
      "total_cost: 502.61\n",
      "total_trades: 5540\n",
      "Sharpe: -0.081\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 25000       |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 125000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24999       |\n",
      "|    policy_loss        | -0.713      |\n",
      "|    reward             | 0.025280261 |\n",
      "|    std                | 52.1        |\n",
      "|    value_loss         | 0.00572     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 25100        |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 125500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25099        |\n",
      "|    policy_loss        | 0.94         |\n",
      "|    reward             | -0.112824805 |\n",
      "|    std                | 52.5         |\n",
      "|    value_loss         | 0.00806      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 25200        |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 126000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25199        |\n",
      "|    policy_loss        | -1.46        |\n",
      "|    reward             | -0.101678684 |\n",
      "|    std                | 53.1         |\n",
      "|    value_loss         | 0.143        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 25300      |\n",
      "|    time_elapsed       | 397        |\n",
      "|    total_timesteps    | 126500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0.0362     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25299      |\n",
      "|    policy_loss        | -2.04      |\n",
      "|    reward             | -1.1563622 |\n",
      "|    std                | 53.8       |\n",
      "|    value_loss         | 0.0454     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 25400      |\n",
      "|    time_elapsed       | 400        |\n",
      "|    total_timesteps    | 127000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0.0446     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25399      |\n",
      "|    policy_loss        | 13.1       |\n",
      "|    reward             | -0.1510414 |\n",
      "|    std                | 53.6       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 25500       |\n",
      "|    time_elapsed       | 401         |\n",
      "|    total_timesteps    | 127500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25499       |\n",
      "|    policy_loss        | 0.0318      |\n",
      "|    reward             | 0.012640529 |\n",
      "|    std                | 53.6        |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 317           |\n",
      "|    iterations         | 25600         |\n",
      "|    time_elapsed       | 403           |\n",
      "|    total_timesteps    | 128000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 25599         |\n",
      "|    policy_loss        | 1.13          |\n",
      "|    reward             | -0.0026267078 |\n",
      "|    std                | 54.3          |\n",
      "|    value_loss         | 0.0136        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 25700      |\n",
      "|    time_elapsed       | 404        |\n",
      "|    total_timesteps    | 128500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25699      |\n",
      "|    policy_loss        | -0.31      |\n",
      "|    reward             | -0.0346774 |\n",
      "|    std                | 54.7       |\n",
      "|    value_loss         | 0.00151    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 25800        |\n",
      "|    time_elapsed       | 406          |\n",
      "|    total_timesteps    | 129000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | -0.000249    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25799        |\n",
      "|    policy_loss        | 0.455        |\n",
      "|    reward             | -0.007783894 |\n",
      "|    std                | 56           |\n",
      "|    value_loss         | 0.00169      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 25900       |\n",
      "|    time_elapsed       | 407         |\n",
      "|    total_timesteps    | 129500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0.0482      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25899       |\n",
      "|    policy_loss        | 1.49        |\n",
      "|    reward             | -0.01206749 |\n",
      "|    std                | 56.3        |\n",
      "|    value_loss         | 0.0214      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 26000        |\n",
      "|    time_elapsed       | 409          |\n",
      "|    total_timesteps    | 130000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0.107        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25999        |\n",
      "|    policy_loss        | 0.479        |\n",
      "|    reward             | -0.035332266 |\n",
      "|    std                | 57.3         |\n",
      "|    value_loss         | 0.00348      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 26100        |\n",
      "|    time_elapsed       | 410          |\n",
      "|    total_timesteps    | 130500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26099        |\n",
      "|    policy_loss        | 0.00144      |\n",
      "|    reward             | -0.063879535 |\n",
      "|    std                | 58.7         |\n",
      "|    value_loss         | 0.000806     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 26200      |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 131000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26199      |\n",
      "|    policy_loss        | -0.173     |\n",
      "|    reward             | 0.06928041 |\n",
      "|    std                | 59.1       |\n",
      "|    value_loss         | 0.000379   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 26300        |\n",
      "|    time_elapsed       | 413          |\n",
      "|    total_timesteps    | 131500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11          |\n",
      "|    explained_variance | -5.07        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26299        |\n",
      "|    policy_loss        | 0.462        |\n",
      "|    reward             | -0.005256838 |\n",
      "|    std                | 59.9         |\n",
      "|    value_loss         | 0.00243      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 26400         |\n",
      "|    time_elapsed       | 415           |\n",
      "|    total_timesteps    | 132000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 26399         |\n",
      "|    policy_loss        | 0.0341        |\n",
      "|    reward             | -0.0051282966 |\n",
      "|    std                | 61            |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 26500        |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 132500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26499        |\n",
      "|    policy_loss        | 0.452        |\n",
      "|    reward             | -0.017183892 |\n",
      "|    std                | 62.1         |\n",
      "|    value_loss         | 0.00192      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 26600       |\n",
      "|    time_elapsed       | 418         |\n",
      "|    total_timesteps    | 133000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26599       |\n",
      "|    policy_loss        | -0.87       |\n",
      "|    reward             | 0.044382166 |\n",
      "|    std                | 62.9        |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 419          |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | 0.09         |\n",
      "|    reward             | 0.0065240287 |\n",
      "|    std                | 64.1         |\n",
      "|    value_loss         | 0.000343     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 26800         |\n",
      "|    time_elapsed       | 420           |\n",
      "|    total_timesteps    | 134000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 26799         |\n",
      "|    policy_loss        | -0.0812       |\n",
      "|    reward             | -0.0069910027 |\n",
      "|    std                | 65.5          |\n",
      "|    value_loss         | 7.21e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 26900        |\n",
      "|    time_elapsed       | 422          |\n",
      "|    total_timesteps    | 134500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26899        |\n",
      "|    policy_loss        | -0.0351      |\n",
      "|    reward             | 0.0062297257 |\n",
      "|    std                | 67.5         |\n",
      "|    value_loss         | 4.06e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 27000       |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 135000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | -0.561      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26999       |\n",
      "|    policy_loss        | 0.33        |\n",
      "|    reward             | 0.010728011 |\n",
      "|    std                | 69.3        |\n",
      "|    value_loss         | 0.00092     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 27100         |\n",
      "|    time_elapsed       | 425           |\n",
      "|    total_timesteps    | 135500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 27099         |\n",
      "|    policy_loss        | 0.101         |\n",
      "|    reward             | -0.0044974377 |\n",
      "|    std                | 71.4          |\n",
      "|    value_loss         | 0.000131      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 27200       |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 136000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27199       |\n",
      "|    policy_loss        | -1.52       |\n",
      "|    reward             | 0.114259526 |\n",
      "|    std                | 74.2        |\n",
      "|    value_loss         | 0.0269      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 27300        |\n",
      "|    time_elapsed       | 429          |\n",
      "|    total_timesteps    | 136500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27299        |\n",
      "|    policy_loss        | -0.0444      |\n",
      "|    reward             | 0.0052951532 |\n",
      "|    std                | 74.1         |\n",
      "|    value_loss         | 0.000492     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 27400       |\n",
      "|    time_elapsed       | 430         |\n",
      "|    total_timesteps    | 137000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0.294       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27399       |\n",
      "|    policy_loss        | 0.364       |\n",
      "|    reward             | 0.010422179 |\n",
      "|    std                | 75.7        |\n",
      "|    value_loss         | 0.001       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 27500        |\n",
      "|    time_elapsed       | 432          |\n",
      "|    total_timesteps    | 137500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | -0.0196      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27499        |\n",
      "|    policy_loss        | -0.801       |\n",
      "|    reward             | -0.025963297 |\n",
      "|    std                | 77.1         |\n",
      "|    value_loss         | 0.0048       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 27600        |\n",
      "|    time_elapsed       | 433          |\n",
      "|    total_timesteps    | 138000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 0.0598       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27599        |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | 0.0013736663 |\n",
      "|    std                | 78.9         |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 27700       |\n",
      "|    time_elapsed       | 435         |\n",
      "|    total_timesteps    | 138500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | -0.012      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27699       |\n",
      "|    policy_loss        | 0.15        |\n",
      "|    reward             | 0.023069175 |\n",
      "|    std                | 80.3        |\n",
      "|    value_loss         | 0.00026     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -52943.72\n",
      "total_reward: -62943.72\n",
      "total_cost: 66.24\n",
      "total_trades: 5540\n",
      "Sharpe: -0.186\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 27800        |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 139000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27799        |\n",
      "|    policy_loss        | -0.614       |\n",
      "|    reward             | -0.037089694 |\n",
      "|    std                | 80.9         |\n",
      "|    value_loss         | 0.00348      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 27900      |\n",
      "|    time_elapsed       | 438        |\n",
      "|    total_timesteps    | 139500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27899      |\n",
      "|    policy_loss        | 0.361      |\n",
      "|    reward             | 0.00480316 |\n",
      "|    std                | 81.4       |\n",
      "|    value_loss         | 0.0011     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 28000       |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 140000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27999       |\n",
      "|    policy_loss        | -0.0741     |\n",
      "|    reward             | 0.016478414 |\n",
      "|    std                | 82.8        |\n",
      "|    value_loss         | 0.000249    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 28100        |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 140500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28099        |\n",
      "|    policy_loss        | -0.134       |\n",
      "|    reward             | -0.006251201 |\n",
      "|    std                | 84.7         |\n",
      "|    value_loss         | 0.000362     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 28200        |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 141000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 0.138        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28199        |\n",
      "|    policy_loss        | -0.0357      |\n",
      "|    reward             | -0.003910792 |\n",
      "|    std                | 86.1         |\n",
      "|    value_loss         | 0.000495     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 28300        |\n",
      "|    time_elapsed       | 444          |\n",
      "|    total_timesteps    | 141500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28299        |\n",
      "|    policy_loss        | 0.17         |\n",
      "|    reward             | 0.0023701696 |\n",
      "|    std                | 87.1         |\n",
      "|    value_loss         | 0.000424     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 28400        |\n",
      "|    time_elapsed       | 445          |\n",
      "|    total_timesteps    | 142000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28399        |\n",
      "|    policy_loss        | -0.0153      |\n",
      "|    reward             | -0.011657752 |\n",
      "|    std                | 88.9         |\n",
      "|    value_loss         | 4.81e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 28500        |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 142500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28499        |\n",
      "|    policy_loss        | -0.0898      |\n",
      "|    reward             | -0.003297235 |\n",
      "|    std                | 91.4         |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 28600       |\n",
      "|    time_elapsed       | 448         |\n",
      "|    total_timesteps    | 143000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28599       |\n",
      "|    policy_loss        | -0.113      |\n",
      "|    reward             | 0.014302896 |\n",
      "|    std                | 94.7        |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 28700       |\n",
      "|    time_elapsed       | 450         |\n",
      "|    total_timesteps    | 143500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | 7.51e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28699       |\n",
      "|    policy_loss        | -0.126      |\n",
      "|    reward             | -0.01210277 |\n",
      "|    std                | 97.8        |\n",
      "|    value_loss         | 0.000358    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 28800        |\n",
      "|    time_elapsed       | 452          |\n",
      "|    total_timesteps    | 144000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | 0.474        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28799        |\n",
      "|    policy_loss        | 0.184        |\n",
      "|    reward             | -0.015772961 |\n",
      "|    std                | 99.4         |\n",
      "|    value_loss         | 0.000327     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 28900         |\n",
      "|    time_elapsed       | 453           |\n",
      "|    total_timesteps    | 144500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28899         |\n",
      "|    policy_loss        | -0.33         |\n",
      "|    reward             | -0.0028170377 |\n",
      "|    std                | 99.8          |\n",
      "|    value_loss         | 0.00379       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 29000      |\n",
      "|    time_elapsed       | 455        |\n",
      "|    total_timesteps    | 145000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28999      |\n",
      "|    policy_loss        | 0.183      |\n",
      "|    reward             | 0.07041923 |\n",
      "|    std                | 102        |\n",
      "|    value_loss         | 0.000507   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 29100      |\n",
      "|    time_elapsed       | 456        |\n",
      "|    total_timesteps    | 145500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.1      |\n",
      "|    explained_variance | 0.0356     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29099      |\n",
      "|    policy_loss        | 0.568      |\n",
      "|    reward             | 0.03661537 |\n",
      "|    std                | 102        |\n",
      "|    value_loss         | 0.00725    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 29200       |\n",
      "|    time_elapsed       | 458         |\n",
      "|    total_timesteps    | 146000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 0.0318      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29199       |\n",
      "|    policy_loss        | 0.522       |\n",
      "|    reward             | -0.19379768 |\n",
      "|    std                | 103         |\n",
      "|    value_loss         | 0.00467     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 29300       |\n",
      "|    time_elapsed       | 459         |\n",
      "|    total_timesteps    | 146500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29299       |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | -0.04533136 |\n",
      "|    std                | 104         |\n",
      "|    value_loss         | 0.0312      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 29400        |\n",
      "|    time_elapsed       | 461          |\n",
      "|    total_timesteps    | 147000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29399        |\n",
      "|    policy_loss        | 0.275        |\n",
      "|    reward             | -0.016147282 |\n",
      "|    std                | 105          |\n",
      "|    value_loss         | 0.000796     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 29500       |\n",
      "|    time_elapsed       | 462         |\n",
      "|    total_timesteps    | 147500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29499       |\n",
      "|    policy_loss        | -0.186      |\n",
      "|    reward             | 0.014415509 |\n",
      "|    std                | 106         |\n",
      "|    value_loss         | 0.00115     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 29600       |\n",
      "|    time_elapsed       | 464         |\n",
      "|    total_timesteps    | 148000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | -0.00236    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29599       |\n",
      "|    policy_loss        | 0.238       |\n",
      "|    reward             | 0.036708076 |\n",
      "|    std                | 108         |\n",
      "|    value_loss         | 0.000673    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 29700        |\n",
      "|    time_elapsed       | 465          |\n",
      "|    total_timesteps    | 148500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | -1.18        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29699        |\n",
      "|    policy_loss        | 0.346        |\n",
      "|    reward             | -0.008586831 |\n",
      "|    std                | 109          |\n",
      "|    value_loss         | 0.00078      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 29800      |\n",
      "|    time_elapsed       | 467        |\n",
      "|    total_timesteps    | 149000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29799      |\n",
      "|    policy_loss        | -0.918     |\n",
      "|    reward             | 0.01985781 |\n",
      "|    std                | 109        |\n",
      "|    value_loss         | 0.00579    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 29900       |\n",
      "|    time_elapsed       | 468         |\n",
      "|    total_timesteps    | 149500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | 0.0909      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29899       |\n",
      "|    policy_loss        | -1.13       |\n",
      "|    reward             | -0.09805247 |\n",
      "|    std                | 112         |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 30000       |\n",
      "|    time_elapsed       | 470         |\n",
      "|    total_timesteps    | 150000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29999       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | -0.08234555 |\n",
      "|    std                | 113         |\n",
      "|    value_loss         | 0.0215      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 30100        |\n",
      "|    time_elapsed       | 472          |\n",
      "|    total_timesteps    | 150500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30099        |\n",
      "|    policy_loss        | 0.0258       |\n",
      "|    reward             | -0.025466686 |\n",
      "|    std                | 113          |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 30200         |\n",
      "|    time_elapsed       | 473           |\n",
      "|    total_timesteps    | 151000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.3         |\n",
      "|    explained_variance | -0.66         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30199         |\n",
      "|    policy_loss        | 0.338         |\n",
      "|    reward             | -0.0025601124 |\n",
      "|    std                | 116           |\n",
      "|    value_loss         | 0.00179       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 30300       |\n",
      "|    time_elapsed       | 475         |\n",
      "|    total_timesteps    | 151500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | -0.0547     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30299       |\n",
      "|    policy_loss        | -0.384      |\n",
      "|    reward             | 0.004198011 |\n",
      "|    std                | 119         |\n",
      "|    value_loss         | 0.0011      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 30400       |\n",
      "|    time_elapsed       | 476         |\n",
      "|    total_timesteps    | 152000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | 0.268       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30399       |\n",
      "|    policy_loss        | -0.821      |\n",
      "|    reward             | -0.01821471 |\n",
      "|    std                | 122         |\n",
      "|    value_loss         | 0.00567     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -37892.05\n",
      "total_reward: -47892.05\n",
      "total_cost: 89.19\n",
      "total_trades: 5540\n",
      "Sharpe: -0.104\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 30500        |\n",
      "|    time_elapsed       | 478          |\n",
      "|    total_timesteps    | 152500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30499        |\n",
      "|    policy_loss        | -0.448       |\n",
      "|    reward             | -0.112805635 |\n",
      "|    std                | 124          |\n",
      "|    value_loss         | 0.00401      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 318            |\n",
      "|    iterations         | 30600          |\n",
      "|    time_elapsed       | 479            |\n",
      "|    total_timesteps    | 153000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -12.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 30599          |\n",
      "|    policy_loss        | 0.0525         |\n",
      "|    reward             | -0.00085764326 |\n",
      "|    std                | 126            |\n",
      "|    value_loss         | 0.000852       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 30700       |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 153500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | 0.25        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30699       |\n",
      "|    policy_loss        | 0.182       |\n",
      "|    reward             | 0.011795794 |\n",
      "|    std                | 129         |\n",
      "|    value_loss         | 0.000282    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 30800       |\n",
      "|    time_elapsed       | 482         |\n",
      "|    total_timesteps    | 154000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30799       |\n",
      "|    policy_loss        | -0.119      |\n",
      "|    reward             | 0.012706453 |\n",
      "|    std                | 132         |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 318       |\n",
      "|    iterations         | 30900     |\n",
      "|    time_elapsed       | 484       |\n",
      "|    total_timesteps    | 154500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0.251     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 30899     |\n",
      "|    policy_loss        | -0.235    |\n",
      "|    reward             | 0.0227839 |\n",
      "|    std                | 136       |\n",
      "|    value_loss         | 0.000608  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 31000       |\n",
      "|    time_elapsed       | 485         |\n",
      "|    total_timesteps    | 155000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | 0.0129      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30999       |\n",
      "|    policy_loss        | -0.0866     |\n",
      "|    reward             | 0.009196878 |\n",
      "|    std                | 140         |\n",
      "|    value_loss         | 0.000478    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 31100        |\n",
      "|    time_elapsed       | 487          |\n",
      "|    total_timesteps    | 155500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31099        |\n",
      "|    policy_loss        | -0.0549      |\n",
      "|    reward             | 0.0073869373 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 6.63e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 31200         |\n",
      "|    time_elapsed       | 488           |\n",
      "|    total_timesteps    | 156000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31199         |\n",
      "|    policy_loss        | -0.145        |\n",
      "|    reward             | -0.0052949525 |\n",
      "|    std                | 147           |\n",
      "|    value_loss         | 0.000163      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 31300         |\n",
      "|    time_elapsed       | 490           |\n",
      "|    total_timesteps    | 156500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31299         |\n",
      "|    policy_loss        | 0.369         |\n",
      "|    reward             | 0.00061382476 |\n",
      "|    std                | 150           |\n",
      "|    value_loss         | 0.000926      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 31400       |\n",
      "|    time_elapsed       | 492         |\n",
      "|    total_timesteps    | 157000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31399       |\n",
      "|    policy_loss        | -0.113      |\n",
      "|    reward             | 0.011701682 |\n",
      "|    std                | 156         |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 31500        |\n",
      "|    time_elapsed       | 493          |\n",
      "|    total_timesteps    | 157500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -1.06        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31499        |\n",
      "|    policy_loss        | -0.424       |\n",
      "|    reward             | -0.005430695 |\n",
      "|    std                | 160          |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 31600        |\n",
      "|    time_elapsed       | 495          |\n",
      "|    total_timesteps    | 158000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31599        |\n",
      "|    policy_loss        | -0.113       |\n",
      "|    reward             | -0.006492472 |\n",
      "|    std                | 165          |\n",
      "|    value_loss         | 0.000372     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 31700      |\n",
      "|    time_elapsed       | 496        |\n",
      "|    total_timesteps    | 158500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31699      |\n",
      "|    policy_loss        | 0.647      |\n",
      "|    reward             | 0.01182236 |\n",
      "|    std                | 169        |\n",
      "|    value_loss         | 0.00328    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 31800         |\n",
      "|    time_elapsed       | 498           |\n",
      "|    total_timesteps    | 159000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31799         |\n",
      "|    policy_loss        | -0.0204       |\n",
      "|    reward             | -0.0024716791 |\n",
      "|    std                | 174           |\n",
      "|    value_loss         | 3.01e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 31900         |\n",
      "|    time_elapsed       | 499           |\n",
      "|    total_timesteps    | 159500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31899         |\n",
      "|    policy_loss        | -0.238        |\n",
      "|    reward             | 0.00013556438 |\n",
      "|    std                | 181           |\n",
      "|    value_loss         | 0.000395      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 32000        |\n",
      "|    time_elapsed       | 501          |\n",
      "|    total_timesteps    | 160000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | -0.0666      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31999        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | 0.0067086313 |\n",
      "|    std                | 187          |\n",
      "|    value_loss         | 0.000356     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 32100       |\n",
      "|    time_elapsed       | 503         |\n",
      "|    total_timesteps    | 160500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32099       |\n",
      "|    policy_loss        | 0.0132      |\n",
      "|    reward             | -0.02093526 |\n",
      "|    std                | 196         |\n",
      "|    value_loss         | 3.62e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 32200        |\n",
      "|    time_elapsed       | 504          |\n",
      "|    total_timesteps    | 161000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32199        |\n",
      "|    policy_loss        | -1.66        |\n",
      "|    reward             | -0.025534812 |\n",
      "|    std                | 196          |\n",
      "|    value_loss         | 0.0185       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 32300        |\n",
      "|    time_elapsed       | 506          |\n",
      "|    total_timesteps    | 161500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32299        |\n",
      "|    policy_loss        | 0.0957       |\n",
      "|    reward             | -0.016330082 |\n",
      "|    std                | 199          |\n",
      "|    value_loss         | 0.000731     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 32400        |\n",
      "|    time_elapsed       | 508          |\n",
      "|    total_timesteps    | 162000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32399        |\n",
      "|    policy_loss        | 3.59         |\n",
      "|    reward             | 0.0004527813 |\n",
      "|    std                | 200          |\n",
      "|    value_loss         | 0.0995       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 32500        |\n",
      "|    time_elapsed       | 509          |\n",
      "|    total_timesteps    | 162500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32499        |\n",
      "|    policy_loss        | -3.22        |\n",
      "|    reward             | -0.029500982 |\n",
      "|    std                | 203          |\n",
      "|    value_loss         | 0.065        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 32600      |\n",
      "|    time_elapsed       | 511        |\n",
      "|    total_timesteps    | 163000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.5      |\n",
      "|    explained_variance | 0.121      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32599      |\n",
      "|    policy_loss        | -0.313     |\n",
      "|    reward             | 0.05811487 |\n",
      "|    std                | 205        |\n",
      "|    value_loss         | 0.019      |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 318            |\n",
      "|    iterations         | 32700          |\n",
      "|    time_elapsed       | 512            |\n",
      "|    total_timesteps    | 163500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.5          |\n",
      "|    explained_variance | 0.00377        |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 32699          |\n",
      "|    policy_loss        | 0.76           |\n",
      "|    reward             | -0.00014697907 |\n",
      "|    std                | 208            |\n",
      "|    value_loss         | 0.00443        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 32800        |\n",
      "|    time_elapsed       | 514          |\n",
      "|    total_timesteps    | 164000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32799        |\n",
      "|    policy_loss        | 0.201        |\n",
      "|    reward             | -0.026010133 |\n",
      "|    std                | 211          |\n",
      "|    value_loss         | 0.000411     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 32900        |\n",
      "|    time_elapsed       | 515          |\n",
      "|    total_timesteps    | 164500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32899        |\n",
      "|    policy_loss        | -0.338       |\n",
      "|    reward             | 0.0017365752 |\n",
      "|    std                | 213          |\n",
      "|    value_loss         | 0.000807     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 33000       |\n",
      "|    time_elapsed       | 517         |\n",
      "|    total_timesteps    | 165000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | -1.35       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32999       |\n",
      "|    policy_loss        | 0.441       |\n",
      "|    reward             | 0.016626405 |\n",
      "|    std                | 215         |\n",
      "|    value_loss         | 0.00141     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 33100      |\n",
      "|    time_elapsed       | 518        |\n",
      "|    total_timesteps    | 165500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33099      |\n",
      "|    policy_loss        | 0.607      |\n",
      "|    reward             | 0.06692986 |\n",
      "|    std                | 218        |\n",
      "|    value_loss         | 0.00765    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 33200       |\n",
      "|    time_elapsed       | 520         |\n",
      "|    total_timesteps    | 166000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33199       |\n",
      "|    policy_loss        | 3           |\n",
      "|    reward             | -0.20514077 |\n",
      "|    std                | 220         |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -57767.55\n",
      "total_reward: -67767.55\n",
      "total_cost: 97.50\n",
      "total_trades: 5540\n",
      "Sharpe: 0.407\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 33300       |\n",
      "|    time_elapsed       | 521         |\n",
      "|    total_timesteps    | 166500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33299       |\n",
      "|    policy_loss        | -0.121      |\n",
      "|    reward             | 0.005676608 |\n",
      "|    std                | 224         |\n",
      "|    value_loss         | 0.000876    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 33400         |\n",
      "|    time_elapsed       | 523           |\n",
      "|    total_timesteps    | 167000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33399         |\n",
      "|    policy_loss        | -0.308        |\n",
      "|    reward             | -0.0044219415 |\n",
      "|    std                | 225           |\n",
      "|    value_loss         | 0.000661      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 33500       |\n",
      "|    time_elapsed       | 525         |\n",
      "|    total_timesteps    | 167500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0.244       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33499       |\n",
      "|    policy_loss        | -1.83       |\n",
      "|    reward             | 0.036923476 |\n",
      "|    std                | 230         |\n",
      "|    value_loss         | 0.0222      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 33600        |\n",
      "|    time_elapsed       | 526          |\n",
      "|    total_timesteps    | 168000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | -1.19e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33599        |\n",
      "|    policy_loss        | -0.67        |\n",
      "|    reward             | -0.050452232 |\n",
      "|    std                | 236          |\n",
      "|    value_loss         | 0.00325      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 33700      |\n",
      "|    time_elapsed       | 528        |\n",
      "|    total_timesteps    | 168500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.8      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33699      |\n",
      "|    policy_loss        | -0.161     |\n",
      "|    reward             | 0.04749339 |\n",
      "|    std                | 239        |\n",
      "|    value_loss         | 0.000887   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 33800        |\n",
      "|    time_elapsed       | 529          |\n",
      "|    total_timesteps    | 169000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33799        |\n",
      "|    policy_loss        | -1.33        |\n",
      "|    reward             | -0.068465814 |\n",
      "|    std                | 240          |\n",
      "|    value_loss         | 0.00975      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 33900        |\n",
      "|    time_elapsed       | 531          |\n",
      "|    total_timesteps    | 169500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33899        |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.004498774 |\n",
      "|    std                | 243          |\n",
      "|    value_loss         | 0.000319     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 34000        |\n",
      "|    time_elapsed       | 532          |\n",
      "|    total_timesteps    | 170000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33999        |\n",
      "|    policy_loss        | -0.0341      |\n",
      "|    reward             | -0.013341969 |\n",
      "|    std                | 248          |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 34100       |\n",
      "|    time_elapsed       | 534         |\n",
      "|    total_timesteps    | 170500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34099       |\n",
      "|    policy_loss        | -0.0766     |\n",
      "|    reward             | 0.016483055 |\n",
      "|    std                | 255         |\n",
      "|    value_loss         | 8.49e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 34200        |\n",
      "|    time_elapsed       | 536          |\n",
      "|    total_timesteps    | 171000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | -3.51        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34199        |\n",
      "|    policy_loss        | -0.0594      |\n",
      "|    reward             | -0.007920419 |\n",
      "|    std                | 261          |\n",
      "|    value_loss         | 0.000117     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 34300         |\n",
      "|    time_elapsed       | 537           |\n",
      "|    total_timesteps    | 171500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34299         |\n",
      "|    policy_loss        | 0.0311        |\n",
      "|    reward             | -0.0029414364 |\n",
      "|    std                | 270           |\n",
      "|    value_loss         | 1.87e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 34400       |\n",
      "|    time_elapsed       | 539         |\n",
      "|    total_timesteps    | 172000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34399       |\n",
      "|    policy_loss        | 0.336       |\n",
      "|    reward             | 0.013604305 |\n",
      "|    std                | 279         |\n",
      "|    value_loss         | 0.00072     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 34500        |\n",
      "|    time_elapsed       | 540          |\n",
      "|    total_timesteps    | 172500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34499        |\n",
      "|    policy_loss        | -0.402       |\n",
      "|    reward             | -0.019867325 |\n",
      "|    std                | 285          |\n",
      "|    value_loss         | 0.000884     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 34600       |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 173000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34599       |\n",
      "|    policy_loss        | 0.12        |\n",
      "|    reward             | 0.012508442 |\n",
      "|    std                | 292         |\n",
      "|    value_loss         | 8.67e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 34700       |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 173500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34699       |\n",
      "|    policy_loss        | -0.0506     |\n",
      "|    reward             | 0.008513089 |\n",
      "|    std                | 304         |\n",
      "|    value_loss         | 2.54e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 34800       |\n",
      "|    time_elapsed       | 544         |\n",
      "|    total_timesteps    | 174000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | -4.62       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34799       |\n",
      "|    policy_loss        | 0.571       |\n",
      "|    reward             | 0.017200615 |\n",
      "|    std                | 313         |\n",
      "|    value_loss         | 0.00196     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 34900        |\n",
      "|    time_elapsed       | 546          |\n",
      "|    total_timesteps    | 174500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34899        |\n",
      "|    policy_loss        | -0.142       |\n",
      "|    reward             | -0.010375026 |\n",
      "|    std                | 325          |\n",
      "|    value_loss         | 0.000313     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 35000      |\n",
      "|    time_elapsed       | 547        |\n",
      "|    total_timesteps    | 175000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34999      |\n",
      "|    policy_loss        | -0.909     |\n",
      "|    reward             | 0.04218813 |\n",
      "|    std                | 336        |\n",
      "|    value_loss         | 0.00477    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 35100        |\n",
      "|    time_elapsed       | 548          |\n",
      "|    total_timesteps    | 175500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35099        |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | -0.022185564 |\n",
      "|    std                | 342          |\n",
      "|    value_loss         | 8.07e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 35200        |\n",
      "|    time_elapsed       | 550          |\n",
      "|    total_timesteps    | 176000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35199        |\n",
      "|    policy_loss        | -0.179       |\n",
      "|    reward             | 0.0008857538 |\n",
      "|    std                | 351          |\n",
      "|    value_loss         | 0.000294     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 35300        |\n",
      "|    time_elapsed       | 551          |\n",
      "|    total_timesteps    | 176500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -0.044       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35299        |\n",
      "|    policy_loss        | -0.0515      |\n",
      "|    reward             | -0.011906141 |\n",
      "|    std                | 365          |\n",
      "|    value_loss         | 1.46e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 35400       |\n",
      "|    time_elapsed       | 553         |\n",
      "|    total_timesteps    | 177000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -0.157      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35399       |\n",
      "|    policy_loss        | -0.00571    |\n",
      "|    reward             | 0.010150386 |\n",
      "|    std                | 375         |\n",
      "|    value_loss         | 4.99e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 35500        |\n",
      "|    time_elapsed       | 555          |\n",
      "|    total_timesteps    | 177500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35499        |\n",
      "|    policy_loss        | -0.406       |\n",
      "|    reward             | -0.009127679 |\n",
      "|    std                | 385          |\n",
      "|    value_loss         | 0.000884     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 35600       |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 178000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35599       |\n",
      "|    policy_loss        | 0.0296      |\n",
      "|    reward             | 0.020927396 |\n",
      "|    std                | 394         |\n",
      "|    value_loss         | 3.58e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 35700        |\n",
      "|    time_elapsed       | 558          |\n",
      "|    total_timesteps    | 178500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35699        |\n",
      "|    policy_loss        | -0.121       |\n",
      "|    reward             | -0.011271184 |\n",
      "|    std                | 410          |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 35800        |\n",
      "|    time_elapsed       | 559          |\n",
      "|    total_timesteps    | 179000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35799        |\n",
      "|    policy_loss        | -0.117       |\n",
      "|    reward             | 0.0011749179 |\n",
      "|    std                | 425          |\n",
      "|    value_loss         | 8.23e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 35900        |\n",
      "|    time_elapsed       | 561          |\n",
      "|    total_timesteps    | 179500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0.236        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35899        |\n",
      "|    policy_loss        | -0.0613      |\n",
      "|    reward             | 0.0067645786 |\n",
      "|    std                | 441          |\n",
      "|    value_loss         | 0.0002       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 36000       |\n",
      "|    time_elapsed       | 562         |\n",
      "|    total_timesteps    | 180000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35999       |\n",
      "|    policy_loss        | -0.245      |\n",
      "|    reward             | 0.008199727 |\n",
      "|    std                | 458         |\n",
      "|    value_loss         | 0.000363    |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -10835.56\n",
      "total_reward: -20835.56\n",
      "total_cost: 565.20\n",
      "total_trades: 5540\n",
      "Sharpe: -0.342\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 36100        |\n",
      "|    time_elapsed       | 564          |\n",
      "|    total_timesteps    | 180500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36099        |\n",
      "|    policy_loss        | 1.06         |\n",
      "|    reward             | -0.048939068 |\n",
      "|    std                | 470          |\n",
      "|    value_loss         | 0.00577      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 36200       |\n",
      "|    time_elapsed       | 565         |\n",
      "|    total_timesteps    | 181000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | -0.00528    |\n",
      "|    reward             | 0.009468746 |\n",
      "|    std                | 480         |\n",
      "|    value_loss         | 1.49e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 567         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | 0.277       |\n",
      "|    reward             | 0.015183868 |\n",
      "|    std                | 493         |\n",
      "|    value_loss         | 0.000453    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 36400        |\n",
      "|    time_elapsed       | 568          |\n",
      "|    total_timesteps    | 182000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | -0.146       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36399        |\n",
      "|    policy_loss        | -0.0757      |\n",
      "|    reward             | 0.0011052521 |\n",
      "|    std                | 515          |\n",
      "|    value_loss         | 3.83e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 36500        |\n",
      "|    time_elapsed       | 570          |\n",
      "|    total_timesteps    | 182500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36499        |\n",
      "|    policy_loss        | 0.0987       |\n",
      "|    reward             | -0.001989719 |\n",
      "|    std                | 537          |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 36600        |\n",
      "|    time_elapsed       | 572          |\n",
      "|    total_timesteps    | 183000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36599        |\n",
      "|    policy_loss        | -0.0476      |\n",
      "|    reward             | -0.050288416 |\n",
      "|    std                | 554          |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 36700        |\n",
      "|    time_elapsed       | 573          |\n",
      "|    total_timesteps    | 183500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36699        |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.056337364 |\n",
      "|    std                | 559          |\n",
      "|    value_loss         | 0.000183     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 36800       |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 184000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36799       |\n",
      "|    policy_loss        | 0.209       |\n",
      "|    reward             | -0.00954213 |\n",
      "|    std                | 569         |\n",
      "|    value_loss         | 0.00029     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 36900         |\n",
      "|    time_elapsed       | 577           |\n",
      "|    total_timesteps    | 184500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | -0.277        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 36899         |\n",
      "|    policy_loss        | -0.112        |\n",
      "|    reward             | -0.0055681947 |\n",
      "|    std                | 580           |\n",
      "|    value_loss         | 0.000351      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 37000       |\n",
      "|    time_elapsed       | 578         |\n",
      "|    total_timesteps    | 185000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.437       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36999       |\n",
      "|    policy_loss        | -0.186      |\n",
      "|    reward             | 0.020991264 |\n",
      "|    std                | 591         |\n",
      "|    value_loss         | 0.00145     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 37100        |\n",
      "|    time_elapsed       | 580          |\n",
      "|    total_timesteps    | 185500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0.237        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37099        |\n",
      "|    policy_loss        | -0.769       |\n",
      "|    reward             | -0.007861238 |\n",
      "|    std                | 598          |\n",
      "|    value_loss         | 0.00359      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 37200      |\n",
      "|    time_elapsed       | 581        |\n",
      "|    total_timesteps    | 186000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37199      |\n",
      "|    policy_loss        | 1.71       |\n",
      "|    reward             | 0.06699606 |\n",
      "|    std                | 598        |\n",
      "|    value_loss         | 0.0221     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 37300        |\n",
      "|    time_elapsed       | 583          |\n",
      "|    total_timesteps    | 186500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37299        |\n",
      "|    policy_loss        | 0.355        |\n",
      "|    reward             | -0.028587766 |\n",
      "|    std                | 607          |\n",
      "|    value_loss         | 0.000689     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 37400       |\n",
      "|    time_elapsed       | 584         |\n",
      "|    total_timesteps    | 187000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | 5.45        |\n",
      "|    reward             | -0.02949539 |\n",
      "|    std                | 610         |\n",
      "|    value_loss         | 0.127       |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 37500    |\n",
      "|    time_elapsed       | 586      |\n",
      "|    total_timesteps    | 187500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 37499    |\n",
      "|    policy_loss        | -1.3     |\n",
      "|    reward             | 0.264174 |\n",
      "|    std                | 604      |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 37600       |\n",
      "|    time_elapsed       | 587         |\n",
      "|    total_timesteps    | 188000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | -0.00281    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37599       |\n",
      "|    policy_loss        | -1.58       |\n",
      "|    reward             | -0.13832185 |\n",
      "|    std                | 602         |\n",
      "|    value_loss         | 0.0667      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 37700       |\n",
      "|    time_elapsed       | 589         |\n",
      "|    total_timesteps    | 188500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37699       |\n",
      "|    policy_loss        | -0.23       |\n",
      "|    reward             | -0.03241822 |\n",
      "|    std                | 611         |\n",
      "|    value_loss         | 0.000615    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 37800      |\n",
      "|    time_elapsed       | 591        |\n",
      "|    total_timesteps    | 189000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37799      |\n",
      "|    policy_loss        | -0.931     |\n",
      "|    reward             | 0.04930013 |\n",
      "|    std                | 617        |\n",
      "|    value_loss         | 0.0039     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 37900       |\n",
      "|    time_elapsed       | 592         |\n",
      "|    total_timesteps    | 189500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37899       |\n",
      "|    policy_loss        | 0.32        |\n",
      "|    reward             | 0.014625887 |\n",
      "|    std                | 622         |\n",
      "|    value_loss         | 0.000561    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 38000       |\n",
      "|    time_elapsed       | 593         |\n",
      "|    total_timesteps    | 190000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.127       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37999       |\n",
      "|    policy_loss        | 0.56        |\n",
      "|    reward             | -0.07157209 |\n",
      "|    std                | 632         |\n",
      "|    value_loss         | 0.00153     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 38100      |\n",
      "|    time_elapsed       | 595        |\n",
      "|    total_timesteps    | 190500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.8      |\n",
      "|    explained_variance | 0.213      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 38099      |\n",
      "|    policy_loss        | 0.294      |\n",
      "|    reward             | 0.11167275 |\n",
      "|    std                | 639        |\n",
      "|    value_loss         | 0.00191    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 319       |\n",
      "|    iterations         | 38200     |\n",
      "|    time_elapsed       | 597       |\n",
      "|    total_timesteps    | 191000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | 0.102     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 38199     |\n",
      "|    policy_loss        | 3.21      |\n",
      "|    reward             | 0.1776538 |\n",
      "|    std                | 646       |\n",
      "|    value_loss         | 0.0576    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 38300       |\n",
      "|    time_elapsed       | 598         |\n",
      "|    total_timesteps    | 191500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38299       |\n",
      "|    policy_loss        | 0.3         |\n",
      "|    reward             | 0.008893303 |\n",
      "|    std                | 652         |\n",
      "|    value_loss         | 0.00052     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 38400         |\n",
      "|    time_elapsed       | 600           |\n",
      "|    total_timesteps    | 192000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38399         |\n",
      "|    policy_loss        | -0.39         |\n",
      "|    reward             | -0.0071170367 |\n",
      "|    std                | 664           |\n",
      "|    value_loss         | 0.000925      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 38500        |\n",
      "|    time_elapsed       | 601          |\n",
      "|    total_timesteps    | 192500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38499        |\n",
      "|    policy_loss        | -0.389       |\n",
      "|    reward             | 0.0025220173 |\n",
      "|    std                | 684          |\n",
      "|    value_loss         | 0.000639     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 38600       |\n",
      "|    time_elapsed       | 603         |\n",
      "|    total_timesteps    | 193000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.0544      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38599       |\n",
      "|    policy_loss        | -0.301      |\n",
      "|    reward             | -0.00168531 |\n",
      "|    std                | 705         |\n",
      "|    value_loss         | 0.00041     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 604         |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.605       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | 0.741       |\n",
      "|    reward             | 0.013338293 |\n",
      "|    std                | 738         |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11918.73\n",
      "total_reward: -21918.73\n",
      "total_cost: 519.93\n",
      "total_trades: 5540\n",
      "Sharpe: 0.225\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 38800       |\n",
      "|    time_elapsed       | 606         |\n",
      "|    total_timesteps    | 194000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38799       |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | 0.032135986 |\n",
      "|    std                | 760         |\n",
      "|    value_loss         | 0.0174      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 38900       |\n",
      "|    time_elapsed       | 607         |\n",
      "|    total_timesteps    | 194500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38899       |\n",
      "|    policy_loss        | -0.369      |\n",
      "|    reward             | 0.005317545 |\n",
      "|    std                | 772         |\n",
      "|    value_loss         | 0.00103     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 39000       |\n",
      "|    time_elapsed       | 608         |\n",
      "|    total_timesteps    | 195000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38999       |\n",
      "|    policy_loss        | 0.398       |\n",
      "|    reward             | -0.01584823 |\n",
      "|    std                | 787         |\n",
      "|    value_loss         | 0.000857    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 39100        |\n",
      "|    time_elapsed       | 610          |\n",
      "|    total_timesteps    | 195500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39099        |\n",
      "|    policy_loss        | 0.0883       |\n",
      "|    reward             | 0.0077419477 |\n",
      "|    std                | 807          |\n",
      "|    value_loss         | 4.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 39200        |\n",
      "|    time_elapsed       | 611          |\n",
      "|    total_timesteps    | 196000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0.166        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39199        |\n",
      "|    policy_loss        | -0.262       |\n",
      "|    reward             | 0.0029097018 |\n",
      "|    std                | 835          |\n",
      "|    value_loss         | 0.000356     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 39300       |\n",
      "|    time_elapsed       | 613         |\n",
      "|    total_timesteps    | 196500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | -2.85       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39299       |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | 0.031309906 |\n",
      "|    std                | 870         |\n",
      "|    value_loss         | 0.00447     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 39400       |\n",
      "|    time_elapsed       | 614         |\n",
      "|    total_timesteps    | 197000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39399       |\n",
      "|    policy_loss        | 0.765       |\n",
      "|    reward             | 0.019365454 |\n",
      "|    std                | 904         |\n",
      "|    value_loss         | 0.00243     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 39500         |\n",
      "|    time_elapsed       | 616           |\n",
      "|    total_timesteps    | 197500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 39499         |\n",
      "|    policy_loss        | 0.742         |\n",
      "|    reward             | -0.0051921094 |\n",
      "|    std                | 909           |\n",
      "|    value_loss         | 0.00219       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 39600       |\n",
      "|    time_elapsed       | 617         |\n",
      "|    total_timesteps    | 198000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39599       |\n",
      "|    policy_loss        | 3.49        |\n",
      "|    reward             | 0.011295688 |\n",
      "|    std                | 908         |\n",
      "|    value_loss         | 0.0589      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 39700        |\n",
      "|    time_elapsed       | 619          |\n",
      "|    total_timesteps    | 198500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39699        |\n",
      "|    policy_loss        | 2.86         |\n",
      "|    reward             | -0.044776756 |\n",
      "|    std                | 909          |\n",
      "|    value_loss         | 0.0311       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 39800      |\n",
      "|    time_elapsed       | 621        |\n",
      "|    total_timesteps    | 199000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0.125      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39799      |\n",
      "|    policy_loss        | -7.29      |\n",
      "|    reward             | 0.00592581 |\n",
      "|    std                | 919        |\n",
      "|    value_loss         | 0.219      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 39900      |\n",
      "|    time_elapsed       | 622        |\n",
      "|    total_timesteps    | 199500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 6.13e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39899      |\n",
      "|    policy_loss        | -6.59      |\n",
      "|    reward             | 0.50221926 |\n",
      "|    std                | 930        |\n",
      "|    value_loss         | 0.22       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 40000       |\n",
      "|    time_elapsed       | 624         |\n",
      "|    total_timesteps    | 200000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39999       |\n",
      "|    policy_loss        | -0.142      |\n",
      "|    reward             | -0.05190316 |\n",
      "|    std                | 930         |\n",
      "|    value_loss         | 0.000354    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 40100        |\n",
      "|    time_elapsed       | 625          |\n",
      "|    total_timesteps    | 200500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40099        |\n",
      "|    policy_loss        | 0.0508       |\n",
      "|    reward             | -0.029873671 |\n",
      "|    std                | 941          |\n",
      "|    value_loss         | 0.00026      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 40200        |\n",
      "|    time_elapsed       | 627          |\n",
      "|    total_timesteps    | 201000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | -0.0591      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40199        |\n",
      "|    policy_loss        | 0.0958       |\n",
      "|    reward             | -0.038143653 |\n",
      "|    std                | 955          |\n",
      "|    value_loss         | 0.000185     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 40300       |\n",
      "|    time_elapsed       | 628         |\n",
      "|    total_timesteps    | 201500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40299       |\n",
      "|    policy_loss        | -2.08       |\n",
      "|    reward             | -0.01376324 |\n",
      "|    std                | 982         |\n",
      "|    value_loss         | 0.0183      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 40400       |\n",
      "|    time_elapsed       | 630         |\n",
      "|    total_timesteps    | 202000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | -0.0997     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40399       |\n",
      "|    policy_loss        | -0.329      |\n",
      "|    reward             | 0.042574264 |\n",
      "|    std                | 999         |\n",
      "|    value_loss         | 0.000901    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 40500       |\n",
      "|    time_elapsed       | 631         |\n",
      "|    total_timesteps    | 202500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40499       |\n",
      "|    policy_loss        | 0.493       |\n",
      "|    reward             | -0.05886732 |\n",
      "|    std                | 1.01e+03    |\n",
      "|    value_loss         | 0.00276     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 40600        |\n",
      "|    time_elapsed       | 633          |\n",
      "|    total_timesteps    | 203000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40599        |\n",
      "|    policy_loss        | -0.845       |\n",
      "|    reward             | -0.016513813 |\n",
      "|    std                | 1.02e+03     |\n",
      "|    value_loss         | 0.00265      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 40700       |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 203500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40699       |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | 0.015776293 |\n",
      "|    std                | 1.03e+03    |\n",
      "|    value_loss         | 0.0057      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 40800       |\n",
      "|    time_elapsed       | 636         |\n",
      "|    total_timesteps    | 204000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40799       |\n",
      "|    policy_loss        | -3.01       |\n",
      "|    reward             | -0.07574403 |\n",
      "|    std                | 1.05e+03    |\n",
      "|    value_loss         | 0.042       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 40900      |\n",
      "|    time_elapsed       | 637        |\n",
      "|    total_timesteps    | 204500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.8      |\n",
      "|    explained_variance | 0.122      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40899      |\n",
      "|    policy_loss        | -6.4       |\n",
      "|    reward             | 0.03484844 |\n",
      "|    std                | 1.06e+03   |\n",
      "|    value_loss         | 0.214      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 41000      |\n",
      "|    time_elapsed       | 639        |\n",
      "|    total_timesteps    | 205000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 0.177      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40999      |\n",
      "|    policy_loss        | -10.6      |\n",
      "|    reward             | 0.33072165 |\n",
      "|    std                | 1.05e+03   |\n",
      "|    value_loss         | 0.516      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 41100         |\n",
      "|    time_elapsed       | 641           |\n",
      "|    total_timesteps    | 205500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41099         |\n",
      "|    policy_loss        | -0.0792       |\n",
      "|    reward             | -0.0045201653 |\n",
      "|    std                | 1.06e+03      |\n",
      "|    value_loss         | 0.000203      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 41200         |\n",
      "|    time_elapsed       | 642           |\n",
      "|    total_timesteps    | 206000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41199         |\n",
      "|    policy_loss        | 0.0393        |\n",
      "|    reward             | -0.0060649766 |\n",
      "|    std                | 1.07e+03      |\n",
      "|    value_loss         | 7.63e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 41300        |\n",
      "|    time_elapsed       | 644          |\n",
      "|    total_timesteps    | 206500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41299        |\n",
      "|    policy_loss        | -0.11        |\n",
      "|    reward             | -0.008622988 |\n",
      "|    std                | 1.08e+03     |\n",
      "|    value_loss         | 9.64e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 41400        |\n",
      "|    time_elapsed       | 645          |\n",
      "|    total_timesteps    | 207000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | -180         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41399        |\n",
      "|    policy_loss        | 0.501        |\n",
      "|    reward             | 0.0041948715 |\n",
      "|    std                | 1.11e+03     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 41500         |\n",
      "|    time_elapsed       | 647           |\n",
      "|    total_timesteps    | 207500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41499         |\n",
      "|    policy_loss        | 0.132         |\n",
      "|    reward             | -0.0018069368 |\n",
      "|    std                | 1.13e+03      |\n",
      "|    value_loss         | 8.34e-05      |\n",
      "-----------------------------------------\n",
      "day: 2770, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12440.66\n",
      "total_reward: -22440.66\n",
      "total_cost: 409.65\n",
      "total_trades: 5540\n",
      "Sharpe: 0.270\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 41600        |\n",
      "|    time_elapsed       | 648          |\n",
      "|    total_timesteps    | 208000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41599        |\n",
      "|    policy_loss        | -0.507       |\n",
      "|    reward             | -0.017760957 |\n",
      "|    std                | 1.16e+03     |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 41700         |\n",
      "|    time_elapsed       | 650           |\n",
      "|    total_timesteps    | 208500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41699         |\n",
      "|    policy_loss        | -0.416        |\n",
      "|    reward             | -0.0012011448 |\n",
      "|    std                | 1.17e+03      |\n",
      "|    value_loss         | 0.000785      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 41800       |\n",
      "|    time_elapsed       | 651         |\n",
      "|    total_timesteps    | 209000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41799       |\n",
      "|    policy_loss        | -0.184      |\n",
      "|    reward             | 0.019358974 |\n",
      "|    std                | 1.2e+03     |\n",
      "|    value_loss         | 0.000115    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 41900         |\n",
      "|    time_elapsed       | 653           |\n",
      "|    total_timesteps    | 209500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0.031         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41899         |\n",
      "|    policy_loss        | -0.00411      |\n",
      "|    reward             | -0.0016670615 |\n",
      "|    std                | 1.23e+03      |\n",
      "|    value_loss         | 0.000108      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 42000       |\n",
      "|    time_elapsed       | 654         |\n",
      "|    total_timesteps    | 210000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0.00254     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41999       |\n",
      "|    policy_loss        | 0.319       |\n",
      "|    reward             | 0.026766885 |\n",
      "|    std                | 1.28e+03    |\n",
      "|    value_loss         | 0.000568    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 42100        |\n",
      "|    time_elapsed       | 656          |\n",
      "|    total_timesteps    | 210500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | -0.0762      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42099        |\n",
      "|    policy_loss        | -0.687       |\n",
      "|    reward             | -0.006357897 |\n",
      "|    std                | 1.34e+03     |\n",
      "|    value_loss         | 0.00219      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 42200         |\n",
      "|    time_elapsed       | 657           |\n",
      "|    total_timesteps    | 211000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42199         |\n",
      "|    policy_loss        | -0.127        |\n",
      "|    reward             | -0.0009203829 |\n",
      "|    std                | 1.36e+03      |\n",
      "|    value_loss         | 0.00296       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 42300       |\n",
      "|    time_elapsed       | 659         |\n",
      "|    total_timesteps    | 211500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42299       |\n",
      "|    policy_loss        | 0.742       |\n",
      "|    reward             | 0.040223308 |\n",
      "|    std                | 1.37e+03    |\n",
      "|    value_loss         | 0.0042      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 42400       |\n",
      "|    time_elapsed       | 660         |\n",
      "|    total_timesteps    | 212000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | -0.537      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42399       |\n",
      "|    policy_loss        | 0.763       |\n",
      "|    reward             | -0.23922138 |\n",
      "|    std                | 1.37e+03    |\n",
      "|    value_loss         | 0.00817     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 42500        |\n",
      "|    time_elapsed       | 662          |\n",
      "|    total_timesteps    | 212500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0.137        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42499        |\n",
      "|    policy_loss        | 1.37         |\n",
      "|    reward             | 0.0009168396 |\n",
      "|    std                | 1.37e+03     |\n",
      "|    value_loss         | 0.00961      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 42600      |\n",
      "|    time_elapsed       | 663        |\n",
      "|    total_timesteps    | 213000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42599      |\n",
      "|    policy_loss        | -3.96      |\n",
      "|    reward             | 0.12993376 |\n",
      "|    std                | 1.38e+03   |\n",
      "|    value_loss         | 0.0968     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 42700         |\n",
      "|    time_elapsed       | 665           |\n",
      "|    total_timesteps    | 213500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42699         |\n",
      "|    policy_loss        | 0.567         |\n",
      "|    reward             | -0.0013499012 |\n",
      "|    std                | 1.39e+03      |\n",
      "|    value_loss         | 0.00124       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 42800        |\n",
      "|    time_elapsed       | 666          |\n",
      "|    total_timesteps    | 214000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42799        |\n",
      "|    policy_loss        | 0.317        |\n",
      "|    reward             | -0.003145358 |\n",
      "|    std                | 1.41e+03     |\n",
      "|    value_loss         | 0.000511     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 668         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42899       |\n",
      "|    policy_loss        | 0.0418      |\n",
      "|    reward             | 0.009787975 |\n",
      "|    std                | 1.43e+03    |\n",
      "|    value_loss         | 7.72e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 43000        |\n",
      "|    time_elapsed       | 669          |\n",
      "|    total_timesteps    | 215000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | -0.0555      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42999        |\n",
      "|    policy_loss        | -0.0393      |\n",
      "|    reward             | 0.0002626536 |\n",
      "|    std                | 1.45e+03     |\n",
      "|    value_loss         | 6.75e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 43100        |\n",
      "|    time_elapsed       | 671          |\n",
      "|    total_timesteps    | 215500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0.443        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43099        |\n",
      "|    policy_loss        | -0.268       |\n",
      "|    reward             | -0.011173719 |\n",
      "|    std                | 1.48e+03     |\n",
      "|    value_loss         | 0.000339     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 43200        |\n",
      "|    time_elapsed       | 673          |\n",
      "|    total_timesteps    | 216000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | -0.662       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43199        |\n",
      "|    policy_loss        | 0.469        |\n",
      "|    reward             | 0.0023734712 |\n",
      "|    std                | 1.51e+03     |\n",
      "|    value_loss         | 0.00199      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 43300       |\n",
      "|    time_elapsed       | 674         |\n",
      "|    total_timesteps    | 216500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | -1.66       |\n",
      "|    reward             | -0.07366613 |\n",
      "|    std                | 1.57e+03    |\n",
      "|    value_loss         | 0.0143      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 43400        |\n",
      "|    time_elapsed       | 676          |\n",
      "|    total_timesteps    | 217000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43399        |\n",
      "|    policy_loss        | 0.222        |\n",
      "|    reward             | -0.022917707 |\n",
      "|    std                | 1.57e+03     |\n",
      "|    value_loss         | 0.00024      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 43500         |\n",
      "|    time_elapsed       | 677           |\n",
      "|    total_timesteps    | 217500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43499         |\n",
      "|    policy_loss        | 1.85          |\n",
      "|    reward             | -0.0114154555 |\n",
      "|    std                | 1.6e+03       |\n",
      "|    value_loss         | 0.0131        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 43600       |\n",
      "|    time_elapsed       | 678         |\n",
      "|    total_timesteps    | 218000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0.47        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43599       |\n",
      "|    policy_loss        | -0.872      |\n",
      "|    reward             | -0.01396595 |\n",
      "|    std                | 1.65e+03    |\n",
      "|    value_loss         | 0.00353     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 43700        |\n",
      "|    time_elapsed       | 680          |\n",
      "|    total_timesteps    | 218500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.169        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43699        |\n",
      "|    policy_loss        | -1.71        |\n",
      "|    reward             | -0.008962381 |\n",
      "|    std                | 1.68e+03     |\n",
      "|    value_loss         | 0.0109       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 43800       |\n",
      "|    time_elapsed       | 682         |\n",
      "|    total_timesteps    | 219000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43799       |\n",
      "|    policy_loss        | 0.0123      |\n",
      "|    reward             | 0.049394663 |\n",
      "|    std                | 1.69e+03    |\n",
      "|    value_loss         | 9.41e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 43900       |\n",
      "|    time_elapsed       | 683         |\n",
      "|    total_timesteps    | 219500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43899       |\n",
      "|    policy_loss        | -0.578      |\n",
      "|    reward             | -0.02118544 |\n",
      "|    std                | 1.72e+03    |\n",
      "|    value_loss         | 0.00118     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44000        |\n",
      "|    time_elapsed       | 685          |\n",
      "|    total_timesteps    | 220000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43999        |\n",
      "|    policy_loss        | 0.47         |\n",
      "|    reward             | -0.005127151 |\n",
      "|    std                | 1.76e+03     |\n",
      "|    value_loss         | 0.000792     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44100        |\n",
      "|    time_elapsed       | 686          |\n",
      "|    total_timesteps    | 220500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44099        |\n",
      "|    policy_loss        | -0.0761      |\n",
      "|    reward             | -0.006680775 |\n",
      "|    std                | 1.81e+03     |\n",
      "|    value_loss         | 3.54e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44200        |\n",
      "|    time_elapsed       | 688          |\n",
      "|    total_timesteps    | 221000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0.0276       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44199        |\n",
      "|    policy_loss        | 0.661        |\n",
      "|    reward             | -0.007463981 |\n",
      "|    std                | 1.88e+03     |\n",
      "|    value_loss         | 0.00195      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 44300       |\n",
      "|    time_elapsed       | 689         |\n",
      "|    total_timesteps    | 221500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | -0.941      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44299       |\n",
      "|    policy_loss        | 0.0554      |\n",
      "|    reward             | -0.00804982 |\n",
      "|    std                | 1.94e+03    |\n",
      "|    value_loss         | 4e-05       |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11534.65\n",
      "total_reward: -21534.65\n",
      "total_cost: 535.73\n",
      "total_trades: 5540\n",
      "Sharpe: 0.102\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 44400       |\n",
      "|    time_elapsed       | 691         |\n",
      "|    total_timesteps    | 222000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44399       |\n",
      "|    policy_loss        | -2.62       |\n",
      "|    reward             | 0.093785994 |\n",
      "|    std                | 1.99e+03    |\n",
      "|    value_loss         | 0.029       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44500        |\n",
      "|    time_elapsed       | 692          |\n",
      "|    total_timesteps    | 222500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44499        |\n",
      "|    policy_loss        | -0.146       |\n",
      "|    reward             | -0.022507587 |\n",
      "|    std                | 2.01e+03     |\n",
      "|    value_loss         | 0.000359     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44600        |\n",
      "|    time_elapsed       | 694          |\n",
      "|    total_timesteps    | 223000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44599        |\n",
      "|    policy_loss        | 0.906        |\n",
      "|    reward             | -0.041691683 |\n",
      "|    std                | 2.03e+03     |\n",
      "|    value_loss         | 0.0043       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44700        |\n",
      "|    time_elapsed       | 695          |\n",
      "|    total_timesteps    | 223500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0.00371      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44699        |\n",
      "|    policy_loss        | 3.71         |\n",
      "|    reward             | -0.045619074 |\n",
      "|    std                | 2.03e+03     |\n",
      "|    value_loss         | 0.0487       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 44800      |\n",
      "|    time_elapsed       | 697        |\n",
      "|    total_timesteps    | 224000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.1      |\n",
      "|    explained_variance | 0.412      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44799      |\n",
      "|    policy_loss        | -1.48      |\n",
      "|    reward             | -0.0808495 |\n",
      "|    std                | 2.02e+03   |\n",
      "|    value_loss         | 0.0234     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44900        |\n",
      "|    time_elapsed       | 699          |\n",
      "|    total_timesteps    | 224500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44899        |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | -0.005102673 |\n",
      "|    std                | 2.02e+03     |\n",
      "|    value_loss         | 0.00412      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 45000        |\n",
      "|    time_elapsed       | 700          |\n",
      "|    total_timesteps    | 225000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44999        |\n",
      "|    policy_loss        | -0.632       |\n",
      "|    reward             | -0.012788842 |\n",
      "|    std                | 2.04e+03     |\n",
      "|    value_loss         | 0.00149      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 45100         |\n",
      "|    time_elapsed       | 702           |\n",
      "|    total_timesteps    | 225500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45099         |\n",
      "|    policy_loss        | -0.27         |\n",
      "|    reward             | -0.0012152035 |\n",
      "|    std                | 2.08e+03      |\n",
      "|    value_loss         | 0.000304      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 45200        |\n",
      "|    time_elapsed       | 704          |\n",
      "|    total_timesteps    | 226000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45199        |\n",
      "|    policy_loss        | -0.209       |\n",
      "|    reward             | 0.0003814493 |\n",
      "|    std                | 2.12e+03     |\n",
      "|    value_loss         | 0.000221     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 45300       |\n",
      "|    time_elapsed       | 706         |\n",
      "|    total_timesteps    | 226500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | -2.56       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45299       |\n",
      "|    policy_loss        | 0.827       |\n",
      "|    reward             | 0.005117244 |\n",
      "|    std                | 2.18e+03    |\n",
      "|    value_loss         | 0.00223     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 45400        |\n",
      "|    time_elapsed       | 707          |\n",
      "|    total_timesteps    | 227000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | -0.0175      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45399        |\n",
      "|    policy_loss        | -0.451       |\n",
      "|    reward             | -0.028788172 |\n",
      "|    std                | 2.23e+03     |\n",
      "|    value_loss         | 0.000765     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 45500        |\n",
      "|    time_elapsed       | 709          |\n",
      "|    total_timesteps    | 227500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45499        |\n",
      "|    policy_loss        | -0.237       |\n",
      "|    reward             | -0.011987298 |\n",
      "|    std                | 2.31e+03     |\n",
      "|    value_loss         | 0.000588     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 45600        |\n",
      "|    time_elapsed       | 710          |\n",
      "|    total_timesteps    | 228000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45599        |\n",
      "|    policy_loss        | 0.0719       |\n",
      "|    reward             | -0.014778834 |\n",
      "|    std                | 2.32e+03     |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 45700        |\n",
      "|    time_elapsed       | 712          |\n",
      "|    total_timesteps    | 228500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45699        |\n",
      "|    policy_loss        | 0.0975       |\n",
      "|    reward             | 0.0056105293 |\n",
      "|    std                | 2.39e+03     |\n",
      "|    value_loss         | 5.48e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 45800         |\n",
      "|    time_elapsed       | 713           |\n",
      "|    total_timesteps    | 229000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.4         |\n",
      "|    explained_variance | 0.000312      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45799         |\n",
      "|    policy_loss        | 0.0711        |\n",
      "|    reward             | -0.0054456997 |\n",
      "|    std                | 2.45e+03      |\n",
      "|    value_loss         | 6.5e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 45900       |\n",
      "|    time_elapsed       | 715         |\n",
      "|    total_timesteps    | 229500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0.232       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45899       |\n",
      "|    policy_loss        | -0.161      |\n",
      "|    reward             | 0.008090145 |\n",
      "|    std                | 2.51e+03    |\n",
      "|    value_loss         | 7.87e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 46000         |\n",
      "|    time_elapsed       | 716           |\n",
      "|    total_timesteps    | 230000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.5         |\n",
      "|    explained_variance | 0.0632        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45999         |\n",
      "|    policy_loss        | 1.86          |\n",
      "|    reward             | -0.0038699214 |\n",
      "|    std                | 2.58e+03      |\n",
      "|    value_loss         | 0.0174        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 46100       |\n",
      "|    time_elapsed       | 718         |\n",
      "|    total_timesteps    | 230500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46099       |\n",
      "|    policy_loss        | 0.367       |\n",
      "|    reward             | 0.040443048 |\n",
      "|    std                | 2.64e+03    |\n",
      "|    value_loss         | 0.000623    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 46200       |\n",
      "|    time_elapsed       | 719         |\n",
      "|    total_timesteps    | 231000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46199       |\n",
      "|    policy_loss        | 0.649       |\n",
      "|    reward             | 0.004124655 |\n",
      "|    std                | 2.68e+03    |\n",
      "|    value_loss         | 0.00145     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 46300        |\n",
      "|    time_elapsed       | 721          |\n",
      "|    total_timesteps    | 231500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0.135        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46299        |\n",
      "|    policy_loss        | -0.222       |\n",
      "|    reward             | -0.011421856 |\n",
      "|    std                | 2.76e+03     |\n",
      "|    value_loss         | 0.000254     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 46400       |\n",
      "|    time_elapsed       | 723         |\n",
      "|    total_timesteps    | 232000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0.17        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46399       |\n",
      "|    policy_loss        | -0.857      |\n",
      "|    reward             | 0.032063067 |\n",
      "|    std                | 2.82e+03    |\n",
      "|    value_loss         | 0.00272     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 46500      |\n",
      "|    time_elapsed       | 724        |\n",
      "|    total_timesteps    | 232500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46499      |\n",
      "|    policy_loss        | 4.03       |\n",
      "|    reward             | 0.19084072 |\n",
      "|    std                | 2.86e+03   |\n",
      "|    value_loss         | 0.0602     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 46600       |\n",
      "|    time_elapsed       | 726         |\n",
      "|    total_timesteps    | 233000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46599       |\n",
      "|    policy_loss        | 0.319       |\n",
      "|    reward             | 0.022689488 |\n",
      "|    std                | 2.88e+03    |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 46700        |\n",
      "|    time_elapsed       | 727          |\n",
      "|    total_timesteps    | 233500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46699        |\n",
      "|    policy_loss        | -0.00503     |\n",
      "|    reward             | -0.009054701 |\n",
      "|    std                | 2.94e+03     |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 46800         |\n",
      "|    time_elapsed       | 729           |\n",
      "|    total_timesteps    | 234000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 46799         |\n",
      "|    policy_loss        | -0.192        |\n",
      "|    reward             | -0.0081627825 |\n",
      "|    std                | 3e+03         |\n",
      "|    value_loss         | 0.000136      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 46900       |\n",
      "|    time_elapsed       | 731         |\n",
      "|    total_timesteps    | 234500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | 0.0707      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46899       |\n",
      "|    policy_loss        | -0.0599     |\n",
      "|    reward             | 0.005422639 |\n",
      "|    std                | 3.11e+03    |\n",
      "|    value_loss         | 1.96e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 47000        |\n",
      "|    time_elapsed       | 732          |\n",
      "|    total_timesteps    | 235000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | -0.209       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46999        |\n",
      "|    policy_loss        | -0.0624      |\n",
      "|    reward             | -0.006291484 |\n",
      "|    std                | 3.21e+03     |\n",
      "|    value_loss         | 3.75e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 47100        |\n",
      "|    time_elapsed       | 733          |\n",
      "|    total_timesteps    | 235500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47099        |\n",
      "|    policy_loss        | 0.0786       |\n",
      "|    reward             | -0.015317407 |\n",
      "|    std                | 3.35e+03     |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12340.48\n",
      "total_reward: -22340.48\n",
      "total_cost: 440.81\n",
      "total_trades: 5540\n",
      "Sharpe: 0.352\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 47200        |\n",
      "|    time_elapsed       | 735          |\n",
      "|    total_timesteps    | 236000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47199        |\n",
      "|    policy_loss        | -0.0565      |\n",
      "|    reward             | -0.017269347 |\n",
      "|    std                | 3.47e+03     |\n",
      "|    value_loss         | 0.000156     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 47300       |\n",
      "|    time_elapsed       | 737         |\n",
      "|    total_timesteps    | 236500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47299       |\n",
      "|    policy_loss        | 0.674       |\n",
      "|    reward             | 0.010476708 |\n",
      "|    std                | 3.58e+03    |\n",
      "|    value_loss         | 0.00134     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 47400       |\n",
      "|    time_elapsed       | 739         |\n",
      "|    total_timesteps    | 237000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47399       |\n",
      "|    policy_loss        | -0.00207    |\n",
      "|    reward             | 0.009076538 |\n",
      "|    std                | 3.74e+03    |\n",
      "|    value_loss         | 0.00019     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 47500        |\n",
      "|    time_elapsed       | 741          |\n",
      "|    total_timesteps    | 237500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | -2.37        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47499        |\n",
      "|    policy_loss        | -0.118       |\n",
      "|    reward             | 0.0011484321 |\n",
      "|    std                | 3.92e+03     |\n",
      "|    value_loss         | 0.000107     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 47600        |\n",
      "|    time_elapsed       | 743          |\n",
      "|    total_timesteps    | 238000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0.276        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47599        |\n",
      "|    policy_loss        | -0.00386     |\n",
      "|    reward             | -0.008449202 |\n",
      "|    std                | 4.09e+03     |\n",
      "|    value_loss         | 4.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 47700        |\n",
      "|    time_elapsed       | 744          |\n",
      "|    total_timesteps    | 238500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47699        |\n",
      "|    policy_loss        | -0.0925      |\n",
      "|    reward             | -0.011360549 |\n",
      "|    std                | 4.24e+03     |\n",
      "|    value_loss         | 0.000141     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 47800         |\n",
      "|    time_elapsed       | 746           |\n",
      "|    total_timesteps    | 239000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47799         |\n",
      "|    policy_loss        | 0.274         |\n",
      "|    reward             | -0.0030951856 |\n",
      "|    std                | 4.37e+03      |\n",
      "|    value_loss         | 0.000241      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 47900         |\n",
      "|    time_elapsed       | 748           |\n",
      "|    total_timesteps    | 239500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47899         |\n",
      "|    policy_loss        | -0.286        |\n",
      "|    reward             | -0.0021091257 |\n",
      "|    std                | 4.5e+03       |\n",
      "|    value_loss         | 0.00033       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 48000         |\n",
      "|    time_elapsed       | 750           |\n",
      "|    total_timesteps    | 240000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47999         |\n",
      "|    policy_loss        | -0.157        |\n",
      "|    reward             | 0.00088261475 |\n",
      "|    std                | 4.62e+03      |\n",
      "|    value_loss         | 0.000201      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 48100        |\n",
      "|    time_elapsed       | 752          |\n",
      "|    total_timesteps    | 240500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | -0.0676      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48099        |\n",
      "|    policy_loss        | -0.182       |\n",
      "|    reward             | 0.0016919771 |\n",
      "|    std                | 4.83e+03     |\n",
      "|    value_loss         | 0.000371     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 48200       |\n",
      "|    time_elapsed       | 754         |\n",
      "|    total_timesteps    | 241000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48199       |\n",
      "|    policy_loss        | -0.114      |\n",
      "|    reward             | 0.007174511 |\n",
      "|    std                | 5.08e+03    |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 48300        |\n",
      "|    time_elapsed       | 756          |\n",
      "|    total_timesteps    | 241500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48299        |\n",
      "|    policy_loss        | 1.78         |\n",
      "|    reward             | -0.043340728 |\n",
      "|    std                | 5.2e+03      |\n",
      "|    value_loss         | 0.011        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 319            |\n",
      "|    iterations         | 48400          |\n",
      "|    time_elapsed       | 758            |\n",
      "|    total_timesteps    | 242000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 48399          |\n",
      "|    policy_loss        | 0.147          |\n",
      "|    reward             | -4.6846144e-05 |\n",
      "|    std                | 5.33e+03       |\n",
      "|    value_loss         | 0.00084        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 760         |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | 0.0005      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48499       |\n",
      "|    policy_loss        | -0.838      |\n",
      "|    reward             | -0.05630201 |\n",
      "|    std                | 5.42e+03    |\n",
      "|    value_loss         | 0.00205     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 48600        |\n",
      "|    time_elapsed       | 762          |\n",
      "|    total_timesteps    | 243000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | -0.00386     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48599        |\n",
      "|    policy_loss        | 2.64         |\n",
      "|    reward             | 0.0026596237 |\n",
      "|    std                | 5.48e+03     |\n",
      "|    value_loss         | 0.021        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 48700      |\n",
      "|    time_elapsed       | 763        |\n",
      "|    total_timesteps    | 243500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 48699      |\n",
      "|    policy_loss        | -1.84      |\n",
      "|    reward             | 0.07035441 |\n",
      "|    std                | 5.51e+03   |\n",
      "|    value_loss         | 0.0202     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 48800        |\n",
      "|    time_elapsed       | 765          |\n",
      "|    total_timesteps    | 244000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48799        |\n",
      "|    policy_loss        | -2.46        |\n",
      "|    reward             | -0.018216174 |\n",
      "|    std                | 5.56e+03     |\n",
      "|    value_loss         | 0.0169       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 48900       |\n",
      "|    time_elapsed       | 767         |\n",
      "|    total_timesteps    | 244500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48899       |\n",
      "|    policy_loss        | 1.38        |\n",
      "|    reward             | -0.13510701 |\n",
      "|    std                | 5.64e+03    |\n",
      "|    value_loss         | 0.00691     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 769         |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | -9.88       |\n",
      "|    reward             | -0.18176813 |\n",
      "|    std                | 5.67e+03    |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 49100       |\n",
      "|    time_elapsed       | 770         |\n",
      "|    total_timesteps    | 245500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | -0.278      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49099       |\n",
      "|    policy_loss        | 3.26        |\n",
      "|    reward             | 0.032217477 |\n",
      "|    std                | 5.72e+03    |\n",
      "|    value_loss         | 0.0555      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 49200      |\n",
      "|    time_elapsed       | 772        |\n",
      "|    total_timesteps    | 246000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | -0.164     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49199      |\n",
      "|    policy_loss        | 19.3       |\n",
      "|    reward             | 0.07152932 |\n",
      "|    std                | 5.78e+03   |\n",
      "|    value_loss         | 0.848      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 49300      |\n",
      "|    time_elapsed       | 773        |\n",
      "|    total_timesteps    | 246500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49299      |\n",
      "|    policy_loss        | 0.839      |\n",
      "|    reward             | 0.06148659 |\n",
      "|    std                | 5.8e+03    |\n",
      "|    value_loss         | 0.0735     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 49400       |\n",
      "|    time_elapsed       | 775         |\n",
      "|    total_timesteps    | 247000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49399       |\n",
      "|    policy_loss        | 0.411       |\n",
      "|    reward             | -0.03325124 |\n",
      "|    std                | 5.84e+03    |\n",
      "|    value_loss         | 0.00293     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 49500        |\n",
      "|    time_elapsed       | 777          |\n",
      "|    total_timesteps    | 247500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49499        |\n",
      "|    policy_loss        | -0.578       |\n",
      "|    reward             | -0.011340613 |\n",
      "|    std                | 5.92e+03     |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 49600        |\n",
      "|    time_elapsed       | 778          |\n",
      "|    total_timesteps    | 248000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | -0.0355      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | 0.476        |\n",
      "|    reward             | -0.012625931 |\n",
      "|    std                | 6e+03        |\n",
      "|    value_loss         | 0.000633     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 49700       |\n",
      "|    time_elapsed       | 780         |\n",
      "|    total_timesteps    | 248500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | 0.195       |\n",
      "|    reward             | 0.034563232 |\n",
      "|    std                | 6.1e+03     |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 49800        |\n",
      "|    time_elapsed       | 781          |\n",
      "|    total_timesteps    | 249000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49799        |\n",
      "|    policy_loss        | -1.3         |\n",
      "|    reward             | 0.0064305877 |\n",
      "|    std                | 6.2e+03      |\n",
      "|    value_loss         | 0.00658      |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -40654.39\n",
      "total_reward: -50654.39\n",
      "total_cost: 92.84\n",
      "total_trades: 5540\n",
      "Sharpe: 0.260\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 49900      |\n",
      "|    time_elapsed       | 783        |\n",
      "|    total_timesteps    | 249500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49899      |\n",
      "|    policy_loss        | 0.384      |\n",
      "|    reward             | 0.02836844 |\n",
      "|    std                | 6.29e+03   |\n",
      "|    value_loss         | 0.000443   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 50000       |\n",
      "|    time_elapsed       | 784         |\n",
      "|    total_timesteps    | 250000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49999       |\n",
      "|    policy_loss        | 0.469       |\n",
      "|    reward             | 0.020800585 |\n",
      "|    std                | 6.33e+03    |\n",
      "|    value_loss         | 0.000758    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 50100         |\n",
      "|    time_elapsed       | 786           |\n",
      "|    total_timesteps    | 250500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50099         |\n",
      "|    policy_loss        | -0.349        |\n",
      "|    reward             | -0.0018564232 |\n",
      "|    std                | 6.43e+03      |\n",
      "|    value_loss         | 0.000696      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 50200        |\n",
      "|    time_elapsed       | 787          |\n",
      "|    total_timesteps    | 251000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50199        |\n",
      "|    policy_loss        | 0.115        |\n",
      "|    reward             | -0.016057853 |\n",
      "|    std                | 6.46e+03     |\n",
      "|    value_loss         | 0.000257     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 50300        |\n",
      "|    time_elapsed       | 789          |\n",
      "|    total_timesteps    | 251500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50299        |\n",
      "|    policy_loss        | 1.41         |\n",
      "|    reward             | 0.0032410782 |\n",
      "|    std                | 6.53e+03     |\n",
      "|    value_loss         | 0.00549      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 50400      |\n",
      "|    time_elapsed       | 790        |\n",
      "|    total_timesteps    | 252000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.4      |\n",
      "|    explained_variance | 0.113      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50399      |\n",
      "|    policy_loss        | -1.12      |\n",
      "|    reward             | 0.03383573 |\n",
      "|    std                | 6.66e+03   |\n",
      "|    value_loss         | 0.00753    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 50500      |\n",
      "|    time_elapsed       | 791        |\n",
      "|    total_timesteps    | 252500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50499      |\n",
      "|    policy_loss        | 4.27       |\n",
      "|    reward             | 0.16626313 |\n",
      "|    std                | 6.72e+03   |\n",
      "|    value_loss         | 0.0595     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 50600       |\n",
      "|    time_elapsed       | 793         |\n",
      "|    total_timesteps    | 253000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50599       |\n",
      "|    policy_loss        | 0.163       |\n",
      "|    reward             | -0.05007574 |\n",
      "|    std                | 6.81e+03    |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 50700        |\n",
      "|    time_elapsed       | 794          |\n",
      "|    total_timesteps    | 253500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | -5.16        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50699        |\n",
      "|    policy_loss        | 0.261        |\n",
      "|    reward             | -0.026343735 |\n",
      "|    std                | 6.93e+03     |\n",
      "|    value_loss         | 0.000363     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 50800         |\n",
      "|    time_elapsed       | 795           |\n",
      "|    total_timesteps    | 254000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50799         |\n",
      "|    policy_loss        | -0.78         |\n",
      "|    reward             | -0.0068613803 |\n",
      "|    std                | 7.09e+03      |\n",
      "|    value_loss         | 0.00186       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 50900        |\n",
      "|    time_elapsed       | 797          |\n",
      "|    total_timesteps    | 254500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50899        |\n",
      "|    policy_loss        | 1.56         |\n",
      "|    reward             | -0.025030809 |\n",
      "|    std                | 7.12e+03     |\n",
      "|    value_loss         | 0.00787      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 51000        |\n",
      "|    time_elapsed       | 798          |\n",
      "|    total_timesteps    | 255000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50999        |\n",
      "|    policy_loss        | 1.01         |\n",
      "|    reward             | -0.015876466 |\n",
      "|    std                | 7.22e+03     |\n",
      "|    value_loss         | 0.00515      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 51100       |\n",
      "|    time_elapsed       | 800         |\n",
      "|    total_timesteps    | 255500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51099       |\n",
      "|    policy_loss        | 1.73        |\n",
      "|    reward             | 0.032923587 |\n",
      "|    std                | 7.39e+03    |\n",
      "|    value_loss         | 0.00782     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 51200        |\n",
      "|    time_elapsed       | 801          |\n",
      "|    total_timesteps    | 256000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51199        |\n",
      "|    policy_loss        | 0.428        |\n",
      "|    reward             | -0.063046135 |\n",
      "|    std                | 7.51e+03     |\n",
      "|    value_loss         | 0.000703     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 51300       |\n",
      "|    time_elapsed       | 803         |\n",
      "|    total_timesteps    | 256500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | -3.56       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51299       |\n",
      "|    policy_loss        | 8.27        |\n",
      "|    reward             | -0.16065256 |\n",
      "|    std                | 7.62e+03    |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 51400       |\n",
      "|    time_elapsed       | 804         |\n",
      "|    total_timesteps    | 257000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51399       |\n",
      "|    policy_loss        | 0.644       |\n",
      "|    reward             | 0.016783638 |\n",
      "|    std                | 7.6e+03     |\n",
      "|    value_loss         | 0.0165      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 806         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.183       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | -9.45       |\n",
      "|    reward             | -0.20223913 |\n",
      "|    std                | 7.57e+03    |\n",
      "|    value_loss         | 0.381       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 51600      |\n",
      "|    time_elapsed       | 807        |\n",
      "|    total_timesteps    | 258000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51599      |\n",
      "|    policy_loss        | -0.671     |\n",
      "|    reward             | 0.03671876 |\n",
      "|    std                | 7.59e+03   |\n",
      "|    value_loss         | 0.00636    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 51700       |\n",
      "|    time_elapsed       | 809         |\n",
      "|    total_timesteps    | 258500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51699       |\n",
      "|    policy_loss        | 0.547       |\n",
      "|    reward             | 0.005413744 |\n",
      "|    std                | 7.68e+03    |\n",
      "|    value_loss         | 0.00105     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 51800       |\n",
      "|    time_elapsed       | 810         |\n",
      "|    total_timesteps    | 259000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | -0.256      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51799       |\n",
      "|    policy_loss        | -0.129      |\n",
      "|    reward             | 0.013768444 |\n",
      "|    std                | 7.74e+03    |\n",
      "|    value_loss         | 0.000176    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 51900        |\n",
      "|    time_elapsed       | 812          |\n",
      "|    total_timesteps    | 259500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51899        |\n",
      "|    policy_loss        | -0.494       |\n",
      "|    reward             | -0.012696248 |\n",
      "|    std                | 7.87e+03     |\n",
      "|    value_loss         | 0.000664     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 52000       |\n",
      "|    time_elapsed       | 813         |\n",
      "|    total_timesteps    | 260000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 0.0398      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51999       |\n",
      "|    policy_loss        | 0.886       |\n",
      "|    reward             | 0.028770853 |\n",
      "|    std                | 7.86e+03    |\n",
      "|    value_loss         | 0.00366     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 52100       |\n",
      "|    time_elapsed       | 815         |\n",
      "|    total_timesteps    | 260500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52099       |\n",
      "|    policy_loss        | 0.246       |\n",
      "|    reward             | -0.19341986 |\n",
      "|    std                | 7.99e+03    |\n",
      "|    value_loss         | 0.00268     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 52200        |\n",
      "|    time_elapsed       | 816          |\n",
      "|    total_timesteps    | 261000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52199        |\n",
      "|    policy_loss        | -0.257       |\n",
      "|    reward             | -0.024284521 |\n",
      "|    std                | 8.11e+03     |\n",
      "|    value_loss         | 0.0201       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 52300       |\n",
      "|    time_elapsed       | 818         |\n",
      "|    total_timesteps    | 261500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52299       |\n",
      "|    policy_loss        | -4.22       |\n",
      "|    reward             | -0.15210761 |\n",
      "|    std                | 8.2e+03     |\n",
      "|    value_loss         | 0.0484      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 52400      |\n",
      "|    time_elapsed       | 819        |\n",
      "|    total_timesteps    | 262000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | -0.00297   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52399      |\n",
      "|    policy_loss        | 1.68       |\n",
      "|    reward             | 0.05548316 |\n",
      "|    std                | 8.32e+03   |\n",
      "|    value_loss         | 0.0129     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 52500      |\n",
      "|    time_elapsed       | 821        |\n",
      "|    total_timesteps    | 262500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | 0.18       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52499      |\n",
      "|    policy_loss        | -2.93      |\n",
      "|    reward             | 0.32458073 |\n",
      "|    std                | 8.46e+03   |\n",
      "|    value_loss         | 0.0498     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 319       |\n",
      "|    iterations         | 52600     |\n",
      "|    time_elapsed       | 822       |\n",
      "|    total_timesteps    | 263000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 52599     |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    reward             | 0.5268913 |\n",
      "|    std                | 8.48e+03  |\n",
      "|    value_loss         | 0.866     |\n",
      "-------------------------------------\n",
      "day: 2770, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -266391.11\n",
      "total_reward: -276391.11\n",
      "total_cost: 107.56\n",
      "total_trades: 5540\n",
      "Sharpe: -0.193\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 52700        |\n",
      "|    time_elapsed       | 823          |\n",
      "|    total_timesteps    | 263500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52699        |\n",
      "|    policy_loss        | 0.00458      |\n",
      "|    reward             | -0.097943455 |\n",
      "|    std                | 8.35e+03     |\n",
      "|    value_loss         | 0.000137     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 52800      |\n",
      "|    time_elapsed       | 825        |\n",
      "|    total_timesteps    | 264000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52799      |\n",
      "|    policy_loss        | -0.0912    |\n",
      "|    reward             | 0.03880863 |\n",
      "|    std                | 8.45e+03   |\n",
      "|    value_loss         | 0.00027    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 826         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | -3.74       |\n",
      "|    reward             | -0.17317732 |\n",
      "|    std                | 8.54e+03    |\n",
      "|    value_loss         | 0.0462      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 53000       |\n",
      "|    time_elapsed       | 828         |\n",
      "|    total_timesteps    | 265000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52999       |\n",
      "|    policy_loss        | -1.58       |\n",
      "|    reward             | -0.06558635 |\n",
      "|    std                | 8.45e+03    |\n",
      "|    value_loss         | 0.0167      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 53100      |\n",
      "|    time_elapsed       | 829        |\n",
      "|    total_timesteps    | 265500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | 0.0464     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53099      |\n",
      "|    policy_loss        | 0.693      |\n",
      "|    reward             | -0.2545769 |\n",
      "|    std                | 8.46e+03   |\n",
      "|    value_loss         | 0.0527     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 53200     |\n",
      "|    time_elapsed       | 831       |\n",
      "|    total_timesteps    | 266000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 53199     |\n",
      "|    policy_loss        | 22.3      |\n",
      "|    reward             | 0.1303071 |\n",
      "|    std                | 8.5e+03   |\n",
      "|    value_loss         | 1.86      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 53300       |\n",
      "|    time_elapsed       | 832         |\n",
      "|    total_timesteps    | 266500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53299       |\n",
      "|    policy_loss        | -0.0707     |\n",
      "|    reward             | 0.032885414 |\n",
      "|    std                | 8.6e+03     |\n",
      "|    value_loss         | 0.000709    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 53400        |\n",
      "|    time_elapsed       | 834          |\n",
      "|    total_timesteps    | 267000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53399        |\n",
      "|    policy_loss        | 0.354        |\n",
      "|    reward             | -0.010423576 |\n",
      "|    std                | 8.71e+03     |\n",
      "|    value_loss         | 0.000934     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 53500        |\n",
      "|    time_elapsed       | 835          |\n",
      "|    total_timesteps    | 267500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 2.19e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53499        |\n",
      "|    policy_loss        | -1.66        |\n",
      "|    reward             | -0.027448673 |\n",
      "|    std                | 8.81e+03     |\n",
      "|    value_loss         | 0.00794      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 53600      |\n",
      "|    time_elapsed       | 837        |\n",
      "|    total_timesteps    | 268000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21        |\n",
      "|    explained_variance | -0.0494    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53599      |\n",
      "|    policy_loss        | -0.1       |\n",
      "|    reward             | 0.03478499 |\n",
      "|    std                | 9e+03      |\n",
      "|    value_loss         | 0.00453    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 53700       |\n",
      "|    time_elapsed       | 838         |\n",
      "|    total_timesteps    | 268500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.1       |\n",
      "|    explained_variance | 0.216       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53699       |\n",
      "|    policy_loss        | -1.45       |\n",
      "|    reward             | 0.008876469 |\n",
      "|    std                | 9.13e+03    |\n",
      "|    value_loss         | 0.00903     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 53800        |\n",
      "|    time_elapsed       | 840          |\n",
      "|    total_timesteps    | 269000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53799        |\n",
      "|    policy_loss        | -1.92        |\n",
      "|    reward             | -0.047547165 |\n",
      "|    std                | 9.17e+03     |\n",
      "|    value_loss         | 0.00883      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 53900        |\n",
      "|    time_elapsed       | 842          |\n",
      "|    total_timesteps    | 269500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53899        |\n",
      "|    policy_loss        | 0.784        |\n",
      "|    reward             | -0.052824445 |\n",
      "|    std                | 9.35e+03     |\n",
      "|    value_loss         | 0.00154      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 54000       |\n",
      "|    time_elapsed       | 843         |\n",
      "|    total_timesteps    | 270000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53999       |\n",
      "|    policy_loss        | -1.27       |\n",
      "|    reward             | 0.103965834 |\n",
      "|    std                | 9.57e+03    |\n",
      "|    value_loss         | 0.00648     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 54100       |\n",
      "|    time_elapsed       | 845         |\n",
      "|    total_timesteps    | 270500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0.394       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54099       |\n",
      "|    policy_loss        | -0.88       |\n",
      "|    reward             | -0.25163782 |\n",
      "|    std                | 9.55e+03    |\n",
      "|    value_loss         | 0.00639     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 54200      |\n",
      "|    time_elapsed       | 846        |\n",
      "|    total_timesteps    | 271000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54199      |\n",
      "|    policy_loss        | -7.96      |\n",
      "|    reward             | 0.23881619 |\n",
      "|    std                | 9.55e+03   |\n",
      "|    value_loss         | 0.297      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 54300        |\n",
      "|    time_elapsed       | 848          |\n",
      "|    total_timesteps    | 271500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54299        |\n",
      "|    policy_loss        | 9.13         |\n",
      "|    reward             | -0.017135693 |\n",
      "|    std                | 9.54e+03     |\n",
      "|    value_loss         | 0.216        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 54400       |\n",
      "|    time_elapsed       | 849         |\n",
      "|    total_timesteps    | 272000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54399       |\n",
      "|    policy_loss        | -0.54       |\n",
      "|    reward             | 0.005487039 |\n",
      "|    std                | 9.68e+03    |\n",
      "|    value_loss         | 0.000841    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 54500        |\n",
      "|    time_elapsed       | 851          |\n",
      "|    total_timesteps    | 272500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54499        |\n",
      "|    policy_loss        | -0.423       |\n",
      "|    reward             | 0.0005760376 |\n",
      "|    std                | 9.82e+03     |\n",
      "|    value_loss         | 0.00128      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 54600         |\n",
      "|    time_elapsed       | 852           |\n",
      "|    total_timesteps    | 273000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54599         |\n",
      "|    policy_loss        | 0.207         |\n",
      "|    reward             | -0.0017785501 |\n",
      "|    std                | 9.98e+03      |\n",
      "|    value_loss         | 0.000191      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 54700       |\n",
      "|    time_elapsed       | 854         |\n",
      "|    total_timesteps    | 273500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | -6.6        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54699       |\n",
      "|    policy_loss        | 0.472       |\n",
      "|    reward             | -0.01555568 |\n",
      "|    std                | 1.02e+04    |\n",
      "|    value_loss         | 0.00138     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 54800       |\n",
      "|    time_elapsed       | 856         |\n",
      "|    total_timesteps    | 274000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54799       |\n",
      "|    policy_loss        | 0.0209      |\n",
      "|    reward             | -0.01602839 |\n",
      "|    std                | 1.05e+04    |\n",
      "|    value_loss         | 6.47e-05    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 319       |\n",
      "|    iterations         | 54900     |\n",
      "|    time_elapsed       | 857       |\n",
      "|    total_timesteps    | 274500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 54899     |\n",
      "|    policy_loss        | -1.47     |\n",
      "|    reward             | 0.1035233 |\n",
      "|    std                | 1.08e+04  |\n",
      "|    value_loss         | 0.00524   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 55000        |\n",
      "|    time_elapsed       | 859          |\n",
      "|    total_timesteps    | 275000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54999        |\n",
      "|    policy_loss        | -0.185       |\n",
      "|    reward             | -0.026225429 |\n",
      "|    std                | 1.08e+04     |\n",
      "|    value_loss         | 0.0005       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 55100        |\n",
      "|    time_elapsed       | 860          |\n",
      "|    total_timesteps    | 275500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.4        |\n",
      "|    explained_variance | -0.00479     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55099        |\n",
      "|    policy_loss        | -0.411       |\n",
      "|    reward             | -0.022328861 |\n",
      "|    std                | 1.1e+04      |\n",
      "|    value_loss         | 0.000747     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 55200       |\n",
      "|    time_elapsed       | 862         |\n",
      "|    total_timesteps    | 276000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0.0338      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55199       |\n",
      "|    policy_loss        | 2.21        |\n",
      "|    reward             | 0.017168535 |\n",
      "|    std                | 1.12e+04    |\n",
      "|    value_loss         | 0.0122      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 55300        |\n",
      "|    time_elapsed       | 863          |\n",
      "|    total_timesteps    | 276500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | 0.000353     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55299        |\n",
      "|    policy_loss        | -2           |\n",
      "|    reward             | -0.021674708 |\n",
      "|    std                | 1.13e+04     |\n",
      "|    value_loss         | 0.0145       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 55400       |\n",
      "|    time_elapsed       | 865         |\n",
      "|    total_timesteps    | 277000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55399       |\n",
      "|    policy_loss        | 1.72        |\n",
      "|    reward             | 0.108513124 |\n",
      "|    std                | 1.13e+04    |\n",
      "|    value_loss         | 0.0289      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -120413.89\n",
      "total_reward: -130413.89\n",
      "total_cost: 104.46\n",
      "total_trades: 5540\n",
      "Sharpe: -0.540\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 55500      |\n",
      "|    time_elapsed       | 867        |\n",
      "|    total_timesteps    | 277500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55499      |\n",
      "|    policy_loss        | -1.63      |\n",
      "|    reward             | 0.06535859 |\n",
      "|    std                | 1.14e+04   |\n",
      "|    value_loss         | 0.00555    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 55600        |\n",
      "|    time_elapsed       | 868          |\n",
      "|    total_timesteps    | 278000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55599        |\n",
      "|    policy_loss        | -0.329       |\n",
      "|    reward             | 0.0032504143 |\n",
      "|    std                | 1.15e+04     |\n",
      "|    value_loss         | 0.000325     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 55700        |\n",
      "|    time_elapsed       | 870          |\n",
      "|    total_timesteps    | 278500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55699        |\n",
      "|    policy_loss        | -0.318       |\n",
      "|    reward             | -0.014947644 |\n",
      "|    std                | 1.18e+04     |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 55800       |\n",
      "|    time_elapsed       | 871         |\n",
      "|    total_timesteps    | 279000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55799       |\n",
      "|    policy_loss        | -0.267      |\n",
      "|    reward             | 0.009524004 |\n",
      "|    std                | 1.22e+04    |\n",
      "|    value_loss         | 0.000162    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 55900         |\n",
      "|    time_elapsed       | 873           |\n",
      "|    total_timesteps    | 279500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.7         |\n",
      "|    explained_variance | -0.2          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55899         |\n",
      "|    policy_loss        | -0.1          |\n",
      "|    reward             | -0.0005517242 |\n",
      "|    std                | 1.25e+04      |\n",
      "|    value_loss         | 0.000128      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 56000        |\n",
      "|    time_elapsed       | 875          |\n",
      "|    total_timesteps    | 280000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55999        |\n",
      "|    policy_loss        | -1.48        |\n",
      "|    reward             | -0.014129808 |\n",
      "|    std                | 1.29e+04     |\n",
      "|    value_loss         | 0.00563      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 56100       |\n",
      "|    time_elapsed       | 876         |\n",
      "|    total_timesteps    | 280500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56099       |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    reward             | -0.06861741 |\n",
      "|    std                | 1.31e+04    |\n",
      "|    value_loss         | 0.0045      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 56200       |\n",
      "|    time_elapsed       | 878         |\n",
      "|    total_timesteps    | 281000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56199       |\n",
      "|    policy_loss        | -0.813      |\n",
      "|    reward             | 0.081036545 |\n",
      "|    std                | 1.34e+04    |\n",
      "|    value_loss         | 0.002       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 56300      |\n",
      "|    time_elapsed       | 880        |\n",
      "|    total_timesteps    | 281500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | 0.193      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56299      |\n",
      "|    policy_loss        | 1.38       |\n",
      "|    reward             | 0.04375404 |\n",
      "|    std                | 1.36e+04   |\n",
      "|    value_loss         | 0.0106     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 56400       |\n",
      "|    time_elapsed       | 882         |\n",
      "|    total_timesteps    | 282000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56399       |\n",
      "|    policy_loss        | -6.14       |\n",
      "|    reward             | -0.01511271 |\n",
      "|    std                | 1.37e+04    |\n",
      "|    value_loss         | 0.0834      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 56500      |\n",
      "|    time_elapsed       | 884        |\n",
      "|    total_timesteps    | 282500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56499      |\n",
      "|    policy_loss        | -14.8      |\n",
      "|    reward             | 0.06262665 |\n",
      "|    std                | 1.4e+04    |\n",
      "|    value_loss         | 0.462      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 56600         |\n",
      "|    time_elapsed       | 886           |\n",
      "|    total_timesteps    | 283000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56599         |\n",
      "|    policy_loss        | -5.41         |\n",
      "|    reward             | -0.0021731746 |\n",
      "|    std                | 1.4e+04       |\n",
      "|    value_loss         | 0.0768        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 56700       |\n",
      "|    time_elapsed       | 888         |\n",
      "|    total_timesteps    | 283500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56699       |\n",
      "|    policy_loss        | -0.0099     |\n",
      "|    reward             | -0.10811947 |\n",
      "|    std                | 1.39e+04    |\n",
      "|    value_loss         | 0.000801    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 56800      |\n",
      "|    time_elapsed       | 890        |\n",
      "|    total_timesteps    | 284000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | -0.0178    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56799      |\n",
      "|    policy_loss        | -0.273     |\n",
      "|    reward             | 0.08433745 |\n",
      "|    std                | 1.41e+04   |\n",
      "|    value_loss         | 0.00946    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 319       |\n",
      "|    iterations         | 56900     |\n",
      "|    time_elapsed       | 891       |\n",
      "|    total_timesteps    | 284500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 56899     |\n",
      "|    policy_loss        | 7.84      |\n",
      "|    reward             | 0.3021734 |\n",
      "|    std                | 1.41e+04  |\n",
      "|    value_loss         | 0.134     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 57000      |\n",
      "|    time_elapsed       | 892        |\n",
      "|    total_timesteps    | 285000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | 0.185      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56999      |\n",
      "|    policy_loss        | 7.76       |\n",
      "|    reward             | 0.60627097 |\n",
      "|    std                | 1.42e+04   |\n",
      "|    value_loss         | 0.304      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 57100       |\n",
      "|    time_elapsed       | 894         |\n",
      "|    total_timesteps    | 285500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57099       |\n",
      "|    policy_loss        | 2.24        |\n",
      "|    reward             | -0.02580127 |\n",
      "|    std                | 1.42e+04    |\n",
      "|    value_loss         | 0.0114      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 57200         |\n",
      "|    time_elapsed       | 895           |\n",
      "|    total_timesteps    | 286000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 57199         |\n",
      "|    policy_loss        | 0.745         |\n",
      "|    reward             | -0.0046839546 |\n",
      "|    std                | 1.43e+04      |\n",
      "|    value_loss         | 0.00315       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 57300        |\n",
      "|    time_elapsed       | 897          |\n",
      "|    total_timesteps    | 286500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57299        |\n",
      "|    policy_loss        | -0.278       |\n",
      "|    reward             | 0.0004398397 |\n",
      "|    std                | 1.44e+04     |\n",
      "|    value_loss         | 0.000528     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 57400       |\n",
      "|    time_elapsed       | 898         |\n",
      "|    total_timesteps    | 287000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | -1.04       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57399       |\n",
      "|    policy_loss        | -0.731      |\n",
      "|    reward             | 0.012559142 |\n",
      "|    std                | 1.46e+04    |\n",
      "|    value_loss         | 0.00178     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 57500        |\n",
      "|    time_elapsed       | 900          |\n",
      "|    total_timesteps    | 287500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -0.00368     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57499        |\n",
      "|    policy_loss        | -1.07        |\n",
      "|    reward             | -0.021270264 |\n",
      "|    std                | 1.48e+04     |\n",
      "|    value_loss         | 0.00289      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 57600      |\n",
      "|    time_elapsed       | 901        |\n",
      "|    total_timesteps    | 288000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57599      |\n",
      "|    policy_loss        | -1         |\n",
      "|    reward             | 0.02999355 |\n",
      "|    std                | 1.51e+04   |\n",
      "|    value_loss         | 0.00288    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 57700       |\n",
      "|    time_elapsed       | 903         |\n",
      "|    total_timesteps    | 288500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57699       |\n",
      "|    policy_loss        | -1.81       |\n",
      "|    reward             | -0.06901221 |\n",
      "|    std                | 1.56e+04    |\n",
      "|    value_loss         | 0.0222      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 57800        |\n",
      "|    time_elapsed       | 904          |\n",
      "|    total_timesteps    | 289000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57799        |\n",
      "|    policy_loss        | 1.28         |\n",
      "|    reward             | -0.002459817 |\n",
      "|    std                | 1.59e+04     |\n",
      "|    value_loss         | 0.00471      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 57900      |\n",
      "|    time_elapsed       | 906        |\n",
      "|    total_timesteps    | 289500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.2      |\n",
      "|    explained_variance | 0.19       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57899      |\n",
      "|    policy_loss        | 1.62       |\n",
      "|    reward             | 0.07247216 |\n",
      "|    std                | 1.6e+04    |\n",
      "|    value_loss         | 0.00737    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 58000       |\n",
      "|    time_elapsed       | 907         |\n",
      "|    total_timesteps    | 290000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57999       |\n",
      "|    policy_loss        | 9.88        |\n",
      "|    reward             | -0.22965027 |\n",
      "|    std                | 1.61e+04    |\n",
      "|    value_loss         | 0.24        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 58100      |\n",
      "|    time_elapsed       | 909        |\n",
      "|    total_timesteps    | 290500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 58099      |\n",
      "|    policy_loss        | -13.2      |\n",
      "|    reward             | 0.74941474 |\n",
      "|    std                | 1.59e+04   |\n",
      "|    value_loss         | 0.495      |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -266649.06\n",
      "total_reward: -276649.06\n",
      "total_cost: 101.71\n",
      "total_trades: 5540\n",
      "Sharpe: -0.272\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 58200       |\n",
      "|    time_elapsed       | 910         |\n",
      "|    total_timesteps    | 291000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58199       |\n",
      "|    policy_loss        | -0.653      |\n",
      "|    reward             | 0.014641213 |\n",
      "|    std                | 1.6e+04     |\n",
      "|    value_loss         | 0.0034      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 58300       |\n",
      "|    time_elapsed       | 911         |\n",
      "|    total_timesteps    | 291500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58299       |\n",
      "|    policy_loss        | -0.772      |\n",
      "|    reward             | 0.068042845 |\n",
      "|    std                | 1.61e+04    |\n",
      "|    value_loss         | 0.00247     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 58400        |\n",
      "|    time_elapsed       | 913          |\n",
      "|    total_timesteps    | 292000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58399        |\n",
      "|    policy_loss        | 0.87         |\n",
      "|    reward             | -0.008904279 |\n",
      "|    std                | 1.64e+04     |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 58500        |\n",
      "|    time_elapsed       | 914          |\n",
      "|    total_timesteps    | 292500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58499        |\n",
      "|    policy_loss        | 0.0306       |\n",
      "|    reward             | -0.020340897 |\n",
      "|    std                | 1.67e+04     |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 58600       |\n",
      "|    time_elapsed       | 916         |\n",
      "|    total_timesteps    | 293000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | -7.15e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58599       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.014779279 |\n",
      "|    std                | 1.68e+04    |\n",
      "|    value_loss         | 0.0028      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 58700       |\n",
      "|    time_elapsed       | 917         |\n",
      "|    total_timesteps    | 293500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58699       |\n",
      "|    policy_loss        | 0.22        |\n",
      "|    reward             | 0.055932734 |\n",
      "|    std                | 1.71e+04    |\n",
      "|    value_loss         | 0.00363     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 58800        |\n",
      "|    time_elapsed       | 918          |\n",
      "|    total_timesteps    | 294000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58799        |\n",
      "|    policy_loss        | -0.172       |\n",
      "|    reward             | 0.0136860795 |\n",
      "|    std                | 1.72e+04     |\n",
      "|    value_loss         | 0.0002       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 58900       |\n",
      "|    time_elapsed       | 920         |\n",
      "|    total_timesteps    | 294500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58899       |\n",
      "|    policy_loss        | -0.137      |\n",
      "|    reward             | 0.007102808 |\n",
      "|    std                | 1.76e+04    |\n",
      "|    value_loss         | 0.000332    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 59000       |\n",
      "|    time_elapsed       | 921         |\n",
      "|    total_timesteps    | 295000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58999       |\n",
      "|    policy_loss        | 0.398       |\n",
      "|    reward             | 0.013058982 |\n",
      "|    std                | 1.81e+04    |\n",
      "|    value_loss         | 0.000352    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 59100         |\n",
      "|    time_elapsed       | 923           |\n",
      "|    total_timesteps    | 295500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.5         |\n",
      "|    explained_variance | -8.12         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59099         |\n",
      "|    policy_loss        | 0.0878        |\n",
      "|    reward             | -0.0011626461 |\n",
      "|    std                | 1.89e+04      |\n",
      "|    value_loss         | 2.76e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 59200       |\n",
      "|    time_elapsed       | 924         |\n",
      "|    total_timesteps    | 296000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 4.17e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59199       |\n",
      "|    policy_loss        | 0.561       |\n",
      "|    reward             | 0.003032254 |\n",
      "|    std                | 1.96e+04    |\n",
      "|    value_loss         | 0.000758    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 59300       |\n",
      "|    time_elapsed       | 926         |\n",
      "|    total_timesteps    | 296500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59299       |\n",
      "|    policy_loss        | -0.545      |\n",
      "|    reward             | 0.009348774 |\n",
      "|    std                | 2.01e+04    |\n",
      "|    value_loss         | 0.00083     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 59400         |\n",
      "|    time_elapsed       | 927           |\n",
      "|    total_timesteps    | 297000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.7         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59399         |\n",
      "|    policy_loss        | 0.813         |\n",
      "|    reward             | -0.0023377426 |\n",
      "|    std                | 2.05e+04      |\n",
      "|    value_loss         | 0.00138       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 59500        |\n",
      "|    time_elapsed       | 929          |\n",
      "|    total_timesteps    | 297500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59499        |\n",
      "|    policy_loss        | -0.234       |\n",
      "|    reward             | 0.0033372368 |\n",
      "|    std                | 2.08e+04     |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 59600        |\n",
      "|    time_elapsed       | 930          |\n",
      "|    total_timesteps    | 298000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59599        |\n",
      "|    policy_loss        | -0.148       |\n",
      "|    reward             | -0.006971154 |\n",
      "|    std                | 2.15e+04     |\n",
      "|    value_loss         | 0.000199     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 59700        |\n",
      "|    time_elapsed       | 932          |\n",
      "|    total_timesteps    | 298500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | 0.591        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59699        |\n",
      "|    policy_loss        | -0.334       |\n",
      "|    reward             | 0.0152452355 |\n",
      "|    std                | 2.25e+04     |\n",
      "|    value_loss         | 0.000212     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 59800      |\n",
      "|    time_elapsed       | 933        |\n",
      "|    total_timesteps    | 299000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | 0.0174     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59799      |\n",
      "|    policy_loss        | 0.026      |\n",
      "|    reward             | 0.06245009 |\n",
      "|    std                | 2.34e+04   |\n",
      "|    value_loss         | 0.000492   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 59900       |\n",
      "|    time_elapsed       | 935         |\n",
      "|    total_timesteps    | 299500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59899       |\n",
      "|    policy_loss        | -0.136      |\n",
      "|    reward             | -0.03837463 |\n",
      "|    std                | 2.42e+04    |\n",
      "|    value_loss         | 0.00489     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 60000        |\n",
      "|    time_elapsed       | 936          |\n",
      "|    total_timesteps    | 300000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59999        |\n",
      "|    policy_loss        | 1.31         |\n",
      "|    reward             | -0.013649702 |\n",
      "|    std                | 2.45e+04     |\n",
      "|    value_loss         | 0.00356      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 60100         |\n",
      "|    time_elapsed       | 937           |\n",
      "|    total_timesteps    | 300500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60099         |\n",
      "|    policy_loss        | -0.832        |\n",
      "|    reward             | -0.0058571477 |\n",
      "|    std                | 2.53e+04      |\n",
      "|    value_loss         | 0.00227       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 60200        |\n",
      "|    time_elapsed       | 939          |\n",
      "|    total_timesteps    | 301000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60199        |\n",
      "|    policy_loss        | 0.101        |\n",
      "|    reward             | -0.010792705 |\n",
      "|    std                | 2.57e+04     |\n",
      "|    value_loss         | 8.06e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 60300        |\n",
      "|    time_elapsed       | 940          |\n",
      "|    total_timesteps    | 301500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60299        |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.019619547 |\n",
      "|    std                | 2.62e+04     |\n",
      "|    value_loss         | 0.0025       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 60400       |\n",
      "|    time_elapsed       | 942         |\n",
      "|    total_timesteps    | 302000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60399       |\n",
      "|    policy_loss        | -1.76       |\n",
      "|    reward             | -0.06918118 |\n",
      "|    std                | 2.65e+04    |\n",
      "|    value_loss         | 0.0188      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 60500        |\n",
      "|    time_elapsed       | 944          |\n",
      "|    total_timesteps    | 302500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60499        |\n",
      "|    policy_loss        | -0.517       |\n",
      "|    reward             | -0.011087858 |\n",
      "|    std                | 2.69e+04     |\n",
      "|    value_loss         | 0.00478      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 60600       |\n",
      "|    time_elapsed       | 945         |\n",
      "|    total_timesteps    | 303000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60599       |\n",
      "|    policy_loss        | -0.736      |\n",
      "|    reward             | -0.01004347 |\n",
      "|    std                | 2.71e+04    |\n",
      "|    value_loss         | 0.002       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 60700         |\n",
      "|    time_elapsed       | 947           |\n",
      "|    total_timesteps    | 303500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.3         |\n",
      "|    explained_variance | -0.778        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60699         |\n",
      "|    policy_loss        | 1.68          |\n",
      "|    reward             | -0.0017070256 |\n",
      "|    std                | 2.77e+04      |\n",
      "|    value_loss         | 0.00669       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 60800       |\n",
      "|    time_elapsed       | 948         |\n",
      "|    total_timesteps    | 304000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60799       |\n",
      "|    policy_loss        | -1.17       |\n",
      "|    reward             | 0.014561591 |\n",
      "|    std                | 2.84e+04    |\n",
      "|    value_loss         | 0.00407     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 60900      |\n",
      "|    time_elapsed       | 949        |\n",
      "|    total_timesteps    | 304500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.4      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60899      |\n",
      "|    policy_loss        | 0.872      |\n",
      "|    reward             | 0.01947453 |\n",
      "|    std                | 2.89e+04   |\n",
      "|    value_loss         | 0.00159    |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -48678.01\n",
      "total_reward: -58678.01\n",
      "total_cost: 66.12\n",
      "total_trades: 5540\n",
      "Sharpe: 0.409\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 61000       |\n",
      "|    time_elapsed       | 951         |\n",
      "|    total_timesteps    | 305000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60999       |\n",
      "|    policy_loss        | -0.059      |\n",
      "|    reward             | 0.024790447 |\n",
      "|    std                | 2.93e+04    |\n",
      "|    value_loss         | 0.000116    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 61100        |\n",
      "|    time_elapsed       | 952          |\n",
      "|    total_timesteps    | 305500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61099        |\n",
      "|    policy_loss        | 0.685        |\n",
      "|    reward             | -0.014637906 |\n",
      "|    std                | 2.95e+04     |\n",
      "|    value_loss         | 0.00255      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 61200        |\n",
      "|    time_elapsed       | 954          |\n",
      "|    total_timesteps    | 306000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61199        |\n",
      "|    policy_loss        | 1.36         |\n",
      "|    reward             | -0.023853963 |\n",
      "|    std                | 3e+04        |\n",
      "|    value_loss         | 0.00425      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 61300        |\n",
      "|    time_elapsed       | 955          |\n",
      "|    total_timesteps    | 306500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0.411        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61299        |\n",
      "|    policy_loss        | -1.21        |\n",
      "|    reward             | -0.030360512 |\n",
      "|    std                | 3.06e+04     |\n",
      "|    value_loss         | 0.00306      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 61400       |\n",
      "|    time_elapsed       | 957         |\n",
      "|    total_timesteps    | 307000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61399       |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | -0.10093995 |\n",
      "|    std                | 3.08e+04    |\n",
      "|    value_loss         | 0.00458     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 61500       |\n",
      "|    time_elapsed       | 958         |\n",
      "|    total_timesteps    | 307500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61499       |\n",
      "|    policy_loss        | -3.88       |\n",
      "|    reward             | -0.10706327 |\n",
      "|    std                | 3.09e+04    |\n",
      "|    value_loss         | 0.0292      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 61600        |\n",
      "|    time_elapsed       | 959          |\n",
      "|    total_timesteps    | 308000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61599        |\n",
      "|    policy_loss        | 0.891        |\n",
      "|    reward             | -0.013785722 |\n",
      "|    std                | 3.15e+04     |\n",
      "|    value_loss         | 0.00157      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 320            |\n",
      "|    iterations         | 61700          |\n",
      "|    time_elapsed       | 961            |\n",
      "|    total_timesteps    | 308500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -23.6          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 61699          |\n",
      "|    policy_loss        | -0.534         |\n",
      "|    reward             | -0.00052507134 |\n",
      "|    std                | 3.2e+04        |\n",
      "|    value_loss         | 0.00062        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 61800        |\n",
      "|    time_elapsed       | 962          |\n",
      "|    total_timesteps    | 309000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61799        |\n",
      "|    policy_loss        | 0.412        |\n",
      "|    reward             | -0.021611834 |\n",
      "|    std                | 3.3e+04      |\n",
      "|    value_loss         | 0.000394     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 61900         |\n",
      "|    time_elapsed       | 964           |\n",
      "|    total_timesteps    | 309500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.7         |\n",
      "|    explained_variance | -0.000637     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61899         |\n",
      "|    policy_loss        | -0.377        |\n",
      "|    reward             | -0.0015904943 |\n",
      "|    std                | 3.4e+04       |\n",
      "|    value_loss         | 0.000287      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 62000         |\n",
      "|    time_elapsed       | 965           |\n",
      "|    total_timesteps    | 310000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61999         |\n",
      "|    policy_loss        | -0.175        |\n",
      "|    reward             | -0.0048600174 |\n",
      "|    std                | 3.53e+04      |\n",
      "|    value_loss         | 5.72e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 62100      |\n",
      "|    time_elapsed       | 967        |\n",
      "|    total_timesteps    | 310500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 62099      |\n",
      "|    policy_loss        | -0.281     |\n",
      "|    reward             | 0.01750441 |\n",
      "|    std                | 3.65e+04   |\n",
      "|    value_loss         | 0.00023    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 62200        |\n",
      "|    time_elapsed       | 968          |\n",
      "|    total_timesteps    | 311000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62199        |\n",
      "|    policy_loss        | -0.478       |\n",
      "|    reward             | 0.0007276545 |\n",
      "|    std                | 3.79e+04     |\n",
      "|    value_loss         | 0.000516     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 62300       |\n",
      "|    time_elapsed       | 970         |\n",
      "|    total_timesteps    | 311500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62299       |\n",
      "|    policy_loss        | 0.605       |\n",
      "|    reward             | 0.014270513 |\n",
      "|    std                | 3.88e+04    |\n",
      "|    value_loss         | 0.00169     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 62400        |\n",
      "|    time_elapsed       | 971          |\n",
      "|    total_timesteps    | 312000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62399        |\n",
      "|    policy_loss        | -0.135       |\n",
      "|    reward             | 0.0020390276 |\n",
      "|    std                | 4e+04        |\n",
      "|    value_loss         | 5.07e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 62500       |\n",
      "|    time_elapsed       | 973         |\n",
      "|    total_timesteps    | 312500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | -0.278      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62499       |\n",
      "|    policy_loss        | 0.179       |\n",
      "|    reward             | 0.012468448 |\n",
      "|    std                | 4.15e+04    |\n",
      "|    value_loss         | 6.86e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 62600        |\n",
      "|    time_elapsed       | 974          |\n",
      "|    total_timesteps    | 313000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62599        |\n",
      "|    policy_loss        | -0.407       |\n",
      "|    reward             | -0.013865593 |\n",
      "|    std                | 4.27e+04     |\n",
      "|    value_loss         | 0.000454     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 62700     |\n",
      "|    time_elapsed       | 976       |\n",
      "|    total_timesteps    | 313500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 62699     |\n",
      "|    policy_loss        | 1.35      |\n",
      "|    reward             | 0.0383987 |\n",
      "|    std                | 4.43e+04  |\n",
      "|    value_loss         | 0.00318   |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 62800         |\n",
      "|    time_elapsed       | 977           |\n",
      "|    total_timesteps    | 314000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62799         |\n",
      "|    policy_loss        | -0.345        |\n",
      "|    reward             | 0.00015568771 |\n",
      "|    std                | 4.51e+04      |\n",
      "|    value_loss         | 0.000207      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 62900        |\n",
      "|    time_elapsed       | 979          |\n",
      "|    total_timesteps    | 314500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62899        |\n",
      "|    policy_loss        | -0.321       |\n",
      "|    reward             | 0.0014296147 |\n",
      "|    std                | 4.63e+04     |\n",
      "|    value_loss         | 0.000415     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 63000         |\n",
      "|    time_elapsed       | 980           |\n",
      "|    total_timesteps    | 315000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.4         |\n",
      "|    explained_variance | 0.000457      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62999         |\n",
      "|    policy_loss        | 0.146         |\n",
      "|    reward             | -0.0024246774 |\n",
      "|    std                | 4.83e+04      |\n",
      "|    value_loss         | 5.96e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 63100        |\n",
      "|    time_elapsed       | 982          |\n",
      "|    total_timesteps    | 315500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.5        |\n",
      "|    explained_variance | 0.0843       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63099        |\n",
      "|    policy_loss        | -0.158       |\n",
      "|    reward             | -0.013354913 |\n",
      "|    std                | 5.01e+04     |\n",
      "|    value_loss         | 8.14e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 63200        |\n",
      "|    time_elapsed       | 984          |\n",
      "|    total_timesteps    | 316000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63199        |\n",
      "|    policy_loss        | 0.435        |\n",
      "|    reward             | -0.049654998 |\n",
      "|    std                | 5.23e+04     |\n",
      "|    value_loss         | 0.000689     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 63300        |\n",
      "|    time_elapsed       | 985          |\n",
      "|    total_timesteps    | 316500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63299        |\n",
      "|    policy_loss        | 0.642        |\n",
      "|    reward             | -0.004105745 |\n",
      "|    std                | 5.36e+04     |\n",
      "|    value_loss         | 0.000912     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 63400        |\n",
      "|    time_elapsed       | 987          |\n",
      "|    total_timesteps    | 317000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63399        |\n",
      "|    policy_loss        | -0.834       |\n",
      "|    reward             | 0.0025842097 |\n",
      "|    std                | 5.49e+04     |\n",
      "|    value_loss         | 0.00118      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 63500         |\n",
      "|    time_elapsed       | 988           |\n",
      "|    total_timesteps    | 317500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63499         |\n",
      "|    policy_loss        | -0.157        |\n",
      "|    reward             | -0.0023714784 |\n",
      "|    std                | 5.64e+04      |\n",
      "|    value_loss         | 6.88e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 63600        |\n",
      "|    time_elapsed       | 989          |\n",
      "|    total_timesteps    | 318000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.8        |\n",
      "|    explained_variance | -0.0119      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63599        |\n",
      "|    policy_loss        | -0.0643      |\n",
      "|    reward             | 0.0035942788 |\n",
      "|    std                | 5.9e+04      |\n",
      "|    value_loss         | 3.51e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 63700       |\n",
      "|    time_elapsed       | 991         |\n",
      "|    total_timesteps    | 318500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63699       |\n",
      "|    policy_loss        | -0.193      |\n",
      "|    reward             | 0.002488449 |\n",
      "|    std                | 6.15e+04    |\n",
      "|    value_loss         | 0.000112    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2770, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13126.95\n",
      "total_reward: -23126.95\n",
      "total_cost: 404.10\n",
      "total_trades: 5540\n",
      "Sharpe: -0.365\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 63800     |\n",
      "|    time_elapsed       | 992       |\n",
      "|    total_timesteps    | 319000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 63799     |\n",
      "|    policy_loss        | -2.1      |\n",
      "|    reward             | 0.0796641 |\n",
      "|    std                | 6.38e+04  |\n",
      "|    value_loss         | 0.00948   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 63900       |\n",
      "|    time_elapsed       | 994         |\n",
      "|    total_timesteps    | 319500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63899       |\n",
      "|    policy_loss        | 1.31        |\n",
      "|    reward             | 0.014670865 |\n",
      "|    std                | 6.52e+04    |\n",
      "|    value_loss         | 0.00414     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 64000      |\n",
      "|    time_elapsed       | 995        |\n",
      "|    total_timesteps    | 320000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25        |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63999      |\n",
      "|    policy_loss        | -3.11      |\n",
      "|    reward             | 0.21539582 |\n",
      "|    std                | 6.56e+04   |\n",
      "|    value_loss         | 0.0274     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 64100       |\n",
      "|    time_elapsed       | 997         |\n",
      "|    total_timesteps    | 320500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64099       |\n",
      "|    policy_loss        | -7.81       |\n",
      "|    reward             | 0.054600555 |\n",
      "|    std                | 6.6e+04     |\n",
      "|    value_loss         | 0.119       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 64200       |\n",
      "|    time_elapsed       | 998         |\n",
      "|    total_timesteps    | 321000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0.00139     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64199       |\n",
      "|    policy_loss        | 10.2        |\n",
      "|    reward             | -0.43386605 |\n",
      "|    std                | 6.69e+04    |\n",
      "|    value_loss         | 0.25        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 64300         |\n",
      "|    time_elapsed       | 1000          |\n",
      "|    total_timesteps    | 321500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64299         |\n",
      "|    policy_loss        | 4.39          |\n",
      "|    reward             | -0.0021292702 |\n",
      "|    std                | 6.75e+04      |\n",
      "|    value_loss         | 0.0426        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 64400       |\n",
      "|    time_elapsed       | 1001        |\n",
      "|    total_timesteps    | 322000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64399       |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | -0.01577149 |\n",
      "|    std                | 6.78e+04    |\n",
      "|    value_loss         | 0.00321     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 64500      |\n",
      "|    time_elapsed       | 1003       |\n",
      "|    total_timesteps    | 322500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64499      |\n",
      "|    policy_loss        | 0.21       |\n",
      "|    reward             | 0.03393447 |\n",
      "|    std                | 6.81e+04   |\n",
      "|    value_loss         | 0.00102    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 64600      |\n",
      "|    time_elapsed       | 1004       |\n",
      "|    total_timesteps    | 323000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64599      |\n",
      "|    policy_loss        | 3.8        |\n",
      "|    reward             | 0.11015697 |\n",
      "|    std                | 6.93e+04   |\n",
      "|    value_loss         | 0.0239     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 64700       |\n",
      "|    time_elapsed       | 1006        |\n",
      "|    total_timesteps    | 323500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64699       |\n",
      "|    policy_loss        | -9.01       |\n",
      "|    reward             | -0.09326347 |\n",
      "|    std                | 6.93e+04    |\n",
      "|    value_loss         | 0.15        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 64800      |\n",
      "|    time_elapsed       | 1007       |\n",
      "|    total_timesteps    | 324000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64799      |\n",
      "|    policy_loss        | -13.3      |\n",
      "|    reward             | 0.11026186 |\n",
      "|    std                | 7e+04      |\n",
      "|    value_loss         | 0.294      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 64900       |\n",
      "|    time_elapsed       | 1009        |\n",
      "|    total_timesteps    | 324500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64899       |\n",
      "|    policy_loss        | 2.55        |\n",
      "|    reward             | 0.011755786 |\n",
      "|    std                | 6.98e+04    |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 65000        |\n",
      "|    time_elapsed       | 1010         |\n",
      "|    total_timesteps    | 325000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64999        |\n",
      "|    policy_loss        | -0.481       |\n",
      "|    reward             | -0.010679711 |\n",
      "|    std                | 7.07e+04     |\n",
      "|    value_loss         | 0.000499     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 65100        |\n",
      "|    time_elapsed       | 1012         |\n",
      "|    total_timesteps    | 325500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65099        |\n",
      "|    policy_loss        | -0.242       |\n",
      "|    reward             | 0.0014479934 |\n",
      "|    std                | 7.18e+04     |\n",
      "|    value_loss         | 9.86e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 65200        |\n",
      "|    time_elapsed       | 1013         |\n",
      "|    total_timesteps    | 326000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65199        |\n",
      "|    policy_loss        | -0.0463      |\n",
      "|    reward             | -0.003591266 |\n",
      "|    std                | 7.34e+04     |\n",
      "|    value_loss         | 9.49e-06     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 65300      |\n",
      "|    time_elapsed       | 1015       |\n",
      "|    total_timesteps    | 326500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65299      |\n",
      "|    policy_loss        | 0.105      |\n",
      "|    reward             | 0.02818262 |\n",
      "|    std                | 7.55e+04   |\n",
      "|    value_loss         | 3.21e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 65400       |\n",
      "|    time_elapsed       | 1016        |\n",
      "|    total_timesteps    | 327000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65399       |\n",
      "|    policy_loss        | 0.425       |\n",
      "|    reward             | 0.031167861 |\n",
      "|    std                | 7.76e+04    |\n",
      "|    value_loss         | 0.000293    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 65500        |\n",
      "|    time_elapsed       | 1017         |\n",
      "|    total_timesteps    | 327500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65499        |\n",
      "|    policy_loss        | 0.698        |\n",
      "|    reward             | -0.008063143 |\n",
      "|    std                | 8e+04        |\n",
      "|    value_loss         | 0.000808     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 65600        |\n",
      "|    time_elapsed       | 1019         |\n",
      "|    total_timesteps    | 328000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65599        |\n",
      "|    policy_loss        | 0.154        |\n",
      "|    reward             | -0.005784225 |\n",
      "|    std                | 8.31e+04     |\n",
      "|    value_loss         | 0.000318     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 65700       |\n",
      "|    time_elapsed       | 1020        |\n",
      "|    total_timesteps    | 328500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65699       |\n",
      "|    policy_loss        | 0.125       |\n",
      "|    reward             | 0.009225351 |\n",
      "|    std                | 8.65e+04    |\n",
      "|    value_loss         | 5.88e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 65800        |\n",
      "|    time_elapsed       | 1022         |\n",
      "|    total_timesteps    | 329000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0.0279       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65799        |\n",
      "|    policy_loss        | 0.353        |\n",
      "|    reward             | -0.010792463 |\n",
      "|    std                | 8.98e+04     |\n",
      "|    value_loss         | 0.000269     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 65900        |\n",
      "|    time_elapsed       | 1023         |\n",
      "|    total_timesteps    | 329500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0.00263      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65899        |\n",
      "|    policy_loss        | 0.532        |\n",
      "|    reward             | -0.025499338 |\n",
      "|    std                | 9.31e+04     |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 66000        |\n",
      "|    time_elapsed       | 1025         |\n",
      "|    total_timesteps    | 330000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65999        |\n",
      "|    policy_loss        | -1.88        |\n",
      "|    reward             | -0.054670587 |\n",
      "|    std                | 9.48e+04     |\n",
      "|    value_loss         | 0.0089       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 66100        |\n",
      "|    time_elapsed       | 1026         |\n",
      "|    total_timesteps    | 330500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66099        |\n",
      "|    policy_loss        | 0.0397       |\n",
      "|    reward             | 0.0079315035 |\n",
      "|    std                | 9.51e+04     |\n",
      "|    value_loss         | 0.0016       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 66200        |\n",
      "|    time_elapsed       | 1028         |\n",
      "|    total_timesteps    | 331000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66199        |\n",
      "|    policy_loss        | -4.73        |\n",
      "|    reward             | -0.056245416 |\n",
      "|    std                | 9.58e+04     |\n",
      "|    value_loss         | 0.0364       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 1030        |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66299       |\n",
      "|    policy_loss        | -2.79       |\n",
      "|    reward             | 0.124564946 |\n",
      "|    std                | 9.68e+04    |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 66400       |\n",
      "|    time_elapsed       | 1031        |\n",
      "|    total_timesteps    | 332000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66399       |\n",
      "|    policy_loss        | 4.48        |\n",
      "|    reward             | -0.07679831 |\n",
      "|    std                | 9.82e+04    |\n",
      "|    value_loss         | 0.0376      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 321      |\n",
      "|    iterations         | 66500    |\n",
      "|    time_elapsed       | 1033     |\n",
      "|    total_timesteps    | 332500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -25.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 66499    |\n",
      "|    policy_loss        | -23.5    |\n",
      "|    reward             | 1.482121 |\n",
      "|    std                | 9.83e+04 |\n",
      "|    value_loss         | 0.982    |\n",
      "------------------------------------\n",
      "day: 2770, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -266861.06\n",
      "total_reward: -276861.06\n",
      "total_cost: 107.20\n",
      "total_trades: 5540\n",
      "Sharpe: -0.103\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 66600        |\n",
      "|    time_elapsed       | 1034         |\n",
      "|    total_timesteps    | 333000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66599        |\n",
      "|    policy_loss        | 0.142        |\n",
      "|    reward             | -0.028409671 |\n",
      "|    std                | 9.92e+04     |\n",
      "|    value_loss         | 0.000264     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 66700       |\n",
      "|    time_elapsed       | 1036        |\n",
      "|    total_timesteps    | 333500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66699       |\n",
      "|    policy_loss        | 0.794       |\n",
      "|    reward             | -0.02516828 |\n",
      "|    std                | 9.99e+04    |\n",
      "|    value_loss         | 0.00157     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 66800      |\n",
      "|    time_elapsed       | 1037       |\n",
      "|    total_timesteps    | 334000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.9      |\n",
      "|    explained_variance | 0.802      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66799      |\n",
      "|    policy_loss        | 0.768      |\n",
      "|    reward             | 0.04340818 |\n",
      "|    std                | 1.01e+05   |\n",
      "|    value_loss         | 0.00203    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 66900       |\n",
      "|    time_elapsed       | 1039        |\n",
      "|    total_timesteps    | 334500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | -0.245      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66899       |\n",
      "|    policy_loss        | 3.88        |\n",
      "|    reward             | -0.10802497 |\n",
      "|    std                | 1.01e+05    |\n",
      "|    value_loss         | 0.0273      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 67000      |\n",
      "|    time_elapsed       | 1040       |\n",
      "|    total_timesteps    | 335000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66999      |\n",
      "|    policy_loss        | 5.07       |\n",
      "|    reward             | 0.06862859 |\n",
      "|    std                | 1.02e+05   |\n",
      "|    value_loss         | 0.0448     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 67100      |\n",
      "|    time_elapsed       | 1041       |\n",
      "|    total_timesteps    | 335500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67099      |\n",
      "|    policy_loss        | 1.11       |\n",
      "|    reward             | 0.07712974 |\n",
      "|    std                | 1.03e+05   |\n",
      "|    value_loss         | 0.00301    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67200        |\n",
      "|    time_elapsed       | 1042         |\n",
      "|    total_timesteps    | 336000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67199        |\n",
      "|    policy_loss        | -0.571       |\n",
      "|    reward             | -0.014998035 |\n",
      "|    std                | 1.03e+05     |\n",
      "|    value_loss         | 0.000642     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67300        |\n",
      "|    time_elapsed       | 1044         |\n",
      "|    total_timesteps    | 336500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67299        |\n",
      "|    policy_loss        | -0.0875      |\n",
      "|    reward             | -0.012476967 |\n",
      "|    std                | 1.05e+05     |\n",
      "|    value_loss         | 0.00448      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67400        |\n",
      "|    time_elapsed       | 1045         |\n",
      "|    total_timesteps    | 337000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67399        |\n",
      "|    policy_loss        | -0.00153     |\n",
      "|    reward             | -0.026632398 |\n",
      "|    std                | 1.08e+05     |\n",
      "|    value_loss         | 0.000909     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67500        |\n",
      "|    time_elapsed       | 1046         |\n",
      "|    total_timesteps    | 337500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67499        |\n",
      "|    policy_loss        | 10.4         |\n",
      "|    reward             | -0.061117433 |\n",
      "|    std                | 1.08e+05     |\n",
      "|    value_loss         | 0.157        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 67600       |\n",
      "|    time_elapsed       | 1048        |\n",
      "|    total_timesteps    | 338000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67599       |\n",
      "|    policy_loss        | 0.422       |\n",
      "|    reward             | -0.06297059 |\n",
      "|    std                | 1.07e+05    |\n",
      "|    value_loss         | 0.00597     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67700        |\n",
      "|    time_elapsed       | 1050         |\n",
      "|    total_timesteps    | 338500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67699        |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | -0.031903863 |\n",
      "|    std                | 1.07e+05     |\n",
      "|    value_loss         | 0.0055       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 67800       |\n",
      "|    time_elapsed       | 1051        |\n",
      "|    total_timesteps    | 339000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67799       |\n",
      "|    policy_loss        | 0.383       |\n",
      "|    reward             | 0.007329909 |\n",
      "|    std                | 1.07e+05    |\n",
      "|    value_loss         | 0.000308    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67900        |\n",
      "|    time_elapsed       | 1053         |\n",
      "|    total_timesteps    | 339500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67899        |\n",
      "|    policy_loss        | -0.0125      |\n",
      "|    reward             | -0.013971536 |\n",
      "|    std                | 1.09e+05     |\n",
      "|    value_loss         | 0.0004       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 68000       |\n",
      "|    time_elapsed       | 1054        |\n",
      "|    total_timesteps    | 340000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0.0372      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67999       |\n",
      "|    policy_loss        | 2.8         |\n",
      "|    reward             | 0.006562747 |\n",
      "|    std                | 1.11e+05    |\n",
      "|    value_loss         | 0.0116      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 68100        |\n",
      "|    time_elapsed       | 1056         |\n",
      "|    total_timesteps    | 340500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68099        |\n",
      "|    policy_loss        | -0.245       |\n",
      "|    reward             | -0.029073376 |\n",
      "|    std                | 1.12e+05     |\n",
      "|    value_loss         | 0.0006       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 68200       |\n",
      "|    time_elapsed       | 1057        |\n",
      "|    total_timesteps    | 341000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68199       |\n",
      "|    policy_loss        | -0.14       |\n",
      "|    reward             | 0.022827746 |\n",
      "|    std                | 1.13e+05    |\n",
      "|    value_loss         | 0.00257     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 68300        |\n",
      "|    time_elapsed       | 1059         |\n",
      "|    total_timesteps    | 341500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68299        |\n",
      "|    policy_loss        | 2.36         |\n",
      "|    reward             | -0.062752575 |\n",
      "|    std                | 1.13e+05     |\n",
      "|    value_loss         | 0.00874      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 68400      |\n",
      "|    time_elapsed       | 1060       |\n",
      "|    total_timesteps    | 342000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 68399      |\n",
      "|    policy_loss        | 0.305      |\n",
      "|    reward             | -0.1495163 |\n",
      "|    std                | 1.13e+05   |\n",
      "|    value_loss         | 0.00295    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 68500       |\n",
      "|    time_elapsed       | 1062        |\n",
      "|    total_timesteps    | 342500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0.344       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68499       |\n",
      "|    policy_loss        | -0.691      |\n",
      "|    reward             | 0.024874805 |\n",
      "|    std                | 1.14e+05    |\n",
      "|    value_loss         | 0.00348     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 68600      |\n",
      "|    time_elapsed       | 1063       |\n",
      "|    total_timesteps    | 343000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 68599      |\n",
      "|    policy_loss        | -7.23      |\n",
      "|    reward             | -0.3200632 |\n",
      "|    std                | 1.15e+05   |\n",
      "|    value_loss         | 0.124      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 68700       |\n",
      "|    time_elapsed       | 1065        |\n",
      "|    total_timesteps    | 343500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68699       |\n",
      "|    policy_loss        | 17          |\n",
      "|    reward             | -0.15052484 |\n",
      "|    std                | 1.15e+05    |\n",
      "|    value_loss         | 0.498       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 68800      |\n",
      "|    time_elapsed       | 1066       |\n",
      "|    total_timesteps    | 344000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 68799      |\n",
      "|    policy_loss        | -1.02      |\n",
      "|    reward             | 0.09828026 |\n",
      "|    std                | 1.15e+05   |\n",
      "|    value_loss         | 0.00234    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 68900      |\n",
      "|    time_elapsed       | 1068       |\n",
      "|    total_timesteps    | 344500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 68899      |\n",
      "|    policy_loss        | -0.0527    |\n",
      "|    reward             | 0.02958895 |\n",
      "|    std                | 1.16e+05   |\n",
      "|    value_loss         | 0.000544   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 69000        |\n",
      "|    time_elapsed       | 1069         |\n",
      "|    total_timesteps    | 345000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | -7.16        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68999        |\n",
      "|    policy_loss        | -2.23        |\n",
      "|    reward             | -0.001965901 |\n",
      "|    std                | 1.18e+05     |\n",
      "|    value_loss         | 0.00759      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 69100        |\n",
      "|    time_elapsed       | 1071         |\n",
      "|    total_timesteps    | 345500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69099        |\n",
      "|    policy_loss        | -0.722       |\n",
      "|    reward             | -0.013489601 |\n",
      "|    std                | 1.2e+05      |\n",
      "|    value_loss         | 0.000821     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 69200      |\n",
      "|    time_elapsed       | 1072       |\n",
      "|    total_timesteps    | 346000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69199      |\n",
      "|    policy_loss        | 0.974      |\n",
      "|    reward             | 0.07621932 |\n",
      "|    std                | 1.21e+05   |\n",
      "|    value_loss         | 0.00135    |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -45773.60\n",
      "total_reward: -55773.60\n",
      "total_cost: 74.63\n",
      "total_trades: 5540\n",
      "Sharpe: 0.347\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 69300         |\n",
      "|    time_elapsed       | 1073          |\n",
      "|    total_timesteps    | 346500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 69299         |\n",
      "|    policy_loss        | -1.21         |\n",
      "|    reward             | -0.0042354204 |\n",
      "|    std                | 1.22e+05      |\n",
      "|    value_loss         | 0.00385       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 69400       |\n",
      "|    time_elapsed       | 1075        |\n",
      "|    total_timesteps    | 347000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69399       |\n",
      "|    policy_loss        | -0.0656     |\n",
      "|    reward             | -0.04798873 |\n",
      "|    std                | 1.24e+05    |\n",
      "|    value_loss         | 0.000292    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 69500        |\n",
      "|    time_elapsed       | 1076         |\n",
      "|    total_timesteps    | 347500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69499        |\n",
      "|    policy_loss        | 0.224        |\n",
      "|    reward             | 0.0055382266 |\n",
      "|    std                | 1.27e+05     |\n",
      "|    value_loss         | 7.39e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 69600        |\n",
      "|    time_elapsed       | 1078         |\n",
      "|    total_timesteps    | 348000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69599        |\n",
      "|    policy_loss        | 0.922        |\n",
      "|    reward             | -0.022122376 |\n",
      "|    std                | 1.31e+05     |\n",
      "|    value_loss         | 0.0014       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 69700        |\n",
      "|    time_elapsed       | 1079         |\n",
      "|    total_timesteps    | 348500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 4.58e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69699        |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.048926353 |\n",
      "|    std                | 1.33e+05     |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 69800      |\n",
      "|    time_elapsed       | 1081       |\n",
      "|    total_timesteps    | 349000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69799      |\n",
      "|    policy_loss        | -0.605     |\n",
      "|    reward             | 0.17326763 |\n",
      "|    std                | 1.34e+05   |\n",
      "|    value_loss         | 0.000939   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 69900       |\n",
      "|    time_elapsed       | 1082        |\n",
      "|    total_timesteps    | 349500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69899       |\n",
      "|    policy_loss        | 1.93        |\n",
      "|    reward             | 0.017809262 |\n",
      "|    std                | 1.37e+05    |\n",
      "|    value_loss         | 0.00537     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 70000        |\n",
      "|    time_elapsed       | 1084         |\n",
      "|    total_timesteps    | 350000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69999        |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | -0.008222463 |\n",
      "|    std                | 1.4e+05      |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 70100        |\n",
      "|    time_elapsed       | 1085         |\n",
      "|    total_timesteps    | 350500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70099        |\n",
      "|    policy_loss        | 0.204        |\n",
      "|    reward             | 0.0078120143 |\n",
      "|    std                | 1.43e+05     |\n",
      "|    value_loss         | 8.73e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 70200         |\n",
      "|    time_elapsed       | 1086          |\n",
      "|    total_timesteps    | 351000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.7         |\n",
      "|    explained_variance | -0.118        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70199         |\n",
      "|    policy_loss        | -0.723        |\n",
      "|    reward             | -0.0077901087 |\n",
      "|    std                | 1.49e+05      |\n",
      "|    value_loss         | 0.000771      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 70300        |\n",
      "|    time_elapsed       | 1088         |\n",
      "|    total_timesteps    | 351500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.42         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70299        |\n",
      "|    policy_loss        | 0.36         |\n",
      "|    reward             | -0.009253516 |\n",
      "|    std                | 1.53e+05     |\n",
      "|    value_loss         | 0.000209     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 70400        |\n",
      "|    time_elapsed       | 1089         |\n",
      "|    total_timesteps    | 352000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70399        |\n",
      "|    policy_loss        | -0.894       |\n",
      "|    reward             | 0.0028614264 |\n",
      "|    std                | 1.58e+05     |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 70500       |\n",
      "|    time_elapsed       | 1091        |\n",
      "|    total_timesteps    | 352500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70499       |\n",
      "|    policy_loss        | -0.196      |\n",
      "|    reward             | 0.013328274 |\n",
      "|    std                | 1.62e+05    |\n",
      "|    value_loss         | 8.57e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 70600         |\n",
      "|    time_elapsed       | 1092          |\n",
      "|    total_timesteps    | 353000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70599         |\n",
      "|    policy_loss        | 0.109         |\n",
      "|    reward             | -0.0060498463 |\n",
      "|    std                | 1.66e+05      |\n",
      "|    value_loss         | 2.54e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 70700         |\n",
      "|    time_elapsed       | 1094          |\n",
      "|    total_timesteps    | 353500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.9         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70699         |\n",
      "|    policy_loss        | -0.277        |\n",
      "|    reward             | 0.00017470054 |\n",
      "|    std                | 1.73e+05      |\n",
      "|    value_loss         | 0.000164      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 70800       |\n",
      "|    time_elapsed       | 1095        |\n",
      "|    total_timesteps    | 354000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70799       |\n",
      "|    policy_loss        | 0.217       |\n",
      "|    reward             | 0.014304618 |\n",
      "|    std                | 1.79e+05    |\n",
      "|    value_loss         | 9.05e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 70900       |\n",
      "|    time_elapsed       | 1097        |\n",
      "|    total_timesteps    | 354500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70899       |\n",
      "|    policy_loss        | 0.165       |\n",
      "|    reward             | 0.006121228 |\n",
      "|    std                | 1.88e+05    |\n",
      "|    value_loss         | 0.000118    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 71000         |\n",
      "|    time_elapsed       | 1098          |\n",
      "|    total_timesteps    | 355000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70999         |\n",
      "|    policy_loss        | 0.359         |\n",
      "|    reward             | -0.0135831265 |\n",
      "|    std                | 1.92e+05      |\n",
      "|    value_loss         | 0.00281       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 71100       |\n",
      "|    time_elapsed       | 1100        |\n",
      "|    total_timesteps    | 355500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71099       |\n",
      "|    policy_loss        | -0.63       |\n",
      "|    reward             | 0.031029895 |\n",
      "|    std                | 1.95e+05    |\n",
      "|    value_loss         | 0.00075     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 71200        |\n",
      "|    time_elapsed       | 1101         |\n",
      "|    total_timesteps    | 356000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0.0457       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71199        |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | -0.011428928 |\n",
      "|    std                | 1.97e+05     |\n",
      "|    value_loss         | 8.47e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 71300         |\n",
      "|    time_elapsed       | 1103          |\n",
      "|    total_timesteps    | 356500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.3         |\n",
      "|    explained_variance | 0.0052        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71299         |\n",
      "|    policy_loss        | -0.228        |\n",
      "|    reward             | -0.0061332854 |\n",
      "|    std                | 2.01e+05      |\n",
      "|    value_loss         | 0.000444      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 71400        |\n",
      "|    time_elapsed       | 1104         |\n",
      "|    total_timesteps    | 357000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71399        |\n",
      "|    policy_loss        | 0.312        |\n",
      "|    reward             | -0.030834718 |\n",
      "|    std                | 2.05e+05     |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 71500      |\n",
      "|    time_elapsed       | 1105       |\n",
      "|    total_timesteps    | 357500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71499      |\n",
      "|    policy_loss        | 0.932      |\n",
      "|    reward             | 0.01397052 |\n",
      "|    std                | 2.09e+05   |\n",
      "|    value_loss         | 0.00161    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 71600        |\n",
      "|    time_elapsed       | 1107         |\n",
      "|    total_timesteps    | 358000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71599        |\n",
      "|    policy_loss        | 0.069        |\n",
      "|    reward             | -0.029788064 |\n",
      "|    std                | 2.14e+05     |\n",
      "|    value_loss         | 2.55e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 71700         |\n",
      "|    time_elapsed       | 1108          |\n",
      "|    total_timesteps    | 358500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71699         |\n",
      "|    policy_loss        | 0.0119        |\n",
      "|    reward             | -0.0085710585 |\n",
      "|    std                | 2.19e+05      |\n",
      "|    value_loss         | 5.21e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 71800        |\n",
      "|    time_elapsed       | 1110         |\n",
      "|    total_timesteps    | 359000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71799        |\n",
      "|    policy_loss        | 0.0948       |\n",
      "|    reward             | -0.008915712 |\n",
      "|    std                | 2.27e+05     |\n",
      "|    value_loss         | 7.11e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 71900        |\n",
      "|    time_elapsed       | 1111         |\n",
      "|    total_timesteps    | 359500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | -0.00509     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71899        |\n",
      "|    policy_loss        | 0.102        |\n",
      "|    reward             | -0.012487249 |\n",
      "|    std                | 2.37e+05     |\n",
      "|    value_loss         | 2.02e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 72000        |\n",
      "|    time_elapsed       | 1113         |\n",
      "|    total_timesteps    | 360000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71999        |\n",
      "|    policy_loss        | -0.817       |\n",
      "|    reward             | -0.005674353 |\n",
      "|    std                | 2.47e+05     |\n",
      "|    value_loss         | 0.000871     |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11671.38\n",
      "total_reward: -21671.38\n",
      "total_cost: 463.55\n",
      "total_trades: 5540\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 72100       |\n",
      "|    time_elapsed       | 1114        |\n",
      "|    total_timesteps    | 360500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72099       |\n",
      "|    policy_loss        | -0.238      |\n",
      "|    reward             | -0.06323021 |\n",
      "|    std                | 2.53e+05    |\n",
      "|    value_loss         | 0.000361    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 72200         |\n",
      "|    time_elapsed       | 1115          |\n",
      "|    total_timesteps    | 361000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 72199         |\n",
      "|    policy_loss        | 3.04          |\n",
      "|    reward             | -0.0119482465 |\n",
      "|    std                | 2.58e+05      |\n",
      "|    value_loss         | 0.0134        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 72300      |\n",
      "|    time_elapsed       | 1117       |\n",
      "|    total_timesteps    | 361500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.8      |\n",
      "|    explained_variance | -0.0621    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72299      |\n",
      "|    policy_loss        | 0.856      |\n",
      "|    reward             | -0.0254169 |\n",
      "|    std                | 2.59e+05   |\n",
      "|    value_loss         | 0.00106    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 72400      |\n",
      "|    time_elapsed       | 1118       |\n",
      "|    total_timesteps    | 362000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72399      |\n",
      "|    policy_loss        | 1.84       |\n",
      "|    reward             | 0.16256022 |\n",
      "|    std                | 2.64e+05   |\n",
      "|    value_loss         | 0.00505    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 72500      |\n",
      "|    time_elapsed       | 1120       |\n",
      "|    total_timesteps    | 362500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.8      |\n",
      "|    explained_variance | 0.0142     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72499      |\n",
      "|    policy_loss        | -1.49      |\n",
      "|    reward             | 0.02366209 |\n",
      "|    std                | 2.67e+05   |\n",
      "|    value_loss         | 0.00716    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 72600      |\n",
      "|    time_elapsed       | 1122       |\n",
      "|    total_timesteps    | 363000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72599      |\n",
      "|    policy_loss        | -9.14      |\n",
      "|    reward             | -0.3027949 |\n",
      "|    std                | 2.74e+05   |\n",
      "|    value_loss         | 0.14       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 1123         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | -0.891       |\n",
      "|    reward             | -0.027053298 |\n",
      "|    std                | 2.74e+05     |\n",
      "|    value_loss         | 0.00223      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 72800       |\n",
      "|    time_elapsed       | 1125        |\n",
      "|    total_timesteps    | 364000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72799       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | 0.026690703 |\n",
      "|    std                | 2.77e+05    |\n",
      "|    value_loss         | 0.00427     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 72900        |\n",
      "|    time_elapsed       | 1127         |\n",
      "|    total_timesteps    | 364500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0.0667       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72899        |\n",
      "|    policy_loss        | 0.44         |\n",
      "|    reward             | -0.013945374 |\n",
      "|    std                | 2.82e+05     |\n",
      "|    value_loss         | 0.000475     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 73000        |\n",
      "|    time_elapsed       | 1128         |\n",
      "|    total_timesteps    | 365000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72999        |\n",
      "|    policy_loss        | 0.867        |\n",
      "|    reward             | -0.019503325 |\n",
      "|    std                | 2.87e+05     |\n",
      "|    value_loss         | 0.00195      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 73100       |\n",
      "|    time_elapsed       | 1130        |\n",
      "|    total_timesteps    | 365500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73099       |\n",
      "|    policy_loss        | 3           |\n",
      "|    reward             | 0.049372666 |\n",
      "|    std                | 2.96e+05    |\n",
      "|    value_loss         | 0.0194      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 73200        |\n",
      "|    time_elapsed       | 1132         |\n",
      "|    total_timesteps    | 366000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73199        |\n",
      "|    policy_loss        | 0.427        |\n",
      "|    reward             | -0.030306054 |\n",
      "|    std                | 3.03e+05     |\n",
      "|    value_loss         | 0.00116      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 73300        |\n",
      "|    time_elapsed       | 1133         |\n",
      "|    total_timesteps    | 366500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73299        |\n",
      "|    policy_loss        | -0.427       |\n",
      "|    reward             | -0.017336983 |\n",
      "|    std                | 3.06e+05     |\n",
      "|    value_loss         | 0.000249     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 73400      |\n",
      "|    time_elapsed       | 1135       |\n",
      "|    total_timesteps    | 367000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73399      |\n",
      "|    policy_loss        | -1.25      |\n",
      "|    reward             | 0.00803428 |\n",
      "|    std                | 3.12e+05   |\n",
      "|    value_loss         | 0.00298    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 73500         |\n",
      "|    time_elapsed       | 1137          |\n",
      "|    total_timesteps    | 367500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.1         |\n",
      "|    explained_variance | 7.52e-05      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73499         |\n",
      "|    policy_loss        | -1.03         |\n",
      "|    reward             | -0.0020260338 |\n",
      "|    std                | 3.14e+05      |\n",
      "|    value_loss         | 0.00274       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 73600      |\n",
      "|    time_elapsed       | 1138       |\n",
      "|    total_timesteps    | 368000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73599      |\n",
      "|    policy_loss        | -0.538     |\n",
      "|    reward             | 0.14042795 |\n",
      "|    std                | 3.18e+05   |\n",
      "|    value_loss         | 0.00229    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 73700       |\n",
      "|    time_elapsed       | 1140        |\n",
      "|    total_timesteps    | 368500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 0.00967     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73699       |\n",
      "|    policy_loss        | 1.13        |\n",
      "|    reward             | -0.22608578 |\n",
      "|    std                | 3.15e+05    |\n",
      "|    value_loss         | 0.00343     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 73800        |\n",
      "|    time_elapsed       | 1141         |\n",
      "|    total_timesteps    | 369000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73799        |\n",
      "|    policy_loss        | -0.413       |\n",
      "|    reward             | -0.015798291 |\n",
      "|    std                | 3.16e+05     |\n",
      "|    value_loss         | 0.000291     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 73900          |\n",
      "|    time_elapsed       | 1143           |\n",
      "|    total_timesteps    | 369500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -28.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 73899          |\n",
      "|    policy_loss        | 0.0633         |\n",
      "|    reward             | -0.00058580283 |\n",
      "|    std                | 3.19e+05       |\n",
      "|    value_loss         | 4.17e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 74000        |\n",
      "|    time_elapsed       | 1145         |\n",
      "|    total_timesteps    | 370000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73999        |\n",
      "|    policy_loss        | 1.4          |\n",
      "|    reward             | -0.012839516 |\n",
      "|    std                | 3.25e+05     |\n",
      "|    value_loss         | 0.00269      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 74100        |\n",
      "|    time_elapsed       | 1146         |\n",
      "|    total_timesteps    | 370500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | -1.57        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74099        |\n",
      "|    policy_loss        | -0.29        |\n",
      "|    reward             | -0.004627898 |\n",
      "|    std                | 3.34e+05     |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 74200         |\n",
      "|    time_elapsed       | 1148          |\n",
      "|    total_timesteps    | 371000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | 0.802         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 74199         |\n",
      "|    policy_loss        | 0.102         |\n",
      "|    reward             | -0.0006678322 |\n",
      "|    std                | 3.48e+05      |\n",
      "|    value_loss         | 1.35e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 74300       |\n",
      "|    time_elapsed       | 1150        |\n",
      "|    total_timesteps    | 371500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | -5.01       |\n",
      "|    reward             | -0.08478815 |\n",
      "|    std                | 3.56e+05    |\n",
      "|    value_loss         | 0.034       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 74400          |\n",
      "|    time_elapsed       | 1151           |\n",
      "|    total_timesteps    | 372000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -28.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 74399          |\n",
      "|    policy_loss        | 1.51           |\n",
      "|    reward             | -0.00011354539 |\n",
      "|    std                | 3.64e+05       |\n",
      "|    value_loss         | 0.00359        |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 74500      |\n",
      "|    time_elapsed       | 1153       |\n",
      "|    total_timesteps    | 372500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74499      |\n",
      "|    policy_loss        | -5.89      |\n",
      "|    reward             | 0.06084419 |\n",
      "|    std                | 3.69e+05   |\n",
      "|    value_loss         | 0.135      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 74600       |\n",
      "|    time_elapsed       | 1155        |\n",
      "|    total_timesteps    | 373000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0.307       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74599       |\n",
      "|    policy_loss        | 10.2        |\n",
      "|    reward             | -0.48500204 |\n",
      "|    std                | 3.74e+05    |\n",
      "|    value_loss         | 0.197       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 74700      |\n",
      "|    time_elapsed       | 1156       |\n",
      "|    total_timesteps    | 373500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74699      |\n",
      "|    policy_loss        | -5.91      |\n",
      "|    reward             | 0.30194607 |\n",
      "|    std                | 3.75e+05   |\n",
      "|    value_loss         | 0.079      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 74800       |\n",
      "|    time_elapsed       | 1158        |\n",
      "|    total_timesteps    | 374000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74799       |\n",
      "|    policy_loss        | -8.78       |\n",
      "|    reward             | -0.18284133 |\n",
      "|    std                | 3.77e+05    |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -341731.41\n",
      "total_reward: -351731.41\n",
      "total_cost: 112.42\n",
      "total_trades: 5540\n",
      "Sharpe: 0.584\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 74900       |\n",
      "|    time_elapsed       | 1160        |\n",
      "|    total_timesteps    | 374500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74899       |\n",
      "|    policy_loss        | 0.311       |\n",
      "|    reward             | 0.015467048 |\n",
      "|    std                | 3.79e+05    |\n",
      "|    value_loss         | 0.00039     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 75000       |\n",
      "|    time_elapsed       | 1161        |\n",
      "|    total_timesteps    | 375000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74999       |\n",
      "|    policy_loss        | 0.122       |\n",
      "|    reward             | 0.011991368 |\n",
      "|    std                | 3.85e+05    |\n",
      "|    value_loss         | 8.92e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 75100        |\n",
      "|    time_elapsed       | 1163         |\n",
      "|    total_timesteps    | 375500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75099        |\n",
      "|    policy_loss        | 0.0815       |\n",
      "|    reward             | 0.0018001065 |\n",
      "|    std                | 3.93e+05     |\n",
      "|    value_loss         | 5.54e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 75200        |\n",
      "|    time_elapsed       | 1164         |\n",
      "|    total_timesteps    | 376000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | 0.558        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75199        |\n",
      "|    policy_loss        | -0.328       |\n",
      "|    reward             | 0.0074770316 |\n",
      "|    std                | 4.07e+05     |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 75300        |\n",
      "|    time_elapsed       | 1166         |\n",
      "|    total_timesteps    | 376500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | -0.627       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75299        |\n",
      "|    policy_loss        | 0.275        |\n",
      "|    reward             | -0.007930819 |\n",
      "|    std                | 4.16e+05     |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 75400       |\n",
      "|    time_elapsed       | 1168        |\n",
      "|    total_timesteps    | 377000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | 0.301       |\n",
      "|    reward             | -0.02457595 |\n",
      "|    std                | 4.28e+05    |\n",
      "|    value_loss         | 0.000289    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 75500       |\n",
      "|    time_elapsed       | 1169        |\n",
      "|    total_timesteps    | 377500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75499       |\n",
      "|    policy_loss        | 0.973       |\n",
      "|    reward             | 0.013198303 |\n",
      "|    std                | 4.36e+05    |\n",
      "|    value_loss         | 0.00175     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 75600       |\n",
      "|    time_elapsed       | 1171        |\n",
      "|    total_timesteps    | 378000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75599       |\n",
      "|    policy_loss        | 0.91        |\n",
      "|    reward             | -0.02736445 |\n",
      "|    std                | 4.47e+05    |\n",
      "|    value_loss         | 0.00115     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 75700      |\n",
      "|    time_elapsed       | 1172       |\n",
      "|    total_timesteps    | 378500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.9      |\n",
      "|    explained_variance | 0.000648   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75699      |\n",
      "|    policy_loss        | 0.366      |\n",
      "|    reward             | 0.03560432 |\n",
      "|    std                | 4.58e+05   |\n",
      "|    value_loss         | 0.000173   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 75800       |\n",
      "|    time_elapsed       | 1174        |\n",
      "|    total_timesteps    | 379000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75799       |\n",
      "|    policy_loss        | 0.314       |\n",
      "|    reward             | 0.021611394 |\n",
      "|    std                | 4.72e+05    |\n",
      "|    value_loss         | 0.000203    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 75900        |\n",
      "|    time_elapsed       | 1175         |\n",
      "|    total_timesteps    | 379500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0.0797       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75899        |\n",
      "|    policy_loss        | 1.88         |\n",
      "|    reward             | -0.024090108 |\n",
      "|    std                | 4.82e+05     |\n",
      "|    value_loss         | 0.00546      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 76000       |\n",
      "|    time_elapsed       | 1177        |\n",
      "|    total_timesteps    | 380000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75999       |\n",
      "|    policy_loss        | -2.15       |\n",
      "|    reward             | 0.041008234 |\n",
      "|    std                | 4.93e+05    |\n",
      "|    value_loss         | 0.00679     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 76100        |\n",
      "|    time_elapsed       | 1178         |\n",
      "|    total_timesteps    | 380500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76099        |\n",
      "|    policy_loss        | -0.0583      |\n",
      "|    reward             | -0.013514102 |\n",
      "|    std                | 5.04e+05     |\n",
      "|    value_loss         | 4.96e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 76200        |\n",
      "|    time_elapsed       | 1180         |\n",
      "|    total_timesteps    | 381000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76199        |\n",
      "|    policy_loss        | -0.719       |\n",
      "|    reward             | -0.013331845 |\n",
      "|    std                | 5.14e+05     |\n",
      "|    value_loss         | 0.000705     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 76300        |\n",
      "|    time_elapsed       | 1182         |\n",
      "|    total_timesteps    | 381500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0.0684       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76299        |\n",
      "|    policy_loss        | -0.453       |\n",
      "|    reward             | 0.0042103785 |\n",
      "|    std                | 5.28e+05     |\n",
      "|    value_loss         | 0.000266     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 76400        |\n",
      "|    time_elapsed       | 1183         |\n",
      "|    total_timesteps    | 382000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0.00274      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76399        |\n",
      "|    policy_loss        | 0.211        |\n",
      "|    reward             | -0.024051907 |\n",
      "|    std                | 5.45e+05     |\n",
      "|    value_loss         | 0.000238     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 76500        |\n",
      "|    time_elapsed       | 1185         |\n",
      "|    total_timesteps    | 382500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76499        |\n",
      "|    policy_loss        | -0.681       |\n",
      "|    reward             | 0.0012364811 |\n",
      "|    std                | 5.7e+05      |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 76600      |\n",
      "|    time_elapsed       | 1186       |\n",
      "|    total_timesteps    | 383000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76599      |\n",
      "|    policy_loss        | 0.231      |\n",
      "|    reward             | 0.01737618 |\n",
      "|    std                | 5.78e+05   |\n",
      "|    value_loss         | 0.000181   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 76700        |\n",
      "|    time_elapsed       | 1188         |\n",
      "|    total_timesteps    | 383500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76699        |\n",
      "|    policy_loss        | 0.0699       |\n",
      "|    reward             | -0.008338862 |\n",
      "|    std                | 5.94e+05     |\n",
      "|    value_loss         | 4.46e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 76800         |\n",
      "|    time_elapsed       | 1189          |\n",
      "|    total_timesteps    | 384000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.5         |\n",
      "|    explained_variance | -0.000298     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 76799         |\n",
      "|    policy_loss        | 0.0877        |\n",
      "|    reward             | -0.0047493167 |\n",
      "|    std                | 6.14e+05      |\n",
      "|    value_loss         | 2.34e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 76900        |\n",
      "|    time_elapsed       | 1191         |\n",
      "|    total_timesteps    | 384500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.6        |\n",
      "|    explained_variance | 0.175        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76899        |\n",
      "|    policy_loss        | -0.0855      |\n",
      "|    reward             | -0.011460204 |\n",
      "|    std                | 6.42e+05     |\n",
      "|    value_loss         | 4.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 77000        |\n",
      "|    time_elapsed       | 1193         |\n",
      "|    total_timesteps    | 385000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.6        |\n",
      "|    explained_variance | -0.0506      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76999        |\n",
      "|    policy_loss        | -0.1         |\n",
      "|    reward             | -0.019703649 |\n",
      "|    std                | 6.68e+05     |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 77100       |\n",
      "|    time_elapsed       | 1194        |\n",
      "|    total_timesteps    | 385500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77099       |\n",
      "|    policy_loss        | 2.21        |\n",
      "|    reward             | 0.021999821 |\n",
      "|    std                | 6.85e+05    |\n",
      "|    value_loss         | 0.00616     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 77200         |\n",
      "|    time_elapsed       | 1195          |\n",
      "|    total_timesteps    | 386000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77199         |\n",
      "|    policy_loss        | -0.0995       |\n",
      "|    reward             | -0.0039067245 |\n",
      "|    std                | 7.07e+05      |\n",
      "|    value_loss         | 9.88e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 77300        |\n",
      "|    time_elapsed       | 1197         |\n",
      "|    total_timesteps    | 386500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77299        |\n",
      "|    policy_loss        | 0.817        |\n",
      "|    reward             | -0.010153838 |\n",
      "|    std                | 7.25e+05     |\n",
      "|    value_loss         | 0.000878     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 77400        |\n",
      "|    time_elapsed       | 1198         |\n",
      "|    total_timesteps    | 387000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.8        |\n",
      "|    explained_variance | -0.00014     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77399        |\n",
      "|    policy_loss        | 0.407        |\n",
      "|    reward             | 0.0015044956 |\n",
      "|    std                | 7.35e+05     |\n",
      "|    value_loss         | 0.00024      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 322       |\n",
      "|    iterations         | 77500     |\n",
      "|    time_elapsed       | 1200      |\n",
      "|    total_timesteps    | 387500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 77499     |\n",
      "|    policy_loss        | -0.602    |\n",
      "|    reward             | 0.0177968 |\n",
      "|    std                | 7.71e+05  |\n",
      "|    value_loss         | 0.000447  |\n",
      "-------------------------------------\n",
      "day: 2770, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12639.14\n",
      "total_reward: -22639.14\n",
      "total_cost: 411.41\n",
      "total_trades: 5540\n",
      "Sharpe: -0.171\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 77600        |\n",
      "|    time_elapsed       | 1201         |\n",
      "|    total_timesteps    | 388000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77599        |\n",
      "|    policy_loss        | -0.752       |\n",
      "|    reward             | -0.013934276 |\n",
      "|    std                | 8e+05        |\n",
      "|    value_loss         | 0.00233      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 77700        |\n",
      "|    time_elapsed       | 1203         |\n",
      "|    total_timesteps    | 388500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77699        |\n",
      "|    policy_loss        | -0.366       |\n",
      "|    reward             | -0.015761044 |\n",
      "|    std                | 8.16e+05     |\n",
      "|    value_loss         | 0.00031      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 77800        |\n",
      "|    time_elapsed       | 1204         |\n",
      "|    total_timesteps    | 389000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77799        |\n",
      "|    policy_loss        | 0.167        |\n",
      "|    reward             | 0.0015478757 |\n",
      "|    std                | 8.3e+05      |\n",
      "|    value_loss         | 4.17e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 77900       |\n",
      "|    time_elapsed       | 1206        |\n",
      "|    total_timesteps    | 389500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 1.64e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77899       |\n",
      "|    policy_loss        | -1.46       |\n",
      "|    reward             | 0.010154572 |\n",
      "|    std                | 8.51e+05    |\n",
      "|    value_loss         | 0.00288     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 78000       |\n",
      "|    time_elapsed       | 1207        |\n",
      "|    total_timesteps    | 390000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0.175       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77999       |\n",
      "|    policy_loss        | -0.663      |\n",
      "|    reward             | -0.00953287 |\n",
      "|    std                | 8.64e+05    |\n",
      "|    value_loss         | 0.000894    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 78100        |\n",
      "|    time_elapsed       | 1209         |\n",
      "|    total_timesteps    | 390500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78099        |\n",
      "|    policy_loss        | -3.07        |\n",
      "|    reward             | -0.100573115 |\n",
      "|    std                | 8.83e+05     |\n",
      "|    value_loss         | 0.0121       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 78200       |\n",
      "|    time_elapsed       | 1210        |\n",
      "|    total_timesteps    | 391000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78199       |\n",
      "|    policy_loss        | 0.53        |\n",
      "|    reward             | 0.006183573 |\n",
      "|    std                | 9.01e+05    |\n",
      "|    value_loss         | 0.000343    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 78300        |\n",
      "|    time_elapsed       | 1212         |\n",
      "|    total_timesteps    | 391500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78299        |\n",
      "|    policy_loss        | -0.275       |\n",
      "|    reward             | -0.010229589 |\n",
      "|    std                | 9.18e+05     |\n",
      "|    value_loss         | 0.000153     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 78400         |\n",
      "|    time_elapsed       | 1213          |\n",
      "|    total_timesteps    | 392000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 78399         |\n",
      "|    policy_loss        | -0.375        |\n",
      "|    reward             | -0.0025141132 |\n",
      "|    std                | 9.39e+05      |\n",
      "|    value_loss         | 0.00025       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 78500          |\n",
      "|    time_elapsed       | 1214           |\n",
      "|    total_timesteps    | 392500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.4          |\n",
      "|    explained_variance | 0.398          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 78499          |\n",
      "|    policy_loss        | -0.113         |\n",
      "|    reward             | -0.00038090345 |\n",
      "|    std                | 9.62e+05       |\n",
      "|    value_loss         | 2.24e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 78600       |\n",
      "|    time_elapsed       | 1216        |\n",
      "|    total_timesteps    | 393000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | -4.81       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78599       |\n",
      "|    policy_loss        | -0.288      |\n",
      "|    reward             | 0.015766174 |\n",
      "|    std                | 1e+06       |\n",
      "|    value_loss         | 9.66e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 78700       |\n",
      "|    time_elapsed       | 1217        |\n",
      "|    total_timesteps    | 393500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | -0.127      |\n",
      "|    reward             | -0.00355569 |\n",
      "|    std                | 1.05e+06    |\n",
      "|    value_loss         | 7.09e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 78800       |\n",
      "|    time_elapsed       | 1219        |\n",
      "|    total_timesteps    | 394000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78799       |\n",
      "|    policy_loss        | 0.561       |\n",
      "|    reward             | 0.013174785 |\n",
      "|    std                | 1.09e+06    |\n",
      "|    value_loss         | 0.000438    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 78900       |\n",
      "|    time_elapsed       | 1220        |\n",
      "|    total_timesteps    | 394500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78899       |\n",
      "|    policy_loss        | 0.693       |\n",
      "|    reward             | -0.01490178 |\n",
      "|    std                | 1.13e+06    |\n",
      "|    value_loss         | 0.000693    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 79000        |\n",
      "|    time_elapsed       | 1222         |\n",
      "|    total_timesteps    | 395000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78999        |\n",
      "|    policy_loss        | -0.0726      |\n",
      "|    reward             | -0.017637711 |\n",
      "|    std                | 1.17e+06     |\n",
      "|    value_loss         | 4.84e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 79100        |\n",
      "|    time_elapsed       | 1223         |\n",
      "|    total_timesteps    | 395500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0.0171       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79099        |\n",
      "|    policy_loss        | 0.87         |\n",
      "|    reward             | -0.015991274 |\n",
      "|    std                | 1.22e+06     |\n",
      "|    value_loss         | 0.000845     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 1225        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | -3.33       |\n",
      "|    reward             | -0.03537601 |\n",
      "|    std                | 1.27e+06    |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 79300       |\n",
      "|    time_elapsed       | 1226        |\n",
      "|    total_timesteps    | 396500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79299       |\n",
      "|    policy_loss        | 3.41        |\n",
      "|    reward             | -0.00515552 |\n",
      "|    std                | 1.31e+06    |\n",
      "|    value_loss         | 0.014       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 79400       |\n",
      "|    time_elapsed       | 1228        |\n",
      "|    total_timesteps    | 397000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79399       |\n",
      "|    policy_loss        | -1.66       |\n",
      "|    reward             | 0.015800158 |\n",
      "|    std                | 1.33e+06    |\n",
      "|    value_loss         | 0.00293     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 79500       |\n",
      "|    time_elapsed       | 1229        |\n",
      "|    total_timesteps    | 397500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79499       |\n",
      "|    policy_loss        | 3.09        |\n",
      "|    reward             | 0.017337037 |\n",
      "|    std                | 1.35e+06    |\n",
      "|    value_loss         | 0.011       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 79600        |\n",
      "|    time_elapsed       | 1231         |\n",
      "|    total_timesteps    | 398000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | 0.0833       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79599        |\n",
      "|    policy_loss        | -2.03        |\n",
      "|    reward             | -0.078382306 |\n",
      "|    std                | 1.36e+06     |\n",
      "|    value_loss         | 0.0055       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 79700      |\n",
      "|    time_elapsed       | 1232       |\n",
      "|    total_timesteps    | 398500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.1      |\n",
      "|    explained_variance | 0.137      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79699      |\n",
      "|    policy_loss        | 1.06       |\n",
      "|    reward             | 0.10193094 |\n",
      "|    std                | 1.39e+06   |\n",
      "|    value_loss         | 0.00438    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 79800      |\n",
      "|    time_elapsed       | 1234       |\n",
      "|    total_timesteps    | 399000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79799      |\n",
      "|    policy_loss        | 10.1       |\n",
      "|    reward             | 0.18067613 |\n",
      "|    std                | 1.4e+06    |\n",
      "|    value_loss         | 0.116      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 79900         |\n",
      "|    time_elapsed       | 1235          |\n",
      "|    total_timesteps    | 399500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79899         |\n",
      "|    policy_loss        | 0.316         |\n",
      "|    reward             | -0.0035113872 |\n",
      "|    std                | 1.41e+06      |\n",
      "|    value_loss         | 0.000296      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 80000         |\n",
      "|    time_elapsed       | 1237          |\n",
      "|    total_timesteps    | 400000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79999         |\n",
      "|    policy_loss        | -1.13         |\n",
      "|    reward             | -0.0052521313 |\n",
      "|    std                | 1.43e+06      |\n",
      "|    value_loss         | 0.00213       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 80100       |\n",
      "|    time_elapsed       | 1238        |\n",
      "|    total_timesteps    | 400500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80099       |\n",
      "|    policy_loss        | -0.856      |\n",
      "|    reward             | 0.029536799 |\n",
      "|    std                | 1.45e+06    |\n",
      "|    value_loss         | 0.00198     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 80200       |\n",
      "|    time_elapsed       | 1240        |\n",
      "|    total_timesteps    | 401000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80199       |\n",
      "|    policy_loss        | 3.56        |\n",
      "|    reward             | -0.10819354 |\n",
      "|    std                | 1.48e+06    |\n",
      "|    value_loss         | 0.016       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 80300        |\n",
      "|    time_elapsed       | 1241         |\n",
      "|    total_timesteps    | 401500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.2        |\n",
      "|    explained_variance | 0.00171      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80299        |\n",
      "|    policy_loss        | 2.9          |\n",
      "|    reward             | 0.0038519043 |\n",
      "|    std                | 1.48e+06     |\n",
      "|    value_loss         | 0.0109       |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -62576.77\n",
      "total_reward: -72576.77\n",
      "total_cost: 94.85\n",
      "total_trades: 5540\n",
      "Sharpe: 0.470\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 80400        |\n",
      "|    time_elapsed       | 1243         |\n",
      "|    total_timesteps    | 402000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80399        |\n",
      "|    policy_loss        | -1.09        |\n",
      "|    reward             | -0.040297057 |\n",
      "|    std                | 1.5e+06      |\n",
      "|    value_loss         | 0.00261      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 80500       |\n",
      "|    time_elapsed       | 1244        |\n",
      "|    total_timesteps    | 402500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80499       |\n",
      "|    policy_loss        | -3.21       |\n",
      "|    reward             | 0.021632113 |\n",
      "|    std                | 1.52e+06    |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 80600       |\n",
      "|    time_elapsed       | 1246        |\n",
      "|    total_timesteps    | 403000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80599       |\n",
      "|    policy_loss        | 1.32        |\n",
      "|    reward             | -0.03434232 |\n",
      "|    std                | 1.53e+06    |\n",
      "|    value_loss         | 0.0112      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 80700        |\n",
      "|    time_elapsed       | 1247         |\n",
      "|    total_timesteps    | 403500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80699        |\n",
      "|    policy_loss        | 6.08         |\n",
      "|    reward             | -0.017311886 |\n",
      "|    std                | 1.52e+06     |\n",
      "|    value_loss         | 0.0395       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 80800       |\n",
      "|    time_elapsed       | 1249        |\n",
      "|    total_timesteps    | 404000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80799       |\n",
      "|    policy_loss        | -10.9       |\n",
      "|    reward             | -0.12330495 |\n",
      "|    std                | 1.55e+06    |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 80900      |\n",
      "|    time_elapsed       | 1250       |\n",
      "|    total_timesteps    | 404500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80899      |\n",
      "|    policy_loss        | -10.7      |\n",
      "|    reward             | 0.14309426 |\n",
      "|    std                | 1.56e+06   |\n",
      "|    value_loss         | 0.285      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 81000      |\n",
      "|    time_elapsed       | 1252       |\n",
      "|    total_timesteps    | 405000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80999      |\n",
      "|    policy_loss        | 3.38       |\n",
      "|    reward             | 0.06692166 |\n",
      "|    std                | 1.56e+06   |\n",
      "|    value_loss         | 0.0126     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 81100       |\n",
      "|    time_elapsed       | 1253        |\n",
      "|    total_timesteps    | 405500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81099       |\n",
      "|    policy_loss        | -1.72       |\n",
      "|    reward             | -0.14927106 |\n",
      "|    std                | 1.57e+06    |\n",
      "|    value_loss         | 0.00457     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 81200      |\n",
      "|    time_elapsed       | 1255       |\n",
      "|    total_timesteps    | 406000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81199      |\n",
      "|    policy_loss        | -7.15      |\n",
      "|    reward             | -0.0346459 |\n",
      "|    std                | 1.59e+06   |\n",
      "|    value_loss         | 0.0523     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 81300      |\n",
      "|    time_elapsed       | 1256       |\n",
      "|    total_timesteps    | 406500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81299      |\n",
      "|    policy_loss        | 1.13       |\n",
      "|    reward             | 0.04265613 |\n",
      "|    std                | 1.62e+06   |\n",
      "|    value_loss         | 0.00601    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 81400      |\n",
      "|    time_elapsed       | 1258       |\n",
      "|    total_timesteps    | 407000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.4      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81399      |\n",
      "|    policy_loss        | -0.0767    |\n",
      "|    reward             | 0.12087605 |\n",
      "|    std                | 1.61e+06   |\n",
      "|    value_loss         | 0.00288    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 81500        |\n",
      "|    time_elapsed       | 1259         |\n",
      "|    total_timesteps    | 407500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81499        |\n",
      "|    policy_loss        | 0.196        |\n",
      "|    reward             | -0.012811286 |\n",
      "|    std                | 1.62e+06     |\n",
      "|    value_loss         | 0.000172     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 81600        |\n",
      "|    time_elapsed       | 1260         |\n",
      "|    total_timesteps    | 408000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81599        |\n",
      "|    policy_loss        | 0.297        |\n",
      "|    reward             | 0.0030908727 |\n",
      "|    std                | 1.64e+06     |\n",
      "|    value_loss         | 0.000176     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 81700         |\n",
      "|    time_elapsed       | 1262          |\n",
      "|    total_timesteps    | 408500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81699         |\n",
      "|    policy_loss        | -0.227        |\n",
      "|    reward             | -0.0020247565 |\n",
      "|    std                | 1.68e+06      |\n",
      "|    value_loss         | 0.000181      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 81800        |\n",
      "|    time_elapsed       | 1263         |\n",
      "|    total_timesteps    | 409000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81799        |\n",
      "|    policy_loss        | 0.285        |\n",
      "|    reward             | -0.020521626 |\n",
      "|    std                | 1.71e+06     |\n",
      "|    value_loss         | 0.000237     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 81900        |\n",
      "|    time_elapsed       | 1265         |\n",
      "|    total_timesteps    | 409500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81899        |\n",
      "|    policy_loss        | 0.293        |\n",
      "|    reward             | -0.013892704 |\n",
      "|    std                | 1.76e+06     |\n",
      "|    value_loss         | 0.000248     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 82000       |\n",
      "|    time_elapsed       | 1266        |\n",
      "|    total_timesteps    | 410000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 1.67e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81999       |\n",
      "|    policy_loss        | 0.0959      |\n",
      "|    reward             | 0.033201702 |\n",
      "|    std                | 1.82e+06    |\n",
      "|    value_loss         | 2.57e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 82100      |\n",
      "|    time_elapsed       | 1268       |\n",
      "|    total_timesteps    | 410500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 82099      |\n",
      "|    policy_loss        | -1.38      |\n",
      "|    reward             | 0.06016604 |\n",
      "|    std                | 1.9e+06    |\n",
      "|    value_loss         | 0.00388    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 82200       |\n",
      "|    time_elapsed       | 1269        |\n",
      "|    total_timesteps    | 411000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82199       |\n",
      "|    policy_loss        | 1.68        |\n",
      "|    reward             | -0.02834649 |\n",
      "|    std                | 1.92e+06    |\n",
      "|    value_loss         | 0.00326     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 82300        |\n",
      "|    time_elapsed       | 1271         |\n",
      "|    total_timesteps    | 411500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | -0.0152      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82299        |\n",
      "|    policy_loss        | -0.935       |\n",
      "|    reward             | 0.0023836857 |\n",
      "|    std                | 1.95e+06     |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 82400         |\n",
      "|    time_elapsed       | 1272          |\n",
      "|    total_timesteps    | 412000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.8         |\n",
      "|    explained_variance | 0.000771      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82399         |\n",
      "|    policy_loss        | 0.48          |\n",
      "|    reward             | -0.0024040595 |\n",
      "|    std                | 1.98e+06      |\n",
      "|    value_loss         | 0.000654      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 323       |\n",
      "|    iterations         | 82500     |\n",
      "|    time_elapsed       | 1274      |\n",
      "|    total_timesteps    | 412500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.9     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 82499     |\n",
      "|    policy_loss        | 1.9       |\n",
      "|    reward             | 0.0449574 |\n",
      "|    std                | 2.03e+06  |\n",
      "|    value_loss         | 0.00398   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 82600        |\n",
      "|    time_elapsed       | 1275         |\n",
      "|    total_timesteps    | 413000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82599        |\n",
      "|    policy_loss        | -1.38        |\n",
      "|    reward             | -0.013846911 |\n",
      "|    std                | 2.05e+06     |\n",
      "|    value_loss         | 0.0024       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 82700         |\n",
      "|    time_elapsed       | 1276          |\n",
      "|    total_timesteps    | 413500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.9         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82699         |\n",
      "|    policy_loss        | 0.0452        |\n",
      "|    reward             | -0.0017064532 |\n",
      "|    std                | 2.08e+06      |\n",
      "|    value_loss         | 0.000703      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 82800       |\n",
      "|    time_elapsed       | 1278        |\n",
      "|    total_timesteps    | 414000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82799       |\n",
      "|    policy_loss        | -0.254      |\n",
      "|    reward             | 0.018483432 |\n",
      "|    std                | 2.12e+06    |\n",
      "|    value_loss         | 0.000242    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 82900        |\n",
      "|    time_elapsed       | 1279         |\n",
      "|    total_timesteps    | 414500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82899        |\n",
      "|    policy_loss        | 0.291        |\n",
      "|    reward             | 0.0031747136 |\n",
      "|    std                | 2.17e+06     |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 83000       |\n",
      "|    time_elapsed       | 1281        |\n",
      "|    total_timesteps    | 415000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82999       |\n",
      "|    policy_loss        | -1.08       |\n",
      "|    reward             | 0.003875203 |\n",
      "|    std                | 2.24e+06    |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 83100        |\n",
      "|    time_elapsed       | 1282         |\n",
      "|    total_timesteps    | 415500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83099        |\n",
      "|    policy_loss        | -0.133       |\n",
      "|    reward             | -0.035827864 |\n",
      "|    std                | 2.3e+06      |\n",
      "|    value_loss         | 3.23e-05     |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -41772.13\n",
      "total_reward: -51772.13\n",
      "total_cost: 72.18\n",
      "total_trades: 5540\n",
      "Sharpe: -0.347\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 83200       |\n",
      "|    time_elapsed       | 1284        |\n",
      "|    total_timesteps    | 416000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83199       |\n",
      "|    policy_loss        | -3.21       |\n",
      "|    reward             | 0.026645819 |\n",
      "|    std                | 2.35e+06    |\n",
      "|    value_loss         | 0.0133      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 83300        |\n",
      "|    time_elapsed       | 1285         |\n",
      "|    total_timesteps    | 416500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83299        |\n",
      "|    policy_loss        | 0.448        |\n",
      "|    reward             | -0.004572028 |\n",
      "|    std                | 2.36e+06     |\n",
      "|    value_loss         | 0.00026      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 83400        |\n",
      "|    time_elapsed       | 1287         |\n",
      "|    total_timesteps    | 417000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 2.98e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83399        |\n",
      "|    policy_loss        | 0.502        |\n",
      "|    reward             | -0.010471049 |\n",
      "|    std                | 2.4e+06      |\n",
      "|    value_loss         | 0.000574     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 83500        |\n",
      "|    time_elapsed       | 1288         |\n",
      "|    total_timesteps    | 417500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83499        |\n",
      "|    policy_loss        | 2.55         |\n",
      "|    reward             | -0.038808923 |\n",
      "|    std                | 2.42e+06     |\n",
      "|    value_loss         | 0.00721      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 83600       |\n",
      "|    time_elapsed       | 1290        |\n",
      "|    total_timesteps    | 418000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83599       |\n",
      "|    policy_loss        | -0.5        |\n",
      "|    reward             | 0.081765324 |\n",
      "|    std                | 2.46e+06    |\n",
      "|    value_loss         | 0.00247     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 83700         |\n",
      "|    time_elapsed       | 1291          |\n",
      "|    total_timesteps    | 418500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83699         |\n",
      "|    policy_loss        | 1.21          |\n",
      "|    reward             | -0.0083127525 |\n",
      "|    std                | 2.47e+06      |\n",
      "|    value_loss         | 0.00209       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 83800        |\n",
      "|    time_elapsed       | 1293         |\n",
      "|    total_timesteps    | 419000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83799        |\n",
      "|    policy_loss        | 0.904        |\n",
      "|    reward             | -0.018535104 |\n",
      "|    std                | 2.49e+06     |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 83900         |\n",
      "|    time_elapsed       | 1294          |\n",
      "|    total_timesteps    | 419500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83899         |\n",
      "|    policy_loss        | 0.352         |\n",
      "|    reward             | -0.0028244483 |\n",
      "|    std                | 2.54e+06      |\n",
      "|    value_loss         | 0.000164      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 84000        |\n",
      "|    time_elapsed       | 1296         |\n",
      "|    total_timesteps    | 420000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | -0.405       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83999        |\n",
      "|    policy_loss        | -0.65        |\n",
      "|    reward             | -0.003303964 |\n",
      "|    std                | 2.59e+06     |\n",
      "|    value_loss         | 0.000709     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 84100        |\n",
      "|    time_elapsed       | 1297         |\n",
      "|    total_timesteps    | 420500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | -0.00457     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84099        |\n",
      "|    policy_loss        | 0.336        |\n",
      "|    reward             | -0.010071657 |\n",
      "|    std                | 2.64e+06     |\n",
      "|    value_loss         | 0.000251     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 84200        |\n",
      "|    time_elapsed       | 1299         |\n",
      "|    total_timesteps    | 421000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84199        |\n",
      "|    policy_loss        | 0.0379       |\n",
      "|    reward             | -0.012451801 |\n",
      "|    std                | 2.68e+06     |\n",
      "|    value_loss         | 3.64e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 84300        |\n",
      "|    time_elapsed       | 1300         |\n",
      "|    total_timesteps    | 421500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84299        |\n",
      "|    policy_loss        | -0.537       |\n",
      "|    reward             | -0.074535176 |\n",
      "|    std                | 2.74e+06     |\n",
      "|    value_loss         | 0.000706     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 84400        |\n",
      "|    time_elapsed       | 1302         |\n",
      "|    total_timesteps    | 422000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84399        |\n",
      "|    policy_loss        | 1.03         |\n",
      "|    reward             | -0.022661949 |\n",
      "|    std                | 2.73e+06     |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 84500      |\n",
      "|    time_elapsed       | 1303       |\n",
      "|    total_timesteps    | 422500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.5      |\n",
      "|    explained_variance | -0.00368   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84499      |\n",
      "|    policy_loss        | 1.05       |\n",
      "|    reward             | 0.02225845 |\n",
      "|    std                | 2.78e+06   |\n",
      "|    value_loss         | 0.00235    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 84600        |\n",
      "|    time_elapsed       | 1305         |\n",
      "|    total_timesteps    | 423000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84599        |\n",
      "|    policy_loss        | 0.454        |\n",
      "|    reward             | -0.010156842 |\n",
      "|    std                | 2.8e+06      |\n",
      "|    value_loss         | 0.000388     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 84700       |\n",
      "|    time_elapsed       | 1306        |\n",
      "|    total_timesteps    | 423500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.5       |\n",
      "|    explained_variance | -0.0199     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84699       |\n",
      "|    policy_loss        | 5.04        |\n",
      "|    reward             | -0.15178274 |\n",
      "|    std                | 2.85e+06    |\n",
      "|    value_loss         | 0.0322      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 84800        |\n",
      "|    time_elapsed       | 1308         |\n",
      "|    total_timesteps    | 424000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84799        |\n",
      "|    policy_loss        | 1.49         |\n",
      "|    reward             | 0.0047464054 |\n",
      "|    std                | 2.85e+06     |\n",
      "|    value_loss         | 0.00217      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 84900       |\n",
      "|    time_elapsed       | 1309        |\n",
      "|    total_timesteps    | 424500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84899       |\n",
      "|    policy_loss        | 0.594       |\n",
      "|    reward             | 0.009644303 |\n",
      "|    std                | 2.89e+06    |\n",
      "|    value_loss         | 0.000515    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 85000       |\n",
      "|    time_elapsed       | 1311        |\n",
      "|    total_timesteps    | 425000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84999       |\n",
      "|    policy_loss        | -0.472      |\n",
      "|    reward             | 0.013021491 |\n",
      "|    std                | 2.95e+06    |\n",
      "|    value_loss         | 0.000271    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 85100        |\n",
      "|    time_elapsed       | 1313         |\n",
      "|    total_timesteps    | 425500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85099        |\n",
      "|    policy_loss        | 0.481        |\n",
      "|    reward             | -0.010977329 |\n",
      "|    std                | 3.03e+06     |\n",
      "|    value_loss         | 0.000274     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 85200        |\n",
      "|    time_elapsed       | 1314         |\n",
      "|    total_timesteps    | 426000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85199        |\n",
      "|    policy_loss        | 0.0385       |\n",
      "|    reward             | -0.011986659 |\n",
      "|    std                | 3.12e+06     |\n",
      "|    value_loss         | 5.82e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 85300       |\n",
      "|    time_elapsed       | 1316        |\n",
      "|    total_timesteps    | 426500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | -0.354      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85299       |\n",
      "|    policy_loss        | 0.328       |\n",
      "|    reward             | 0.014732432 |\n",
      "|    std                | 3.2e+06     |\n",
      "|    value_loss         | 0.000439    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 85400       |\n",
      "|    time_elapsed       | 1318        |\n",
      "|    total_timesteps    | 427000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85399       |\n",
      "|    policy_loss        | -0.684      |\n",
      "|    reward             | -0.05142795 |\n",
      "|    std                | 3.26e+06    |\n",
      "|    value_loss         | 0.000573    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 85500       |\n",
      "|    time_elapsed       | 1319        |\n",
      "|    total_timesteps    | 427500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85499       |\n",
      "|    policy_loss        | -0.916      |\n",
      "|    reward             | 0.014456825 |\n",
      "|    std                | 3.35e+06    |\n",
      "|    value_loss         | 0.000794    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 85600       |\n",
      "|    time_elapsed       | 1321        |\n",
      "|    total_timesteps    | 428000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85599       |\n",
      "|    policy_loss        | 0.126       |\n",
      "|    reward             | 0.003564336 |\n",
      "|    std                | 3.48e+06    |\n",
      "|    value_loss         | 6.74e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 85700         |\n",
      "|    time_elapsed       | 1322          |\n",
      "|    total_timesteps    | 428500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85699         |\n",
      "|    policy_loss        | 0.105         |\n",
      "|    reward             | -0.0029995008 |\n",
      "|    std                | 3.6e+06       |\n",
      "|    value_loss         | 1.12e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 85800        |\n",
      "|    time_elapsed       | 1324         |\n",
      "|    total_timesteps    | 429000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | -0.081       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85799        |\n",
      "|    policy_loss        | 0.288        |\n",
      "|    reward             | -0.004807494 |\n",
      "|    std                | 3.73e+06     |\n",
      "|    value_loss         | 0.000143     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 85900      |\n",
      "|    time_elapsed       | 1326       |\n",
      "|    total_timesteps    | 429500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.1      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85899      |\n",
      "|    policy_loss        | -0.0273    |\n",
      "|    reward             | 0.01239606 |\n",
      "|    std                | 3.83e+06   |\n",
      "|    value_loss         | 8.26e-05   |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -10585.51\n",
      "total_reward: -20585.51\n",
      "total_cost: 524.62\n",
      "total_trades: 5540\n",
      "Sharpe: 0.238\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 86000         |\n",
      "|    time_elapsed       | 1328          |\n",
      "|    total_timesteps    | 430000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85999         |\n",
      "|    policy_loss        | -0.206        |\n",
      "|    reward             | 0.00066776265 |\n",
      "|    std                | 3.97e+06      |\n",
      "|    value_loss         | 0.000204      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 86100       |\n",
      "|    time_elapsed       | 1329        |\n",
      "|    total_timesteps    | 430500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86099       |\n",
      "|    policy_loss        | 0.125       |\n",
      "|    reward             | -0.00607363 |\n",
      "|    std                | 4.08e+06    |\n",
      "|    value_loss         | 5.32e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 86200        |\n",
      "|    time_elapsed       | 1331         |\n",
      "|    total_timesteps    | 431000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86199        |\n",
      "|    policy_loss        | -0.557       |\n",
      "|    reward             | -0.004972282 |\n",
      "|    std                | 4.26e+06     |\n",
      "|    value_loss         | 0.000416     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 86300        |\n",
      "|    time_elapsed       | 1333         |\n",
      "|    total_timesteps    | 431500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.4        |\n",
      "|    explained_variance | -1.63        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86299        |\n",
      "|    policy_loss        | 0.194        |\n",
      "|    reward             | -0.009014645 |\n",
      "|    std                | 4.4e+06      |\n",
      "|    value_loss         | 4.2e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 86400       |\n",
      "|    time_elapsed       | 1334        |\n",
      "|    total_timesteps    | 432000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | -0.117      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86399       |\n",
      "|    policy_loss        | 1.53        |\n",
      "|    reward             | -0.03195229 |\n",
      "|    std                | 4.6e+06     |\n",
      "|    value_loss         | 0.00203     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 86500        |\n",
      "|    time_elapsed       | 1336         |\n",
      "|    total_timesteps    | 432500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86499        |\n",
      "|    policy_loss        | -2.34        |\n",
      "|    reward             | -0.010660776 |\n",
      "|    std                | 4.7e+06      |\n",
      "|    value_loss         | 0.0059       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 86600      |\n",
      "|    time_elapsed       | 1338       |\n",
      "|    total_timesteps    | 433000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86599      |\n",
      "|    policy_loss        | 0.421      |\n",
      "|    reward             | 0.03584753 |\n",
      "|    std                | 4.79e+06   |\n",
      "|    value_loss         | 0.000489   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 86700       |\n",
      "|    time_elapsed       | 1339        |\n",
      "|    total_timesteps    | 433500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.6       |\n",
      "|    explained_variance | 0.0976      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86699       |\n",
      "|    policy_loss        | -0.101      |\n",
      "|    reward             | -0.00819015 |\n",
      "|    std                | 4.85e+06    |\n",
      "|    value_loss         | 0.000434    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 86800         |\n",
      "|    time_elapsed       | 1341          |\n",
      "|    total_timesteps    | 434000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86799         |\n",
      "|    policy_loss        | -0.643        |\n",
      "|    reward             | -0.0026448334 |\n",
      "|    std                | 4.92e+06      |\n",
      "|    value_loss         | 0.00312       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 86900      |\n",
      "|    time_elapsed       | 1343       |\n",
      "|    total_timesteps    | 434500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.7      |\n",
      "|    explained_variance | 0.235      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86899      |\n",
      "|    policy_loss        | -3.14      |\n",
      "|    reward             | 0.01496151 |\n",
      "|    std                | 4.99e+06   |\n",
      "|    value_loss         | 0.00947    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 87000      |\n",
      "|    time_elapsed       | 1345       |\n",
      "|    total_timesteps    | 435000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86999      |\n",
      "|    policy_loss        | -3.07      |\n",
      "|    reward             | 0.27341464 |\n",
      "|    std                | 5.03e+06   |\n",
      "|    value_loss         | 0.0109     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 87100        |\n",
      "|    time_elapsed       | 1346         |\n",
      "|    total_timesteps    | 435500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87099        |\n",
      "|    policy_loss        | -2.9         |\n",
      "|    reward             | -0.113238126 |\n",
      "|    std                | 5.08e+06     |\n",
      "|    value_loss         | 0.00868      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1348        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | -0.166      |\n",
      "|    reward             | -0.07623159 |\n",
      "|    std                | 5.11e+06    |\n",
      "|    value_loss         | 7.85e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 87300       |\n",
      "|    time_elapsed       | 1349        |\n",
      "|    total_timesteps    | 436500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87299       |\n",
      "|    policy_loss        | 1.17        |\n",
      "|    reward             | 0.015516239 |\n",
      "|    std                | 5.2e+06     |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 87400       |\n",
      "|    time_elapsed       | 1351        |\n",
      "|    total_timesteps    | 437000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87399       |\n",
      "|    policy_loss        | 3.39        |\n",
      "|    reward             | -0.05829227 |\n",
      "|    std                | 5.21e+06    |\n",
      "|    value_loss         | 0.0112      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 87500       |\n",
      "|    time_elapsed       | 1353        |\n",
      "|    total_timesteps    | 437500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87499       |\n",
      "|    policy_loss        | 0.282       |\n",
      "|    reward             | 0.049286053 |\n",
      "|    std                | 5.3e+06     |\n",
      "|    value_loss         | 0.00299     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 87600        |\n",
      "|    time_elapsed       | 1355         |\n",
      "|    total_timesteps    | 438000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87599        |\n",
      "|    policy_loss        | -0.346       |\n",
      "|    reward             | 0.0055991914 |\n",
      "|    std                | 5.33e+06     |\n",
      "|    value_loss         | 0.000277     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 87700       |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 438500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87699       |\n",
      "|    policy_loss        | 0.337       |\n",
      "|    reward             | 0.028028637 |\n",
      "|    std                | 5.42e+06    |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 87800      |\n",
      "|    time_elapsed       | 1358       |\n",
      "|    total_timesteps    | 439000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87799      |\n",
      "|    policy_loss        | -0.222     |\n",
      "|    reward             | 0.02280491 |\n",
      "|    std                | 5.53e+06   |\n",
      "|    value_loss         | 0.000116   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 87900         |\n",
      "|    time_elapsed       | 1360          |\n",
      "|    total_timesteps    | 439500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87899         |\n",
      "|    policy_loss        | 0.258         |\n",
      "|    reward             | -0.0075181215 |\n",
      "|    std                | 5.75e+06      |\n",
      "|    value_loss         | 0.000108      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 88000         |\n",
      "|    time_elapsed       | 1362          |\n",
      "|    total_timesteps    | 440000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34           |\n",
      "|    explained_variance | -0.0297       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87999         |\n",
      "|    policy_loss        | -0.537        |\n",
      "|    reward             | -0.0012383374 |\n",
      "|    std                | 6e+06         |\n",
      "|    value_loss         | 0.000389      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 88100        |\n",
      "|    time_elapsed       | 1364         |\n",
      "|    total_timesteps    | 440500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88099        |\n",
      "|    policy_loss        | -0.262       |\n",
      "|    reward             | -0.016348293 |\n",
      "|    std                | 6.14e+06     |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 88200        |\n",
      "|    time_elapsed       | 1366         |\n",
      "|    total_timesteps    | 441000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88199        |\n",
      "|    policy_loss        | -1.92        |\n",
      "|    reward             | -0.014127928 |\n",
      "|    std                | 6.26e+06     |\n",
      "|    value_loss         | 0.00384      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 88300        |\n",
      "|    time_elapsed       | 1367         |\n",
      "|    total_timesteps    | 441500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88299        |\n",
      "|    policy_loss        | 0.181        |\n",
      "|    reward             | -0.006965012 |\n",
      "|    std                | 6.41e+06     |\n",
      "|    value_loss         | 7.01e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 88400        |\n",
      "|    time_elapsed       | 1369         |\n",
      "|    total_timesteps    | 442000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88399        |\n",
      "|    policy_loss        | 0.154        |\n",
      "|    reward             | -0.023894046 |\n",
      "|    std                | 6.59e+06     |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 88500       |\n",
      "|    time_elapsed       | 1371        |\n",
      "|    total_timesteps    | 442500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.3       |\n",
      "|    explained_variance | 0.0497      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88499       |\n",
      "|    policy_loss        | -0.102      |\n",
      "|    reward             | 0.006484475 |\n",
      "|    std                | 6.83e+06    |\n",
      "|    value_loss         | 1.37e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 88600       |\n",
      "|    time_elapsed       | 1373        |\n",
      "|    total_timesteps    | 443000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.4       |\n",
      "|    explained_variance | 0.26        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88599       |\n",
      "|    policy_loss        | 0.0797      |\n",
      "|    reward             | 0.004427698 |\n",
      "|    std                | 7.11e+06    |\n",
      "|    value_loss         | 1.36e-05    |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -14043.03\n",
      "total_reward: -24043.03\n",
      "total_cost: 382.45\n",
      "total_trades: 5540\n",
      "Sharpe: 0.171\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 88700         |\n",
      "|    time_elapsed       | 1375          |\n",
      "|    total_timesteps    | 443500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88699         |\n",
      "|    policy_loss        | -0.0868       |\n",
      "|    reward             | -0.0010957082 |\n",
      "|    std                | 7.34e+06      |\n",
      "|    value_loss         | 4.36e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 88800        |\n",
      "|    time_elapsed       | 1376         |\n",
      "|    total_timesteps    | 444000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88799        |\n",
      "|    policy_loss        | 0.149        |\n",
      "|    reward             | 0.0036564902 |\n",
      "|    std                | 7.56e+06     |\n",
      "|    value_loss         | 1.96e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 88900      |\n",
      "|    time_elapsed       | 1378       |\n",
      "|    total_timesteps    | 444500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.5      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88899      |\n",
      "|    policy_loss        | 0.388      |\n",
      "|    reward             | 0.04827369 |\n",
      "|    std                | 7.8e+06    |\n",
      "|    value_loss         | 0.000246   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 89000        |\n",
      "|    time_elapsed       | 1380         |\n",
      "|    total_timesteps    | 445000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88999        |\n",
      "|    policy_loss        | -0.256       |\n",
      "|    reward             | -0.012033039 |\n",
      "|    std                | 8.11e+06     |\n",
      "|    value_loss         | 6.19e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 89100         |\n",
      "|    time_elapsed       | 1382          |\n",
      "|    total_timesteps    | 445500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89099         |\n",
      "|    policy_loss        | -0.277        |\n",
      "|    reward             | -0.0084062405 |\n",
      "|    std                | 8.57e+06      |\n",
      "|    value_loss         | 0.000143      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 89200       |\n",
      "|    time_elapsed       | 1384        |\n",
      "|    total_timesteps    | 446000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89199       |\n",
      "|    policy_loss        | 0.349       |\n",
      "|    reward             | -0.01025018 |\n",
      "|    std                | 9e+06       |\n",
      "|    value_loss         | 0.00012     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 89300       |\n",
      "|    time_elapsed       | 1385        |\n",
      "|    total_timesteps    | 446500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89299       |\n",
      "|    policy_loss        | 0.176       |\n",
      "|    reward             | 0.016772103 |\n",
      "|    std                | 9.36e+06    |\n",
      "|    value_loss         | 0.000955    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 89400        |\n",
      "|    time_elapsed       | 1387         |\n",
      "|    total_timesteps    | 447000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89399        |\n",
      "|    policy_loss        | 0.139        |\n",
      "|    reward             | 0.0017464431 |\n",
      "|    std                | 9.45e+06     |\n",
      "|    value_loss         | 6.02e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 89500       |\n",
      "|    time_elapsed       | 1389        |\n",
      "|    total_timesteps    | 447500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35         |\n",
      "|    explained_variance | 0.00502     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89499       |\n",
      "|    policy_loss        | 0.504       |\n",
      "|    reward             | 0.014063437 |\n",
      "|    std                | 9.69e+06    |\n",
      "|    value_loss         | 0.00157     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 89600        |\n",
      "|    time_elapsed       | 1390         |\n",
      "|    total_timesteps    | 448000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | 0.12         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89599        |\n",
      "|    policy_loss        | 0.629        |\n",
      "|    reward             | 0.0017335693 |\n",
      "|    std                | 1.01e+07     |\n",
      "|    value_loss         | 0.000556     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 89700      |\n",
      "|    time_elapsed       | 1392       |\n",
      "|    total_timesteps    | 448500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.1      |\n",
      "|    explained_variance | 0.156      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89699      |\n",
      "|    policy_loss        | -1.08      |\n",
      "|    reward             | -0.0331355 |\n",
      "|    std                | 1.01e+07   |\n",
      "|    value_loss         | 0.00166    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 89800         |\n",
      "|    time_elapsed       | 1394          |\n",
      "|    total_timesteps    | 449000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89799         |\n",
      "|    policy_loss        | 1.68          |\n",
      "|    reward             | 0.00094392773 |\n",
      "|    std                | 1.03e+07      |\n",
      "|    value_loss         | 0.00298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 89900         |\n",
      "|    time_elapsed       | 1396          |\n",
      "|    total_timesteps    | 449500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89899         |\n",
      "|    policy_loss        | -0.756        |\n",
      "|    reward             | 0.00044680524 |\n",
      "|    std                | 1.05e+07      |\n",
      "|    value_loss         | 0.000517      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 90000        |\n",
      "|    time_elapsed       | 1397         |\n",
      "|    total_timesteps    | 450000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89999        |\n",
      "|    policy_loss        | 0.296        |\n",
      "|    reward             | 0.0038619617 |\n",
      "|    std                | 1.07e+07     |\n",
      "|    value_loss         | 8.7e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 90100        |\n",
      "|    time_elapsed       | 1399         |\n",
      "|    total_timesteps    | 450500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90099        |\n",
      "|    policy_loss        | -0.0288      |\n",
      "|    reward             | -0.010311475 |\n",
      "|    std                | 1.12e+07     |\n",
      "|    value_loss         | 3.96e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 90200       |\n",
      "|    time_elapsed       | 1401        |\n",
      "|    total_timesteps    | 451000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90199       |\n",
      "|    policy_loss        | -1.06       |\n",
      "|    reward             | 0.012319679 |\n",
      "|    std                | 1.16e+07    |\n",
      "|    value_loss         | 0.000962    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 1402        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | -0.262      |\n",
      "|    reward             | 0.014177155 |\n",
      "|    std                | 1.21e+07    |\n",
      "|    value_loss         | 8e-05       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 90400        |\n",
      "|    time_elapsed       | 1404         |\n",
      "|    total_timesteps    | 452000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90399        |\n",
      "|    policy_loss        | 7.13         |\n",
      "|    reward             | -0.075593576 |\n",
      "|    std                | 1.26e+07     |\n",
      "|    value_loss         | 0.0424       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 90500        |\n",
      "|    time_elapsed       | 1406         |\n",
      "|    total_timesteps    | 452500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90499        |\n",
      "|    policy_loss        | 0.566        |\n",
      "|    reward             | -0.030252712 |\n",
      "|    std                | 1.28e+07     |\n",
      "|    value_loss         | 0.000706     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 90600        |\n",
      "|    time_elapsed       | 1407         |\n",
      "|    total_timesteps    | 453000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | -0.000248    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90599        |\n",
      "|    policy_loss        | -1.33        |\n",
      "|    reward             | -0.100243494 |\n",
      "|    std                | 1.3e+07      |\n",
      "|    value_loss         | 0.00462      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 90700       |\n",
      "|    time_elapsed       | 1409        |\n",
      "|    total_timesteps    | 453500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | 0.314       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90699       |\n",
      "|    policy_loss        | 6.01        |\n",
      "|    reward             | -0.03796041 |\n",
      "|    std                | 1.31e+07    |\n",
      "|    value_loss         | 0.03        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 90800       |\n",
      "|    time_elapsed       | 1410        |\n",
      "|    total_timesteps    | 454000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | 0.005       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90799       |\n",
      "|    policy_loss        | -3.75       |\n",
      "|    reward             | -0.24396612 |\n",
      "|    std                | 1.31e+07    |\n",
      "|    value_loss         | 0.02        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 90900       |\n",
      "|    time_elapsed       | 1412        |\n",
      "|    total_timesteps    | 454500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90899       |\n",
      "|    policy_loss        | -1.37       |\n",
      "|    reward             | 0.043604337 |\n",
      "|    std                | 1.34e+07    |\n",
      "|    value_loss         | 0.0018      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 91000       |\n",
      "|    time_elapsed       | 1413        |\n",
      "|    total_timesteps    | 455000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90999       |\n",
      "|    policy_loss        | -1.58       |\n",
      "|    reward             | 0.018218584 |\n",
      "|    std                | 1.34e+07    |\n",
      "|    value_loss         | 0.00432     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 91100       |\n",
      "|    time_elapsed       | 1415        |\n",
      "|    total_timesteps    | 455500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91099       |\n",
      "|    policy_loss        | -0.364      |\n",
      "|    reward             | 0.002656923 |\n",
      "|    std                | 1.36e+07    |\n",
      "|    value_loss         | 0.000127    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 91200        |\n",
      "|    time_elapsed       | 1416         |\n",
      "|    total_timesteps    | 456000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91199        |\n",
      "|    policy_loss        | -0.638       |\n",
      "|    reward             | -0.019022308 |\n",
      "|    std                | 1.38e+07     |\n",
      "|    value_loss         | 0.000698     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 91300        |\n",
      "|    time_elapsed       | 1418         |\n",
      "|    total_timesteps    | 456500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 0.0749       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91299        |\n",
      "|    policy_loss        | -1.77        |\n",
      "|    reward             | -0.053055152 |\n",
      "|    std                | 1.4e+07      |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 91400       |\n",
      "|    time_elapsed       | 1420        |\n",
      "|    total_timesteps    | 457000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.7       |\n",
      "|    explained_variance | 0.0173      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91399       |\n",
      "|    policy_loss        | -4.69       |\n",
      "|    reward             | 0.045932606 |\n",
      "|    std                | 1.41e+07    |\n",
      "|    value_loss         | 0.0204      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -70643.37\n",
      "total_reward: -80643.37\n",
      "total_cost: 97.61\n",
      "total_trades: 5540\n",
      "Sharpe: 0.106\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 91500        |\n",
      "|    time_elapsed       | 1421         |\n",
      "|    total_timesteps    | 457500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91499        |\n",
      "|    policy_loss        | -4.11        |\n",
      "|    reward             | -0.040029284 |\n",
      "|    std                | 1.43e+07     |\n",
      "|    value_loss         | 0.0246       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 91600        |\n",
      "|    time_elapsed       | 1423         |\n",
      "|    total_timesteps    | 458000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91599        |\n",
      "|    policy_loss        | -3.33        |\n",
      "|    reward             | -0.048070952 |\n",
      "|    std                | 1.44e+07     |\n",
      "|    value_loss         | 0.00999      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 91700      |\n",
      "|    time_elapsed       | 1424       |\n",
      "|    total_timesteps    | 458500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91699      |\n",
      "|    policy_loss        | -3.59      |\n",
      "|    reward             | 0.02516854 |\n",
      "|    std                | 1.48e+07   |\n",
      "|    value_loss         | 0.0232     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 91800      |\n",
      "|    time_elapsed       | 1426       |\n",
      "|    total_timesteps    | 459000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91799      |\n",
      "|    policy_loss        | -3.79      |\n",
      "|    reward             | 0.06457634 |\n",
      "|    std                | 1.5e+07    |\n",
      "|    value_loss         | 0.0201     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 91900        |\n",
      "|    time_elapsed       | 1428         |\n",
      "|    total_timesteps    | 459500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91899        |\n",
      "|    policy_loss        | 7.6          |\n",
      "|    reward             | -0.015126921 |\n",
      "|    std                | 1.5e+07      |\n",
      "|    value_loss         | 0.0603       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 92000       |\n",
      "|    time_elapsed       | 1429        |\n",
      "|    total_timesteps    | 460000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91999       |\n",
      "|    policy_loss        | 0.0715      |\n",
      "|    reward             | 0.003352892 |\n",
      "|    std                | 1.52e+07    |\n",
      "|    value_loss         | 0.000258    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 92100       |\n",
      "|    time_elapsed       | 1431        |\n",
      "|    total_timesteps    | 460500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92099       |\n",
      "|    policy_loss        | 0.657       |\n",
      "|    reward             | 0.004626779 |\n",
      "|    std                | 1.53e+07    |\n",
      "|    value_loss         | 0.00043     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 92200       |\n",
      "|    time_elapsed       | 1433        |\n",
      "|    total_timesteps    | 461000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92199       |\n",
      "|    policy_loss        | 0.837       |\n",
      "|    reward             | 0.014723256 |\n",
      "|    std                | 1.55e+07    |\n",
      "|    value_loss         | 0.000576    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 92300       |\n",
      "|    time_elapsed       | 1434        |\n",
      "|    total_timesteps    | 461500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92299       |\n",
      "|    policy_loss        | 0.00929     |\n",
      "|    reward             | 0.012695218 |\n",
      "|    std                | 1.58e+07    |\n",
      "|    value_loss         | 2.9e-05     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 92400        |\n",
      "|    time_elapsed       | 1436         |\n",
      "|    total_timesteps    | 462000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36          |\n",
      "|    explained_variance | 0.0374       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92399        |\n",
      "|    policy_loss        | -0.232       |\n",
      "|    reward             | -0.017899176 |\n",
      "|    std                | 1.62e+07     |\n",
      "|    value_loss         | 7.88e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 92500      |\n",
      "|    time_elapsed       | 1437       |\n",
      "|    total_timesteps    | 462500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92499      |\n",
      "|    policy_loss        | -0.0298    |\n",
      "|    reward             | 0.03580519 |\n",
      "|    std                | 1.68e+07   |\n",
      "|    value_loss         | 0.00146    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 92600        |\n",
      "|    time_elapsed       | 1439         |\n",
      "|    total_timesteps    | 463000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92599        |\n",
      "|    policy_loss        | 3.08         |\n",
      "|    reward             | -0.091552824 |\n",
      "|    std                | 1.7e+07      |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 92700       |\n",
      "|    time_elapsed       | 1440        |\n",
      "|    total_timesteps    | 463500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92699       |\n",
      "|    policy_loss        | -2.54       |\n",
      "|    reward             | 0.046198368 |\n",
      "|    std                | 1.72e+07    |\n",
      "|    value_loss         | 0.00654     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 92800       |\n",
      "|    time_elapsed       | 1442        |\n",
      "|    total_timesteps    | 464000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92799       |\n",
      "|    policy_loss        | -6.34       |\n",
      "|    reward             | 0.021012394 |\n",
      "|    std                | 1.74e+07    |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 92900       |\n",
      "|    time_elapsed       | 1444        |\n",
      "|    total_timesteps    | 464500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92899       |\n",
      "|    policy_loss        | -0.327      |\n",
      "|    reward             | 0.023387104 |\n",
      "|    std                | 1.76e+07    |\n",
      "|    value_loss         | 0.00625     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 93000      |\n",
      "|    time_elapsed       | 1445       |\n",
      "|    total_timesteps    | 465000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92999      |\n",
      "|    policy_loss        | 11         |\n",
      "|    reward             | 0.10553625 |\n",
      "|    std                | 1.79e+07   |\n",
      "|    value_loss         | 0.0923     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 93100       |\n",
      "|    time_elapsed       | 1447        |\n",
      "|    total_timesteps    | 465500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.2       |\n",
      "|    explained_variance | 0.24        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93099       |\n",
      "|    policy_loss        | -6.05       |\n",
      "|    reward             | -0.48180947 |\n",
      "|    std                | 1.81e+07    |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 93200        |\n",
      "|    time_elapsed       | 1449         |\n",
      "|    total_timesteps    | 466000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93199        |\n",
      "|    policy_loss        | -0.0988      |\n",
      "|    reward             | 0.0036787363 |\n",
      "|    std                | 1.82e+07     |\n",
      "|    value_loss         | 0.000126     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 93300       |\n",
      "|    time_elapsed       | 1450        |\n",
      "|    total_timesteps    | 466500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93299       |\n",
      "|    policy_loss        | 0.136       |\n",
      "|    reward             | -0.01712581 |\n",
      "|    std                | 1.84e+07    |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 93400      |\n",
      "|    time_elapsed       | 1452       |\n",
      "|    total_timesteps    | 467000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93399      |\n",
      "|    policy_loss        | -1.29      |\n",
      "|    reward             | 0.03644391 |\n",
      "|    std                | 1.87e+07   |\n",
      "|    value_loss         | 0.00131    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 93500       |\n",
      "|    time_elapsed       | 1453        |\n",
      "|    total_timesteps    | 467500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.4       |\n",
      "|    explained_variance | 0.13        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93499       |\n",
      "|    policy_loss        | 0.429       |\n",
      "|    reward             | -0.00931378 |\n",
      "|    std                | 1.93e+07    |\n",
      "|    value_loss         | 0.000143    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 93600        |\n",
      "|    time_elapsed       | 1455         |\n",
      "|    total_timesteps    | 468000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.4        |\n",
      "|    explained_variance | -3.14        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93599        |\n",
      "|    policy_loss        | -0.231       |\n",
      "|    reward             | -0.013350485 |\n",
      "|    std                | 2.01e+07     |\n",
      "|    value_loss         | 0.000161     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 93700      |\n",
      "|    time_elapsed       | 1456       |\n",
      "|    total_timesteps    | 468500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93699      |\n",
      "|    policy_loss        | -2.21      |\n",
      "|    reward             | 0.08660274 |\n",
      "|    std                | 2.06e+07   |\n",
      "|    value_loss         | 0.00395    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 93800        |\n",
      "|    time_elapsed       | 1458         |\n",
      "|    total_timesteps    | 469000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93799        |\n",
      "|    policy_loss        | -0.837       |\n",
      "|    reward             | -0.016638061 |\n",
      "|    std                | 2.1e+07      |\n",
      "|    value_loss         | 0.00301      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 93900       |\n",
      "|    time_elapsed       | 1460        |\n",
      "|    total_timesteps    | 469500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93899       |\n",
      "|    policy_loss        | 1.47        |\n",
      "|    reward             | -0.27178213 |\n",
      "|    std                | 2.09e+07    |\n",
      "|    value_loss         | 0.00182     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 94000        |\n",
      "|    time_elapsed       | 1461         |\n",
      "|    total_timesteps    | 470000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93999        |\n",
      "|    policy_loss        | -1.09        |\n",
      "|    reward             | -0.081184044 |\n",
      "|    std                | 2.08e+07     |\n",
      "|    value_loss         | 0.00415      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 94100       |\n",
      "|    time_elapsed       | 1463        |\n",
      "|    total_timesteps    | 470500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | 0.378       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94099       |\n",
      "|    policy_loss        | 15.6        |\n",
      "|    reward             | -0.12942114 |\n",
      "|    std                | 2.11e+07    |\n",
      "|    value_loss         | 0.21        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 94200       |\n",
      "|    time_elapsed       | 1465        |\n",
      "|    total_timesteps    | 471000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94199       |\n",
      "|    policy_loss        | -6.9        |\n",
      "|    reward             | -0.21833624 |\n",
      "|    std                | 2.12e+07    |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -273900.83\n",
      "total_reward: -283900.83\n",
      "total_cost: 107.84\n",
      "total_trades: 5540\n",
      "Sharpe: 0.179\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 94300       |\n",
      "|    time_elapsed       | 1466        |\n",
      "|    total_timesteps    | 471500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94299       |\n",
      "|    policy_loss        | -0.699      |\n",
      "|    reward             | 0.014029684 |\n",
      "|    std                | 2.15e+07    |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 94400      |\n",
      "|    time_elapsed       | 1467       |\n",
      "|    total_timesteps    | 472000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.6      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94399      |\n",
      "|    policy_loss        | 0.229      |\n",
      "|    reward             | 0.01545778 |\n",
      "|    std                | 2.17e+07   |\n",
      "|    value_loss         | 0.000119   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 94500        |\n",
      "|    time_elapsed       | 1469         |\n",
      "|    total_timesteps    | 472500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.6        |\n",
      "|    explained_variance | -24.2        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94499        |\n",
      "|    policy_loss        | 1.52         |\n",
      "|    reward             | -0.034844853 |\n",
      "|    std                | 2.21e+07     |\n",
      "|    value_loss         | 0.00565      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 94600      |\n",
      "|    time_elapsed       | 1471       |\n",
      "|    total_timesteps    | 473000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.7      |\n",
      "|    explained_variance | -0.5       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94599      |\n",
      "|    policy_loss        | -2.92      |\n",
      "|    reward             | 0.07486829 |\n",
      "|    std                | 2.25e+07   |\n",
      "|    value_loss         | 0.00954    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 94700       |\n",
      "|    time_elapsed       | 1472        |\n",
      "|    total_timesteps    | 473500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94699       |\n",
      "|    policy_loss        | 1.08        |\n",
      "|    reward             | -0.05967601 |\n",
      "|    std                | 2.25e+07    |\n",
      "|    value_loss         | 0.00161     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 94800       |\n",
      "|    time_elapsed       | 1474        |\n",
      "|    total_timesteps    | 474000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94799       |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | 0.068322934 |\n",
      "|    std                | 2.27e+07    |\n",
      "|    value_loss         | 0.00295     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 94900         |\n",
      "|    time_elapsed       | 1475          |\n",
      "|    total_timesteps    | 474500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 94899         |\n",
      "|    policy_loss        | -1.66         |\n",
      "|    reward             | 4.9708397e-05 |\n",
      "|    std                | 2.29e+07      |\n",
      "|    value_loss         | 0.00254       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 95000        |\n",
      "|    time_elapsed       | 1477         |\n",
      "|    total_timesteps    | 475000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94999        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | -0.032748528 |\n",
      "|    std                | 2.32e+07     |\n",
      "|    value_loss         | 0.000138     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 95100        |\n",
      "|    time_elapsed       | 1478         |\n",
      "|    total_timesteps    | 475500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.8        |\n",
      "|    explained_variance | -0.709       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95099        |\n",
      "|    policy_loss        | 1.67         |\n",
      "|    reward             | 0.0055940836 |\n",
      "|    std                | 2.36e+07     |\n",
      "|    value_loss         | 0.00222      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 95200       |\n",
      "|    time_elapsed       | 1480        |\n",
      "|    total_timesteps    | 476000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.8       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95199       |\n",
      "|    policy_loss        | 2.06        |\n",
      "|    reward             | 0.024159929 |\n",
      "|    std                | 2.42e+07    |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 95300        |\n",
      "|    time_elapsed       | 1482         |\n",
      "|    total_timesteps    | 476500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.8        |\n",
      "|    explained_variance | 0.0633       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95299        |\n",
      "|    policy_loss        | 0.676        |\n",
      "|    reward             | -0.042711813 |\n",
      "|    std                | 2.43e+07     |\n",
      "|    value_loss         | 0.000557     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 95400        |\n",
      "|    time_elapsed       | 1483         |\n",
      "|    total_timesteps    | 477000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95399        |\n",
      "|    policy_loss        | -1.3         |\n",
      "|    reward             | 0.0018520043 |\n",
      "|    std                | 2.45e+07     |\n",
      "|    value_loss         | 0.00208      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 95500        |\n",
      "|    time_elapsed       | 1485         |\n",
      "|    total_timesteps    | 477500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95499        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | -0.032944374 |\n",
      "|    std                | 2.49e+07     |\n",
      "|    value_loss         | 4.72e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 95600      |\n",
      "|    time_elapsed       | 1487       |\n",
      "|    total_timesteps    | 478000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.9      |\n",
      "|    explained_variance | -1.67e-06  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95599      |\n",
      "|    policy_loss        | 7.05       |\n",
      "|    reward             | 0.02770731 |\n",
      "|    std                | 2.53e+07   |\n",
      "|    value_loss         | 0.0371     |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 95700          |\n",
      "|    time_elapsed       | 1488           |\n",
      "|    total_timesteps    | 478500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -36.9          |\n",
      "|    explained_variance | 0.00684        |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 95699          |\n",
      "|    policy_loss        | 1.88           |\n",
      "|    reward             | -0.00023776703 |\n",
      "|    std                | 2.57e+07       |\n",
      "|    value_loss         | 0.00329        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 95800        |\n",
      "|    time_elapsed       | 1490         |\n",
      "|    total_timesteps    | 479000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37          |\n",
      "|    explained_variance | -0.0473      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95799        |\n",
      "|    policy_loss        | 0.127        |\n",
      "|    reward             | -0.008819367 |\n",
      "|    std                | 2.64e+07     |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 95900        |\n",
      "|    time_elapsed       | 1491         |\n",
      "|    total_timesteps    | 479500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95899        |\n",
      "|    policy_loss        | 3.81         |\n",
      "|    reward             | -0.046742227 |\n",
      "|    std                | 2.72e+07     |\n",
      "|    value_loss         | 0.0115       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 96000       |\n",
      "|    time_elapsed       | 1493        |\n",
      "|    total_timesteps    | 480000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95999       |\n",
      "|    policy_loss        | 0.426       |\n",
      "|    reward             | 0.005015681 |\n",
      "|    std                | 2.75e+07    |\n",
      "|    value_loss         | 0.000253    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 96100         |\n",
      "|    time_elapsed       | 1494          |\n",
      "|    total_timesteps    | 480500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96099         |\n",
      "|    policy_loss        | -4.51         |\n",
      "|    reward             | -0.0026815156 |\n",
      "|    std                | 2.81e+07      |\n",
      "|    value_loss         | 0.0163        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 96200         |\n",
      "|    time_elapsed       | 1496          |\n",
      "|    total_timesteps    | 481000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.1         |\n",
      "|    explained_variance | -0.931        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96199         |\n",
      "|    policy_loss        | 0.492         |\n",
      "|    reward             | -0.0067916443 |\n",
      "|    std                | 2.88e+07      |\n",
      "|    value_loss         | 0.000517      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 96300       |\n",
      "|    time_elapsed       | 1497        |\n",
      "|    total_timesteps    | 481500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.2       |\n",
      "|    explained_variance | 0.106       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96299       |\n",
      "|    policy_loss        | -0.806      |\n",
      "|    reward             | -0.02202785 |\n",
      "|    std                | 2.93e+07    |\n",
      "|    value_loss         | 0.000696    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 96400        |\n",
      "|    time_elapsed       | 1499         |\n",
      "|    total_timesteps    | 482000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96399        |\n",
      "|    policy_loss        | -0.384       |\n",
      "|    reward             | -0.037894618 |\n",
      "|    std                | 2.98e+07     |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 96500        |\n",
      "|    time_elapsed       | 1500         |\n",
      "|    total_timesteps    | 482500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96499        |\n",
      "|    policy_loss        | 9.64         |\n",
      "|    reward             | -0.037675112 |\n",
      "|    std                | 3.02e+07     |\n",
      "|    value_loss         | 0.0725       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 96600        |\n",
      "|    time_elapsed       | 1502         |\n",
      "|    total_timesteps    | 483000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96599        |\n",
      "|    policy_loss        | -0.0334      |\n",
      "|    reward             | -0.025240606 |\n",
      "|    std                | 3.05e+07     |\n",
      "|    value_loss         | 0.000188     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 96700      |\n",
      "|    time_elapsed       | 1503       |\n",
      "|    total_timesteps    | 483500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.3      |\n",
      "|    explained_variance | 0.0904     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96699      |\n",
      "|    policy_loss        | 0.707      |\n",
      "|    reward             | 0.02107524 |\n",
      "|    std                | 3.12e+07   |\n",
      "|    value_loss         | 0.00119    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 96800        |\n",
      "|    time_elapsed       | 1505         |\n",
      "|    total_timesteps    | 484000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96799        |\n",
      "|    policy_loss        | 0.304        |\n",
      "|    reward             | -0.019903453 |\n",
      "|    std                | 3.19e+07     |\n",
      "|    value_loss         | 0.000204     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 96900        |\n",
      "|    time_elapsed       | 1506         |\n",
      "|    total_timesteps    | 484500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.4        |\n",
      "|    explained_variance | 2.09e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96899        |\n",
      "|    policy_loss        | -2.66        |\n",
      "|    reward             | -0.018945731 |\n",
      "|    std                | 3.23e+07     |\n",
      "|    value_loss         | 0.00581      |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 175\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -74281.59\n",
      "total_reward: -84281.59\n",
      "total_cost: 94.64\n",
      "total_trades: 5540\n",
      "Sharpe: -0.519\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 97000        |\n",
      "|    time_elapsed       | 1508         |\n",
      "|    total_timesteps    | 485000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96999        |\n",
      "|    policy_loss        | -0.25        |\n",
      "|    reward             | 0.0050376025 |\n",
      "|    std                | 3.24e+07     |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 97100       |\n",
      "|    time_elapsed       | 1509        |\n",
      "|    total_timesteps    | 485500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97099       |\n",
      "|    policy_loss        | -0.301      |\n",
      "|    reward             | 0.011163217 |\n",
      "|    std                | 3.27e+07    |\n",
      "|    value_loss         | 0.000207    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 97200        |\n",
      "|    time_elapsed       | 1511         |\n",
      "|    total_timesteps    | 486000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97199        |\n",
      "|    policy_loss        | -0.674       |\n",
      "|    reward             | 0.0076423073 |\n",
      "|    std                | 3.34e+07     |\n",
      "|    value_loss         | 0.00036      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 97300       |\n",
      "|    time_elapsed       | 1512        |\n",
      "|    total_timesteps    | 486500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97299       |\n",
      "|    policy_loss        | 2.17        |\n",
      "|    reward             | 0.013929319 |\n",
      "|    std                | 3.45e+07    |\n",
      "|    value_loss         | 0.00344     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 97400        |\n",
      "|    time_elapsed       | 1514         |\n",
      "|    total_timesteps    | 487000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97399        |\n",
      "|    policy_loss        | 0.552        |\n",
      "|    reward             | 0.0021917347 |\n",
      "|    std                | 3.53e+07     |\n",
      "|    value_loss         | 0.000343     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 97500       |\n",
      "|    time_elapsed       | 1516        |\n",
      "|    total_timesteps    | 487500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 3.64e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97499       |\n",
      "|    policy_loss        | -0.269      |\n",
      "|    reward             | 0.015110831 |\n",
      "|    std                | 3.65e+07    |\n",
      "|    value_loss         | 0.000252    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 97600       |\n",
      "|    time_elapsed       | 1517        |\n",
      "|    total_timesteps    | 488000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97599       |\n",
      "|    policy_loss        | 0.0799      |\n",
      "|    reward             | 0.017236851 |\n",
      "|    std                | 3.8e+07     |\n",
      "|    value_loss         | 2.31e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 97700       |\n",
      "|    time_elapsed       | 1519        |\n",
      "|    total_timesteps    | 488500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97699       |\n",
      "|    policy_loss        | 0.446       |\n",
      "|    reward             | 0.007199154 |\n",
      "|    std                | 3.95e+07    |\n",
      "|    value_loss         | 0.000291    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 97800       |\n",
      "|    time_elapsed       | 1521        |\n",
      "|    total_timesteps    | 489000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97799       |\n",
      "|    policy_loss        | -0.304      |\n",
      "|    reward             | 0.017327176 |\n",
      "|    std                | 4.09e+07    |\n",
      "|    value_loss         | 0.000253    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 97900      |\n",
      "|    time_elapsed       | 1522       |\n",
      "|    total_timesteps    | 489500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.9      |\n",
      "|    explained_variance | -1.04e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97899      |\n",
      "|    policy_loss        | -0.71      |\n",
      "|    reward             | 0.00491597 |\n",
      "|    std                | 4.28e+07   |\n",
      "|    value_loss         | 0.000409   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 98000        |\n",
      "|    time_elapsed       | 1524         |\n",
      "|    total_timesteps    | 490000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38          |\n",
      "|    explained_variance | 0.0111       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97999        |\n",
      "|    policy_loss        | 1.06         |\n",
      "|    reward             | -0.000595191 |\n",
      "|    std                | 4.52e+07     |\n",
      "|    value_loss         | 0.00122      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 98100        |\n",
      "|    time_elapsed       | 1525         |\n",
      "|    total_timesteps    | 490500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98099        |\n",
      "|    policy_loss        | -2.32        |\n",
      "|    reward             | -0.002510654 |\n",
      "|    std                | 4.72e+07     |\n",
      "|    value_loss         | 0.00558      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 98200         |\n",
      "|    time_elapsed       | 1527          |\n",
      "|    total_timesteps    | 491000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 98199         |\n",
      "|    policy_loss        | 4.67          |\n",
      "|    reward             | 0.00040393326 |\n",
      "|    std                | 4.83e+07      |\n",
      "|    value_loss         | 0.0154        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 98300       |\n",
      "|    time_elapsed       | 1528        |\n",
      "|    total_timesteps    | 491500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98299       |\n",
      "|    policy_loss        | -1.43       |\n",
      "|    reward             | 0.010484587 |\n",
      "|    std                | 4.99e+07    |\n",
      "|    value_loss         | 0.002       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 98400       |\n",
      "|    time_elapsed       | 1530        |\n",
      "|    total_timesteps    | 492000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98399       |\n",
      "|    policy_loss        | 0.189       |\n",
      "|    reward             | 0.018769808 |\n",
      "|    std                | 5.15e+07    |\n",
      "|    value_loss         | 0.000362    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 98500       |\n",
      "|    time_elapsed       | 1531        |\n",
      "|    total_timesteps    | 492500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98499       |\n",
      "|    policy_loss        | 5.87        |\n",
      "|    reward             | 0.042237706 |\n",
      "|    std                | 5.19e+07    |\n",
      "|    value_loss         | 0.0283      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 98600        |\n",
      "|    time_elapsed       | 1533         |\n",
      "|    total_timesteps    | 493000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98599        |\n",
      "|    policy_loss        | -3.13        |\n",
      "|    reward             | -0.077048376 |\n",
      "|    std                | 5.31e+07     |\n",
      "|    value_loss         | 0.01         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 98700       |\n",
      "|    time_elapsed       | 1534        |\n",
      "|    total_timesteps    | 493500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98699       |\n",
      "|    policy_loss        | -0.198      |\n",
      "|    reward             | 0.025454413 |\n",
      "|    std                | 5.4e+07     |\n",
      "|    value_loss         | 0.000929    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 98800        |\n",
      "|    time_elapsed       | 1536         |\n",
      "|    total_timesteps    | 494000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98799        |\n",
      "|    policy_loss        | 0.0779       |\n",
      "|    reward             | -0.012181981 |\n",
      "|    std                | 5.47e+07     |\n",
      "|    value_loss         | 0.000717     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 98900        |\n",
      "|    time_elapsed       | 1538         |\n",
      "|    total_timesteps    | 494500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.4        |\n",
      "|    explained_variance | -0.00205     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98899        |\n",
      "|    policy_loss        | -0.0117      |\n",
      "|    reward             | 0.0006644409 |\n",
      "|    std                | 5.55e+07     |\n",
      "|    value_loss         | 0.000245     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 99000       |\n",
      "|    time_elapsed       | 1539        |\n",
      "|    total_timesteps    | 495000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98999       |\n",
      "|    policy_loss        | 0.351       |\n",
      "|    reward             | 0.010239307 |\n",
      "|    std                | 5.65e+07    |\n",
      "|    value_loss         | 0.000273    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 99100      |\n",
      "|    time_elapsed       | 1541       |\n",
      "|    total_timesteps    | 495500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99099      |\n",
      "|    policy_loss        | -1.59      |\n",
      "|    reward             | -0.0255635 |\n",
      "|    std                | 5.82e+07   |\n",
      "|    value_loss         | 0.00284    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 99200       |\n",
      "|    time_elapsed       | 1542        |\n",
      "|    total_timesteps    | 496000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99199       |\n",
      "|    policy_loss        | -4.1        |\n",
      "|    reward             | 0.075724356 |\n",
      "|    std                | 5.94e+07    |\n",
      "|    value_loss         | 0.0154      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 99300        |\n",
      "|    time_elapsed       | 1544         |\n",
      "|    total_timesteps    | 496500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99299        |\n",
      "|    policy_loss        | 5.35         |\n",
      "|    reward             | -0.095982246 |\n",
      "|    std                | 5.95e+07     |\n",
      "|    value_loss         | 0.0239       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 99400       |\n",
      "|    time_elapsed       | 1545        |\n",
      "|    total_timesteps    | 497000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99399       |\n",
      "|    policy_loss        | -4.63       |\n",
      "|    reward             | 0.055370677 |\n",
      "|    std                | 6.05e+07    |\n",
      "|    value_loss         | 0.0182      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 99500       |\n",
      "|    time_elapsed       | 1547        |\n",
      "|    total_timesteps    | 497500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99499       |\n",
      "|    policy_loss        | -3.89       |\n",
      "|    reward             | -0.39376256 |\n",
      "|    std                | 6e+07       |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 99600      |\n",
      "|    time_elapsed       | 1548       |\n",
      "|    total_timesteps    | 498000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99599      |\n",
      "|    policy_loss        | 0.841      |\n",
      "|    reward             | 0.25329882 |\n",
      "|    std                | 6.02e+07   |\n",
      "|    value_loss         | 0.0106     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 99700      |\n",
      "|    time_elapsed       | 1550       |\n",
      "|    total_timesteps    | 498500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99699      |\n",
      "|    policy_loss        | 19.1       |\n",
      "|    reward             | 0.47911036 |\n",
      "|    std                | 6.01e+07   |\n",
      "|    value_loss         | 0.288      |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 180\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -274728.37\n",
      "total_reward: -284728.37\n",
      "total_cost: 104.23\n",
      "total_trades: 5540\n",
      "Sharpe: -0.161\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 99800        |\n",
      "|    time_elapsed       | 1551         |\n",
      "|    total_timesteps    | 499000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.6        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99799        |\n",
      "|    policy_loss        | -5.27        |\n",
      "|    reward             | -0.057695664 |\n",
      "|    std                | 6.05e+07     |\n",
      "|    value_loss         | 0.0252       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 99900         |\n",
      "|    time_elapsed       | 1553          |\n",
      "|    total_timesteps    | 499500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99899         |\n",
      "|    policy_loss        | 0.954         |\n",
      "|    reward             | -0.0011130963 |\n",
      "|    std                | 6.12e+07      |\n",
      "|    value_loss         | 0.00219       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 100000      |\n",
      "|    time_elapsed       | 1554        |\n",
      "|    total_timesteps    | 500000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99999       |\n",
      "|    policy_loss        | -0.624      |\n",
      "|    reward             | -0.07265747 |\n",
      "|    std                | 6.16e+07    |\n",
      "|    value_loss         | 0.00296     |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2021-04-06 to  2021-07-06\n",
      "A2C Sharpe Ratio:  -0.29121039053638076\n",
      "======Best Model Retraining from:  2010-04-01 to  2021-07-06\n",
      "======Trading from:  2021-07-06 to  2021-10-04\n",
      "[[ 1.9628033e+04  1.4784787e+02  4.5230362e+02 -5.1000000e+01\n",
      "  -7.0000000e+00  3.1223807e+00  3.5672317e+00  1.5008386e+02\n",
      "   4.5665942e+02  1.3879756e+02  4.3660876e+02  6.6720078e+01\n",
      "   5.3663357e+01  9.5907776e+01  8.8577980e+01  3.7719433e+01\n",
      "   1.6090811e+01  1.4126389e+02  4.4520511e+02  1.3640550e+02\n",
      "   4.3844110e+02]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "turbulence_threshold:  18.962641042223694\n",
      "======Model training from:  2010-04-01 to  2021-07-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_252_1\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 344          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.85        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0853      |\n",
      "|    reward             | -0.045984533 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.9        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.0425     |\n",
      "|    reward             | 0.042183142 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000675    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.249      |\n",
      "|    reward             | -0.13565633 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.031       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 326        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.9       |\n",
      "|    explained_variance | -0.488     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.274     |\n",
      "|    reward             | 0.06592125 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.0364     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 325       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.91     |\n",
      "|    explained_variance | 0.109     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 0.0291    |\n",
      "|    reward             | 1.0136185 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.95       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 0.00382     |\n",
      "|    reward             | -0.01268802 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00021     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.97        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.0558       |\n",
      "|    reward             | 0.0043942397 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 0.00101     |\n",
      "|    reward             | 0.009426983 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000179    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.04       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.0539     |\n",
      "|    reward             | 0.035872187 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.000461    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.07      |\n",
      "|    explained_variance | 0.573      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 0.0862     |\n",
      "|    reward             | -0.0602772 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.00206    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.07        |\n",
      "|    explained_variance | 0.209        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 0.0301       |\n",
      "|    reward             | -0.039938983 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.00035      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -0.029      |\n",
      "|    reward             | 0.010316439 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.000264    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -0.0246    |\n",
      "|    reward             | 0.00616182 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.000189   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.23       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.0368      |\n",
      "|    reward             | 0.013093317 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.00177     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 23           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.26        |\n",
      "|    explained_variance | -22          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.0149      |\n",
      "|    reward             | -0.022751288 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.3         |\n",
      "|    explained_variance | -20.9        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -0.381       |\n",
      "|    reward             | 0.0045543094 |\n",
      "|    std                | 1.26         |\n",
      "|    value_loss         | 0.023        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.32       |\n",
      "|    explained_variance | 0.0221      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0606      |\n",
      "|    reward             | 0.010167914 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.00043     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.34       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -0.152      |\n",
      "|    reward             | 0.026530078 |\n",
      "|    std                | 1.29        |\n",
      "|    value_loss         | 0.00141     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.36        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.0842       |\n",
      "|    reward             | -0.008282669 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.4         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.0654       |\n",
      "|    reward             | 0.0083208475 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 0.000397     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.41       |\n",
      "|    explained_variance | -1.78       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | 0.0191      |\n",
      "|    reward             | -0.02478038 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.00109     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.45      |\n",
      "|    explained_variance | -0.798     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 0.434      |\n",
      "|    reward             | 0.06433022 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.0183     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 35          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.48       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | 0.049       |\n",
      "|    reward             | 0.010677354 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 0.00038     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.5         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.0438       |\n",
      "|    reward             | -0.029438922 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 0.000329     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 38            |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.55         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | -0.119        |\n",
      "|    reward             | -0.0014176246 |\n",
      "|    std                | 1.42          |\n",
      "|    value_loss         | 0.00125       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 2600         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 13000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.62        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2599         |\n",
      "|    policy_loss        | -0.00107     |\n",
      "|    reward             | 0.0014331324 |\n",
      "|    std                | 1.48         |\n",
      "|    value_loss         | 8.99e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.66       |\n",
      "|    explained_variance | -0.116      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | -0.0668     |\n",
      "|    reward             | -0.03528947 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.000623    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.72       |\n",
      "|    explained_variance | -0.0713     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | -0.124      |\n",
      "|    reward             | 0.015706364 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.000876    |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11953.81\n",
      "total_reward: -21953.81\n",
      "total_cost: 207.60\n",
      "total_trades: 5666\n",
      "Sharpe: 0.176\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.77        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 0.216        |\n",
      "|    reward             | -0.009050318 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 0.00537      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 45           |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.82        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | -0.0562      |\n",
      "|    reward             | -0.005958147 |\n",
      "|    std                | 1.63         |\n",
      "|    value_loss         | 0.000327     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.87        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.0922       |\n",
      "|    reward             | 0.0072240205 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 0.000706     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.92        |\n",
      "|    explained_variance | -0.00895     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | 0.00134      |\n",
      "|    reward             | -0.005200299 |\n",
      "|    std                | 1.72         |\n",
      "|    value_loss         | 7.45e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4          |\n",
      "|    explained_variance | -0.135      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 0.00286     |\n",
      "|    reward             | 0.016587472 |\n",
      "|    std                | 1.79        |\n",
      "|    value_loss         | 8.31e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.03        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.0147      |\n",
      "|    reward             | -0.012436555 |\n",
      "|    std                | 1.82         |\n",
      "|    value_loss         | 0.000303     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.04       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | -0.343      |\n",
      "|    reward             | 0.007171314 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 0.00425     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.07       |\n",
      "|    explained_variance | 2.27e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 0.112       |\n",
      "|    reward             | -0.01728938 |\n",
      "|    std                | 1.85        |\n",
      "|    value_loss         | 0.000902    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | -0.176      |\n",
      "|    reward             | -0.03114899 |\n",
      "|    std                | 1.89        |\n",
      "|    value_loss         | 0.00199     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 57           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.14        |\n",
      "|    explained_variance | -11.8        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.181        |\n",
      "|    reward             | -0.024425618 |\n",
      "|    std                | 1.92         |\n",
      "|    value_loss         | 0.00406      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.18      |\n",
      "|    explained_variance | 0.161      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 0.127      |\n",
      "|    reward             | 0.04147775 |\n",
      "|    std                | 1.96       |\n",
      "|    value_loss         | 0.00249    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.22        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.0785      |\n",
      "|    reward             | -0.008957604 |\n",
      "|    std                | 2            |\n",
      "|    value_loss         | 0.000727     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.26       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | 0.0473      |\n",
      "|    reward             | 0.013594839 |\n",
      "|    std                | 2.04        |\n",
      "|    value_loss         | 0.000261    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 63            |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.31         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | -0.0448       |\n",
      "|    reward             | -0.0033374652 |\n",
      "|    std                | 2.08          |\n",
      "|    value_loss         | 0.000396      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.38        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | 0.113        |\n",
      "|    reward             | -0.009869621 |\n",
      "|    std                | 2.16         |\n",
      "|    value_loss         | 0.00108      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.43        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.405        |\n",
      "|    reward             | -0.024627792 |\n",
      "|    std                | 2.22         |\n",
      "|    value_loss         | 0.0087       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.49        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.0455       |\n",
      "|    reward             | -0.023141501 |\n",
      "|    std                | 2.29         |\n",
      "|    value_loss         | 0.000223     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.54        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.898        |\n",
      "|    reward             | 0.0070730927 |\n",
      "|    std                | 2.34         |\n",
      "|    value_loss         | 0.0378       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.57      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -0.0945    |\n",
      "|    reward             | 0.00132247 |\n",
      "|    std                | 2.38       |\n",
      "|    value_loss         | 0.00108    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 72          |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.62       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 0.152       |\n",
      "|    reward             | 0.017177343 |\n",
      "|    std                | 2.44        |\n",
      "|    value_loss         | 0.00837     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.63      |\n",
      "|    explained_variance | 0.1        |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | 0.315      |\n",
      "|    reward             | -0.0972876 |\n",
      "|    std                | 2.45       |\n",
      "|    value_loss         | 0.0226     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | -0.001     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 0.131      |\n",
      "|    reward             | 0.17185935 |\n",
      "|    std                | 2.48       |\n",
      "|    value_loss         | 0.00336    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 327       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.68     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 1.48      |\n",
      "|    reward             | 0.2750361 |\n",
      "|    std                | 2.51      |\n",
      "|    value_loss         | 0.098     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 80           |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.7         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.0939      |\n",
      "|    reward             | 0.0011636568 |\n",
      "|    std                | 2.54         |\n",
      "|    value_loss         | 0.000617     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.74        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.0055       |\n",
      "|    reward             | 0.0049932543 |\n",
      "|    std                | 2.59         |\n",
      "|    value_loss         | 7.71e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 83            |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.77         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 5399          |\n",
      "|    policy_loss        | -0.136        |\n",
      "|    reward             | -0.0063742916 |\n",
      "|    std                | 2.63          |\n",
      "|    value_loss         | 0.00119       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 84           |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.81        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 0.0613       |\n",
      "|    reward             | 0.0046564434 |\n",
      "|    std                | 2.69         |\n",
      "|    value_loss         | 0.000269     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | 0.106       |\n",
      "|    reward             | 0.007461917 |\n",
      "|    std                | 2.75        |\n",
      "|    value_loss         | 0.000843    |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -24488.46\n",
      "total_reward: -34488.46\n",
      "total_cost: 463.90\n",
      "total_trades: 5666\n",
      "Sharpe: 0.001\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 87           |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.9         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.084        |\n",
      "|    reward             | 0.0032473246 |\n",
      "|    std                | 2.8          |\n",
      "|    value_loss         | 0.00042      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -0.169      |\n",
      "|    reward             | 0.008727377 |\n",
      "|    std                | 2.87        |\n",
      "|    value_loss         | 0.00106     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.99      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -0.106     |\n",
      "|    reward             | 0.01570081 |\n",
      "|    std                | 2.94       |\n",
      "|    value_loss         | 0.000583   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.05        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | 0.172        |\n",
      "|    reward             | -0.005476058 |\n",
      "|    std                | 3.03         |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 93          |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.14       |\n",
      "|    explained_variance | 0.00996     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | 0.109       |\n",
      "|    reward             | 0.010858403 |\n",
      "|    std                | 3.16        |\n",
      "|    value_loss         | 0.00075     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 95          |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.16       |\n",
      "|    explained_variance | -102        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 1.14        |\n",
      "|    reward             | 0.008183238 |\n",
      "|    std                | 3.2         |\n",
      "|    value_loss         | 0.0781      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.18       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 0.24        |\n",
      "|    reward             | 0.023828505 |\n",
      "|    std                | 3.23        |\n",
      "|    value_loss         | 0.00248     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.22       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -0.00612    |\n",
      "|    reward             | 0.003101359 |\n",
      "|    std                | 3.3         |\n",
      "|    value_loss         | 6.47e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.3         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 0.0459       |\n",
      "|    reward             | 0.0060931467 |\n",
      "|    std                | 3.42         |\n",
      "|    value_loss         | 0.000463     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.38       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 0.113       |\n",
      "|    reward             | 0.007464576 |\n",
      "|    std                | 3.56        |\n",
      "|    value_loss         | 0.000473    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 103          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.44        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | -0.186       |\n",
      "|    reward             | -0.024349505 |\n",
      "|    std                | 3.68         |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.47        |\n",
      "|    explained_variance | -2.74        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | 0.168        |\n",
      "|    reward             | -0.009409453 |\n",
      "|    std                | 3.73         |\n",
      "|    value_loss         | 0.00218      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 106        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.52      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | 0.185      |\n",
      "|    reward             | 0.02377661 |\n",
      "|    std                | 3.82       |\n",
      "|    value_loss         | 0.00368    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 108        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.57      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -0.189     |\n",
      "|    reward             | -0.0329896 |\n",
      "|    std                | 3.92       |\n",
      "|    value_loss         | 0.00114    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 109         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.61       |\n",
      "|    explained_variance | -2.05       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 0.0636      |\n",
      "|    reward             | 0.034772642 |\n",
      "|    std                | 3.99        |\n",
      "|    value_loss         | 0.00153     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 111        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.65      |\n",
      "|    explained_variance | 0.334      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -0.03      |\n",
      "|    reward             | 0.06214934 |\n",
      "|    std                | 4.07       |\n",
      "|    value_loss         | 0.000614   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.67       |\n",
      "|    explained_variance | 0.318       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | 0.179       |\n",
      "|    reward             | -0.05294956 |\n",
      "|    std                | 4.12        |\n",
      "|    value_loss         | 0.00622     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 114         |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.7        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | -0.194      |\n",
      "|    reward             | 0.039609276 |\n",
      "|    std                | 4.18        |\n",
      "|    value_loss         | 0.00334     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.71       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | -0.167      |\n",
      "|    reward             | 0.019569876 |\n",
      "|    std                | 4.21        |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.73        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | -0.652       |\n",
      "|    reward             | -0.057909276 |\n",
      "|    std                | 4.24         |\n",
      "|    value_loss         | 0.0144       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 119          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.72        |\n",
      "|    explained_variance | -0.0322      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | -0.832       |\n",
      "|    reward             | -0.033625443 |\n",
      "|    std                | 4.22         |\n",
      "|    value_loss         | 0.019        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.73       |\n",
      "|    explained_variance | 0.0291      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | 0.774       |\n",
      "|    reward             | -0.13652161 |\n",
      "|    std                | 4.25        |\n",
      "|    value_loss         | 0.0344      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 122        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.76      |\n",
      "|    explained_variance | 0.19       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -0.527     |\n",
      "|    reward             | 0.19348948 |\n",
      "|    std                | 4.33       |\n",
      "|    value_loss         | 0.0449     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.77       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -0.0291     |\n",
      "|    reward             | 0.010249951 |\n",
      "|    std                | 4.35        |\n",
      "|    value_loss         | 9.71e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 323           |\n",
      "|    iterations         | 8100          |\n",
      "|    time_elapsed       | 125           |\n",
      "|    total_timesteps    | 40500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.8          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8099          |\n",
      "|    policy_loss        | -0.0802       |\n",
      "|    reward             | -0.0053910646 |\n",
      "|    std                | 4.41          |\n",
      "|    value_loss         | 0.000149      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 8200           |\n",
      "|    time_elapsed       | 126            |\n",
      "|    total_timesteps    | 41000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.85          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 8199           |\n",
      "|    policy_loss        | 0.184          |\n",
      "|    reward             | -0.00015778444 |\n",
      "|    std                | 4.51           |\n",
      "|    value_loss         | 0.00111        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | -0.049      |\n",
      "|    reward             | 0.012483258 |\n",
      "|    std                | 4.63        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.98        |\n",
      "|    explained_variance | -0.0828      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.0487       |\n",
      "|    reward             | -0.004723543 |\n",
      "|    std                | 4.82         |\n",
      "|    value_loss         | 0.000203     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 130           |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.98         |\n",
      "|    explained_variance | -1.57         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | -0.0661       |\n",
      "|    reward             | -0.0127816545 |\n",
      "|    std                | 4.81          |\n",
      "|    value_loss         | 0.00046       |\n",
      "-----------------------------------------\n",
      "day: 2833, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13173.48\n",
      "total_reward: -23173.48\n",
      "total_cost: 255.54\n",
      "total_trades: 5666\n",
      "Sharpe: -0.302\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 8600        |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 43000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8599        |\n",
      "|    policy_loss        | 0.196       |\n",
      "|    reward             | 0.011442394 |\n",
      "|    std                | 4.89        |\n",
      "|    value_loss         | 0.00109     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 133          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.09        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.0278      |\n",
      "|    reward             | 0.0015032957 |\n",
      "|    std                | 5.08         |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 8800          |\n",
      "|    time_elapsed       | 135           |\n",
      "|    total_timesteps    | 44000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.14         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8799          |\n",
      "|    policy_loss        | -0.103        |\n",
      "|    reward             | -0.0029938493 |\n",
      "|    std                | 5.22          |\n",
      "|    value_loss         | 0.00039       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 137          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.19        |\n",
      "|    explained_variance | -64.2        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 0.96         |\n",
      "|    reward             | 0.0098834615 |\n",
      "|    std                | 5.33         |\n",
      "|    value_loss         | 0.0337       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 139         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.22       |\n",
      "|    explained_variance | 0.785       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -0.0363     |\n",
      "|    reward             | 0.045107283 |\n",
      "|    std                | 5.43        |\n",
      "|    value_loss         | 6.11e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -0.294      |\n",
      "|    reward             | -0.01748783 |\n",
      "|    std                | 5.57        |\n",
      "|    value_loss         | 0.00209     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.29       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 0.00645     |\n",
      "|    reward             | 0.028835308 |\n",
      "|    std                | 5.63        |\n",
      "|    value_loss         | 5.45e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.33        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.0669      |\n",
      "|    reward             | -0.027443178 |\n",
      "|    std                | 5.73         |\n",
      "|    value_loss         | 0.000429     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.37        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -0.064       |\n",
      "|    reward             | 0.0016095085 |\n",
      "|    std                | 5.86         |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.41       |\n",
      "|    explained_variance | -3.43       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -0.0874     |\n",
      "|    reward             | 0.007044717 |\n",
      "|    std                | 5.96        |\n",
      "|    value_loss         | 0.00119     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.44       |\n",
      "|    explained_variance | 0.412       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -0.0948     |\n",
      "|    reward             | 0.011032917 |\n",
      "|    std                | 6.07        |\n",
      "|    value_loss         | 0.000298    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -0.177      |\n",
      "|    reward             | 0.036989305 |\n",
      "|    std                | 6.21        |\n",
      "|    value_loss         | 0.00128     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.54       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -0.0902     |\n",
      "|    reward             | -0.00535883 |\n",
      "|    std                | 6.37        |\n",
      "|    value_loss         | 0.00022     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 153          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.61        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | 0.0425       |\n",
      "|    reward             | -0.008934169 |\n",
      "|    std                | 6.58         |\n",
      "|    value_loss         | 5.5e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.68       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -0.00265    |\n",
      "|    reward             | 0.013310577 |\n",
      "|    std                | 6.83        |\n",
      "|    value_loss         | 2.43e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 10100         |\n",
      "|    time_elapsed       | 156           |\n",
      "|    total_timesteps    | 50500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.76         |\n",
      "|    explained_variance | -26.8         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10099         |\n",
      "|    policy_loss        | -0.213        |\n",
      "|    reward             | -0.0058902814 |\n",
      "|    std                | 7.11          |\n",
      "|    value_loss         | 0.00211       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 10200        |\n",
      "|    time_elapsed       | 157          |\n",
      "|    total_timesteps    | 51000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.81        |\n",
      "|    explained_variance | 3.08e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | -0.15        |\n",
      "|    reward             | -0.022096554 |\n",
      "|    std                | 7.28         |\n",
      "|    value_loss         | 0.000565     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 10300        |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 51500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.85        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10299        |\n",
      "|    policy_loss        | -0.0226      |\n",
      "|    reward             | -0.035299588 |\n",
      "|    std                | 7.45         |\n",
      "|    value_loss         | 0.000288     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 10400       |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 52000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | -0.285      |\n",
      "|    reward             | -0.02341772 |\n",
      "|    std                | 7.56        |\n",
      "|    value_loss         | 0.00298     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 163         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.91       |\n",
      "|    explained_variance | -0.215      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 0.402       |\n",
      "|    reward             | -0.09628488 |\n",
      "|    std                | 7.67        |\n",
      "|    value_loss         | 0.00519     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.92       |\n",
      "|    explained_variance | -9.89e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | -1.57       |\n",
      "|    reward             | -0.08693983 |\n",
      "|    std                | 7.71        |\n",
      "|    value_loss         | 0.0783      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 10700      |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 53500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.95      |\n",
      "|    explained_variance | 0.00471    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | -0.723     |\n",
      "|    reward             | 0.14836174 |\n",
      "|    std                | 7.81       |\n",
      "|    value_loss         | 0.0155     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 10800       |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 54000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.96       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | -0.00863    |\n",
      "|    reward             | 0.015449141 |\n",
      "|    std                | 7.84        |\n",
      "|    value_loss         | 4.68e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 10900        |\n",
      "|    time_elapsed       | 169          |\n",
      "|    total_timesteps    | 54500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.99        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | -0.0449      |\n",
      "|    reward             | -0.010626936 |\n",
      "|    std                | 7.99         |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 11000       |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 55000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10999       |\n",
      "|    policy_loss        | -0.151      |\n",
      "|    reward             | 0.015901163 |\n",
      "|    std                | 8.15        |\n",
      "|    value_loss         | 0.000797    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 11100       |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 55500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.07       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | -0.0372     |\n",
      "|    reward             | 0.025241738 |\n",
      "|    std                | 8.32        |\n",
      "|    value_loss         | 4e-05       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 11200       |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 56000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | -9.62       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | 0.352       |\n",
      "|    reward             | 0.007033732 |\n",
      "|    std                | 8.51        |\n",
      "|    value_loss         | 0.00726     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 11300         |\n",
      "|    time_elapsed       | 175           |\n",
      "|    total_timesteps    | 56500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.16         |\n",
      "|    explained_variance | 0.525         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11299         |\n",
      "|    policy_loss        | -0.136        |\n",
      "|    reward             | -0.0006628588 |\n",
      "|    std                | 8.7           |\n",
      "|    value_loss         | 0.000439      |\n",
      "-----------------------------------------\n",
      "day: 2833, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -14682.67\n",
      "total_reward: -24682.67\n",
      "total_cost: 227.82\n",
      "total_trades: 5666\n",
      "Sharpe: -0.076\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 11400      |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 57000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11399      |\n",
      "|    policy_loss        | -1.24      |\n",
      "|    reward             | 0.10856895 |\n",
      "|    std                | 8.74       |\n",
      "|    value_loss         | 0.0379     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 11500        |\n",
      "|    time_elapsed       | 179          |\n",
      "|    total_timesteps    | 57500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.2         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | -0.0762      |\n",
      "|    reward             | -0.030326866 |\n",
      "|    std                | 8.86         |\n",
      "|    value_loss         | 0.00063      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 11600      |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 58000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11599      |\n",
      "|    policy_loss        | 0.654      |\n",
      "|    reward             | -0.0709026 |\n",
      "|    std                | 8.97       |\n",
      "|    value_loss         | 0.0107     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 11700       |\n",
      "|    time_elapsed       | 182         |\n",
      "|    total_timesteps    | 58500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.23       |\n",
      "|    explained_variance | 1.73e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | 1.44        |\n",
      "|    reward             | -0.08221895 |\n",
      "|    std                | 8.99        |\n",
      "|    value_loss         | 0.0498      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 11800       |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 59000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.22       |\n",
      "|    explained_variance | 6.14e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11799       |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | -0.12214519 |\n",
      "|    std                | 8.96        |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 11900      |\n",
      "|    time_elapsed       | 185        |\n",
      "|    total_timesteps    | 59500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | 1.41e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11899      |\n",
      "|    policy_loss        | 3.72       |\n",
      "|    reward             | 0.41789237 |\n",
      "|    std                | 8.96       |\n",
      "|    value_loss         | 0.442      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 12000       |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 60000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.24       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -0.198      |\n",
      "|    reward             | 0.011336147 |\n",
      "|    std                | 9.05        |\n",
      "|    value_loss         | 0.00151     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.25       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -0.0473     |\n",
      "|    reward             | -0.06001411 |\n",
      "|    std                | 9.11        |\n",
      "|    value_loss         | 0.000481    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 12200        |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 61000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.27        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12199        |\n",
      "|    policy_loss        | -0.622       |\n",
      "|    reward             | -0.014772913 |\n",
      "|    std                | 9.21         |\n",
      "|    value_loss         | 0.0227       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 12300      |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 61500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.29      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12299      |\n",
      "|    policy_loss        | -1.19      |\n",
      "|    reward             | 0.02111125 |\n",
      "|    std                | 9.27       |\n",
      "|    value_loss         | 0.0455     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 12400      |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 62000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | 0.0543     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12399      |\n",
      "|    policy_loss        | 0.188      |\n",
      "|    reward             | 0.17793077 |\n",
      "|    std                | 9.38       |\n",
      "|    value_loss         | 0.0141     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 12500        |\n",
      "|    time_elapsed       | 194          |\n",
      "|    total_timesteps    | 62500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.33        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | -0.476       |\n",
      "|    reward             | -0.009150194 |\n",
      "|    std                | 9.44         |\n",
      "|    value_loss         | 0.00386      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 12600       |\n",
      "|    time_elapsed       | 195         |\n",
      "|    total_timesteps    | 63000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.34       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12599       |\n",
      "|    policy_loss        | 0.252       |\n",
      "|    reward             | -0.07137276 |\n",
      "|    std                | 9.51        |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 12700       |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 63500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.37       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | -1.5        |\n",
      "|    reward             | -0.08123208 |\n",
      "|    std                | 9.66        |\n",
      "|    value_loss         | 0.0508      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.4        |\n",
      "|    explained_variance | 0.322       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | 0.592       |\n",
      "|    reward             | 0.015099246 |\n",
      "|    std                | 9.78        |\n",
      "|    value_loss         | 0.00976     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 12900       |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 64500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.4        |\n",
      "|    explained_variance | 0.407       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12899       |\n",
      "|    policy_loss        | 2.61        |\n",
      "|    reward             | 0.027735202 |\n",
      "|    std                | 9.82        |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 13000       |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 65000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.42       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | 0.163       |\n",
      "|    reward             | 0.022270277 |\n",
      "|    std                | 9.92        |\n",
      "|    value_loss         | 0.0112      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 13100         |\n",
      "|    time_elapsed       | 203           |\n",
      "|    total_timesteps    | 65500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.44         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13099         |\n",
      "|    policy_loss        | -0.27         |\n",
      "|    reward             | -0.0051206346 |\n",
      "|    std                | 9.99          |\n",
      "|    value_loss         | 0.00148       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 13200          |\n",
      "|    time_elapsed       | 204            |\n",
      "|    total_timesteps    | 66000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.47          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 13199          |\n",
      "|    policy_loss        | 0.124          |\n",
      "|    reward             | -0.00026684706 |\n",
      "|    std                | 10.2           |\n",
      "|    value_loss         | 0.000781       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 13300       |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 66500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.51       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | 0.0187      |\n",
      "|    reward             | 0.008737756 |\n",
      "|    std                | 10.4        |\n",
      "|    value_loss         | 1.1e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 13400         |\n",
      "|    time_elapsed       | 207           |\n",
      "|    total_timesteps    | 67000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.53         |\n",
      "|    explained_variance | -0.133        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13399         |\n",
      "|    policy_loss        | 0.243         |\n",
      "|    reward             | -0.0032780606 |\n",
      "|    std                | 10.5          |\n",
      "|    value_loss         | 0.00179       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 13500        |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 67500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.58        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13499        |\n",
      "|    policy_loss        | -0.199       |\n",
      "|    reward             | -0.026864942 |\n",
      "|    std                | 10.7         |\n",
      "|    value_loss         | 0.00086      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 13600        |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 68000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.63        |\n",
      "|    explained_variance | -0.000939    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13599        |\n",
      "|    policy_loss        | -0.0564      |\n",
      "|    reward             | -0.005799057 |\n",
      "|    std                | 11           |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 13700       |\n",
      "|    time_elapsed       | 212         |\n",
      "|    total_timesteps    | 68500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.68       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13699       |\n",
      "|    policy_loss        | -0.0486     |\n",
      "|    reward             | 0.033994813 |\n",
      "|    std                | 11.3        |\n",
      "|    value_loss         | 0.000807    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 13800        |\n",
      "|    time_elapsed       | 213          |\n",
      "|    total_timesteps    | 69000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.73        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13799        |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | -0.012456139 |\n",
      "|    std                | 11.5         |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 13900        |\n",
      "|    time_elapsed       | 215          |\n",
      "|    total_timesteps    | 69500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.78        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13899        |\n",
      "|    policy_loss        | -1.21        |\n",
      "|    reward             | -0.035721194 |\n",
      "|    std                | 11.9         |\n",
      "|    value_loss         | 0.0262       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.79       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | -0.0855     |\n",
      "|    reward             | 0.046390273 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.00697     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 14100       |\n",
      "|    time_elapsed       | 218         |\n",
      "|    total_timesteps    | 70500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.79       |\n",
      "|    explained_variance | 0.167       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | -0.732      |\n",
      "|    reward             | 0.012016931 |\n",
      "|    std                | 12          |\n",
      "|    value_loss         | 0.0181      |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -98667.57\n",
      "total_reward: -108667.57\n",
      "total_cost: 79.73\n",
      "total_trades: 5666\n",
      "Sharpe: 0.224\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 14200        |\n",
      "|    time_elapsed       | 220          |\n",
      "|    total_timesteps    | 71000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.81        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.028325805 |\n",
      "|    std                | 12.1         |\n",
      "|    value_loss         | 0.00118      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 14300        |\n",
      "|    time_elapsed       | 221          |\n",
      "|    total_timesteps    | 71500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.83        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14299        |\n",
      "|    policy_loss        | 0.694        |\n",
      "|    reward             | 0.0027799641 |\n",
      "|    std                | 12.2         |\n",
      "|    value_loss         | 0.00925      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 14400        |\n",
      "|    time_elapsed       | 223          |\n",
      "|    total_timesteps    | 72000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.86        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | -0.528       |\n",
      "|    reward             | -0.016734798 |\n",
      "|    std                | 12.3         |\n",
      "|    value_loss         | 0.00524      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 14500        |\n",
      "|    time_elapsed       | 225          |\n",
      "|    total_timesteps    | 72500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.89        |\n",
      "|    explained_variance | 0.431        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | 0.248        |\n",
      "|    reward             | -0.017276175 |\n",
      "|    std                | 12.5         |\n",
      "|    value_loss         | 0.0019       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 14600       |\n",
      "|    time_elapsed       | 226         |\n",
      "|    total_timesteps    | 73000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.92       |\n",
      "|    explained_variance | 0.113       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | 0.845       |\n",
      "|    reward             | 0.024301784 |\n",
      "|    std                | 12.8        |\n",
      "|    value_loss         | 0.0133      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.95       |\n",
      "|    explained_variance | 0.0332      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | 0.642       |\n",
      "|    reward             | -0.08251583 |\n",
      "|    std                | 12.9        |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | -0.36       |\n",
      "|    reward             | -0.03752828 |\n",
      "|    std                | 13.1        |\n",
      "|    value_loss         | 0.00708     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 14900         |\n",
      "|    time_elapsed       | 230           |\n",
      "|    total_timesteps    | 74500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.01         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14899         |\n",
      "|    policy_loss        | 0.262         |\n",
      "|    reward             | -0.0005833434 |\n",
      "|    std                | 13.3          |\n",
      "|    value_loss         | 0.00188       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 15000      |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 75000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.04      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14999      |\n",
      "|    policy_loss        | 0.439      |\n",
      "|    reward             | 0.02624871 |\n",
      "|    std                | 13.5       |\n",
      "|    value_loss         | 0.00374    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 15100        |\n",
      "|    time_elapsed       | 233          |\n",
      "|    total_timesteps    | 75500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.03        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15099        |\n",
      "|    policy_loss        | 1.52         |\n",
      "|    reward             | -0.095905885 |\n",
      "|    std                | 13.5         |\n",
      "|    value_loss         | 0.048        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 323       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 235       |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.06     |\n",
      "|    explained_variance | 0.121     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -1.83     |\n",
      "|    reward             | 0.2973548 |\n",
      "|    std                | 13.6      |\n",
      "|    value_loss         | 0.0716    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 15300        |\n",
      "|    time_elapsed       | 236          |\n",
      "|    total_timesteps    | 76500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.07        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15299        |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | -0.021579072 |\n",
      "|    std                | 13.8         |\n",
      "|    value_loss         | 0.0271       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 15400        |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 77000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.09        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15399        |\n",
      "|    policy_loss        | 0.00734      |\n",
      "|    reward             | -0.007332597 |\n",
      "|    std                | 13.9         |\n",
      "|    value_loss         | 4.68e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 15500       |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 77500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.13       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15499       |\n",
      "|    policy_loss        | 0.184       |\n",
      "|    reward             | -0.01948509 |\n",
      "|    std                | 14.2        |\n",
      "|    value_loss         | 0.000811    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 15600        |\n",
      "|    time_elapsed       | 241          |\n",
      "|    total_timesteps    | 78000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.19        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | -0.0782      |\n",
      "|    reward             | -0.010806797 |\n",
      "|    std                | 14.6         |\n",
      "|    value_loss         | 0.000237     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.23        |\n",
      "|    explained_variance | -6.11        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | -0.269       |\n",
      "|    reward             | -0.009033527 |\n",
      "|    std                | 14.9         |\n",
      "|    value_loss         | 0.00436      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 15800        |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 79000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.28        |\n",
      "|    explained_variance | -0.999       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | 0.292        |\n",
      "|    reward             | -0.009772372 |\n",
      "|    std                | 15.3         |\n",
      "|    value_loss         | 0.00188      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 15900       |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 79500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.3        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | -0.305      |\n",
      "|    reward             | 0.076054774 |\n",
      "|    std                | 15.5        |\n",
      "|    value_loss         | 0.00211     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 16000       |\n",
      "|    time_elapsed       | 246         |\n",
      "|    total_timesteps    | 80000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.35       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | -0.544      |\n",
      "|    reward             | 0.035134833 |\n",
      "|    std                | 15.9        |\n",
      "|    value_loss         | 0.00669     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 16100      |\n",
      "|    time_elapsed       | 248        |\n",
      "|    total_timesteps    | 80500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.36      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16099      |\n",
      "|    policy_loss        | 1.6        |\n",
      "|    reward             | 0.09832475 |\n",
      "|    std                | 15.9       |\n",
      "|    value_loss         | 0.171      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 16200      |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 81000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.38      |\n",
      "|    explained_variance | 0.237      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16199      |\n",
      "|    policy_loss        | -0.687     |\n",
      "|    reward             | 0.05961634 |\n",
      "|    std                | 16.1       |\n",
      "|    value_loss         | 0.0144     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 16300      |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 81500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.39      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16299      |\n",
      "|    policy_loss        | 0.349      |\n",
      "|    reward             | 0.17407823 |\n",
      "|    std                | 16.2       |\n",
      "|    value_loss         | 0.00499    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 16400       |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 82000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.39       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | -3.37       |\n",
      "|    reward             | -0.18333052 |\n",
      "|    std                | 16.1        |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 16500      |\n",
      "|    time_elapsed       | 254        |\n",
      "|    total_timesteps    | 82500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16499      |\n",
      "|    policy_loss        | -1.04      |\n",
      "|    reward             | -0.0351621 |\n",
      "|    std                | 16.3       |\n",
      "|    value_loss         | 0.0164     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 16600         |\n",
      "|    time_elapsed       | 255           |\n",
      "|    total_timesteps    | 83000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.42         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 16599         |\n",
      "|    policy_loss        | -0.083        |\n",
      "|    reward             | -0.0034414746 |\n",
      "|    std                | 16.4          |\n",
      "|    value_loss         | 0.0011        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 257          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.49        |\n",
      "|    explained_variance | 0.0018       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | 0.0595       |\n",
      "|    reward             | -0.007840042 |\n",
      "|    std                | 16.9         |\n",
      "|    value_loss         | 0.000418     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 16800       |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 84000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.51       |\n",
      "|    explained_variance | 0.143       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16799       |\n",
      "|    policy_loss        | -0.479      |\n",
      "|    reward             | 0.020066518 |\n",
      "|    std                | 17.2        |\n",
      "|    value_loss         | 0.00972     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 16900       |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 84500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.56       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | -0.875      |\n",
      "|    reward             | 0.045475356 |\n",
      "|    std                | 17.6        |\n",
      "|    value_loss         | 0.0166      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 17000      |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 85000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.58      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16999      |\n",
      "|    policy_loss        | -1.58      |\n",
      "|    reward             | 0.15754892 |\n",
      "|    std                | 17.8       |\n",
      "|    value_loss         | 0.0398     |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -81775.84\n",
      "total_reward: -91775.84\n",
      "total_cost: 97.41\n",
      "total_trades: 5666\n",
      "Sharpe: 0.140\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 17100         |\n",
      "|    time_elapsed       | 263           |\n",
      "|    total_timesteps    | 85500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.58         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | 0.16          |\n",
      "|    reward             | -0.0148661705 |\n",
      "|    std                | 17.8          |\n",
      "|    value_loss         | 0.000356      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 17200        |\n",
      "|    time_elapsed       | 264          |\n",
      "|    total_timesteps    | 86000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.59        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | 0.385        |\n",
      "|    reward             | -0.009762144 |\n",
      "|    std                | 17.9         |\n",
      "|    value_loss         | 0.00199      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 17300      |\n",
      "|    time_elapsed       | 266        |\n",
      "|    total_timesteps    | 86500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.62      |\n",
      "|    explained_variance | 0.11       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17299      |\n",
      "|    policy_loss        | 0.209      |\n",
      "|    reward             | 0.01698627 |\n",
      "|    std                | 18.2       |\n",
      "|    value_loss         | 0.00112    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 17400        |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 87000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.66        |\n",
      "|    explained_variance | -0.97        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17399        |\n",
      "|    policy_loss        | 0.422        |\n",
      "|    reward             | -0.018976431 |\n",
      "|    std                | 18.5         |\n",
      "|    value_loss         | 0.00276      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 17500       |\n",
      "|    time_elapsed       | 269         |\n",
      "|    total_timesteps    | 87500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.68       |\n",
      "|    explained_variance | 0.334       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | 0.353       |\n",
      "|    reward             | 0.015322036 |\n",
      "|    std                | 18.7        |\n",
      "|    value_loss         | 0.00182     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 17600         |\n",
      "|    time_elapsed       | 270           |\n",
      "|    total_timesteps    | 88000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.72         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17599         |\n",
      "|    policy_loss        | 0.0564        |\n",
      "|    reward             | -0.0033451319 |\n",
      "|    std                | 19.1          |\n",
      "|    value_loss         | 0.000129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 17700         |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 88500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.79         |\n",
      "|    explained_variance | 2.38e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17699         |\n",
      "|    policy_loss        | 0.0702        |\n",
      "|    reward             | -0.0056023663 |\n",
      "|    std                | 19.7          |\n",
      "|    value_loss         | 0.000195      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 17800        |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 89000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.83        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17799        |\n",
      "|    policy_loss        | 0.485        |\n",
      "|    reward             | -0.004665469 |\n",
      "|    std                | 20.1         |\n",
      "|    value_loss         | 0.00372      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 17900       |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 89500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.89       |\n",
      "|    explained_variance | 0.00452     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | -0.0389     |\n",
      "|    reward             | 0.004922891 |\n",
      "|    std                | 20.8        |\n",
      "|    value_loss         | 3.09e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 18000         |\n",
      "|    time_elapsed       | 276           |\n",
      "|    total_timesteps    | 90000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.96         |\n",
      "|    explained_variance | -40.9         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17999         |\n",
      "|    policy_loss        | -0.0575       |\n",
      "|    reward             | -0.0038084935 |\n",
      "|    std                | 21.5          |\n",
      "|    value_loss         | 0.000351      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 18100        |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 90500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.01        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18099        |\n",
      "|    policy_loss        | -0.232       |\n",
      "|    reward             | -0.029731115 |\n",
      "|    std                | 22           |\n",
      "|    value_loss         | 0.000716     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 18200         |\n",
      "|    time_elapsed       | 279           |\n",
      "|    total_timesteps    | 91000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.06         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18199         |\n",
      "|    policy_loss        | 0.296         |\n",
      "|    reward             | 7.7877296e-05 |\n",
      "|    std                | 22.5          |\n",
      "|    value_loss         | 0.00187       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 18300      |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 91500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18299      |\n",
      "|    policy_loss        | -0.235     |\n",
      "|    reward             | 0.01792057 |\n",
      "|    std                | 22.9       |\n",
      "|    value_loss         | 0.000906   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 18400        |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 92000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.12        |\n",
      "|    explained_variance | -65.6        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | 0.359        |\n",
      "|    reward             | -0.008095676 |\n",
      "|    std                | 23.3         |\n",
      "|    value_loss         | 0.00574      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 18500         |\n",
      "|    time_elapsed       | 284           |\n",
      "|    total_timesteps    | 92500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.16         |\n",
      "|    explained_variance | 0.699         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18499         |\n",
      "|    policy_loss        | -0.057        |\n",
      "|    reward             | -0.0033057665 |\n",
      "|    std                | 23.8          |\n",
      "|    value_loss         | 0.000143      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 18600        |\n",
      "|    time_elapsed       | 285          |\n",
      "|    total_timesteps    | 93000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.21        |\n",
      "|    explained_variance | -0.636       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18599        |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | -0.022309953 |\n",
      "|    std                | 24.4         |\n",
      "|    value_loss         | 0.000357     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 18700      |\n",
      "|    time_elapsed       | 287        |\n",
      "|    total_timesteps    | 93500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18699      |\n",
      "|    policy_loss        | -0.246     |\n",
      "|    reward             | 0.02964617 |\n",
      "|    std                | 25.3       |\n",
      "|    value_loss         | 0.00156    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 18800        |\n",
      "|    time_elapsed       | 288          |\n",
      "|    total_timesteps    | 94000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.3         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18799        |\n",
      "|    policy_loss        | 0.209        |\n",
      "|    reward             | -0.103857845 |\n",
      "|    std                | 25.4         |\n",
      "|    value_loss         | 0.00165      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 18900      |\n",
      "|    time_elapsed       | 290        |\n",
      "|    total_timesteps    | 94500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18899      |\n",
      "|    policy_loss        | -1.42      |\n",
      "|    reward             | -0.0761628 |\n",
      "|    std                | 25.6       |\n",
      "|    value_loss         | 0.0266     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 19000       |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 95000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.34       |\n",
      "|    explained_variance | 0.00245     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | 4.16        |\n",
      "|    reward             | -0.17982592 |\n",
      "|    std                | 25.9        |\n",
      "|    value_loss         | 0.207       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 19100      |\n",
      "|    time_elapsed       | 293        |\n",
      "|    total_timesteps    | 95500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.37      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 19099      |\n",
      "|    policy_loss        | 3.01       |\n",
      "|    reward             | 0.33254862 |\n",
      "|    std                | 26.3       |\n",
      "|    value_loss         | 0.135      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 326       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 294       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.39     |\n",
      "|    explained_variance | 0.0233    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 0.172     |\n",
      "|    reward             | -0.257762 |\n",
      "|    std                | 26.7      |\n",
      "|    value_loss         | 0.0498    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 19300         |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 96500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.4          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19299         |\n",
      "|    policy_loss        | 0.252         |\n",
      "|    reward             | -0.0077061397 |\n",
      "|    std                | 26.8          |\n",
      "|    value_loss         | 0.000631      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 19400       |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 97000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.42       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | 0.189       |\n",
      "|    reward             | 0.020406533 |\n",
      "|    std                | 27.1        |\n",
      "|    value_loss         | 0.00067     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 19500        |\n",
      "|    time_elapsed       | 298          |\n",
      "|    total_timesteps    | 97500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.46        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19499        |\n",
      "|    policy_loss        | 0.164        |\n",
      "|    reward             | -0.012920197 |\n",
      "|    std                | 27.5         |\n",
      "|    value_loss         | 0.000389     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 19600       |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 98000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.5        |\n",
      "|    explained_variance | -15.3       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | -0.00133    |\n",
      "|    reward             | 0.021349855 |\n",
      "|    std                | 28.1        |\n",
      "|    value_loss         | 9.48e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 19700        |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 98500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.55        |\n",
      "|    explained_variance | -3.69e+03    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19699        |\n",
      "|    policy_loss        | 1.15         |\n",
      "|    reward             | 0.0065257684 |\n",
      "|    std                | 28.8         |\n",
      "|    value_loss         | 0.0313       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 326           |\n",
      "|    iterations         | 19800         |\n",
      "|    time_elapsed       | 302           |\n",
      "|    total_timesteps    | 99000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.57         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19799         |\n",
      "|    policy_loss        | 0.222         |\n",
      "|    reward             | -0.0068625347 |\n",
      "|    std                | 29.2          |\n",
      "|    value_loss         | 0.000685      |\n",
      "-----------------------------------------\n",
      "day: 2833, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12933.52\n",
      "total_reward: -22933.52\n",
      "total_cost: 502.87\n",
      "total_trades: 5666\n",
      "Sharpe: -0.448\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 326            |\n",
      "|    iterations         | 19900          |\n",
      "|    time_elapsed       | 304            |\n",
      "|    total_timesteps    | 99500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -9.61          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 19899          |\n",
      "|    policy_loss        | 0.158          |\n",
      "|    reward             | -0.00045987018 |\n",
      "|    std                | 29.7           |\n",
      "|    value_loss         | 0.000362       |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 326       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 305       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -0.0103   |\n",
      "|    reward             | 0.0194048 |\n",
      "|    std                | 30.6      |\n",
      "|    value_loss         | 0.000104  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 20100        |\n",
      "|    time_elapsed       | 307          |\n",
      "|    total_timesteps    | 100500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.73        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20099        |\n",
      "|    policy_loss        | 0.107        |\n",
      "|    reward             | 0.0006726747 |\n",
      "|    std                | 31.7         |\n",
      "|    value_loss         | 0.000182     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 326      |\n",
      "|    iterations         | 20200    |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 101000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 20199    |\n",
      "|    policy_loss        | -0.123   |\n",
      "|    reward             | 0.019101 |\n",
      "|    std                | 32.9     |\n",
      "|    value_loss         | 0.000158 |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 20300        |\n",
      "|    time_elapsed       | 310          |\n",
      "|    total_timesteps    | 101500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.89        |\n",
      "|    explained_variance | -81.4        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20299        |\n",
      "|    policy_loss        | -0.285       |\n",
      "|    reward             | -0.011853455 |\n",
      "|    std                | 34.3         |\n",
      "|    value_loss         | 0.00574      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 20400        |\n",
      "|    time_elapsed       | 311          |\n",
      "|    total_timesteps    | 102000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.95        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20399        |\n",
      "|    policy_loss        | -0.268       |\n",
      "|    reward             | 0.0096413735 |\n",
      "|    std                | 35.4         |\n",
      "|    value_loss         | 0.000994     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 20500         |\n",
      "|    time_elapsed       | 313           |\n",
      "|    total_timesteps    | 102500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.98         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20499         |\n",
      "|    policy_loss        | 0.0798        |\n",
      "|    reward             | -0.0012855536 |\n",
      "|    std                | 35.8          |\n",
      "|    value_loss         | 0.0002        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 20600         |\n",
      "|    time_elapsed       | 314           |\n",
      "|    total_timesteps    | 103000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20599         |\n",
      "|    policy_loss        | -0.167        |\n",
      "|    reward             | -0.0014251578 |\n",
      "|    std                | 36.4          |\n",
      "|    value_loss         | 0.000463      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 20700       |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 103500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | -0.0297     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20699       |\n",
      "|    policy_loss        | -0.132      |\n",
      "|    reward             | 0.014082284 |\n",
      "|    std                | 37.2        |\n",
      "|    value_loss         | 0.00037     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 20800       |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 104000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | -2          |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20799       |\n",
      "|    policy_loss        | 0.355       |\n",
      "|    reward             | -0.02013307 |\n",
      "|    std                | 38.7        |\n",
      "|    value_loss         | 0.00151     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 20900        |\n",
      "|    time_elapsed       | 319          |\n",
      "|    total_timesteps    | 104500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | 0.672        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20899        |\n",
      "|    policy_loss        | 0.365        |\n",
      "|    reward             | 0.0029632833 |\n",
      "|    std                | 40.5         |\n",
      "|    value_loss         | 0.00135      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 21000        |\n",
      "|    time_elapsed       | 320          |\n",
      "|    total_timesteps    | 105000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | -0.24        |\n",
      "|    reward             | -0.026726322 |\n",
      "|    std                | 41.8         |\n",
      "|    value_loss         | 0.000592     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 21100        |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 105500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21099        |\n",
      "|    policy_loss        | 0.28         |\n",
      "|    reward             | -0.039847832 |\n",
      "|    std                | 43           |\n",
      "|    value_loss         | 0.000653     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 21200         |\n",
      "|    time_elapsed       | 323           |\n",
      "|    total_timesteps    | 106000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.4         |\n",
      "|    explained_variance | -0.178        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21199         |\n",
      "|    policy_loss        | 0.305         |\n",
      "|    reward             | -0.0070295874 |\n",
      "|    std                | 43.9          |\n",
      "|    value_loss         | 0.0011        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 21300         |\n",
      "|    time_elapsed       | 325           |\n",
      "|    total_timesteps    | 106500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.4         |\n",
      "|    explained_variance | 0.951         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21299         |\n",
      "|    policy_loss        | -0.0828       |\n",
      "|    reward             | -0.0008212475 |\n",
      "|    std                | 45.2          |\n",
      "|    value_loss         | 5.71e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 326          |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.5        |\n",
      "|    explained_variance | 0.000582     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | 0.0695       |\n",
      "|    reward             | -0.007987782 |\n",
      "|    std                | 46.1         |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 21500        |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 107500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.5        |\n",
      "|    explained_variance | 0.317        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21499        |\n",
      "|    policy_loss        | 0.153        |\n",
      "|    reward             | 0.0021587359 |\n",
      "|    std                | 46.6         |\n",
      "|    value_loss         | 0.000585     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 21600        |\n",
      "|    time_elapsed       | 329          |\n",
      "|    total_timesteps    | 108000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21599        |\n",
      "|    policy_loss        | -0.0769      |\n",
      "|    reward             | -0.024944667 |\n",
      "|    std                | 48.5         |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 21700        |\n",
      "|    time_elapsed       | 331          |\n",
      "|    total_timesteps    | 108500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21699        |\n",
      "|    policy_loss        | 0.133        |\n",
      "|    reward             | -0.009710834 |\n",
      "|    std                | 49.1         |\n",
      "|    value_loss         | 0.000197     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 21800       |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 109000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21799       |\n",
      "|    policy_loss        | 0.139       |\n",
      "|    reward             | 0.009875464 |\n",
      "|    std                | 50.4        |\n",
      "|    value_loss         | 0.000228    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 21900         |\n",
      "|    time_elapsed       | 334           |\n",
      "|    total_timesteps    | 109500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21899         |\n",
      "|    policy_loss        | -0.0547       |\n",
      "|    reward             | -0.0035646637 |\n",
      "|    std                | 52.2          |\n",
      "|    value_loss         | 3.03e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 335        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | -22.2      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21999      |\n",
      "|    policy_loss        | 0.0471     |\n",
      "|    reward             | -0.0237329 |\n",
      "|    std                | 53.7       |\n",
      "|    value_loss         | 0.00192    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 22100       |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 110500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22099       |\n",
      "|    policy_loss        | -0.339      |\n",
      "|    reward             | -0.02798071 |\n",
      "|    std                | 55.3        |\n",
      "|    value_loss         | 0.00105     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 22200       |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 111000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22199       |\n",
      "|    policy_loss        | -0.228      |\n",
      "|    reward             | -0.06663005 |\n",
      "|    std                | 56.3        |\n",
      "|    value_loss         | 0.00108     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 22300        |\n",
      "|    time_elapsed       | 340          |\n",
      "|    total_timesteps    | 111500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22299        |\n",
      "|    policy_loss        | -0.382       |\n",
      "|    reward             | -0.008705598 |\n",
      "|    std                | 56.7         |\n",
      "|    value_loss         | 0.00366      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 22400      |\n",
      "|    time_elapsed       | 341        |\n",
      "|    total_timesteps    | 112000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | -0.00308   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22399      |\n",
      "|    policy_loss        | -1.55      |\n",
      "|    reward             | 0.07720108 |\n",
      "|    std                | 57.2       |\n",
      "|    value_loss         | 0.0743     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 327       |\n",
      "|    iterations         | 22500     |\n",
      "|    time_elapsed       | 343       |\n",
      "|    total_timesteps    | 112500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.9     |\n",
      "|    explained_variance | 0.264     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 22499     |\n",
      "|    policy_loss        | 2.93      |\n",
      "|    reward             | 0.1493671 |\n",
      "|    std                | 57        |\n",
      "|    value_loss         | 0.129     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 22600      |\n",
      "|    time_elapsed       | 344        |\n",
      "|    total_timesteps    | 113000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | 0.532      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22599      |\n",
      "|    policy_loss        | -3.62      |\n",
      "|    reward             | 0.13156869 |\n",
      "|    std                | 57.2       |\n",
      "|    value_loss         | 0.118      |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -232738.70\n",
      "total_reward: -242738.70\n",
      "total_cost: 102.01\n",
      "total_trades: 5666\n",
      "Sharpe: 0.486\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 22700        |\n",
      "|    time_elapsed       | 346          |\n",
      "|    total_timesteps    | 113500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22699        |\n",
      "|    policy_loss        | -0.0706      |\n",
      "|    reward             | -0.013498752 |\n",
      "|    std                | 57.7         |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 22800       |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 114000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22799       |\n",
      "|    policy_loss        | 0.0417      |\n",
      "|    reward             | 0.004307806 |\n",
      "|    std                | 58.2        |\n",
      "|    value_loss         | 1.74e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 22900       |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 114500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22899       |\n",
      "|    policy_loss        | 0.126       |\n",
      "|    reward             | 0.045951325 |\n",
      "|    std                | 59.1        |\n",
      "|    value_loss         | 0.000229    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 23000         |\n",
      "|    time_elapsed       | 350           |\n",
      "|    total_timesteps    | 115000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11           |\n",
      "|    explained_variance | -5.6e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22999         |\n",
      "|    policy_loss        | -0.0989       |\n",
      "|    reward             | -0.0106518455 |\n",
      "|    std                | 60.6          |\n",
      "|    value_loss         | 9.79e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 23100        |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 115500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | -0.256       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23099        |\n",
      "|    policy_loss        | -0.0177      |\n",
      "|    reward             | -0.007023802 |\n",
      "|    std                | 62.1         |\n",
      "|    value_loss         | 5.76e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 23200        |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 116000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23199        |\n",
      "|    policy_loss        | 0.154        |\n",
      "|    reward             | -0.012447158 |\n",
      "|    std                | 63.2         |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 23300       |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 116500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23299       |\n",
      "|    policy_loss        | 0.132       |\n",
      "|    reward             | 0.062288318 |\n",
      "|    std                | 64.7        |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 23400        |\n",
      "|    time_elapsed       | 356          |\n",
      "|    total_timesteps    | 117000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23399        |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | -0.025219668 |\n",
      "|    std                | 65.9         |\n",
      "|    value_loss         | 0.00105      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 23500       |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 117500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23499       |\n",
      "|    policy_loss        | 0.915       |\n",
      "|    reward             | -0.10520913 |\n",
      "|    std                | 66.9        |\n",
      "|    value_loss         | 0.015       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 23600       |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 118000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | -1.25       |\n",
      "|    reward             | 0.093380295 |\n",
      "|    std                | 67.4        |\n",
      "|    value_loss         | 0.0209      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 328       |\n",
      "|    iterations         | 23700     |\n",
      "|    time_elapsed       | 361       |\n",
      "|    total_timesteps    | 118500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 23699     |\n",
      "|    policy_loss        | 10.2      |\n",
      "|    reward             | 0.2032052 |\n",
      "|    std                | 68        |\n",
      "|    value_loss         | 1         |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 23800         |\n",
      "|    time_elapsed       | 362           |\n",
      "|    total_timesteps    | 119000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.3         |\n",
      "|    explained_variance | 0.08          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23799         |\n",
      "|    policy_loss        | 1.72          |\n",
      "|    reward             | -0.0144186625 |\n",
      "|    std                | 68.4          |\n",
      "|    value_loss         | 0.127         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 23900       |\n",
      "|    time_elapsed       | 364         |\n",
      "|    total_timesteps    | 119500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23899       |\n",
      "|    policy_loss        | -0.00379    |\n",
      "|    reward             | 0.012941111 |\n",
      "|    std                | 69          |\n",
      "|    value_loss         | 0.00235     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 24000        |\n",
      "|    time_elapsed       | 365          |\n",
      "|    total_timesteps    | 120000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23999        |\n",
      "|    policy_loss        | 0.161        |\n",
      "|    reward             | -0.044813503 |\n",
      "|    std                | 70.2         |\n",
      "|    value_loss         | 0.00212      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 24100       |\n",
      "|    time_elapsed       | 366         |\n",
      "|    total_timesteps    | 120500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 0.00319     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24099       |\n",
      "|    policy_loss        | -0.239      |\n",
      "|    reward             | 0.056493632 |\n",
      "|    std                | 70.2        |\n",
      "|    value_loss         | 0.000868    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 24200        |\n",
      "|    time_elapsed       | 368          |\n",
      "|    total_timesteps    | 121000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | -0.0376      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24199        |\n",
      "|    policy_loss        | 0.0303       |\n",
      "|    reward             | -0.030942032 |\n",
      "|    std                | 71.4         |\n",
      "|    value_loss         | 4.25e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 24300        |\n",
      "|    time_elapsed       | 369          |\n",
      "|    total_timesteps    | 121500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | -4.14        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24299        |\n",
      "|    policy_loss        | -0.922       |\n",
      "|    reward             | -0.044315662 |\n",
      "|    std                | 73           |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 24400        |\n",
      "|    time_elapsed       | 371          |\n",
      "|    total_timesteps    | 122000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24399        |\n",
      "|    policy_loss        | 0.0601       |\n",
      "|    reward             | -0.004431298 |\n",
      "|    std                | 75           |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 24500       |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 122500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24499       |\n",
      "|    policy_loss        | -0.0994     |\n",
      "|    reward             | 0.037813004 |\n",
      "|    std                | 75          |\n",
      "|    value_loss         | 0.000407    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 24600        |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 123000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24599        |\n",
      "|    policy_loss        | 0.361        |\n",
      "|    reward             | -0.026933705 |\n",
      "|    std                | 77.7         |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 24700       |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 123500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0.235       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | 0.0082      |\n",
      "|    reward             | 0.011105857 |\n",
      "|    std                | 79.2        |\n",
      "|    value_loss         | 2.18e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 24800        |\n",
      "|    time_elapsed       | 377          |\n",
      "|    total_timesteps    | 124000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 1.79e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24799        |\n",
      "|    policy_loss        | -0.704       |\n",
      "|    reward             | -0.009471807 |\n",
      "|    std                | 80.1         |\n",
      "|    value_loss         | 0.00395      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 24900      |\n",
      "|    time_elapsed       | 378        |\n",
      "|    total_timesteps    | 124500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.6      |\n",
      "|    explained_variance | 0.756      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24899      |\n",
      "|    policy_loss        | -0.357     |\n",
      "|    reward             | 0.07068563 |\n",
      "|    std                | 81.4       |\n",
      "|    value_loss         | 0.00111    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 25000      |\n",
      "|    time_elapsed       | 380        |\n",
      "|    total_timesteps    | 125000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24999      |\n",
      "|    policy_loss        | 0.213      |\n",
      "|    reward             | 0.04175931 |\n",
      "|    std                | 82.6       |\n",
      "|    value_loss         | 0.000602   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 25100       |\n",
      "|    time_elapsed       | 381         |\n",
      "|    total_timesteps    | 125500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 0.00468     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25099       |\n",
      "|    policy_loss        | 0.158       |\n",
      "|    reward             | 0.015192624 |\n",
      "|    std                | 83.5        |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 25200      |\n",
      "|    time_elapsed       | 383        |\n",
      "|    total_timesteps    | 126000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 0.21       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25199      |\n",
      "|    policy_loss        | -1.28      |\n",
      "|    reward             | 0.09322491 |\n",
      "|    std                | 84.8       |\n",
      "|    value_loss         | 0.0182     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 25300      |\n",
      "|    time_elapsed       | 384        |\n",
      "|    total_timesteps    | 126500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 0.0804     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25299      |\n",
      "|    policy_loss        | -0.699     |\n",
      "|    reward             | 0.08117238 |\n",
      "|    std                | 86.1       |\n",
      "|    value_loss         | 0.00553    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 1.66e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | 4.4         |\n",
      "|    reward             | 0.004394205 |\n",
      "|    std                | 85.8        |\n",
      "|    value_loss         | 0.195       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 25500       |\n",
      "|    time_elapsed       | 387         |\n",
      "|    total_timesteps    | 127500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25499       |\n",
      "|    policy_loss        | -0.779      |\n",
      "|    reward             | 0.074596755 |\n",
      "|    std                | 86.4        |\n",
      "|    value_loss         | 0.0622      |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -111676.59\n",
      "total_reward: -121676.59\n",
      "total_cost: 101.52\n",
      "total_trades: 5666\n",
      "Sharpe: -0.319\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 25600       |\n",
      "|    time_elapsed       | 388         |\n",
      "|    total_timesteps    | 128000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25599       |\n",
      "|    policy_loss        | -0.444      |\n",
      "|    reward             | 0.021646056 |\n",
      "|    std                | 86.8        |\n",
      "|    value_loss         | 0.00156     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 25700        |\n",
      "|    time_elapsed       | 390          |\n",
      "|    total_timesteps    | 128500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25699        |\n",
      "|    policy_loss        | 0.0569       |\n",
      "|    reward             | -0.017375702 |\n",
      "|    std                | 87.9         |\n",
      "|    value_loss         | 4.99e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 25800        |\n",
      "|    time_elapsed       | 391          |\n",
      "|    total_timesteps    | 129000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25799        |\n",
      "|    policy_loss        | 0.0989       |\n",
      "|    reward             | 0.0039535747 |\n",
      "|    std                | 89.8         |\n",
      "|    value_loss         | 7.78e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 25900      |\n",
      "|    time_elapsed       | 393        |\n",
      "|    total_timesteps    | 129500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.9      |\n",
      "|    explained_variance | -19.1      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25899      |\n",
      "|    policy_loss        | -0.237     |\n",
      "|    reward             | 0.00882698 |\n",
      "|    std                | 92.2       |\n",
      "|    value_loss         | 0.000813   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 26000         |\n",
      "|    time_elapsed       | 394           |\n",
      "|    total_timesteps    | 130000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.9         |\n",
      "|    explained_variance | -16.3         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 25999         |\n",
      "|    policy_loss        | -0.131        |\n",
      "|    reward             | -0.0015018211 |\n",
      "|    std                | 93.4          |\n",
      "|    value_loss         | 0.000523      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 26100        |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 130500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26099        |\n",
      "|    policy_loss        | -0.388       |\n",
      "|    reward             | -0.034271963 |\n",
      "|    std                | 95.4         |\n",
      "|    value_loss         | 0.00167      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 26200       |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 131000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26199       |\n",
      "|    policy_loss        | -0.406      |\n",
      "|    reward             | 0.039629184 |\n",
      "|    std                | 96          |\n",
      "|    value_loss         | 0.00396     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 26300       |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 131500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26299       |\n",
      "|    policy_loss        | 0.486       |\n",
      "|    reward             | 0.030819831 |\n",
      "|    std                | 96.7        |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 26400       |\n",
      "|    time_elapsed       | 400         |\n",
      "|    total_timesteps    | 132000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -0.111      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26399       |\n",
      "|    policy_loss        | 0.463       |\n",
      "|    reward             | -0.06212539 |\n",
      "|    std                | 97.3        |\n",
      "|    value_loss         | 0.00765     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 26500      |\n",
      "|    time_elapsed       | 402        |\n",
      "|    total_timesteps    | 132500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26499      |\n",
      "|    policy_loss        | -3.68      |\n",
      "|    reward             | 0.07190344 |\n",
      "|    std                | 99.3       |\n",
      "|    value_loss         | 0.104      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 26600     |\n",
      "|    time_elapsed       | 403       |\n",
      "|    total_timesteps    | 133000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12       |\n",
      "|    explained_variance | -0.114    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 26599     |\n",
      "|    policy_loss        | -3.03     |\n",
      "|    reward             | 0.2319012 |\n",
      "|    std                | 99.6      |\n",
      "|    value_loss         | 0.113     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 26700       |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 133500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26699       |\n",
      "|    policy_loss        | 0.809       |\n",
      "|    reward             | 0.019925088 |\n",
      "|    std                | 100         |\n",
      "|    value_loss         | 0.00625     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 26800       |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 134000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26799       |\n",
      "|    policy_loss        | -0.655      |\n",
      "|    reward             | 0.017744752 |\n",
      "|    std                | 100         |\n",
      "|    value_loss         | 0.00482     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 26900      |\n",
      "|    time_elapsed       | 408        |\n",
      "|    total_timesteps    | 134500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.1      |\n",
      "|    explained_variance | 0.928      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26899      |\n",
      "|    policy_loss        | -0.824     |\n",
      "|    reward             | 0.02752535 |\n",
      "|    std                | 101        |\n",
      "|    value_loss         | 0.00503    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 27000       |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 135000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26999       |\n",
      "|    policy_loss        | -0.0288     |\n",
      "|    reward             | 0.008617794 |\n",
      "|    std                | 103         |\n",
      "|    value_loss         | 0.00263     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 27100      |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 135500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.1      |\n",
      "|    explained_variance | 0.00038    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27099      |\n",
      "|    policy_loss        | 1.14       |\n",
      "|    reward             | 0.04805621 |\n",
      "|    std                | 105        |\n",
      "|    value_loss         | 0.0142     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 27200       |\n",
      "|    time_elapsed       | 412         |\n",
      "|    total_timesteps    | 136000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | -0.041      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27199       |\n",
      "|    policy_loss        | 4.54        |\n",
      "|    reward             | -0.12886618 |\n",
      "|    std                | 107         |\n",
      "|    value_loss         | 0.158       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 27300       |\n",
      "|    time_elapsed       | 414         |\n",
      "|    total_timesteps    | 136500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27299       |\n",
      "|    policy_loss        | -0.474      |\n",
      "|    reward             | -0.02644173 |\n",
      "|    std                | 108         |\n",
      "|    value_loss         | 0.00197     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 27400        |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 137000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27399        |\n",
      "|    policy_loss        | 1.29         |\n",
      "|    reward             | 0.0038735732 |\n",
      "|    std                | 110          |\n",
      "|    value_loss         | 0.0151       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 27500      |\n",
      "|    time_elapsed       | 417        |\n",
      "|    total_timesteps    | 137500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.2      |\n",
      "|    explained_variance | 0.0792     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27499      |\n",
      "|    policy_loss        | -0.715     |\n",
      "|    reward             | -0.1671847 |\n",
      "|    std                | 111        |\n",
      "|    value_loss         | 0.00884    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 27600      |\n",
      "|    time_elapsed       | 418        |\n",
      "|    total_timesteps    | 138000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0.0142     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27599      |\n",
      "|    policy_loss        | -2.73      |\n",
      "|    reward             | 0.41342556 |\n",
      "|    std                | 112        |\n",
      "|    value_loss         | 0.0463     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 27700      |\n",
      "|    time_elapsed       | 419        |\n",
      "|    total_timesteps    | 138500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27699      |\n",
      "|    policy_loss        | -1.19      |\n",
      "|    reward             | -0.2369813 |\n",
      "|    std                | 114        |\n",
      "|    value_loss         | 0.0667     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 27800       |\n",
      "|    time_elapsed       | 421         |\n",
      "|    total_timesteps    | 139000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27799       |\n",
      "|    policy_loss        | 0.147       |\n",
      "|    reward             | 0.007001866 |\n",
      "|    std                | 116         |\n",
      "|    value_loss         | 0.000213    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 27900          |\n",
      "|    time_elapsed       | 422            |\n",
      "|    total_timesteps    | 139500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -12.3          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 27899          |\n",
      "|    policy_loss        | -0.0698        |\n",
      "|    reward             | -0.00044080045 |\n",
      "|    std                | 117            |\n",
      "|    value_loss         | 0.000174       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 28000       |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 140000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27999       |\n",
      "|    policy_loss        | 0.245       |\n",
      "|    reward             | 0.011745523 |\n",
      "|    std                | 119         |\n",
      "|    value_loss         | 0.000483    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 28100         |\n",
      "|    time_elapsed       | 425           |\n",
      "|    total_timesteps    | 140500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28099         |\n",
      "|    policy_loss        | -0.0206       |\n",
      "|    reward             | -0.0103283785 |\n",
      "|    std                | 122           |\n",
      "|    value_loss         | 4.18e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 28200         |\n",
      "|    time_elapsed       | 427           |\n",
      "|    total_timesteps    | 141000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.5         |\n",
      "|    explained_variance | 0.00632       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28199         |\n",
      "|    policy_loss        | -0.0353       |\n",
      "|    reward             | -0.0020218142 |\n",
      "|    std                | 126           |\n",
      "|    value_loss         | 5.63e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 28300      |\n",
      "|    time_elapsed       | 428        |\n",
      "|    total_timesteps    | 141500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | -1.62      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28299      |\n",
      "|    policy_loss        | -0.109     |\n",
      "|    reward             | 0.00258314 |\n",
      "|    std                | 129        |\n",
      "|    value_loss         | 0.00148    |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11632.45\n",
      "total_reward: -21632.45\n",
      "total_cost: 544.65\n",
      "total_trades: 5666\n",
      "Sharpe: -0.380\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 28400        |\n",
      "|    time_elapsed       | 430          |\n",
      "|    total_timesteps    | 142000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28399        |\n",
      "|    policy_loss        | 0.744        |\n",
      "|    reward             | -0.044256095 |\n",
      "|    std                | 132          |\n",
      "|    value_loss         | 0.00417      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 28500        |\n",
      "|    time_elapsed       | 431          |\n",
      "|    total_timesteps    | 142500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28499        |\n",
      "|    policy_loss        | -1.16        |\n",
      "|    reward             | 0.0029632128 |\n",
      "|    std                | 134          |\n",
      "|    value_loss         | 0.00867      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 28600       |\n",
      "|    time_elapsed       | 433         |\n",
      "|    total_timesteps    | 143000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | -0.697      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28599       |\n",
      "|    policy_loss        | -0.139      |\n",
      "|    reward             | 0.024288798 |\n",
      "|    std                | 136         |\n",
      "|    value_loss         | 0.000389    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 28700        |\n",
      "|    time_elapsed       | 434          |\n",
      "|    total_timesteps    | 143500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | -0.0452      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28699        |\n",
      "|    policy_loss        | 0.0494       |\n",
      "|    reward             | -0.013489351 |\n",
      "|    std                | 140          |\n",
      "|    value_loss         | 0.00195      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 28800      |\n",
      "|    time_elapsed       | 436        |\n",
      "|    total_timesteps    | 144000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0.0774     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28799      |\n",
      "|    policy_loss        | 1.3        |\n",
      "|    reward             | 0.07005877 |\n",
      "|    std                | 141        |\n",
      "|    value_loss         | 0.0138     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 28900       |\n",
      "|    time_elapsed       | 437         |\n",
      "|    total_timesteps    | 144500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28899       |\n",
      "|    policy_loss        | 2.44        |\n",
      "|    reward             | 0.030129276 |\n",
      "|    std                | 141         |\n",
      "|    value_loss         | 0.0337      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 438         |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28999       |\n",
      "|    policy_loss        | -0.00988    |\n",
      "|    reward             | 0.016186247 |\n",
      "|    std                | 143         |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 29100       |\n",
      "|    time_elapsed       | 440         |\n",
      "|    total_timesteps    | 145500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29099       |\n",
      "|    policy_loss        | 0.359       |\n",
      "|    reward             | 0.020072877 |\n",
      "|    std                | 146         |\n",
      "|    value_loss         | 0.000984    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 29200        |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 146000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29199        |\n",
      "|    policy_loss        | -0.0726      |\n",
      "|    reward             | -0.004016608 |\n",
      "|    std                | 150          |\n",
      "|    value_loss         | 7.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 29300        |\n",
      "|    time_elapsed       | 443          |\n",
      "|    total_timesteps    | 146500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -3.06        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29299        |\n",
      "|    policy_loss        | -0.174       |\n",
      "|    reward             | -0.001157751 |\n",
      "|    std                | 154          |\n",
      "|    value_loss         | 0.000395     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 29400        |\n",
      "|    time_elapsed       | 444          |\n",
      "|    total_timesteps    | 147000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -4.91        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29399        |\n",
      "|    policy_loss        | -0.621       |\n",
      "|    reward             | -0.004848768 |\n",
      "|    std                | 160          |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 29500         |\n",
      "|    time_elapsed       | 446           |\n",
      "|    total_timesteps    | 147500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29499         |\n",
      "|    policy_loss        | -0.509        |\n",
      "|    reward             | -0.0029439067 |\n",
      "|    std                | 164           |\n",
      "|    value_loss         | 0.00187       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 29600        |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 148000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29599        |\n",
      "|    policy_loss        | 0.356        |\n",
      "|    reward             | 0.0026209792 |\n",
      "|    std                | 168          |\n",
      "|    value_loss         | 0.000801     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 29700        |\n",
      "|    time_elapsed       | 449          |\n",
      "|    total_timesteps    | 148500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29699        |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | 0.0015028574 |\n",
      "|    std                | 173          |\n",
      "|    value_loss         | 0.000314     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 29800        |\n",
      "|    time_elapsed       | 450          |\n",
      "|    total_timesteps    | 149000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | -0.282       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29799        |\n",
      "|    policy_loss        | -0.122       |\n",
      "|    reward             | 0.0054927017 |\n",
      "|    std                | 177          |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 29900         |\n",
      "|    time_elapsed       | 452           |\n",
      "|    total_timesteps    | 149500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | -4.56         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29899         |\n",
      "|    policy_loss        | -0.331        |\n",
      "|    reward             | -0.0058294833 |\n",
      "|    std                | 184           |\n",
      "|    value_loss         | 0.00144       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 30000       |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 150000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | -0.118      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29999       |\n",
      "|    policy_loss        | 0.524       |\n",
      "|    reward             | -0.01040503 |\n",
      "|    std                | 190         |\n",
      "|    value_loss         | 0.00189     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 30100        |\n",
      "|    time_elapsed       | 455          |\n",
      "|    total_timesteps    | 150500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30099        |\n",
      "|    policy_loss        | -0.0681      |\n",
      "|    reward             | -0.039527316 |\n",
      "|    std                | 196          |\n",
      "|    value_loss         | 0.00447      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 30200        |\n",
      "|    time_elapsed       | 456          |\n",
      "|    total_timesteps    | 151000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30199        |\n",
      "|    policy_loss        | -0.0105      |\n",
      "|    reward             | -0.014543325 |\n",
      "|    std                | 203          |\n",
      "|    value_loss         | 0.000232     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 30300        |\n",
      "|    time_elapsed       | 458          |\n",
      "|    total_timesteps    | 151500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -2.43        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30299        |\n",
      "|    policy_loss        | -0.785       |\n",
      "|    reward             | -0.064026676 |\n",
      "|    std                | 206          |\n",
      "|    value_loss         | 0.00387      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 30400       |\n",
      "|    time_elapsed       | 459         |\n",
      "|    total_timesteps    | 152000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0.00893     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30399       |\n",
      "|    policy_loss        | -0.935      |\n",
      "|    reward             | -0.00567582 |\n",
      "|    std                | 209         |\n",
      "|    value_loss         | 0.00658     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 330       |\n",
      "|    iterations         | 30500     |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 152500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.6     |\n",
      "|    explained_variance | 0.0196    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 30499     |\n",
      "|    policy_loss        | 2.77      |\n",
      "|    reward             | 0.2240852 |\n",
      "|    std                | 215       |\n",
      "|    value_loss         | 0.044     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 30600       |\n",
      "|    time_elapsed       | 462         |\n",
      "|    total_timesteps    | 153000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30599       |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | -0.12980095 |\n",
      "|    std                | 216         |\n",
      "|    value_loss         | 0.0238      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 30700        |\n",
      "|    time_elapsed       | 463          |\n",
      "|    total_timesteps    | 153500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30699        |\n",
      "|    policy_loss        | -0.297       |\n",
      "|    reward             | -0.023809118 |\n",
      "|    std                | 217          |\n",
      "|    value_loss         | 0.000763     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 30800       |\n",
      "|    time_elapsed       | 465         |\n",
      "|    total_timesteps    | 154000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30799       |\n",
      "|    policy_loss        | 0.611       |\n",
      "|    reward             | -0.06820552 |\n",
      "|    std                | 218         |\n",
      "|    value_loss         | 0.00319     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 30900        |\n",
      "|    time_elapsed       | 466          |\n",
      "|    total_timesteps    | 154500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 8.94e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30899        |\n",
      "|    policy_loss        | 3.28         |\n",
      "|    reward             | 0.0051817694 |\n",
      "|    std                | 221          |\n",
      "|    value_loss         | 0.0919       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 31000      |\n",
      "|    time_elapsed       | 468        |\n",
      "|    total_timesteps    | 155000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30999      |\n",
      "|    policy_loss        | 3.56       |\n",
      "|    reward             | 0.14370683 |\n",
      "|    std                | 221        |\n",
      "|    value_loss         | 0.0957     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 31100      |\n",
      "|    time_elapsed       | 470        |\n",
      "|    total_timesteps    | 155500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31099      |\n",
      "|    policy_loss        | 4.92       |\n",
      "|    reward             | 0.23788573 |\n",
      "|    std                | 223        |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -254234.26\n",
      "total_reward: -264234.26\n",
      "total_cost: 107.65\n",
      "total_trades: 5666\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 31200      |\n",
      "|    time_elapsed       | 471        |\n",
      "|    total_timesteps    | 156000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31199      |\n",
      "|    policy_loss        | -1.01      |\n",
      "|    reward             | 0.02353807 |\n",
      "|    std                | 224        |\n",
      "|    value_loss         | 0.00793    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 31300       |\n",
      "|    time_elapsed       | 473         |\n",
      "|    total_timesteps    | 156500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31299       |\n",
      "|    policy_loss        | -0.368      |\n",
      "|    reward             | 0.002386681 |\n",
      "|    std                | 224         |\n",
      "|    value_loss         | 0.00273     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 31400        |\n",
      "|    time_elapsed       | 474          |\n",
      "|    total_timesteps    | 157000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31399        |\n",
      "|    policy_loss        | -0.749       |\n",
      "|    reward             | -0.052215632 |\n",
      "|    std                | 229          |\n",
      "|    value_loss         | 0.00542      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 31500        |\n",
      "|    time_elapsed       | 476          |\n",
      "|    total_timesteps    | 157500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.174        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31499        |\n",
      "|    policy_loss        | -2.05        |\n",
      "|    reward             | -0.071670726 |\n",
      "|    std                | 228          |\n",
      "|    value_loss         | 0.0384       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 31600      |\n",
      "|    time_elapsed       | 477        |\n",
      "|    total_timesteps    | 158000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31599      |\n",
      "|    policy_loss        | -10.6      |\n",
      "|    reward             | 0.06552826 |\n",
      "|    std                | 231        |\n",
      "|    value_loss         | 0.673      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 31700       |\n",
      "|    time_elapsed       | 478         |\n",
      "|    total_timesteps    | 158500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0.0255      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31699       |\n",
      "|    policy_loss        | 1.72        |\n",
      "|    reward             | -0.12837662 |\n",
      "|    std                | 233         |\n",
      "|    value_loss         | 0.385       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 31800       |\n",
      "|    time_elapsed       | 480         |\n",
      "|    total_timesteps    | 159000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31799       |\n",
      "|    policy_loss        | 0.0742      |\n",
      "|    reward             | 0.014282798 |\n",
      "|    std                | 234         |\n",
      "|    value_loss         | 0.00163     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 31900       |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 159500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31899       |\n",
      "|    policy_loss        | 0.145       |\n",
      "|    reward             | 0.005551021 |\n",
      "|    std                | 236         |\n",
      "|    value_loss         | 0.000158    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 32000       |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 160000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31999       |\n",
      "|    policy_loss        | -0.14       |\n",
      "|    reward             | -0.03207548 |\n",
      "|    std                | 240         |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 32100        |\n",
      "|    time_elapsed       | 484          |\n",
      "|    total_timesteps    | 160500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | -8.85        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32099        |\n",
      "|    policy_loss        | -0.0634      |\n",
      "|    reward             | 0.0028362724 |\n",
      "|    std                | 247          |\n",
      "|    value_loss         | 9.51e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 32200          |\n",
      "|    time_elapsed       | 486            |\n",
      "|    total_timesteps    | 161000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.9          |\n",
      "|    explained_variance | -273           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 32199          |\n",
      "|    policy_loss        | -0.959         |\n",
      "|    reward             | -0.00023600027 |\n",
      "|    std                | 253            |\n",
      "|    value_loss         | 0.109          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 32300         |\n",
      "|    time_elapsed       | 487           |\n",
      "|    total_timesteps    | 161500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.9         |\n",
      "|    explained_variance | 0.356         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32299         |\n",
      "|    policy_loss        | 0.571         |\n",
      "|    reward             | -0.0030403885 |\n",
      "|    std                | 260           |\n",
      "|    value_loss         | 0.0019        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 32400        |\n",
      "|    time_elapsed       | 489          |\n",
      "|    total_timesteps    | 162000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32399        |\n",
      "|    policy_loss        | -0.299       |\n",
      "|    reward             | 0.0053795725 |\n",
      "|    std                | 264          |\n",
      "|    value_loss         | 0.000664     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 32500          |\n",
      "|    time_elapsed       | 490            |\n",
      "|    total_timesteps    | 162500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 32499          |\n",
      "|    policy_loss        | -0.0859        |\n",
      "|    reward             | -0.00025263862 |\n",
      "|    std                | 273            |\n",
      "|    value_loss         | 0.00016        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 32600         |\n",
      "|    time_elapsed       | 492           |\n",
      "|    total_timesteps    | 163000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32599         |\n",
      "|    policy_loss        | 0.135         |\n",
      "|    reward             | -0.0077976813 |\n",
      "|    std                | 282           |\n",
      "|    value_loss         | 0.00022       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 32700         |\n",
      "|    time_elapsed       | 493           |\n",
      "|    total_timesteps    | 163500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | -0.943        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32699         |\n",
      "|    policy_loss        | -0.142        |\n",
      "|    reward             | -0.0077135093 |\n",
      "|    std                | 294           |\n",
      "|    value_loss         | 0.000146      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 32800         |\n",
      "|    time_elapsed       | 495           |\n",
      "|    total_timesteps    | 164000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32799         |\n",
      "|    policy_loss        | 0.164         |\n",
      "|    reward             | -0.0016061976 |\n",
      "|    std                | 302           |\n",
      "|    value_loss         | 0.000152      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 32900      |\n",
      "|    time_elapsed       | 496        |\n",
      "|    total_timesteps    | 164500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32899      |\n",
      "|    policy_loss        | -0.962     |\n",
      "|    reward             | 0.03514881 |\n",
      "|    std                | 309        |\n",
      "|    value_loss         | 0.00519    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 33000        |\n",
      "|    time_elapsed       | 498          |\n",
      "|    total_timesteps    | 165000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32999        |\n",
      "|    policy_loss        | -0.105       |\n",
      "|    reward             | -0.022514392 |\n",
      "|    std                | 313          |\n",
      "|    value_loss         | 0.000137     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 33100        |\n",
      "|    time_elapsed       | 499          |\n",
      "|    total_timesteps    | 165500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33099        |\n",
      "|    policy_loss        | 0.259        |\n",
      "|    reward             | -0.055337187 |\n",
      "|    std                | 318          |\n",
      "|    value_loss         | 0.00164      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 33200       |\n",
      "|    time_elapsed       | 500         |\n",
      "|    total_timesteps    | 166000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0.571       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33199       |\n",
      "|    policy_loss        | 0.85        |\n",
      "|    reward             | 0.011401247 |\n",
      "|    std                | 320         |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 33300       |\n",
      "|    time_elapsed       | 502         |\n",
      "|    total_timesteps    | 166500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33299       |\n",
      "|    policy_loss        | 1.05        |\n",
      "|    reward             | -0.16118732 |\n",
      "|    std                | 327         |\n",
      "|    value_loss         | 0.0059      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 33400       |\n",
      "|    time_elapsed       | 503         |\n",
      "|    total_timesteps    | 167000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33399       |\n",
      "|    policy_loss        | -7.17       |\n",
      "|    reward             | -0.30232018 |\n",
      "|    std                | 334         |\n",
      "|    value_loss         | 0.272       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 33500     |\n",
      "|    time_elapsed       | 505       |\n",
      "|    total_timesteps    | 167500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 33499     |\n",
      "|    policy_loss        | 1.29      |\n",
      "|    reward             | 0.0444641 |\n",
      "|    std                | 333       |\n",
      "|    value_loss         | 0.0095    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 33600        |\n",
      "|    time_elapsed       | 506          |\n",
      "|    total_timesteps    | 168000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33599        |\n",
      "|    policy_loss        | -0.262       |\n",
      "|    reward             | 0.0029812388 |\n",
      "|    std                | 335          |\n",
      "|    value_loss         | 0.000409     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 33700        |\n",
      "|    time_elapsed       | 508          |\n",
      "|    total_timesteps    | 168500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33699        |\n",
      "|    policy_loss        | -0.0651      |\n",
      "|    reward             | -0.010443937 |\n",
      "|    std                | 340          |\n",
      "|    value_loss         | 3.95e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 33800       |\n",
      "|    time_elapsed       | 509         |\n",
      "|    total_timesteps    | 169000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | -1.55e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33799       |\n",
      "|    policy_loss        | -0.0341     |\n",
      "|    reward             | 0.021750707 |\n",
      "|    std                | 347         |\n",
      "|    value_loss         | 1.07e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 33900        |\n",
      "|    time_elapsed       | 511          |\n",
      "|    total_timesteps    | 169500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33899        |\n",
      "|    policy_loss        | 0.383        |\n",
      "|    reward             | -0.021865811 |\n",
      "|    std                | 356          |\n",
      "|    value_loss         | 0.000759     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 34000        |\n",
      "|    time_elapsed       | 512          |\n",
      "|    total_timesteps    | 170000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33999        |\n",
      "|    policy_loss        | 0.436        |\n",
      "|    reward             | -0.013697351 |\n",
      "|    std                | 367          |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -14881.70\n",
      "total_reward: -24881.70\n",
      "total_cost: 390.03\n",
      "total_trades: 5666\n",
      "Sharpe: -0.104\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 34100        |\n",
      "|    time_elapsed       | 514          |\n",
      "|    total_timesteps    | 170500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34099        |\n",
      "|    policy_loss        | -0.982       |\n",
      "|    reward             | 0.0021660742 |\n",
      "|    std                | 376          |\n",
      "|    value_loss         | 0.00792      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 34200       |\n",
      "|    time_elapsed       | 516         |\n",
      "|    total_timesteps    | 171000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34199       |\n",
      "|    policy_loss        | -0.389      |\n",
      "|    reward             | 0.053367723 |\n",
      "|    std                | 381         |\n",
      "|    value_loss         | 0.00156     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 34300        |\n",
      "|    time_elapsed       | 517          |\n",
      "|    total_timesteps    | 171500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0.485        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34299        |\n",
      "|    policy_loss        | 0.306        |\n",
      "|    reward             | -0.011918653 |\n",
      "|    std                | 388          |\n",
      "|    value_loss         | 0.00082      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 34400        |\n",
      "|    time_elapsed       | 518          |\n",
      "|    total_timesteps    | 172000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34399        |\n",
      "|    policy_loss        | -0.724       |\n",
      "|    reward             | -0.019310292 |\n",
      "|    std                | 402          |\n",
      "|    value_loss         | 0.00329      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 34500        |\n",
      "|    time_elapsed       | 520          |\n",
      "|    total_timesteps    | 172500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34499        |\n",
      "|    policy_loss        | -0.281       |\n",
      "|    reward             | -0.016994804 |\n",
      "|    std                | 410          |\n",
      "|    value_loss         | 0.000576     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 34600        |\n",
      "|    time_elapsed       | 521          |\n",
      "|    total_timesteps    | 173000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34599        |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | -0.024458893 |\n",
      "|    std                | 414          |\n",
      "|    value_loss         | 0.000529     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 34700       |\n",
      "|    time_elapsed       | 523         |\n",
      "|    total_timesteps    | 173500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34699       |\n",
      "|    policy_loss        | -0.171      |\n",
      "|    reward             | 0.010819063 |\n",
      "|    std                | 423         |\n",
      "|    value_loss         | 0.000174    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 34800       |\n",
      "|    time_elapsed       | 524         |\n",
      "|    total_timesteps    | 174000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34799       |\n",
      "|    policy_loss        | 0.172       |\n",
      "|    reward             | 0.011905628 |\n",
      "|    std                | 431         |\n",
      "|    value_loss         | 0.000127    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 34900         |\n",
      "|    time_elapsed       | 526           |\n",
      "|    total_timesteps    | 174500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34899         |\n",
      "|    policy_loss        | 0.166         |\n",
      "|    reward             | -0.0111901285 |\n",
      "|    std                | 441           |\n",
      "|    value_loss         | 0.000168      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 35000       |\n",
      "|    time_elapsed       | 527         |\n",
      "|    total_timesteps    | 175000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 0.163       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34999       |\n",
      "|    policy_loss        | -0.112      |\n",
      "|    reward             | 0.013469941 |\n",
      "|    std                | 455         |\n",
      "|    value_loss         | 8.16e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 35100        |\n",
      "|    time_elapsed       | 529          |\n",
      "|    total_timesteps    | 175500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0.0951       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35099        |\n",
      "|    policy_loss        | -0.232       |\n",
      "|    reward             | 0.0004736445 |\n",
      "|    std                | 467          |\n",
      "|    value_loss         | 0.000284     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 35200        |\n",
      "|    time_elapsed       | 530          |\n",
      "|    total_timesteps    | 176000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35199        |\n",
      "|    policy_loss        | 0.922        |\n",
      "|    reward             | -0.018529799 |\n",
      "|    std                | 478          |\n",
      "|    value_loss         | 0.005        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 35300         |\n",
      "|    time_elapsed       | 532           |\n",
      "|    total_timesteps    | 176500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 35299         |\n",
      "|    policy_loss        | -0.428        |\n",
      "|    reward             | -0.0012317005 |\n",
      "|    std                | 487           |\n",
      "|    value_loss         | 0.000996      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 35400          |\n",
      "|    time_elapsed       | 533            |\n",
      "|    total_timesteps    | 177000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.2          |\n",
      "|    explained_variance | -0.00754       |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 35399          |\n",
      "|    policy_loss        | -0.0985        |\n",
      "|    reward             | -2.6630318e-05 |\n",
      "|    std                | 492            |\n",
      "|    value_loss         | 0.000367       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 35500        |\n",
      "|    time_elapsed       | 535          |\n",
      "|    total_timesteps    | 177500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | -0.107       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35499        |\n",
      "|    policy_loss        | 0.0683       |\n",
      "|    reward             | -0.024378223 |\n",
      "|    std                | 502          |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 35600          |\n",
      "|    time_elapsed       | 536            |\n",
      "|    total_timesteps    | 178000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.3          |\n",
      "|    explained_variance | 0.154          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 35599          |\n",
      "|    policy_loss        | -0.0705        |\n",
      "|    reward             | -0.00029063114 |\n",
      "|    std                | 513            |\n",
      "|    value_loss         | 0.0004         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 35700       |\n",
      "|    time_elapsed       | 538         |\n",
      "|    total_timesteps    | 178500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0.00821     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35699       |\n",
      "|    policy_loss        | 0.901       |\n",
      "|    reward             | -0.01899074 |\n",
      "|    std                | 521         |\n",
      "|    value_loss         | 0.00601     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 35800        |\n",
      "|    time_elapsed       | 539          |\n",
      "|    total_timesteps    | 179000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35799        |\n",
      "|    policy_loss        | -2.88        |\n",
      "|    reward             | -0.023821466 |\n",
      "|    std                | 533          |\n",
      "|    value_loss         | 0.0381       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 35900        |\n",
      "|    time_elapsed       | 541          |\n",
      "|    total_timesteps    | 179500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35899        |\n",
      "|    policy_loss        | -1.74        |\n",
      "|    reward             | -0.059915822 |\n",
      "|    std                | 543          |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 36000      |\n",
      "|    time_elapsed       | 542        |\n",
      "|    total_timesteps    | 180000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.4      |\n",
      "|    explained_variance | 0.175      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35999      |\n",
      "|    policy_loss        | 6.44       |\n",
      "|    reward             | 0.22151875 |\n",
      "|    std                | 543        |\n",
      "|    value_loss         | 0.24       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 36100      |\n",
      "|    time_elapsed       | 544        |\n",
      "|    total_timesteps    | 180500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.5      |\n",
      "|    explained_variance | -0.142     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 36099      |\n",
      "|    policy_loss        | -4.72      |\n",
      "|    reward             | 0.25374615 |\n",
      "|    std                | 552        |\n",
      "|    value_loss         | 0.124      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 36200       |\n",
      "|    time_elapsed       | 545         |\n",
      "|    total_timesteps    | 181000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0.799       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | 3.19        |\n",
      "|    reward             | 0.047461767 |\n",
      "|    std                | 552         |\n",
      "|    value_loss         | 0.044       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 547         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | -1.35       |\n",
      "|    reward             | -0.03865614 |\n",
      "|    std                | 552         |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 36400      |\n",
      "|    time_elapsed       | 548        |\n",
      "|    total_timesteps    | 182000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 36399      |\n",
      "|    policy_loss        | 0.81       |\n",
      "|    reward             | 0.09990409 |\n",
      "|    std                | 563        |\n",
      "|    value_loss         | 0.00552    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 36500        |\n",
      "|    time_elapsed       | 550          |\n",
      "|    total_timesteps    | 182500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36499        |\n",
      "|    policy_loss        | -0.629       |\n",
      "|    reward             | -0.095676154 |\n",
      "|    std                | 564          |\n",
      "|    value_loss         | 0.00368      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 36600        |\n",
      "|    time_elapsed       | 551          |\n",
      "|    total_timesteps    | 183000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0.609        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36599        |\n",
      "|    policy_loss        | 3.35         |\n",
      "|    reward             | -0.026857764 |\n",
      "|    std                | 572          |\n",
      "|    value_loss         | 0.0493       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 36700     |\n",
      "|    time_elapsed       | 553       |\n",
      "|    total_timesteps    | 183500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.6     |\n",
      "|    explained_variance | 0.211     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 36699     |\n",
      "|    policy_loss        | -2.88     |\n",
      "|    reward             | -0.800519 |\n",
      "|    std                | 578       |\n",
      "|    value_loss         | 0.0559    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 36800       |\n",
      "|    time_elapsed       | 554         |\n",
      "|    total_timesteps    | 184000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36799       |\n",
      "|    policy_loss        | -5.67       |\n",
      "|    reward             | -0.83129096 |\n",
      "|    std                | 580         |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -267391.69\n",
      "total_reward: -277391.69\n",
      "total_cost: 101.68\n",
      "total_trades: 5666\n",
      "Sharpe: 0.354\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 36900        |\n",
      "|    time_elapsed       | 556          |\n",
      "|    total_timesteps    | 184500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36899        |\n",
      "|    policy_loss        | 0.0739       |\n",
      "|    reward             | -0.037187997 |\n",
      "|    std                | 582          |\n",
      "|    value_loss         | 6.52e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 37000       |\n",
      "|    time_elapsed       | 557         |\n",
      "|    total_timesteps    | 185000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36999       |\n",
      "|    policy_loss        | -0.384      |\n",
      "|    reward             | 0.010580547 |\n",
      "|    std                | 590         |\n",
      "|    value_loss         | 0.000588    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 37100        |\n",
      "|    time_elapsed       | 559          |\n",
      "|    total_timesteps    | 185500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37099        |\n",
      "|    policy_loss        | -0.17        |\n",
      "|    reward             | -0.010796322 |\n",
      "|    std                | 599          |\n",
      "|    value_loss         | 0.000218     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 37200        |\n",
      "|    time_elapsed       | 560          |\n",
      "|    total_timesteps    | 186000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37199        |\n",
      "|    policy_loss        | -0.0594      |\n",
      "|    reward             | 0.0006196736 |\n",
      "|    std                | 611          |\n",
      "|    value_loss         | 2.88e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 37300       |\n",
      "|    time_elapsed       | 562         |\n",
      "|    total_timesteps    | 186500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | -285        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37299       |\n",
      "|    policy_loss        | -2.19       |\n",
      "|    reward             | 0.004381185 |\n",
      "|    std                | 623         |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 37400       |\n",
      "|    time_elapsed       | 563         |\n",
      "|    total_timesteps    | 187000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | -1.43       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | -0.073      |\n",
      "|    reward             | 0.009297244 |\n",
      "|    std                | 628         |\n",
      "|    value_loss         | 0.000162    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 37500        |\n",
      "|    time_elapsed       | 565          |\n",
      "|    total_timesteps    | 187500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37499        |\n",
      "|    policy_loss        | -0.28        |\n",
      "|    reward             | 0.0016579151 |\n",
      "|    std                | 642          |\n",
      "|    value_loss         | 0.00076      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 37600         |\n",
      "|    time_elapsed       | 566           |\n",
      "|    total_timesteps    | 188000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37599         |\n",
      "|    policy_loss        | -0.035        |\n",
      "|    reward             | -0.0062810495 |\n",
      "|    std                | 664           |\n",
      "|    value_loss         | 2.82e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 37700       |\n",
      "|    time_elapsed       | 568         |\n",
      "|    total_timesteps    | 188500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37699       |\n",
      "|    policy_loss        | 0.58        |\n",
      "|    reward             | 0.030636858 |\n",
      "|    std                | 680         |\n",
      "|    value_loss         | 0.00171     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 37800         |\n",
      "|    time_elapsed       | 569           |\n",
      "|    total_timesteps    | 189000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37799         |\n",
      "|    policy_loss        | 0.0593        |\n",
      "|    reward             | -0.0015290283 |\n",
      "|    std                | 708           |\n",
      "|    value_loss         | 1.91e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 37900       |\n",
      "|    time_elapsed       | 571         |\n",
      "|    total_timesteps    | 189500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -25.3       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37899       |\n",
      "|    policy_loss        | -0.0771     |\n",
      "|    reward             | 0.014129023 |\n",
      "|    std                | 742         |\n",
      "|    value_loss         | 9.97e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 38000        |\n",
      "|    time_elapsed       | 572          |\n",
      "|    total_timesteps    | 190000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37999        |\n",
      "|    policy_loss        | -0.872       |\n",
      "|    reward             | -0.028997997 |\n",
      "|    std                | 751          |\n",
      "|    value_loss         | 0.00344      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 38100          |\n",
      "|    time_elapsed       | 573            |\n",
      "|    total_timesteps    | 190500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 38099          |\n",
      "|    policy_loss        | 0.282          |\n",
      "|    reward             | -0.00039193686 |\n",
      "|    std                | 763            |\n",
      "|    value_loss         | 0.000683       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 38200        |\n",
      "|    time_elapsed       | 575          |\n",
      "|    total_timesteps    | 191000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38199        |\n",
      "|    policy_loss        | -0.0635      |\n",
      "|    reward             | -0.011129978 |\n",
      "|    std                | 779          |\n",
      "|    value_loss         | 5.43e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 38300      |\n",
      "|    time_elapsed       | 576        |\n",
      "|    total_timesteps    | 191500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.2      |\n",
      "|    explained_variance | 0.619      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 38299      |\n",
      "|    policy_loss        | 0.00728    |\n",
      "|    reward             | 0.04928817 |\n",
      "|    std                | 801        |\n",
      "|    value_loss         | 8.27e-06   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 38400        |\n",
      "|    time_elapsed       | 578          |\n",
      "|    total_timesteps    | 192000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0.00753      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38399        |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.004148465 |\n",
      "|    std                | 822          |\n",
      "|    value_loss         | 0.000297     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 38500        |\n",
      "|    time_elapsed       | 579          |\n",
      "|    total_timesteps    | 192500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38499        |\n",
      "|    policy_loss        | -0.088       |\n",
      "|    reward             | -0.015119445 |\n",
      "|    std                | 848          |\n",
      "|    value_loss         | 4.73e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 38600       |\n",
      "|    time_elapsed       | 581         |\n",
      "|    total_timesteps    | 193000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38599       |\n",
      "|    policy_loss        | 0.238       |\n",
      "|    reward             | 0.044371344 |\n",
      "|    std                | 861         |\n",
      "|    value_loss         | 0.000255    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 38700         |\n",
      "|    time_elapsed       | 582           |\n",
      "|    total_timesteps    | 193500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38699         |\n",
      "|    policy_loss        | -0.086        |\n",
      "|    reward             | -0.0071831234 |\n",
      "|    std                | 881           |\n",
      "|    value_loss         | 0.000158      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 38800        |\n",
      "|    time_elapsed       | 584          |\n",
      "|    total_timesteps    | 194000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38799        |\n",
      "|    policy_loss        | -0.184       |\n",
      "|    reward             | -0.013402434 |\n",
      "|    std                | 906          |\n",
      "|    value_loss         | 0.000218     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 38900        |\n",
      "|    time_elapsed       | 585          |\n",
      "|    total_timesteps    | 194500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38899        |\n",
      "|    policy_loss        | -0.0541      |\n",
      "|    reward             | -0.008156757 |\n",
      "|    std                | 941          |\n",
      "|    value_loss         | 1.88e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 39000        |\n",
      "|    time_elapsed       | 587          |\n",
      "|    total_timesteps    | 195000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38999        |\n",
      "|    policy_loss        | 0.263        |\n",
      "|    reward             | 0.0041854195 |\n",
      "|    std                | 962          |\n",
      "|    value_loss         | 0.000274     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 39100        |\n",
      "|    time_elapsed       | 588          |\n",
      "|    total_timesteps    | 195500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39099        |\n",
      "|    policy_loss        | 0.35         |\n",
      "|    reward             | -0.008919269 |\n",
      "|    std                | 982          |\n",
      "|    value_loss         | 0.00086      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 39200         |\n",
      "|    time_elapsed       | 589           |\n",
      "|    total_timesteps    | 196000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 39199         |\n",
      "|    policy_loss        | -0.704        |\n",
      "|    reward             | -0.0014781051 |\n",
      "|    std                | 1.01e+03      |\n",
      "|    value_loss         | 0.00241       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 39300        |\n",
      "|    time_elapsed       | 591          |\n",
      "|    total_timesteps    | 196500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39299        |\n",
      "|    policy_loss        | -0.124       |\n",
      "|    reward             | -0.013671202 |\n",
      "|    std                | 1.04e+03     |\n",
      "|    value_loss         | 7.25e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 39400        |\n",
      "|    time_elapsed       | 592          |\n",
      "|    total_timesteps    | 197000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39399        |\n",
      "|    policy_loss        | 0.439        |\n",
      "|    reward             | 0.0058468166 |\n",
      "|    std                | 1.07e+03     |\n",
      "|    value_loss         | 0.000732     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 39500        |\n",
      "|    time_elapsed       | 594          |\n",
      "|    total_timesteps    | 197500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | -0.281       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39499        |\n",
      "|    policy_loss        | 0.0855       |\n",
      "|    reward             | 0.0024548853 |\n",
      "|    std                | 1.12e+03     |\n",
      "|    value_loss         | 4.42e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 39600        |\n",
      "|    time_elapsed       | 595          |\n",
      "|    total_timesteps    | 198000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | -195         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39599        |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | -0.004244964 |\n",
      "|    std                | 1.15e+03     |\n",
      "|    value_loss         | 0.000713     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -10783.55\n",
      "total_reward: -20783.55\n",
      "total_cost: 543.98\n",
      "total_trades: 5666\n",
      "Sharpe: -0.309\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 39700       |\n",
      "|    time_elapsed       | 597         |\n",
      "|    total_timesteps    | 198500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39699       |\n",
      "|    policy_loss        | -0.236      |\n",
      "|    reward             | 0.010741844 |\n",
      "|    std                | 1.2e+03     |\n",
      "|    value_loss         | 0.000319    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 39800        |\n",
      "|    time_elapsed       | 598          |\n",
      "|    total_timesteps    | 199000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39799        |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | -0.015075675 |\n",
      "|    std                | 1.24e+03     |\n",
      "|    value_loss         | 0.000296     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 39900         |\n",
      "|    time_elapsed       | 600           |\n",
      "|    total_timesteps    | 199500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 39899         |\n",
      "|    policy_loss        | -0.41         |\n",
      "|    reward             | -0.0007057192 |\n",
      "|    std                | 1.27e+03      |\n",
      "|    value_loss         | 0.000855      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 40000       |\n",
      "|    time_elapsed       | 601         |\n",
      "|    total_timesteps    | 200000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39999       |\n",
      "|    policy_loss        | 0.0497      |\n",
      "|    reward             | 0.002328688 |\n",
      "|    std                | 1.31e+03    |\n",
      "|    value_loss         | 2.59e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 40100        |\n",
      "|    time_elapsed       | 603          |\n",
      "|    total_timesteps    | 200500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0.168        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40099        |\n",
      "|    policy_loss        | -0.241       |\n",
      "|    reward             | -0.005429332 |\n",
      "|    std                | 1.38e+03     |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 40200        |\n",
      "|    time_elapsed       | 604          |\n",
      "|    total_timesteps    | 201000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40199        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | 0.0023229397 |\n",
      "|    std                | 1.44e+03     |\n",
      "|    value_loss         | 6.93e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 40300         |\n",
      "|    time_elapsed       | 606           |\n",
      "|    total_timesteps    | 201500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.4         |\n",
      "|    explained_variance | -2.38e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40299         |\n",
      "|    policy_loss        | 0.293         |\n",
      "|    reward             | -0.0055268933 |\n",
      "|    std                | 1.45e+03      |\n",
      "|    value_loss         | 0.00908       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 40400        |\n",
      "|    time_elapsed       | 607          |\n",
      "|    total_timesteps    | 202000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40399        |\n",
      "|    policy_loss        | -1.88        |\n",
      "|    reward             | 0.0026234996 |\n",
      "|    std                | 1.47e+03     |\n",
      "|    value_loss         | 0.0139       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 40500        |\n",
      "|    time_elapsed       | 609          |\n",
      "|    total_timesteps    | 202500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40499        |\n",
      "|    policy_loss        | 3.11         |\n",
      "|    reward             | -0.002774139 |\n",
      "|    std                | 1.48e+03     |\n",
      "|    value_loss         | 0.0525       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 40600       |\n",
      "|    time_elapsed       | 610         |\n",
      "|    total_timesteps    | 203000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0.282       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40599       |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | -0.17648189 |\n",
      "|    std                | 1.49e+03    |\n",
      "|    value_loss         | 0.0162      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 40700      |\n",
      "|    time_elapsed       | 612        |\n",
      "|    total_timesteps    | 203500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.5      |\n",
      "|    explained_variance | 0.161      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40699      |\n",
      "|    policy_loss        | 5.58       |\n",
      "|    reward             | 0.18433161 |\n",
      "|    std                | 1.51e+03   |\n",
      "|    value_loss         | 0.109      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 40800      |\n",
      "|    time_elapsed       | 613        |\n",
      "|    total_timesteps    | 204000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40799      |\n",
      "|    policy_loss        | 23.6       |\n",
      "|    reward             | 0.38018337 |\n",
      "|    std                | 1.51e+03   |\n",
      "|    value_loss         | 2.18       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 40900       |\n",
      "|    time_elapsed       | 615         |\n",
      "|    total_timesteps    | 204500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40899       |\n",
      "|    policy_loss        | -0.831      |\n",
      "|    reward             | -0.01605407 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 0.00251     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 41000        |\n",
      "|    time_elapsed       | 616          |\n",
      "|    total_timesteps    | 205000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40999        |\n",
      "|    policy_loss        | 0.154        |\n",
      "|    reward             | 0.0048728604 |\n",
      "|    std                | 1.55e+03     |\n",
      "|    value_loss         | 9.99e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 41100       |\n",
      "|    time_elapsed       | 618         |\n",
      "|    total_timesteps    | 205500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41099       |\n",
      "|    policy_loss        | -0.0202     |\n",
      "|    reward             | 0.027879322 |\n",
      "|    std                | 1.58e+03    |\n",
      "|    value_loss         | 1.36e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 41200        |\n",
      "|    time_elapsed       | 619          |\n",
      "|    total_timesteps    | 206000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 2.62e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41199        |\n",
      "|    policy_loss        | -0.894       |\n",
      "|    reward             | -0.015496211 |\n",
      "|    std                | 1.62e+03     |\n",
      "|    value_loss         | 0.00267      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 41300        |\n",
      "|    time_elapsed       | 621          |\n",
      "|    total_timesteps    | 206500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.235        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41299        |\n",
      "|    policy_loss        | 0.0364       |\n",
      "|    reward             | 0.0018399849 |\n",
      "|    std                | 1.66e+03     |\n",
      "|    value_loss         | 4.09e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 41400        |\n",
      "|    time_elapsed       | 623          |\n",
      "|    total_timesteps    | 207000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41399        |\n",
      "|    policy_loss        | 1.74         |\n",
      "|    reward             | -0.063775495 |\n",
      "|    std                | 1.69e+03     |\n",
      "|    value_loss         | 0.0165       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 41500        |\n",
      "|    time_elapsed       | 624          |\n",
      "|    total_timesteps    | 207500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41499        |\n",
      "|    policy_loss        | 1.64         |\n",
      "|    reward             | -0.016122296 |\n",
      "|    std                | 1.7e+03      |\n",
      "|    value_loss         | 0.00926      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 41600        |\n",
      "|    time_elapsed       | 626          |\n",
      "|    total_timesteps    | 208000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41599        |\n",
      "|    policy_loss        | -5.75        |\n",
      "|    reward             | -0.034766834 |\n",
      "|    std                | 1.74e+03     |\n",
      "|    value_loss         | 0.153        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 41700      |\n",
      "|    time_elapsed       | 627        |\n",
      "|    total_timesteps    | 208500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.7      |\n",
      "|    explained_variance | -1.54e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 41699      |\n",
      "|    policy_loss        | 0.312      |\n",
      "|    reward             | 0.18021156 |\n",
      "|    std                | 1.71e+03   |\n",
      "|    value_loss         | 0.00244    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 41800        |\n",
      "|    time_elapsed       | 629          |\n",
      "|    total_timesteps    | 209000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41799        |\n",
      "|    policy_loss        | 1.62         |\n",
      "|    reward             | -0.030274441 |\n",
      "|    std                | 1.72e+03     |\n",
      "|    value_loss         | 0.0111       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 41900       |\n",
      "|    time_elapsed       | 631         |\n",
      "|    total_timesteps    | 209500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41899       |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | -0.11949084 |\n",
      "|    std                | 1.71e+03    |\n",
      "|    value_loss         | 0.0307      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 42000       |\n",
      "|    time_elapsed       | 632         |\n",
      "|    total_timesteps    | 210000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41999       |\n",
      "|    policy_loss        | -0.581      |\n",
      "|    reward             | 0.007092243 |\n",
      "|    std                | 1.72e+03    |\n",
      "|    value_loss         | 0.0013      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 42100        |\n",
      "|    time_elapsed       | 634          |\n",
      "|    total_timesteps    | 210500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42099        |\n",
      "|    policy_loss        | -0.219       |\n",
      "|    reward             | -0.008009276 |\n",
      "|    std                | 1.73e+03     |\n",
      "|    value_loss         | 0.000209     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 42200        |\n",
      "|    time_elapsed       | 636          |\n",
      "|    total_timesteps    | 211000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42199        |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.008544209 |\n",
      "|    std                | 1.77e+03     |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 42300         |\n",
      "|    time_elapsed       | 637           |\n",
      "|    total_timesteps    | 211500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42299         |\n",
      "|    policy_loss        | -0.179        |\n",
      "|    reward             | -0.0007111576 |\n",
      "|    std                | 1.81e+03      |\n",
      "|    value_loss         | 0.000182      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 42400        |\n",
      "|    time_elapsed       | 639          |\n",
      "|    total_timesteps    | 212000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0.585        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42399        |\n",
      "|    policy_loss        | 0.181        |\n",
      "|    reward             | -0.011362505 |\n",
      "|    std                | 1.86e+03     |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 42500        |\n",
      "|    time_elapsed       | 640          |\n",
      "|    total_timesteps    | 212500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42499        |\n",
      "|    policy_loss        | -0.0892      |\n",
      "|    reward             | -0.024644757 |\n",
      "|    std                | 1.92e+03     |\n",
      "|    value_loss         | 5.18e-05     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13199.14\n",
      "total_reward: -23199.14\n",
      "total_cost: 479.34\n",
      "total_trades: 5666\n",
      "Sharpe: -0.266\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 42600        |\n",
      "|    time_elapsed       | 642          |\n",
      "|    total_timesteps    | 213000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42599        |\n",
      "|    policy_loss        | 0.234        |\n",
      "|    reward             | -0.045609344 |\n",
      "|    std                | 1.96e+03     |\n",
      "|    value_loss         | 0.000563     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 42700       |\n",
      "|    time_elapsed       | 643         |\n",
      "|    total_timesteps    | 213500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42699       |\n",
      "|    policy_loss        | 0.492       |\n",
      "|    reward             | 0.034609705 |\n",
      "|    std                | 1.96e+03    |\n",
      "|    value_loss         | 0.000799    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 42800      |\n",
      "|    time_elapsed       | 645        |\n",
      "|    total_timesteps    | 214000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18        |\n",
      "|    explained_variance | -0.381     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42799      |\n",
      "|    policy_loss        | -1.1       |\n",
      "|    reward             | 0.22274314 |\n",
      "|    std                | 1.98e+03   |\n",
      "|    value_loss         | 0.0168     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 646         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0.547       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42899       |\n",
      "|    policy_loss        | -1.46       |\n",
      "|    reward             | -0.06398194 |\n",
      "|    std                | 1.98e+03    |\n",
      "|    value_loss         | 0.0124      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 43000        |\n",
      "|    time_elapsed       | 648          |\n",
      "|    total_timesteps    | 215000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42999        |\n",
      "|    policy_loss        | -2.32        |\n",
      "|    reward             | -0.051169008 |\n",
      "|    std                | 1.97e+03     |\n",
      "|    value_loss         | 0.0766       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 43100        |\n",
      "|    time_elapsed       | 650          |\n",
      "|    total_timesteps    | 215500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43099        |\n",
      "|    policy_loss        | 1.54         |\n",
      "|    reward             | -0.015568127 |\n",
      "|    std                | 1.96e+03     |\n",
      "|    value_loss         | 0.00814      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 43200       |\n",
      "|    time_elapsed       | 651         |\n",
      "|    total_timesteps    | 216000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43199       |\n",
      "|    policy_loss        | -0.157      |\n",
      "|    reward             | 0.051273104 |\n",
      "|    std                | 1.99e+03    |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 43300         |\n",
      "|    time_elapsed       | 653           |\n",
      "|    total_timesteps    | 216500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43299         |\n",
      "|    policy_loss        | -2.12         |\n",
      "|    reward             | -0.0053864038 |\n",
      "|    std                | 2.02e+03      |\n",
      "|    value_loss         | 0.0146        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 43400     |\n",
      "|    time_elapsed       | 654       |\n",
      "|    total_timesteps    | 217000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -18.1     |\n",
      "|    explained_variance | -0.121    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 43399     |\n",
      "|    policy_loss        | 0.44      |\n",
      "|    reward             | 0.0101374 |\n",
      "|    std                | 2.03e+03  |\n",
      "|    value_loss         | 0.000825  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 43500       |\n",
      "|    time_elapsed       | 656         |\n",
      "|    total_timesteps    | 217500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | -0.936      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43499       |\n",
      "|    policy_loss        | -0.294      |\n",
      "|    reward             | -0.06173915 |\n",
      "|    std                | 2.06e+03    |\n",
      "|    value_loss         | 0.00161     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 43600        |\n",
      "|    time_elapsed       | 658          |\n",
      "|    total_timesteps    | 218000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -7.99e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43599        |\n",
      "|    policy_loss        | -0.432       |\n",
      "|    reward             | -0.025686393 |\n",
      "|    std                | 2.07e+03     |\n",
      "|    value_loss         | 0.00412      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 43700       |\n",
      "|    time_elapsed       | 660         |\n",
      "|    total_timesteps    | 218500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43699       |\n",
      "|    policy_loss        | -0.229      |\n",
      "|    reward             | -0.04680204 |\n",
      "|    std                | 2.09e+03    |\n",
      "|    value_loss         | 0.000449    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 43800        |\n",
      "|    time_elapsed       | 661          |\n",
      "|    total_timesteps    | 219000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43799        |\n",
      "|    policy_loss        | -0.0242      |\n",
      "|    reward             | -0.005720666 |\n",
      "|    std                | 2.12e+03     |\n",
      "|    value_loss         | 2.1e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 43900         |\n",
      "|    time_elapsed       | 663           |\n",
      "|    total_timesteps    | 219500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43899         |\n",
      "|    policy_loss        | 0.405         |\n",
      "|    reward             | 1.6829417e-05 |\n",
      "|    std                | 2.16e+03      |\n",
      "|    value_loss         | 0.000742      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 44000        |\n",
      "|    time_elapsed       | 665          |\n",
      "|    total_timesteps    | 220000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | -0.0978      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43999        |\n",
      "|    policy_loss        | -0.119       |\n",
      "|    reward             | -0.005174311 |\n",
      "|    std                | 2.24e+03     |\n",
      "|    value_loss         | 5.23e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 44100        |\n",
      "|    time_elapsed       | 666          |\n",
      "|    total_timesteps    | 220500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | -6.63        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44099        |\n",
      "|    policy_loss        | 0.713        |\n",
      "|    reward             | -0.001756121 |\n",
      "|    std                | 2.31e+03     |\n",
      "|    value_loss         | 0.00238      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 44200        |\n",
      "|    time_elapsed       | 668          |\n",
      "|    total_timesteps    | 221000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44199        |\n",
      "|    policy_loss        | 0.265        |\n",
      "|    reward             | -0.009916987 |\n",
      "|    std                | 2.37e+03     |\n",
      "|    value_loss         | 0.000227     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 44300        |\n",
      "|    time_elapsed       | 669          |\n",
      "|    total_timesteps    | 221500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44299        |\n",
      "|    policy_loss        | 0.207        |\n",
      "|    reward             | -0.050607495 |\n",
      "|    std                | 2.41e+03     |\n",
      "|    value_loss         | 0.0016       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 44400        |\n",
      "|    time_elapsed       | 671          |\n",
      "|    total_timesteps    | 222000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44399        |\n",
      "|    policy_loss        | -0.257       |\n",
      "|    reward             | -0.042700917 |\n",
      "|    std                | 2.46e+03     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 44500      |\n",
      "|    time_elapsed       | 673        |\n",
      "|    total_timesteps    | 222500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.5      |\n",
      "|    explained_variance | 0.14       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44499      |\n",
      "|    policy_loss        | -2.69      |\n",
      "|    reward             | 0.12568378 |\n",
      "|    std                | 2.49e+03   |\n",
      "|    value_loss         | 0.0342     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 44600      |\n",
      "|    time_elapsed       | 674        |\n",
      "|    total_timesteps    | 223000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.5      |\n",
      "|    explained_variance | 8.82e-06   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44599      |\n",
      "|    policy_loss        | -4.17      |\n",
      "|    reward             | 0.24392982 |\n",
      "|    std                | 2.48e+03   |\n",
      "|    value_loss         | 0.0671     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 44700       |\n",
      "|    time_elapsed       | 676         |\n",
      "|    total_timesteps    | 223500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44699       |\n",
      "|    policy_loss        | 4.24        |\n",
      "|    reward             | 0.107957944 |\n",
      "|    std                | 2.48e+03    |\n",
      "|    value_loss         | 0.142       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 44800        |\n",
      "|    time_elapsed       | 678          |\n",
      "|    total_timesteps    | 224000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44799        |\n",
      "|    policy_loss        | 0.0839       |\n",
      "|    reward             | -0.020321019 |\n",
      "|    std                | 2.46e+03     |\n",
      "|    value_loss         | 0.000212     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 44900       |\n",
      "|    time_elapsed       | 679         |\n",
      "|    total_timesteps    | 224500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44899       |\n",
      "|    policy_loss        | 0.00159     |\n",
      "|    reward             | -0.02245889 |\n",
      "|    std                | 2.49e+03    |\n",
      "|    value_loss         | 1.22e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 45000        |\n",
      "|    time_elapsed       | 681          |\n",
      "|    total_timesteps    | 225000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44999        |\n",
      "|    policy_loss        | 0.137        |\n",
      "|    reward             | -0.000557836 |\n",
      "|    std                | 2.52e+03     |\n",
      "|    value_loss         | 7.64e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 45100         |\n",
      "|    time_elapsed       | 683           |\n",
      "|    total_timesteps    | 225500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45099         |\n",
      "|    policy_loss        | 0.0534        |\n",
      "|    reward             | -0.0027934914 |\n",
      "|    std                | 2.57e+03      |\n",
      "|    value_loss         | 5.45e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 45200        |\n",
      "|    time_elapsed       | 684          |\n",
      "|    total_timesteps    | 226000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | -0.172       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45199        |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | 0.0025577573 |\n",
      "|    std                | 2.64e+03     |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 45300         |\n",
      "|    time_elapsed       | 686           |\n",
      "|    total_timesteps    | 226500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | 0.22          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45299         |\n",
      "|    policy_loss        | -0.0241       |\n",
      "|    reward             | -0.0011811039 |\n",
      "|    std                | 2.74e+03      |\n",
      "|    value_loss         | 6.73e-05      |\n",
      "-----------------------------------------\n",
      "day: 2833, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12903.63\n",
      "total_reward: -22903.63\n",
      "total_cost: 464.84\n",
      "total_trades: 5666\n",
      "Sharpe: -0.207\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 45400        |\n",
      "|    time_elapsed       | 687          |\n",
      "|    total_timesteps    | 227000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45399        |\n",
      "|    policy_loss        | 0.698        |\n",
      "|    reward             | 0.0017047821 |\n",
      "|    std                | 2.81e+03     |\n",
      "|    value_loss         | 0.00199      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 45500        |\n",
      "|    time_elapsed       | 689          |\n",
      "|    total_timesteps    | 227500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45499        |\n",
      "|    policy_loss        | 0.644        |\n",
      "|    reward             | -0.030040586 |\n",
      "|    std                | 2.85e+03     |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 45600       |\n",
      "|    time_elapsed       | 690         |\n",
      "|    total_timesteps    | 228000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | 0.555       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45599       |\n",
      "|    policy_loss        | 0.449       |\n",
      "|    reward             | 0.011806595 |\n",
      "|    std                | 2.93e+03    |\n",
      "|    value_loss         | 0.000897    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 45700        |\n",
      "|    time_elapsed       | 692          |\n",
      "|    total_timesteps    | 228500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.28e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45699        |\n",
      "|    policy_loss        | -0.748       |\n",
      "|    reward             | -0.016844528 |\n",
      "|    std                | 2.97e+03     |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 45800       |\n",
      "|    time_elapsed       | 693         |\n",
      "|    total_timesteps    | 229000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45799       |\n",
      "|    policy_loss        | -0.309      |\n",
      "|    reward             | 0.007932617 |\n",
      "|    std                | 3e+03       |\n",
      "|    value_loss         | 0.00135     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 45900      |\n",
      "|    time_elapsed       | 695        |\n",
      "|    total_timesteps    | 229500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.9      |\n",
      "|    explained_variance | -6.37      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45899      |\n",
      "|    policy_loss        | -0.378     |\n",
      "|    reward             | 0.15676455 |\n",
      "|    std                | 3.05e+03   |\n",
      "|    value_loss         | 0.00619    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 46000         |\n",
      "|    time_elapsed       | 696           |\n",
      "|    total_timesteps    | 230000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45999         |\n",
      "|    policy_loss        | -0.131        |\n",
      "|    reward             | -0.0021410703 |\n",
      "|    std                | 3.08e+03      |\n",
      "|    value_loss         | 0.000198      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 46100         |\n",
      "|    time_elapsed       | 698           |\n",
      "|    total_timesteps    | 230500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 46099         |\n",
      "|    policy_loss        | 0.0677        |\n",
      "|    reward             | -0.0051657455 |\n",
      "|    std                | 3.14e+03      |\n",
      "|    value_loss         | 6.52e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 46200        |\n",
      "|    time_elapsed       | 699          |\n",
      "|    total_timesteps    | 231000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46199        |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | -0.009249415 |\n",
      "|    std                | 3.23e+03     |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 46300       |\n",
      "|    time_elapsed       | 701         |\n",
      "|    total_timesteps    | 231500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0.752       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46299       |\n",
      "|    policy_loss        | 0.0413      |\n",
      "|    reward             | 0.004537188 |\n",
      "|    std                | 3.31e+03    |\n",
      "|    value_loss         | 5.75e-06    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 46400         |\n",
      "|    time_elapsed       | 702           |\n",
      "|    total_timesteps    | 232000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.1         |\n",
      "|    explained_variance | -29.9         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 46399         |\n",
      "|    policy_loss        | 0.334         |\n",
      "|    reward             | -0.0015987946 |\n",
      "|    std                | 3.41e+03      |\n",
      "|    value_loss         | 0.000491      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 46500      |\n",
      "|    time_elapsed       | 704        |\n",
      "|    total_timesteps    | 232500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46499      |\n",
      "|    policy_loss        | -1.77      |\n",
      "|    reward             | 0.08876893 |\n",
      "|    std                | 3.52e+03   |\n",
      "|    value_loss         | 0.00969    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 46600       |\n",
      "|    time_elapsed       | 705         |\n",
      "|    total_timesteps    | 233000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 2.38e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46599       |\n",
      "|    policy_loss        | 0.575       |\n",
      "|    reward             | 0.048886873 |\n",
      "|    std                | 3.57e+03    |\n",
      "|    value_loss         | 0.00118     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 46700       |\n",
      "|    time_elapsed       | 707         |\n",
      "|    total_timesteps    | 233500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46699       |\n",
      "|    policy_loss        | 0.676       |\n",
      "|    reward             | -0.16106349 |\n",
      "|    std                | 3.62e+03    |\n",
      "|    value_loss         | 0.00149     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 46800        |\n",
      "|    time_elapsed       | 708          |\n",
      "|    total_timesteps    | 234000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46799        |\n",
      "|    policy_loss        | 0.382        |\n",
      "|    reward             | -0.036733385 |\n",
      "|    std                | 3.66e+03     |\n",
      "|    value_loss         | 0.00332      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 46900       |\n",
      "|    time_elapsed       | 710         |\n",
      "|    total_timesteps    | 234500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46899       |\n",
      "|    policy_loss        | 7.9         |\n",
      "|    reward             | -0.17607334 |\n",
      "|    std                | 3.69e+03    |\n",
      "|    value_loss         | 0.199       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 47000        |\n",
      "|    time_elapsed       | 711          |\n",
      "|    total_timesteps    | 235000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46999        |\n",
      "|    policy_loss        | 0.196        |\n",
      "|    reward             | -0.124458484 |\n",
      "|    std                | 3.7e+03      |\n",
      "|    value_loss         | 0.0202       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 47100        |\n",
      "|    time_elapsed       | 713          |\n",
      "|    total_timesteps    | 235500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47099        |\n",
      "|    policy_loss        | -0.397       |\n",
      "|    reward             | -0.027396645 |\n",
      "|    std                | 3.71e+03     |\n",
      "|    value_loss         | 0.00198      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 47200        |\n",
      "|    time_elapsed       | 714          |\n",
      "|    total_timesteps    | 236000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47199        |\n",
      "|    policy_loss        | 0.39         |\n",
      "|    reward             | -0.031020753 |\n",
      "|    std                | 3.75e+03     |\n",
      "|    value_loss         | 0.000964     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 47300       |\n",
      "|    time_elapsed       | 715         |\n",
      "|    total_timesteps    | 236500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | -14.3       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47299       |\n",
      "|    policy_loss        | 0.735       |\n",
      "|    reward             | 0.012370951 |\n",
      "|    std                | 3.82e+03    |\n",
      "|    value_loss         | 0.00244     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 47400        |\n",
      "|    time_elapsed       | 717          |\n",
      "|    total_timesteps    | 237000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47399        |\n",
      "|    policy_loss        | 0.112        |\n",
      "|    reward             | -0.014015427 |\n",
      "|    std                | 3.89e+03     |\n",
      "|    value_loss         | 0.000325     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 47500       |\n",
      "|    time_elapsed       | 718         |\n",
      "|    total_timesteps    | 237500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.4       |\n",
      "|    explained_variance | -0.232      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47499       |\n",
      "|    policy_loss        | -0.383      |\n",
      "|    reward             | 0.025240513 |\n",
      "|    std                | 3.98e+03    |\n",
      "|    value_loss         | 0.000458    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 47600       |\n",
      "|    time_elapsed       | 720         |\n",
      "|    total_timesteps    | 238000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47599       |\n",
      "|    policy_loss        | -0.821      |\n",
      "|    reward             | -0.03815531 |\n",
      "|    std                | 4.06e+03    |\n",
      "|    value_loss         | 0.00512     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 47700       |\n",
      "|    time_elapsed       | 721         |\n",
      "|    total_timesteps    | 238500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47699       |\n",
      "|    policy_loss        | -0.595      |\n",
      "|    reward             | 0.013949018 |\n",
      "|    std                | 4.15e+03    |\n",
      "|    value_loss         | 0.00172     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 47800         |\n",
      "|    time_elapsed       | 723           |\n",
      "|    total_timesteps    | 239000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.5         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47799         |\n",
      "|    policy_loss        | 0.00265       |\n",
      "|    reward             | 0.00011473932 |\n",
      "|    std                | 4.21e+03      |\n",
      "|    value_loss         | 0.000287      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 47900         |\n",
      "|    time_elapsed       | 724           |\n",
      "|    total_timesteps    | 239500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | 0.00564       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47899         |\n",
      "|    policy_loss        | 0.273         |\n",
      "|    reward             | -0.0028185705 |\n",
      "|    std                | 4.33e+03      |\n",
      "|    value_loss         | 0.000248      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 48000         |\n",
      "|    time_elapsed       | 726           |\n",
      "|    total_timesteps    | 240000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.6         |\n",
      "|    explained_variance | -3.52         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47999         |\n",
      "|    policy_loss        | -0.00196      |\n",
      "|    reward             | 0.00040752944 |\n",
      "|    std                | 4.42e+03      |\n",
      "|    value_loss         | 2.21e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 48100        |\n",
      "|    time_elapsed       | 727          |\n",
      "|    total_timesteps    | 240500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0.0024       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48099        |\n",
      "|    policy_loss        | -0.0702      |\n",
      "|    reward             | -0.015963858 |\n",
      "|    std                | 4.55e+03     |\n",
      "|    value_loss         | 5.52e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2833, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -15765.89\n",
      "total_reward: -25765.89\n",
      "total_cost: 245.88\n",
      "total_trades: 5666\n",
      "Sharpe: 0.230\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 48200      |\n",
      "|    time_elapsed       | 729        |\n",
      "|    total_timesteps    | 241000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 48199      |\n",
      "|    policy_loss        | 0.752      |\n",
      "|    reward             | 0.03336902 |\n",
      "|    std                | 4.73e+03   |\n",
      "|    value_loss         | 0.00179    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 48300       |\n",
      "|    time_elapsed       | 730         |\n",
      "|    total_timesteps    | 241500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48299       |\n",
      "|    policy_loss        | 0.299       |\n",
      "|    reward             | 0.023354746 |\n",
      "|    std                | 4.81e+03    |\n",
      "|    value_loss         | 0.000715    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 48400        |\n",
      "|    time_elapsed       | 732          |\n",
      "|    total_timesteps    | 242000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48399        |\n",
      "|    policy_loss        | -0.297       |\n",
      "|    reward             | 0.0033524544 |\n",
      "|    std                | 4.83e+03     |\n",
      "|    value_loss         | 0.00159      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 48500        |\n",
      "|    time_elapsed       | 733          |\n",
      "|    total_timesteps    | 242500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48499        |\n",
      "|    policy_loss        | -0.0358      |\n",
      "|    reward             | -0.015671406 |\n",
      "|    std                | 4.92e+03     |\n",
      "|    value_loss         | 0.000265     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 48600       |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 243000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0.000808    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48599       |\n",
      "|    policy_loss        | 1.2         |\n",
      "|    reward             | 0.020027373 |\n",
      "|    std                | 4.98e+03    |\n",
      "|    value_loss         | 0.00425     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 48700        |\n",
      "|    time_elapsed       | 736          |\n",
      "|    total_timesteps    | 243500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0.0226       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48699        |\n",
      "|    policy_loss        | -0.67        |\n",
      "|    reward             | -0.002231494 |\n",
      "|    std                | 5.03e+03     |\n",
      "|    value_loss         | 0.00479      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 48800         |\n",
      "|    time_elapsed       | 737           |\n",
      "|    total_timesteps    | 244000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 48799         |\n",
      "|    policy_loss        | -0.674        |\n",
      "|    reward             | -0.0089942105 |\n",
      "|    std                | 5.04e+03      |\n",
      "|    value_loss         | 0.0024        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 48900        |\n",
      "|    time_elapsed       | 739          |\n",
      "|    total_timesteps    | 244500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48899        |\n",
      "|    policy_loss        | -0.451       |\n",
      "|    reward             | -0.017788257 |\n",
      "|    std                | 5.05e+03     |\n",
      "|    value_loss         | 0.000858     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 49000        |\n",
      "|    time_elapsed       | 740          |\n",
      "|    total_timesteps    | 245000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0.46         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48999        |\n",
      "|    policy_loss        | 0.0947       |\n",
      "|    reward             | 0.0039595636 |\n",
      "|    std                | 5.13e+03     |\n",
      "|    value_loss         | 6.07e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 49100         |\n",
      "|    time_elapsed       | 742           |\n",
      "|    total_timesteps    | 245500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20           |\n",
      "|    explained_variance | 0.0727        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49099         |\n",
      "|    policy_loss        | 0.58          |\n",
      "|    reward             | -0.0009130014 |\n",
      "|    std                | 5.22e+03      |\n",
      "|    value_loss         | 0.00109       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 49200       |\n",
      "|    time_elapsed       | 743         |\n",
      "|    total_timesteps    | 246000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | 0.562       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49199       |\n",
      "|    policy_loss        | -0.225      |\n",
      "|    reward             | 0.032183576 |\n",
      "|    std                | 5.34e+03    |\n",
      "|    value_loss         | 0.000157    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 49300        |\n",
      "|    time_elapsed       | 745          |\n",
      "|    total_timesteps    | 246500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49299        |\n",
      "|    policy_loss        | -1.82        |\n",
      "|    reward             | -0.035631567 |\n",
      "|    std                | 5.49e+03     |\n",
      "|    value_loss         | 0.0117       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 49400        |\n",
      "|    time_elapsed       | 746          |\n",
      "|    total_timesteps    | 247000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49399        |\n",
      "|    policy_loss        | -0.448       |\n",
      "|    reward             | 0.0042809374 |\n",
      "|    std                | 5.54e+03     |\n",
      "|    value_loss         | 0.000594     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 49500        |\n",
      "|    time_elapsed       | 748          |\n",
      "|    total_timesteps    | 247500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49499        |\n",
      "|    policy_loss        | -0.425       |\n",
      "|    reward             | 0.0006475215 |\n",
      "|    std                | 5.7e+03      |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 49600         |\n",
      "|    time_elapsed       | 749           |\n",
      "|    total_timesteps    | 248000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49599         |\n",
      "|    policy_loss        | 0.184         |\n",
      "|    reward             | -0.0012940256 |\n",
      "|    std                | 5.84e+03      |\n",
      "|    value_loss         | 0.000179      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 49700        |\n",
      "|    time_elapsed       | 751          |\n",
      "|    total_timesteps    | 248500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | -7.01        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49699        |\n",
      "|    policy_loss        | 0.386        |\n",
      "|    reward             | -0.013493857 |\n",
      "|    std                | 6.07e+03     |\n",
      "|    value_loss         | 0.00126      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 49800         |\n",
      "|    time_elapsed       | 752           |\n",
      "|    total_timesteps    | 249000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | -0.953        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49799         |\n",
      "|    policy_loss        | 0.0328        |\n",
      "|    reward             | -0.0139081115 |\n",
      "|    std                | 6.38e+03      |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 49900        |\n",
      "|    time_elapsed       | 754          |\n",
      "|    total_timesteps    | 249500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49899        |\n",
      "|    policy_loss        | -0.0757      |\n",
      "|    reward             | -0.006407618 |\n",
      "|    std                | 6.55e+03     |\n",
      "|    value_loss         | 3.86e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 50000         |\n",
      "|    time_elapsed       | 755           |\n",
      "|    total_timesteps    | 250000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49999         |\n",
      "|    policy_loss        | 0.229         |\n",
      "|    reward             | 2.0621757e-05 |\n",
      "|    std                | 6.81e+03      |\n",
      "|    value_loss         | 0.000302      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 50100         |\n",
      "|    time_elapsed       | 757           |\n",
      "|    total_timesteps    | 250500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50099         |\n",
      "|    policy_loss        | -0.576        |\n",
      "|    reward             | -0.0016941872 |\n",
      "|    std                | 7.05e+03      |\n",
      "|    value_loss         | 0.00112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 50200         |\n",
      "|    time_elapsed       | 759           |\n",
      "|    total_timesteps    | 251000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50199         |\n",
      "|    policy_loss        | 0.00586       |\n",
      "|    reward             | -0.0081860395 |\n",
      "|    std                | 7.27e+03      |\n",
      "|    value_loss         | 6.61e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 50300       |\n",
      "|    time_elapsed       | 760         |\n",
      "|    total_timesteps    | 251500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.142       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50299       |\n",
      "|    policy_loss        | -0.16       |\n",
      "|    reward             | 0.012447812 |\n",
      "|    std                | 7.6e+03     |\n",
      "|    value_loss         | 9.56e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 50400        |\n",
      "|    time_elapsed       | 762          |\n",
      "|    total_timesteps    | 252000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50399        |\n",
      "|    policy_loss        | -0.36        |\n",
      "|    reward             | 0.0068916413 |\n",
      "|    std                | 7.93e+03     |\n",
      "|    value_loss         | 0.000374     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 50500       |\n",
      "|    time_elapsed       | 763         |\n",
      "|    total_timesteps    | 252500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50499       |\n",
      "|    policy_loss        | -0.201      |\n",
      "|    reward             | 0.013711059 |\n",
      "|    std                | 8.22e+03    |\n",
      "|    value_loss         | 0.000263    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 50600       |\n",
      "|    time_elapsed       | 764         |\n",
      "|    total_timesteps    | 253000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50599       |\n",
      "|    policy_loss        | -0.15       |\n",
      "|    reward             | 0.006703719 |\n",
      "|    std                | 8.49e+03    |\n",
      "|    value_loss         | 0.0003      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 50700       |\n",
      "|    time_elapsed       | 766         |\n",
      "|    total_timesteps    | 253500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50699       |\n",
      "|    policy_loss        | 0.393       |\n",
      "|    reward             | 0.014320566 |\n",
      "|    std                | 8.83e+03    |\n",
      "|    value_loss         | 0.000379    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 50800         |\n",
      "|    time_elapsed       | 767           |\n",
      "|    total_timesteps    | 254000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.1         |\n",
      "|    explained_variance | 0.00027       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50799         |\n",
      "|    policy_loss        | 0.0404        |\n",
      "|    reward             | -0.0010971649 |\n",
      "|    std                | 9.24e+03      |\n",
      "|    value_loss         | 5.74e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 50900        |\n",
      "|    time_elapsed       | 769          |\n",
      "|    total_timesteps    | 254500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50899        |\n",
      "|    policy_loss        | 0.0968       |\n",
      "|    reward             | 0.0029235962 |\n",
      "|    std                | 9.74e+03     |\n",
      "|    value_loss         | 4.33e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 51000        |\n",
      "|    time_elapsed       | 770          |\n",
      "|    total_timesteps    | 255000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50999        |\n",
      "|    policy_loss        | -0.539       |\n",
      "|    reward             | -0.004523703 |\n",
      "|    std                | 1.01e+04     |\n",
      "|    value_loss         | 0.000917     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12869.16\n",
      "total_reward: -22869.16\n",
      "total_cost: 504.65\n",
      "total_trades: 5666\n",
      "Sharpe: -0.207\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 51100      |\n",
      "|    time_elapsed       | 772        |\n",
      "|    total_timesteps    | 255500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51099      |\n",
      "|    policy_loss        | -0.459     |\n",
      "|    reward             | 0.03607749 |\n",
      "|    std                | 1.04e+04   |\n",
      "|    value_loss         | 0.000996   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 51200        |\n",
      "|    time_elapsed       | 773          |\n",
      "|    total_timesteps    | 256000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51199        |\n",
      "|    policy_loss        | -3.35        |\n",
      "|    reward             | -0.010420904 |\n",
      "|    std                | 1.06e+04     |\n",
      "|    value_loss         | 0.0238       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 51300       |\n",
      "|    time_elapsed       | 775         |\n",
      "|    total_timesteps    | 256500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 0.381       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51299       |\n",
      "|    policy_loss        | 0.772       |\n",
      "|    reward             | 0.009081311 |\n",
      "|    std                | 1.09e+04    |\n",
      "|    value_loss         | 0.00131     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 51400       |\n",
      "|    time_elapsed       | 777         |\n",
      "|    total_timesteps    | 257000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 1.11e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51399       |\n",
      "|    policy_loss        | 1.73        |\n",
      "|    reward             | -0.03064324 |\n",
      "|    std                | 1.11e+04    |\n",
      "|    value_loss         | 0.0127      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 778         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 5.96e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | 2.88        |\n",
      "|    reward             | -0.02014779 |\n",
      "|    std                | 1.13e+04    |\n",
      "|    value_loss         | 0.0199      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 51600       |\n",
      "|    time_elapsed       | 779         |\n",
      "|    total_timesteps    | 258000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51599       |\n",
      "|    policy_loss        | 0.676       |\n",
      "|    reward             | -0.06421454 |\n",
      "|    std                | 1.15e+04    |\n",
      "|    value_loss         | 0.00157     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 51700        |\n",
      "|    time_elapsed       | 781          |\n",
      "|    total_timesteps    | 258500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51699        |\n",
      "|    policy_loss        | 0.534        |\n",
      "|    reward             | -0.004825096 |\n",
      "|    std                | 1.15e+04     |\n",
      "|    value_loss         | 0.000952     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 51800       |\n",
      "|    time_elapsed       | 782         |\n",
      "|    total_timesteps    | 259000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51799       |\n",
      "|    policy_loss        | -1.55       |\n",
      "|    reward             | 0.003196016 |\n",
      "|    std                | 1.17e+04    |\n",
      "|    value_loss         | 0.00524     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 51900        |\n",
      "|    time_elapsed       | 784          |\n",
      "|    total_timesteps    | 259500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | 6.01e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51899        |\n",
      "|    policy_loss        | -0.691       |\n",
      "|    reward             | -0.009098853 |\n",
      "|    std                | 1.19e+04     |\n",
      "|    value_loss         | 0.00177      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 52000      |\n",
      "|    time_elapsed       | 785        |\n",
      "|    total_timesteps    | 260000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51999      |\n",
      "|    policy_loss        | 0.508      |\n",
      "|    reward             | 0.01797914 |\n",
      "|    std                | 1.2e+04    |\n",
      "|    value_loss         | 0.00232    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 52100      |\n",
      "|    time_elapsed       | 787        |\n",
      "|    total_timesteps    | 260500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52099      |\n",
      "|    policy_loss        | -2.08      |\n",
      "|    reward             | 0.03972668 |\n",
      "|    std                | 1.21e+04   |\n",
      "|    value_loss         | 0.0105     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 52200         |\n",
      "|    time_elapsed       | 788           |\n",
      "|    total_timesteps    | 261000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 52199         |\n",
      "|    policy_loss        | -0.423        |\n",
      "|    reward             | -0.0055847582 |\n",
      "|    std                | 1.22e+04      |\n",
      "|    value_loss         | 0.000437      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 52300       |\n",
      "|    time_elapsed       | 790         |\n",
      "|    total_timesteps    | 261500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52299       |\n",
      "|    policy_loss        | 0.694       |\n",
      "|    reward             | 0.018736884 |\n",
      "|    std                | 1.24e+04    |\n",
      "|    value_loss         | 0.00146     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 52400        |\n",
      "|    time_elapsed       | 791          |\n",
      "|    total_timesteps    | 262000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52399        |\n",
      "|    policy_loss        | 0.000729     |\n",
      "|    reward             | -0.013106299 |\n",
      "|    std                | 1.27e+04     |\n",
      "|    value_loss         | 1.87e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 52500        |\n",
      "|    time_elapsed       | 793          |\n",
      "|    total_timesteps    | 262500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | -0.654       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52499        |\n",
      "|    policy_loss        | 0.263        |\n",
      "|    reward             | -0.010455582 |\n",
      "|    std                | 1.3e+04      |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 52600        |\n",
      "|    time_elapsed       | 794          |\n",
      "|    total_timesteps    | 263000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -0.901       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52599        |\n",
      "|    policy_loss        | -1.1         |\n",
      "|    reward             | 0.0010544388 |\n",
      "|    std                | 1.35e+04     |\n",
      "|    value_loss         | 0.00261      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 52700        |\n",
      "|    time_elapsed       | 796          |\n",
      "|    total_timesteps    | 263500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | 0.000131     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52699        |\n",
      "|    policy_loss        | 0.283        |\n",
      "|    reward             | 0.0086461995 |\n",
      "|    std                | 1.37e+04     |\n",
      "|    value_loss         | 0.000448     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 52800        |\n",
      "|    time_elapsed       | 797          |\n",
      "|    total_timesteps    | 264000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52799        |\n",
      "|    policy_loss        | 1.2          |\n",
      "|    reward             | -0.035323925 |\n",
      "|    std                | 1.39e+04     |\n",
      "|    value_loss         | 0.00827      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 799         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | 1.37        |\n",
      "|    reward             | -0.00992611 |\n",
      "|    std                | 1.4e+04     |\n",
      "|    value_loss         | 0.00557     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 53000        |\n",
      "|    time_elapsed       | 801          |\n",
      "|    total_timesteps    | 265000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | 0.0102       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52999        |\n",
      "|    policy_loss        | -1.16        |\n",
      "|    reward             | -0.052003615 |\n",
      "|    std                | 1.41e+04     |\n",
      "|    value_loss         | 0.0732       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 53100       |\n",
      "|    time_elapsed       | 802         |\n",
      "|    total_timesteps    | 265500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | -0.0197     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53099       |\n",
      "|    policy_loss        | 14.8        |\n",
      "|    reward             | 0.001614386 |\n",
      "|    std                | 1.41e+04    |\n",
      "|    value_loss         | 0.511       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 53200       |\n",
      "|    time_elapsed       | 804         |\n",
      "|    total_timesteps    | 266000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | 2.32e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53199       |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | -0.24609533 |\n",
      "|    std                | 1.42e+04    |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 53300       |\n",
      "|    time_elapsed       | 805         |\n",
      "|    total_timesteps    | 266500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53299       |\n",
      "|    policy_loss        | 0.657       |\n",
      "|    reward             | 0.008273886 |\n",
      "|    std                | 1.44e+04    |\n",
      "|    value_loss         | 0.00103     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 53400         |\n",
      "|    time_elapsed       | 807           |\n",
      "|    total_timesteps    | 267000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53399         |\n",
      "|    policy_loss        | 0.137         |\n",
      "|    reward             | -0.0041886093 |\n",
      "|    std                | 1.46e+04      |\n",
      "|    value_loss         | 0.000106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 53500         |\n",
      "|    time_elapsed       | 809           |\n",
      "|    total_timesteps    | 267500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53499         |\n",
      "|    policy_loss        | -0.0542       |\n",
      "|    reward             | -0.0019774798 |\n",
      "|    std                | 1.48e+04      |\n",
      "|    value_loss         | 1.58e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 53600        |\n",
      "|    time_elapsed       | 810          |\n",
      "|    total_timesteps    | 268000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53599        |\n",
      "|    policy_loss        | -0.0636      |\n",
      "|    reward             | -0.008067871 |\n",
      "|    std                | 1.51e+04     |\n",
      "|    value_loss         | 3.84e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 53700        |\n",
      "|    time_elapsed       | 812          |\n",
      "|    total_timesteps    | 268500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | -0.0394      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53699        |\n",
      "|    policy_loss        | 0.188        |\n",
      "|    reward             | 0.0075734584 |\n",
      "|    std                | 1.56e+04     |\n",
      "|    value_loss         | 0.000115     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 53800         |\n",
      "|    time_elapsed       | 813           |\n",
      "|    total_timesteps    | 269000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.2         |\n",
      "|    explained_variance | -0.000141     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53799         |\n",
      "|    policy_loss        | 0.109         |\n",
      "|    reward             | -0.0028020798 |\n",
      "|    std                | 1.6e+04       |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "day: 2833, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11667.70\n",
      "total_reward: -21667.70\n",
      "total_cost: 510.00\n",
      "total_trades: 5666\n",
      "Sharpe: -0.308\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 53900       |\n",
      "|    time_elapsed       | 815         |\n",
      "|    total_timesteps    | 269500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53899       |\n",
      "|    policy_loss        | -0.217      |\n",
      "|    reward             | -0.06519326 |\n",
      "|    std                | 1.65e+04    |\n",
      "|    value_loss         | 0.00163     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 54000        |\n",
      "|    time_elapsed       | 817          |\n",
      "|    total_timesteps    | 270000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53999        |\n",
      "|    policy_loss        | 1.82         |\n",
      "|    reward             | -0.011201681 |\n",
      "|    std                | 1.65e+04     |\n",
      "|    value_loss         | 0.00764      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 54100         |\n",
      "|    time_elapsed       | 818           |\n",
      "|    total_timesteps    | 270500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.3         |\n",
      "|    explained_variance | -0.517        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54099         |\n",
      "|    policy_loss        | -0.0636       |\n",
      "|    reward             | -0.0065958495 |\n",
      "|    std                | 1.67e+04      |\n",
      "|    value_loss         | 9.2e-05       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 54200      |\n",
      "|    time_elapsed       | 820        |\n",
      "|    total_timesteps    | 271000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.3      |\n",
      "|    explained_variance | 0.393      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54199      |\n",
      "|    policy_loss        | 0.384      |\n",
      "|    reward             | 0.02913386 |\n",
      "|    std                | 1.71e+04   |\n",
      "|    value_loss         | 0.000317   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 54300       |\n",
      "|    time_elapsed       | 822         |\n",
      "|    total_timesteps    | 271500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54299       |\n",
      "|    policy_loss        | -0.376      |\n",
      "|    reward             | 0.007777637 |\n",
      "|    std                | 1.74e+04    |\n",
      "|    value_loss         | 0.000763    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 54400       |\n",
      "|    time_elapsed       | 823         |\n",
      "|    total_timesteps    | 272000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | 0.153       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54399       |\n",
      "|    policy_loss        | -2.02       |\n",
      "|    reward             | -0.08552519 |\n",
      "|    std                | 1.76e+04    |\n",
      "|    value_loss         | 0.0106      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 54500      |\n",
      "|    time_elapsed       | 825        |\n",
      "|    total_timesteps    | 272500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54499      |\n",
      "|    policy_loss        | 2.36       |\n",
      "|    reward             | 0.05220241 |\n",
      "|    std                | 1.8e+04    |\n",
      "|    value_loss         | 0.0139     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 54600        |\n",
      "|    time_elapsed       | 826          |\n",
      "|    total_timesteps    | 273000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54599        |\n",
      "|    policy_loss        | 0.575        |\n",
      "|    reward             | -0.002262715 |\n",
      "|    std                | 1.84e+04     |\n",
      "|    value_loss         | 0.00224      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 54700      |\n",
      "|    time_elapsed       | 828        |\n",
      "|    total_timesteps    | 273500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.5      |\n",
      "|    explained_variance | 0.00109    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54699      |\n",
      "|    policy_loss        | -4.71      |\n",
      "|    reward             | 0.03919847 |\n",
      "|    std                | 1.89e+04   |\n",
      "|    value_loss         | 0.065      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 54800         |\n",
      "|    time_elapsed       | 829           |\n",
      "|    total_timesteps    | 274000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54799         |\n",
      "|    policy_loss        | 0.725         |\n",
      "|    reward             | -0.0074959127 |\n",
      "|    std                | 1.91e+04      |\n",
      "|    value_loss         | 0.013         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 54900        |\n",
      "|    time_elapsed       | 831          |\n",
      "|    total_timesteps    | 274500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | 4.35e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54899        |\n",
      "|    policy_loss        | -0.0989      |\n",
      "|    reward             | -0.082122594 |\n",
      "|    std                | 1.93e+04     |\n",
      "|    value_loss         | 0.00419      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 55000         |\n",
      "|    time_elapsed       | 832           |\n",
      "|    total_timesteps    | 275000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.6         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54999         |\n",
      "|    policy_loss        | 0.175         |\n",
      "|    reward             | 0.00062775577 |\n",
      "|    std                | 1.92e+04      |\n",
      "|    value_loss         | 0.000732      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 55100       |\n",
      "|    time_elapsed       | 834         |\n",
      "|    total_timesteps    | 275500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55099       |\n",
      "|    policy_loss        | 0.279       |\n",
      "|    reward             | 0.017996918 |\n",
      "|    std                | 1.94e+04    |\n",
      "|    value_loss         | 0.000215    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 55200        |\n",
      "|    time_elapsed       | 835          |\n",
      "|    total_timesteps    | 276000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55199        |\n",
      "|    policy_loss        | 0.0571       |\n",
      "|    reward             | -0.008607976 |\n",
      "|    std                | 1.97e+04     |\n",
      "|    value_loss         | 5.13e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 55300         |\n",
      "|    time_elapsed       | 837           |\n",
      "|    total_timesteps    | 276500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.7         |\n",
      "|    explained_variance | 0.731         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55299         |\n",
      "|    policy_loss        | -0.0376       |\n",
      "|    reward             | -0.0048012156 |\n",
      "|    std                | 2.01e+04      |\n",
      "|    value_loss         | 7.87e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 55400        |\n",
      "|    time_elapsed       | 838          |\n",
      "|    total_timesteps    | 277000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.122        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55399        |\n",
      "|    policy_loss        | 0.179        |\n",
      "|    reward             | -0.010829911 |\n",
      "|    std                | 2.08e+04     |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 55500        |\n",
      "|    time_elapsed       | 840          |\n",
      "|    total_timesteps    | 277500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | -0.111       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55499        |\n",
      "|    policy_loss        | 0.00848      |\n",
      "|    reward             | -0.019822037 |\n",
      "|    std                | 2.14e+04     |\n",
      "|    value_loss         | 7.4e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 55600       |\n",
      "|    time_elapsed       | 841         |\n",
      "|    total_timesteps    | 278000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55599       |\n",
      "|    policy_loss        | -0.161      |\n",
      "|    reward             | 0.013869656 |\n",
      "|    std                | 2.23e+04    |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 55700         |\n",
      "|    time_elapsed       | 843           |\n",
      "|    total_timesteps    | 278500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55699         |\n",
      "|    policy_loss        | 0.251         |\n",
      "|    reward             | -0.0017748536 |\n",
      "|    std                | 2.31e+04      |\n",
      "|    value_loss         | 0.000306      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 55800        |\n",
      "|    time_elapsed       | 844          |\n",
      "|    total_timesteps    | 279000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55799        |\n",
      "|    policy_loss        | -0.176       |\n",
      "|    reward             | 0.0036790043 |\n",
      "|    std                | 2.42e+04     |\n",
      "|    value_loss         | 6.88e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 55900        |\n",
      "|    time_elapsed       | 846          |\n",
      "|    total_timesteps    | 279500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0.037        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55899        |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | 0.0012374363 |\n",
      "|    std                | 2.51e+04     |\n",
      "|    value_loss         | 4.27e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 56000        |\n",
      "|    time_elapsed       | 847          |\n",
      "|    total_timesteps    | 280000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | -0.0742      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55999        |\n",
      "|    policy_loss        | 0.251        |\n",
      "|    reward             | -0.004888745 |\n",
      "|    std                | 2.62e+04     |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 56100        |\n",
      "|    time_elapsed       | 848          |\n",
      "|    total_timesteps    | 280500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | 0.04         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56099        |\n",
      "|    policy_loss        | 0.729        |\n",
      "|    reward             | -0.019715322 |\n",
      "|    std                | 2.71e+04     |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56200       |\n",
      "|    time_elapsed       | 850         |\n",
      "|    total_timesteps    | 281000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56199       |\n",
      "|    policy_loss        | 1.05        |\n",
      "|    reward             | 0.019461922 |\n",
      "|    std                | 2.8e+04     |\n",
      "|    value_loss         | 0.00214     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 56300        |\n",
      "|    time_elapsed       | 851          |\n",
      "|    total_timesteps    | 281500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56299        |\n",
      "|    policy_loss        | -0.37        |\n",
      "|    reward             | -0.030869387 |\n",
      "|    std                | 2.91e+04     |\n",
      "|    value_loss         | 0.000363     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 56400         |\n",
      "|    time_elapsed       | 853           |\n",
      "|    total_timesteps    | 282000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56399         |\n",
      "|    policy_loss        | -0.563        |\n",
      "|    reward             | -0.0072325286 |\n",
      "|    std                | 3.01e+04      |\n",
      "|    value_loss         | 0.000625      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56500       |\n",
      "|    time_elapsed       | 854         |\n",
      "|    total_timesteps    | 282500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | 0.0287      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56499       |\n",
      "|    policy_loss        | 0.0756      |\n",
      "|    reward             | 0.004307765 |\n",
      "|    std                | 3.12e+04    |\n",
      "|    value_loss         | 2.41e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56600       |\n",
      "|    time_elapsed       | 856         |\n",
      "|    total_timesteps    | 283000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56599       |\n",
      "|    policy_loss        | 0.0249      |\n",
      "|    reward             | 0.008126554 |\n",
      "|    std                | 3.26e+04    |\n",
      "|    value_loss         | 2.13e-05    |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12731.07\n",
      "total_reward: -22731.07\n",
      "total_cost: 487.98\n",
      "total_trades: 5666\n",
      "Sharpe: 0.407\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 56700      |\n",
      "|    time_elapsed       | 857        |\n",
      "|    total_timesteps    | 283500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56699      |\n",
      "|    policy_loss        | -0.449     |\n",
      "|    reward             | 0.03301655 |\n",
      "|    std                | 3.39e+04   |\n",
      "|    value_loss         | 0.0114     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56800       |\n",
      "|    time_elapsed       | 858         |\n",
      "|    total_timesteps    | 284000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56799       |\n",
      "|    policy_loss        | -0.176      |\n",
      "|    reward             | 0.007063694 |\n",
      "|    std                | 3.43e+04    |\n",
      "|    value_loss         | 0.000909    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 56900      |\n",
      "|    time_elapsed       | 860        |\n",
      "|    total_timesteps    | 284500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56899      |\n",
      "|    policy_loss        | 1.6        |\n",
      "|    reward             | -0.1368645 |\n",
      "|    std                | 3.46e+04   |\n",
      "|    value_loss         | 0.00646    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 57000       |\n",
      "|    time_elapsed       | 861         |\n",
      "|    total_timesteps    | 285000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.0123      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56999       |\n",
      "|    policy_loss        | 1.5         |\n",
      "|    reward             | -0.16255304 |\n",
      "|    std                | 3.44e+04    |\n",
      "|    value_loss         | 0.00844     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 57100       |\n",
      "|    time_elapsed       | 863         |\n",
      "|    total_timesteps    | 285500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.25        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57099       |\n",
      "|    policy_loss        | -1.67       |\n",
      "|    reward             | -0.09215726 |\n",
      "|    std                | 3.46e+04    |\n",
      "|    value_loss         | 0.0824      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 57200       |\n",
      "|    time_elapsed       | 864         |\n",
      "|    total_timesteps    | 286000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.629       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57199       |\n",
      "|    policy_loss        | 6.1         |\n",
      "|    reward             | -0.20077634 |\n",
      "|    std                | 3.5e+04     |\n",
      "|    value_loss         | 0.0683      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57300        |\n",
      "|    time_elapsed       | 866          |\n",
      "|    total_timesteps    | 286500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57299        |\n",
      "|    policy_loss        | -0.515       |\n",
      "|    reward             | -0.117552884 |\n",
      "|    std                | 3.49e+04     |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 57400      |\n",
      "|    time_elapsed       | 867        |\n",
      "|    total_timesteps    | 287000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57399      |\n",
      "|    policy_loss        | -1.78      |\n",
      "|    reward             | 0.03133026 |\n",
      "|    std                | 3.54e+04   |\n",
      "|    value_loss         | 0.00583    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57500        |\n",
      "|    time_elapsed       | 868          |\n",
      "|    total_timesteps    | 287500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | -7.23        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57499        |\n",
      "|    policy_loss        | -0.719       |\n",
      "|    reward             | 0.0029435449 |\n",
      "|    std                | 3.56e+04     |\n",
      "|    value_loss         | 0.00192      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 57600       |\n",
      "|    time_elapsed       | 870         |\n",
      "|    total_timesteps    | 288000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | -5.46       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57599       |\n",
      "|    policy_loss        | 0.276       |\n",
      "|    reward             | -0.01040311 |\n",
      "|    std                | 3.65e+04    |\n",
      "|    value_loss         | 0.000202    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57700        |\n",
      "|    time_elapsed       | 871          |\n",
      "|    total_timesteps    | 288500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0.502        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57699        |\n",
      "|    policy_loss        | 0.67         |\n",
      "|    reward             | -0.020862874 |\n",
      "|    std                | 3.73e+04     |\n",
      "|    value_loss         | 0.00126      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 57800       |\n",
      "|    time_elapsed       | 873         |\n",
      "|    total_timesteps    | 289000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | -1.3        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57799       |\n",
      "|    policy_loss        | 0.991       |\n",
      "|    reward             | 0.036968477 |\n",
      "|    std                | 3.76e+04    |\n",
      "|    value_loss         | 0.00349     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57900        |\n",
      "|    time_elapsed       | 874          |\n",
      "|    total_timesteps    | 289500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57899        |\n",
      "|    policy_loss        | 0.693        |\n",
      "|    reward             | -0.006185265 |\n",
      "|    std                | 3.84e+04     |\n",
      "|    value_loss         | 0.000818     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 58000         |\n",
      "|    time_elapsed       | 876           |\n",
      "|    total_timesteps    | 290000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 57999         |\n",
      "|    policy_loss        | -0.495        |\n",
      "|    reward             | 0.00042273538 |\n",
      "|    std                | 3.93e+04      |\n",
      "|    value_loss         | 0.000441      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 58100         |\n",
      "|    time_elapsed       | 877           |\n",
      "|    total_timesteps    | 290500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58099         |\n",
      "|    policy_loss        | -0.17         |\n",
      "|    reward             | -0.0012201223 |\n",
      "|    std                | 4.05e+04      |\n",
      "|    value_loss         | 0.000152      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 58200       |\n",
      "|    time_elapsed       | 879         |\n",
      "|    total_timesteps    | 291000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | -8.05       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58199       |\n",
      "|    policy_loss        | 0.0164      |\n",
      "|    reward             | 0.010750269 |\n",
      "|    std                | 4.18e+04    |\n",
      "|    value_loss         | 0.000116    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 58300        |\n",
      "|    time_elapsed       | 880          |\n",
      "|    total_timesteps    | 291500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | -0.13        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58299        |\n",
      "|    policy_loss        | -0.045       |\n",
      "|    reward             | -0.002750255 |\n",
      "|    std                | 4.33e+04     |\n",
      "|    value_loss         | 6.1e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 58400       |\n",
      "|    time_elapsed       | 882         |\n",
      "|    total_timesteps    | 292000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58399       |\n",
      "|    policy_loss        | 4.82        |\n",
      "|    reward             | 0.006588629 |\n",
      "|    std                | 4.44e+04    |\n",
      "|    value_loss         | 0.0509      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 58500       |\n",
      "|    time_elapsed       | 883         |\n",
      "|    total_timesteps    | 292500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58499       |\n",
      "|    policy_loss        | -0.915      |\n",
      "|    reward             | 0.007944375 |\n",
      "|    std                | 4.43e+04    |\n",
      "|    value_loss         | 0.00179     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 58600        |\n",
      "|    time_elapsed       | 885          |\n",
      "|    total_timesteps    | 293000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58599        |\n",
      "|    policy_loss        | 1.02         |\n",
      "|    reward             | -0.013260196 |\n",
      "|    std                | 4.52e+04     |\n",
      "|    value_loss         | 0.00244      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 58700       |\n",
      "|    time_elapsed       | 886         |\n",
      "|    total_timesteps    | 293500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.3       |\n",
      "|    explained_variance | 0.339       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58699       |\n",
      "|    policy_loss        | 1.51        |\n",
      "|    reward             | -0.15047218 |\n",
      "|    std                | 4.53e+04    |\n",
      "|    value_loss         | 0.0108      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 58800      |\n",
      "|    time_elapsed       | 888        |\n",
      "|    total_timesteps    | 294000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.2      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 58799      |\n",
      "|    policy_loss        | -14.8      |\n",
      "|    reward             | 0.25240776 |\n",
      "|    std                | 4.44e+04   |\n",
      "|    value_loss         | 0.399      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 58900      |\n",
      "|    time_elapsed       | 889        |\n",
      "|    total_timesteps    | 294500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.2      |\n",
      "|    explained_variance | -0.076     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 58899      |\n",
      "|    policy_loss        | -0.271     |\n",
      "|    reward             | 0.30224812 |\n",
      "|    std                | 4.46e+04   |\n",
      "|    value_loss         | 0.0121     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 59000       |\n",
      "|    time_elapsed       | 890         |\n",
      "|    total_timesteps    | 295000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58999       |\n",
      "|    policy_loss        | 0.232       |\n",
      "|    reward             | 0.022457628 |\n",
      "|    std                | 4.52e+04    |\n",
      "|    value_loss         | 0.000222    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 59100        |\n",
      "|    time_elapsed       | 892          |\n",
      "|    total_timesteps    | 295500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59099        |\n",
      "|    policy_loss        | -0.128       |\n",
      "|    reward             | -0.011021024 |\n",
      "|    std                | 4.58e+04     |\n",
      "|    value_loss         | 4.24e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 59200        |\n",
      "|    time_elapsed       | 893          |\n",
      "|    total_timesteps    | 296000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59199        |\n",
      "|    policy_loss        | 0.125        |\n",
      "|    reward             | -0.007872839 |\n",
      "|    std                | 4.66e+04     |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 59300      |\n",
      "|    time_elapsed       | 895        |\n",
      "|    total_timesteps    | 296500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.4      |\n",
      "|    explained_variance | -57.7      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59299      |\n",
      "|    policy_loss        | -0.442     |\n",
      "|    reward             | 0.00398374 |\n",
      "|    std                | 4.75e+04   |\n",
      "|    value_loss         | 0.000398   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 59400        |\n",
      "|    time_elapsed       | 896          |\n",
      "|    total_timesteps    | 297000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | -5.13e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59399        |\n",
      "|    policy_loss        | 0.509        |\n",
      "|    reward             | -0.013266978 |\n",
      "|    std                | 4.88e+04     |\n",
      "|    value_loss         | 0.000497     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 59500        |\n",
      "|    time_elapsed       | 898          |\n",
      "|    total_timesteps    | 297500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59499        |\n",
      "|    policy_loss        | 0.18         |\n",
      "|    reward             | -0.012911252 |\n",
      "|    std                | 5.02e+04     |\n",
      "|    value_loss         | 0.000647     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -15583.86\n",
      "total_reward: -25583.86\n",
      "total_cost: 386.60\n",
      "total_trades: 5666\n",
      "Sharpe: -0.343\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 59600       |\n",
      "|    time_elapsed       | 899         |\n",
      "|    total_timesteps    | 298000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59599       |\n",
      "|    policy_loss        | -0.269      |\n",
      "|    reward             | 0.009017308 |\n",
      "|    std                | 5.19e+04    |\n",
      "|    value_loss         | 0.000468    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 59700       |\n",
      "|    time_elapsed       | 901         |\n",
      "|    total_timesteps    | 298500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59699       |\n",
      "|    policy_loss        | 0.145       |\n",
      "|    reward             | 0.004461938 |\n",
      "|    std                | 5.32e+04    |\n",
      "|    value_loss         | 4.63e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 59800       |\n",
      "|    time_elapsed       | 902         |\n",
      "|    total_timesteps    | 299000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59799       |\n",
      "|    policy_loss        | -0.733      |\n",
      "|    reward             | -0.01619285 |\n",
      "|    std                | 5.56e+04    |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 59900       |\n",
      "|    time_elapsed       | 904         |\n",
      "|    total_timesteps    | 299500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | -1.43       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59899       |\n",
      "|    policy_loss        | -0.0888     |\n",
      "|    reward             | 0.016355462 |\n",
      "|    std                | 5.78e+04    |\n",
      "|    value_loss         | 0.000183    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 60000        |\n",
      "|    time_elapsed       | 905          |\n",
      "|    total_timesteps    | 300000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.8        |\n",
      "|    explained_variance | 0.368        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59999        |\n",
      "|    policy_loss        | 0.121        |\n",
      "|    reward             | -0.009295382 |\n",
      "|    std                | 6.02e+04     |\n",
      "|    value_loss         | 3.5e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 60100        |\n",
      "|    time_elapsed       | 907          |\n",
      "|    total_timesteps    | 300500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60099        |\n",
      "|    policy_loss        | 5.29         |\n",
      "|    reward             | -0.037190977 |\n",
      "|    std                | 6.28e+04     |\n",
      "|    value_loss         | 0.0479       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 60200      |\n",
      "|    time_elapsed       | 908        |\n",
      "|    total_timesteps    | 301000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60199      |\n",
      "|    policy_loss        | -1.14      |\n",
      "|    reward             | 0.01461161 |\n",
      "|    std                | 6.36e+04   |\n",
      "|    value_loss         | 0.00273    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 60300        |\n",
      "|    time_elapsed       | 909          |\n",
      "|    total_timesteps    | 301500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60299        |\n",
      "|    policy_loss        | -0.0241      |\n",
      "|    reward             | -0.045187987 |\n",
      "|    std                | 6.47e+04     |\n",
      "|    value_loss         | 0.000868     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 60400        |\n",
      "|    time_elapsed       | 911          |\n",
      "|    total_timesteps    | 302000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 7.09e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60399        |\n",
      "|    policy_loss        | -4.3         |\n",
      "|    reward             | -0.052522693 |\n",
      "|    std                | 6.57e+04     |\n",
      "|    value_loss         | 0.0327       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 60500       |\n",
      "|    time_elapsed       | 913         |\n",
      "|    total_timesteps    | 302500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0.445       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60499       |\n",
      "|    policy_loss        | -7.6        |\n",
      "|    reward             | -0.18134603 |\n",
      "|    std                | 6.51e+04    |\n",
      "|    value_loss         | 0.0967      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 60600      |\n",
      "|    time_elapsed       | 914        |\n",
      "|    total_timesteps    | 303000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25        |\n",
      "|    explained_variance | 0.408      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60599      |\n",
      "|    policy_loss        | -1.92      |\n",
      "|    reward             | 0.21156617 |\n",
      "|    std                | 6.47e+04   |\n",
      "|    value_loss         | 0.0191     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 60700       |\n",
      "|    time_elapsed       | 916         |\n",
      "|    total_timesteps    | 303500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60699       |\n",
      "|    policy_loss        | 0.0735      |\n",
      "|    reward             | 0.006699696 |\n",
      "|    std                | 6.44e+04    |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 60800          |\n",
      "|    time_elapsed       | 918            |\n",
      "|    total_timesteps    | 304000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -25            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 60799          |\n",
      "|    policy_loss        | 0.0857         |\n",
      "|    reward             | -0.00061585614 |\n",
      "|    std                | 6.48e+04       |\n",
      "|    value_loss         | 0.000138       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 60900         |\n",
      "|    time_elapsed       | 919           |\n",
      "|    total_timesteps    | 304500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25           |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60899         |\n",
      "|    policy_loss        | 0.0698        |\n",
      "|    reward             | -0.0021059425 |\n",
      "|    std                | 6.59e+04      |\n",
      "|    value_loss         | 0.000133      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61000        |\n",
      "|    time_elapsed       | 921          |\n",
      "|    total_timesteps    | 305000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60999        |\n",
      "|    policy_loss        | 0.112        |\n",
      "|    reward             | 0.0036444399 |\n",
      "|    std                | 6.75e+04     |\n",
      "|    value_loss         | 6.56e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 61100         |\n",
      "|    time_elapsed       | 923           |\n",
      "|    total_timesteps    | 305500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.1         |\n",
      "|    explained_variance | 0.762         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61099         |\n",
      "|    policy_loss        | -0.195        |\n",
      "|    reward             | -0.0067637307 |\n",
      "|    std                | 7.01e+04      |\n",
      "|    value_loss         | 9.56e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 61200       |\n",
      "|    time_elapsed       | 924         |\n",
      "|    total_timesteps    | 306000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61199       |\n",
      "|    policy_loss        | -0.917      |\n",
      "|    reward             | 0.022731986 |\n",
      "|    std                | 7.26e+04    |\n",
      "|    value_loss         | 0.00178     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61300        |\n",
      "|    time_elapsed       | 926          |\n",
      "|    total_timesteps    | 306500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61299        |\n",
      "|    policy_loss        | -0.848       |\n",
      "|    reward             | -0.008444734 |\n",
      "|    std                | 7.55e+04     |\n",
      "|    value_loss         | 0.00171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 61400         |\n",
      "|    time_elapsed       | 927           |\n",
      "|    total_timesteps    | 307000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61399         |\n",
      "|    policy_loss        | -0.144        |\n",
      "|    reward             | -0.0048930245 |\n",
      "|    std                | 7.72e+04      |\n",
      "|    value_loss         | 6.08e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61500        |\n",
      "|    time_elapsed       | 929          |\n",
      "|    total_timesteps    | 307500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61499        |\n",
      "|    policy_loss        | -0.622       |\n",
      "|    reward             | 0.0071650743 |\n",
      "|    std                | 8.02e+04     |\n",
      "|    value_loss         | 0.000652     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 61600         |\n",
      "|    time_elapsed       | 931           |\n",
      "|    total_timesteps    | 308000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61599         |\n",
      "|    policy_loss        | -0.197        |\n",
      "|    reward             | -0.0018201689 |\n",
      "|    std                | 8.29e+04      |\n",
      "|    value_loss         | 9.51e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61700        |\n",
      "|    time_elapsed       | 932          |\n",
      "|    total_timesteps    | 308500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.5        |\n",
      "|    explained_variance | 0.39         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61699        |\n",
      "|    policy_loss        | 0.182        |\n",
      "|    reward             | -0.003364032 |\n",
      "|    std                | 8.59e+04     |\n",
      "|    value_loss         | 5.58e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 61800         |\n",
      "|    time_elapsed       | 934           |\n",
      "|    total_timesteps    | 309000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61799         |\n",
      "|    policy_loss        | -2.65         |\n",
      "|    reward             | -0.0026794544 |\n",
      "|    std                | 8.75e+04      |\n",
      "|    value_loss         | 0.0112        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61900        |\n",
      "|    time_elapsed       | 935          |\n",
      "|    total_timesteps    | 309500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61899        |\n",
      "|    policy_loss        | -1.23        |\n",
      "|    reward             | -0.018092696 |\n",
      "|    std                | 9e+04        |\n",
      "|    value_loss         | 0.00526      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62000        |\n",
      "|    time_elapsed       | 937          |\n",
      "|    total_timesteps    | 310000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61999        |\n",
      "|    policy_loss        | 0.372        |\n",
      "|    reward             | -0.009847407 |\n",
      "|    std                | 9.17e+04     |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62100        |\n",
      "|    time_elapsed       | 939          |\n",
      "|    total_timesteps    | 310500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | -0.18        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62099        |\n",
      "|    policy_loss        | 0.616        |\n",
      "|    reward             | 0.0004458992 |\n",
      "|    std                | 9.37e+04     |\n",
      "|    value_loss         | 0.000647     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62200        |\n",
      "|    time_elapsed       | 940          |\n",
      "|    total_timesteps    | 311000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62199        |\n",
      "|    policy_loss        | -0.916       |\n",
      "|    reward             | -0.008343568 |\n",
      "|    std                | 9.54e+04     |\n",
      "|    value_loss         | 0.00146      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62300        |\n",
      "|    time_elapsed       | 942          |\n",
      "|    total_timesteps    | 311500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62299        |\n",
      "|    policy_loss        | -0.978       |\n",
      "|    reward             | -0.005537669 |\n",
      "|    std                | 9.72e+04     |\n",
      "|    value_loss         | 0.00194      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -51414.81\n",
      "total_reward: -61414.81\n",
      "total_cost: 85.96\n",
      "total_trades: 5666\n",
      "Sharpe: -0.313\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 62400       |\n",
      "|    time_elapsed       | 943         |\n",
      "|    total_timesteps    | 312000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62399       |\n",
      "|    policy_loss        | -0.278      |\n",
      "|    reward             | 0.014477434 |\n",
      "|    std                | 9.75e+04    |\n",
      "|    value_loss         | 0.000245    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62500        |\n",
      "|    time_elapsed       | 945          |\n",
      "|    total_timesteps    | 312500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62499        |\n",
      "|    policy_loss        | 0.645        |\n",
      "|    reward             | -0.013550127 |\n",
      "|    std                | 9.91e+04     |\n",
      "|    value_loss         | 0.000769     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 62600         |\n",
      "|    time_elapsed       | 946           |\n",
      "|    total_timesteps    | 313000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62599         |\n",
      "|    policy_loss        | 0.352         |\n",
      "|    reward             | -0.0018162777 |\n",
      "|    std                | 1.01e+05      |\n",
      "|    value_loss         | 0.000567      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62700        |\n",
      "|    time_elapsed       | 948          |\n",
      "|    total_timesteps    | 313500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | -0.316       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62699        |\n",
      "|    policy_loss        | 0.391        |\n",
      "|    reward             | 0.0014900985 |\n",
      "|    std                | 1.05e+05     |\n",
      "|    value_loss         | 0.000345     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62800        |\n",
      "|    time_elapsed       | 949          |\n",
      "|    total_timesteps    | 314000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | 0.672        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62799        |\n",
      "|    policy_loss        | -0.562       |\n",
      "|    reward             | -0.012737355 |\n",
      "|    std                | 1.07e+05     |\n",
      "|    value_loss         | 0.000532     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62900        |\n",
      "|    time_elapsed       | 951          |\n",
      "|    total_timesteps    | 314500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62899        |\n",
      "|    policy_loss        | -0.699       |\n",
      "|    reward             | -0.021668466 |\n",
      "|    std                | 1.11e+05     |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 63000         |\n",
      "|    time_elapsed       | 952           |\n",
      "|    total_timesteps    | 315000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62999         |\n",
      "|    policy_loss        | -1.01         |\n",
      "|    reward             | -0.0014619251 |\n",
      "|    std                | 1.14e+05      |\n",
      "|    value_loss         | 0.00159       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 63100        |\n",
      "|    time_elapsed       | 954          |\n",
      "|    total_timesteps    | 315500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63099        |\n",
      "|    policy_loss        | -0.197       |\n",
      "|    reward             | -0.002372103 |\n",
      "|    std                | 1.17e+05     |\n",
      "|    value_loss         | 6.37e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 63200         |\n",
      "|    time_elapsed       | 955           |\n",
      "|    total_timesteps    | 316000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63199         |\n",
      "|    policy_loss        | -0.507        |\n",
      "|    reward             | 0.00028898087 |\n",
      "|    std                | 1.23e+05      |\n",
      "|    value_loss         | 0.000605      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 63300       |\n",
      "|    time_elapsed       | 957         |\n",
      "|    total_timesteps    | 316500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63299       |\n",
      "|    policy_loss        | 0.101       |\n",
      "|    reward             | 0.008183861 |\n",
      "|    std                | 1.27e+05    |\n",
      "|    value_loss         | 6.37e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 63400        |\n",
      "|    time_elapsed       | 958          |\n",
      "|    total_timesteps    | 317000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | -0.0668      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63399        |\n",
      "|    policy_loss        | -0.118       |\n",
      "|    reward             | -0.011293811 |\n",
      "|    std                | 1.33e+05     |\n",
      "|    value_loss         | 2.25e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 63500       |\n",
      "|    time_elapsed       | 960         |\n",
      "|    total_timesteps    | 317500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63499       |\n",
      "|    policy_loss        | -0.733      |\n",
      "|    reward             | 0.015933339 |\n",
      "|    std                | 1.38e+05    |\n",
      "|    value_loss         | 0.000921    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 63600         |\n",
      "|    time_elapsed       | 961           |\n",
      "|    total_timesteps    | 318000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63599         |\n",
      "|    policy_loss        | -0.909        |\n",
      "|    reward             | -0.0010341698 |\n",
      "|    std                | 1.41e+05      |\n",
      "|    value_loss         | 0.00149       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 63700       |\n",
      "|    time_elapsed       | 962         |\n",
      "|    total_timesteps    | 318500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63699       |\n",
      "|    policy_loss        | 0.625       |\n",
      "|    reward             | -0.00526187 |\n",
      "|    std                | 1.46e+05    |\n",
      "|    value_loss         | 0.000745    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 63800        |\n",
      "|    time_elapsed       | 964          |\n",
      "|    total_timesteps    | 319000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63799        |\n",
      "|    policy_loss        | 0.221        |\n",
      "|    reward             | 0.0013950686 |\n",
      "|    std                | 1.49e+05     |\n",
      "|    value_loss         | 7.19e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 63900        |\n",
      "|    time_elapsed       | 965          |\n",
      "|    total_timesteps    | 319500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.00447      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63899        |\n",
      "|    policy_loss        | 0.611        |\n",
      "|    reward             | -0.006668305 |\n",
      "|    std                | 1.54e+05     |\n",
      "|    value_loss         | 0.00132      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 64000        |\n",
      "|    time_elapsed       | 967          |\n",
      "|    total_timesteps    | 320000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63999        |\n",
      "|    policy_loss        | 0.324        |\n",
      "|    reward             | -0.009371549 |\n",
      "|    std                | 1.6e+05      |\n",
      "|    value_loss         | 0.00015      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 64100        |\n",
      "|    time_elapsed       | 969          |\n",
      "|    total_timesteps    | 320500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64099        |\n",
      "|    policy_loss        | -0.754       |\n",
      "|    reward             | -0.008651464 |\n",
      "|    std                | 1.66e+05     |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 64200        |\n",
      "|    time_elapsed       | 970          |\n",
      "|    total_timesteps    | 321000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64199        |\n",
      "|    policy_loss        | 0.917        |\n",
      "|    reward             | -0.022838363 |\n",
      "|    std                | 1.68e+05     |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 64300       |\n",
      "|    time_elapsed       | 972         |\n",
      "|    total_timesteps    | 321500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64299       |\n",
      "|    policy_loss        | 11.7        |\n",
      "|    reward             | 0.067460515 |\n",
      "|    std                | 1.71e+05    |\n",
      "|    value_loss         | 0.196       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 64400        |\n",
      "|    time_elapsed       | 973          |\n",
      "|    total_timesteps    | 322000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64399        |\n",
      "|    policy_loss        | 3.6          |\n",
      "|    reward             | -0.005045896 |\n",
      "|    std                | 1.72e+05     |\n",
      "|    value_loss         | 0.0251       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 64500      |\n",
      "|    time_elapsed       | 975        |\n",
      "|    total_timesteps    | 322500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64499      |\n",
      "|    policy_loss        | -22.5      |\n",
      "|    reward             | 0.22652042 |\n",
      "|    std                | 1.74e+05   |\n",
      "|    value_loss         | 0.709      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 64600       |\n",
      "|    time_elapsed       | 976         |\n",
      "|    total_timesteps    | 323000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0.0365      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64599       |\n",
      "|    policy_loss        | 6.68        |\n",
      "|    reward             | -0.27332115 |\n",
      "|    std                | 1.75e+05    |\n",
      "|    value_loss         | 0.561       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 64700        |\n",
      "|    time_elapsed       | 978          |\n",
      "|    total_timesteps    | 323500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64699        |\n",
      "|    policy_loss        | 0.308        |\n",
      "|    reward             | -0.003685802 |\n",
      "|    std                | 1.75e+05     |\n",
      "|    value_loss         | 0.000947     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 64800         |\n",
      "|    time_elapsed       | 979           |\n",
      "|    total_timesteps    | 324000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27           |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64799         |\n",
      "|    policy_loss        | 0.221         |\n",
      "|    reward             | 0.00032022418 |\n",
      "|    std                | 1.78e+05      |\n",
      "|    value_loss         | 0.000179      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 64900        |\n",
      "|    time_elapsed       | 981          |\n",
      "|    total_timesteps    | 324500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64899        |\n",
      "|    policy_loss        | -0.884       |\n",
      "|    reward             | -0.005390288 |\n",
      "|    std                | 1.81e+05     |\n",
      "|    value_loss         | 0.00114      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 65000        |\n",
      "|    time_elapsed       | 982          |\n",
      "|    total_timesteps    | 325000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | 0.472        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64999        |\n",
      "|    policy_loss        | 0.302        |\n",
      "|    reward             | -0.008541946 |\n",
      "|    std                | 1.86e+05     |\n",
      "|    value_loss         | 0.000219     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 65100        |\n",
      "|    time_elapsed       | 984          |\n",
      "|    total_timesteps    | 325500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 8.34e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65099        |\n",
      "|    policy_loss        | -0.215       |\n",
      "|    reward             | -0.011966394 |\n",
      "|    std                | 1.93e+05     |\n",
      "|    value_loss         | 8.6e-05      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -14531.37\n",
      "total_reward: -24531.37\n",
      "total_cost: 398.82\n",
      "total_trades: 5666\n",
      "Sharpe: -0.435\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 65200      |\n",
      "|    time_elapsed       | 985        |\n",
      "|    total_timesteps    | 326000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65199      |\n",
      "|    policy_loss        | 0.548      |\n",
      "|    reward             | 0.03370819 |\n",
      "|    std                | 1.99e+05   |\n",
      "|    value_loss         | 0.00064    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 65300       |\n",
      "|    time_elapsed       | 987         |\n",
      "|    total_timesteps    | 326500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65299       |\n",
      "|    policy_loss        | -0.238      |\n",
      "|    reward             | 0.008125518 |\n",
      "|    std                | 2.03e+05    |\n",
      "|    value_loss         | 0.00126     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 65400      |\n",
      "|    time_elapsed       | 988        |\n",
      "|    total_timesteps    | 327000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65399      |\n",
      "|    policy_loss        | 0.735      |\n",
      "|    reward             | 0.02017328 |\n",
      "|    std                | 2.06e+05   |\n",
      "|    value_loss         | 0.00127    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 65500        |\n",
      "|    time_elapsed       | 990          |\n",
      "|    total_timesteps    | 327500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65499        |\n",
      "|    policy_loss        | -0.134       |\n",
      "|    reward             | -0.032300293 |\n",
      "|    std                | 2.11e+05     |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 65600        |\n",
      "|    time_elapsed       | 991          |\n",
      "|    total_timesteps    | 328000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0.0604       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65599        |\n",
      "|    policy_loss        | 6.99         |\n",
      "|    reward             | 0.0032471558 |\n",
      "|    std                | 2.15e+05     |\n",
      "|    value_loss         | 0.0759       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 65700      |\n",
      "|    time_elapsed       | 993        |\n",
      "|    total_timesteps    | 328500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.4      |\n",
      "|    explained_variance | 0.303      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65699      |\n",
      "|    policy_loss        | -0.824     |\n",
      "|    reward             | 0.01892429 |\n",
      "|    std                | 2.2e+05    |\n",
      "|    value_loss         | 0.00118    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 65800        |\n",
      "|    time_elapsed       | 994          |\n",
      "|    total_timesteps    | 329000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65799        |\n",
      "|    policy_loss        | -0.561       |\n",
      "|    reward             | -0.015305574 |\n",
      "|    std                | 2.23e+05     |\n",
      "|    value_loss         | 0.000433     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 65900        |\n",
      "|    time_elapsed       | 996          |\n",
      "|    total_timesteps    | 329500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65899        |\n",
      "|    policy_loss        | 0.000855     |\n",
      "|    reward             | -0.009746214 |\n",
      "|    std                | 2.26e+05     |\n",
      "|    value_loss         | 3.16e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 66000        |\n",
      "|    time_elapsed       | 997          |\n",
      "|    total_timesteps    | 330000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65999        |\n",
      "|    policy_loss        | -0.129       |\n",
      "|    reward             | -0.012294538 |\n",
      "|    std                | 2.33e+05     |\n",
      "|    value_loss         | 3.6e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 66100         |\n",
      "|    time_elapsed       | 999           |\n",
      "|    total_timesteps    | 330500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66099         |\n",
      "|    policy_loss        | 0.126         |\n",
      "|    reward             | 0.00044559775 |\n",
      "|    std                | 2.42e+05      |\n",
      "|    value_loss         | 5.64e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 66200       |\n",
      "|    time_elapsed       | 1000        |\n",
      "|    total_timesteps    | 331000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | 0.061       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66199       |\n",
      "|    policy_loss        | -0.042      |\n",
      "|    reward             | 0.008199125 |\n",
      "|    std                | 2.49e+05    |\n",
      "|    value_loss         | 3.26e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 1002        |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | 0.279       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66299       |\n",
      "|    policy_loss        | 2.33        |\n",
      "|    reward             | -0.04237123 |\n",
      "|    std                | 2.56e+05    |\n",
      "|    value_loss         | 0.0086      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 66400        |\n",
      "|    time_elapsed       | 1003         |\n",
      "|    total_timesteps    | 332000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66399        |\n",
      "|    policy_loss        | 5.02         |\n",
      "|    reward             | -0.012899212 |\n",
      "|    std                | 2.6e+05      |\n",
      "|    value_loss         | 0.0392       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 66500         |\n",
      "|    time_elapsed       | 1004          |\n",
      "|    total_timesteps    | 332500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66499         |\n",
      "|    policy_loss        | 0.132         |\n",
      "|    reward             | -0.0031047682 |\n",
      "|    std                | 2.63e+05      |\n",
      "|    value_loss         | 0.00213       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 66600        |\n",
      "|    time_elapsed       | 1006         |\n",
      "|    total_timesteps    | 333000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.8        |\n",
      "|    explained_variance | 0.496        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66599        |\n",
      "|    policy_loss        | -0.0789      |\n",
      "|    reward             | -0.008378625 |\n",
      "|    std                | 2.66e+05     |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 66700        |\n",
      "|    time_elapsed       | 1007         |\n",
      "|    total_timesteps    | 333500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0.0944       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66699        |\n",
      "|    policy_loss        | 1.04         |\n",
      "|    reward             | -0.045843013 |\n",
      "|    std                | 2.72e+05     |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 66800        |\n",
      "|    time_elapsed       | 1009         |\n",
      "|    total_timesteps    | 334000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0.0428       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66799        |\n",
      "|    policy_loss        | -0.889       |\n",
      "|    reward             | 0.0036765311 |\n",
      "|    std                | 2.79e+05     |\n",
      "|    value_loss         | 0.00168      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 66900       |\n",
      "|    time_elapsed       | 1010        |\n",
      "|    total_timesteps    | 334500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66899       |\n",
      "|    policy_loss        | 1.58        |\n",
      "|    reward             | 0.004390932 |\n",
      "|    std                | 2.78e+05    |\n",
      "|    value_loss         | 0.00468     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 67000        |\n",
      "|    time_elapsed       | 1012         |\n",
      "|    total_timesteps    | 335000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66999        |\n",
      "|    policy_loss        | 0.859        |\n",
      "|    reward             | -0.033660058 |\n",
      "|    std                | 2.81e+05     |\n",
      "|    value_loss         | 0.00253      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 67100       |\n",
      "|    time_elapsed       | 1013        |\n",
      "|    total_timesteps    | 335500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67099       |\n",
      "|    policy_loss        | -0.68       |\n",
      "|    reward             | 0.011105881 |\n",
      "|    std                | 2.87e+05    |\n",
      "|    value_loss         | 0.00102     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67200        |\n",
      "|    time_elapsed       | 1015         |\n",
      "|    total_timesteps    | 336000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28          |\n",
      "|    explained_variance | 0.404        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67199        |\n",
      "|    policy_loss        | -0.475       |\n",
      "|    reward             | 0.0069216783 |\n",
      "|    std                | 2.94e+05     |\n",
      "|    value_loss         | 0.000398     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67300        |\n",
      "|    time_elapsed       | 1016         |\n",
      "|    total_timesteps    | 336500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67299        |\n",
      "|    policy_loss        | 0.563        |\n",
      "|    reward             | -0.003453079 |\n",
      "|    std                | 2.99e+05     |\n",
      "|    value_loss         | 0.00199      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67400        |\n",
      "|    time_elapsed       | 1018         |\n",
      "|    total_timesteps    | 337000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0.296        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67399        |\n",
      "|    policy_loss        | 0.59         |\n",
      "|    reward             | -0.050790098 |\n",
      "|    std                | 3.01e+05     |\n",
      "|    value_loss         | 0.00105      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 67500       |\n",
      "|    time_elapsed       | 1019        |\n",
      "|    total_timesteps    | 337500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67499       |\n",
      "|    policy_loss        | 0.117       |\n",
      "|    reward             | 0.012515735 |\n",
      "|    std                | 3.07e+05    |\n",
      "|    value_loss         | 3.3e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67600        |\n",
      "|    time_elapsed       | 1020         |\n",
      "|    total_timesteps    | 338000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67599        |\n",
      "|    policy_loss        | 0.207        |\n",
      "|    reward             | 0.0066203256 |\n",
      "|    std                | 3.12e+05     |\n",
      "|    value_loss         | 7.07e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67700        |\n",
      "|    time_elapsed       | 1022         |\n",
      "|    total_timesteps    | 338500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67699        |\n",
      "|    policy_loss        | -0.276       |\n",
      "|    reward             | 4.775636e-05 |\n",
      "|    std                | 3.2e+05      |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 67800       |\n",
      "|    time_elapsed       | 1023        |\n",
      "|    total_timesteps    | 339000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67799       |\n",
      "|    policy_loss        | -0.0404     |\n",
      "|    reward             | 0.010018902 |\n",
      "|    std                | 3.29e+05    |\n",
      "|    value_loss         | 2.98e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 67900         |\n",
      "|    time_elapsed       | 1025          |\n",
      "|    total_timesteps    | 339500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | 0.682         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 67899         |\n",
      "|    policy_loss        | -0.00346      |\n",
      "|    reward             | -0.0035057212 |\n",
      "|    std                | 3.41e+05      |\n",
      "|    value_loss         | 5.09e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 68000        |\n",
      "|    time_elapsed       | 1027         |\n",
      "|    total_timesteps    | 340000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.4        |\n",
      "|    explained_variance | 0.451        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67999        |\n",
      "|    policy_loss        | 1.8          |\n",
      "|    reward             | -0.026736176 |\n",
      "|    std                | 3.56e+05     |\n",
      "|    value_loss         | 0.00403      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12307.84\n",
      "total_reward: -22307.84\n",
      "total_cost: 482.34\n",
      "total_trades: 5666\n",
      "Sharpe: -0.348\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 68100        |\n",
      "|    time_elapsed       | 1028         |\n",
      "|    total_timesteps    | 340500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68099        |\n",
      "|    policy_loss        | 4.79         |\n",
      "|    reward             | -0.015273726 |\n",
      "|    std                | 3.65e+05     |\n",
      "|    value_loss         | 0.0346       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 68200         |\n",
      "|    time_elapsed       | 1029          |\n",
      "|    total_timesteps    | 341000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68199         |\n",
      "|    policy_loss        | 0.471         |\n",
      "|    reward             | -0.0118968515 |\n",
      "|    std                | 3.75e+05      |\n",
      "|    value_loss         | 0.00176       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68300       |\n",
      "|    time_elapsed       | 1031        |\n",
      "|    total_timesteps    | 341500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0.0779      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68299       |\n",
      "|    policy_loss        | 2.36        |\n",
      "|    reward             | 0.025247589 |\n",
      "|    std                | 3.78e+05    |\n",
      "|    value_loss         | 0.0144      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68400       |\n",
      "|    time_elapsed       | 1032        |\n",
      "|    total_timesteps    | 342000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0.0109      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68399       |\n",
      "|    policy_loss        | -2.57       |\n",
      "|    reward             | 0.036688086 |\n",
      "|    std                | 3.79e+05    |\n",
      "|    value_loss         | 0.0348      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68500       |\n",
      "|    time_elapsed       | 1034        |\n",
      "|    total_timesteps    | 342500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0.00137     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68499       |\n",
      "|    policy_loss        | -8.25       |\n",
      "|    reward             | 0.014094905 |\n",
      "|    std                | 3.82e+05    |\n",
      "|    value_loss         | 0.0885      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 68600        |\n",
      "|    time_elapsed       | 1035         |\n",
      "|    total_timesteps    | 343000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68599        |\n",
      "|    policy_loss        | 1.17         |\n",
      "|    reward             | -0.024875546 |\n",
      "|    std                | 3.84e+05     |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 68700        |\n",
      "|    time_elapsed       | 1037         |\n",
      "|    total_timesteps    | 343500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68699        |\n",
      "|    policy_loss        | -0.461       |\n",
      "|    reward             | -0.023606414 |\n",
      "|    std                | 3.87e+05     |\n",
      "|    value_loss         | 0.000701     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68800       |\n",
      "|    time_elapsed       | 1038        |\n",
      "|    total_timesteps    | 344000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68799       |\n",
      "|    policy_loss        | -0.101      |\n",
      "|    reward             | 0.014676614 |\n",
      "|    std                | 3.93e+05    |\n",
      "|    value_loss         | 9.32e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 68900         |\n",
      "|    time_elapsed       | 1040          |\n",
      "|    total_timesteps    | 344500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.6         |\n",
      "|    explained_variance | -0.238        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68899         |\n",
      "|    policy_loss        | -0.384        |\n",
      "|    reward             | -0.0047042468 |\n",
      "|    std                | 4.05e+05      |\n",
      "|    value_loss         | 0.000324      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 69000        |\n",
      "|    time_elapsed       | 1041         |\n",
      "|    total_timesteps    | 345000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | -0.239       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68999        |\n",
      "|    policy_loss        | -0.338       |\n",
      "|    reward             | 0.0027069142 |\n",
      "|    std                | 4.17e+05     |\n",
      "|    value_loss         | 0.000177     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 69100        |\n",
      "|    time_elapsed       | 1043         |\n",
      "|    total_timesteps    | 345500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69099        |\n",
      "|    policy_loss        | -0.305       |\n",
      "|    reward             | 0.0052797655 |\n",
      "|    std                | 4.32e+05     |\n",
      "|    value_loss         | 0.000175     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 69200       |\n",
      "|    time_elapsed       | 1044        |\n",
      "|    total_timesteps    | 346000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69199       |\n",
      "|    policy_loss        | -0.57       |\n",
      "|    reward             | 0.012442177 |\n",
      "|    std                | 4.41e+05    |\n",
      "|    value_loss         | 0.000742    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 69300        |\n",
      "|    time_elapsed       | 1046         |\n",
      "|    total_timesteps    | 346500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69299        |\n",
      "|    policy_loss        | 0.334        |\n",
      "|    reward             | -0.002662127 |\n",
      "|    std                | 4.5e+05      |\n",
      "|    value_loss         | 0.00021      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 69400       |\n",
      "|    time_elapsed       | 1047        |\n",
      "|    total_timesteps    | 347000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69399       |\n",
      "|    policy_loss        | -0.27       |\n",
      "|    reward             | 0.013304472 |\n",
      "|    std                | 4.58e+05    |\n",
      "|    value_loss         | 0.000148    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 69500       |\n",
      "|    time_elapsed       | 1049        |\n",
      "|    total_timesteps    | 347500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69499       |\n",
      "|    policy_loss        | -0.297      |\n",
      "|    reward             | 4.21875e-05 |\n",
      "|    std                | 4.7e+05     |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 69600        |\n",
      "|    time_elapsed       | 1050         |\n",
      "|    total_timesteps    | 348000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | -0.438       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69599        |\n",
      "|    policy_loss        | 0.602        |\n",
      "|    reward             | 0.0012883339 |\n",
      "|    std                | 4.89e+05     |\n",
      "|    value_loss         | 0.000487     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 69700        |\n",
      "|    time_elapsed       | 1052         |\n",
      "|    total_timesteps    | 348500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69699        |\n",
      "|    policy_loss        | -0.138       |\n",
      "|    reward             | -0.046184644 |\n",
      "|    std                | 5e+05        |\n",
      "|    value_loss         | 0.000379     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 69800       |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 349000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | 2.73        |\n",
      "|    reward             | 0.020231253 |\n",
      "|    std                | 5.11e+05    |\n",
      "|    value_loss         | 0.00984     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 69900        |\n",
      "|    time_elapsed       | 1054         |\n",
      "|    total_timesteps    | 349500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69899        |\n",
      "|    policy_loss        | 1.36         |\n",
      "|    reward             | -0.012246653 |\n",
      "|    std                | 5.25e+05     |\n",
      "|    value_loss         | 0.0024       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70000        |\n",
      "|    time_elapsed       | 1056         |\n",
      "|    total_timesteps    | 350000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0.0439       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69999        |\n",
      "|    policy_loss        | 1.44         |\n",
      "|    reward             | -0.016357874 |\n",
      "|    std                | 5.33e+05     |\n",
      "|    value_loss         | 0.00351      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70100       |\n",
      "|    time_elapsed       | 1057        |\n",
      "|    total_timesteps    | 350500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | -0.0683     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70099       |\n",
      "|    policy_loss        | -4.1        |\n",
      "|    reward             | 0.013866118 |\n",
      "|    std                | 5.4e+05     |\n",
      "|    value_loss         | 0.0204      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70200       |\n",
      "|    time_elapsed       | 1059        |\n",
      "|    total_timesteps    | 351000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | 0.348       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70199       |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.015359768 |\n",
      "|    std                | 5.45e+05    |\n",
      "|    value_loss         | 0.00272     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70300        |\n",
      "|    time_elapsed       | 1061         |\n",
      "|    total_timesteps    | 351500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70299        |\n",
      "|    policy_loss        | -1.54        |\n",
      "|    reward             | -0.033796906 |\n",
      "|    std                | 5.56e+05     |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70400        |\n",
      "|    time_elapsed       | 1062         |\n",
      "|    total_timesteps    | 352000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70399        |\n",
      "|    policy_loss        | -1.03        |\n",
      "|    reward             | -0.010748297 |\n",
      "|    std                | 5.61e+05     |\n",
      "|    value_loss         | 0.00132      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70500       |\n",
      "|    time_elapsed       | 1064        |\n",
      "|    total_timesteps    | 352500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70499       |\n",
      "|    policy_loss        | 0.0678      |\n",
      "|    reward             | 0.008571903 |\n",
      "|    std                | 5.69e+05    |\n",
      "|    value_loss         | 1.99e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 70600         |\n",
      "|    time_elapsed       | 1065          |\n",
      "|    total_timesteps    | 353000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.4         |\n",
      "|    explained_variance | 0.000276      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70599         |\n",
      "|    policy_loss        | -0.456        |\n",
      "|    reward             | -0.0032257843 |\n",
      "|    std                | 5.86e+05      |\n",
      "|    value_loss         | 0.00031       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70700       |\n",
      "|    time_elapsed       | 1067        |\n",
      "|    total_timesteps    | 353500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 1.59e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70699       |\n",
      "|    policy_loss        | -0.189      |\n",
      "|    reward             | 0.042649593 |\n",
      "|    std                | 6.09e+05    |\n",
      "|    value_loss         | 4.91e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70800        |\n",
      "|    time_elapsed       | 1068         |\n",
      "|    total_timesteps    | 354000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70799        |\n",
      "|    policy_loss        | -0.241       |\n",
      "|    reward             | -0.012859696 |\n",
      "|    std                | 6.23e+05     |\n",
      "|    value_loss         | 0.000179     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -15380.14\n",
      "total_reward: -25380.14\n",
      "total_cost: 275.83\n",
      "total_trades: 5666\n",
      "Sharpe: 0.375\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 70900         |\n",
      "|    time_elapsed       | 1070          |\n",
      "|    total_timesteps    | 354500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70899         |\n",
      "|    policy_loss        | -0.359        |\n",
      "|    reward             | -0.0033932002 |\n",
      "|    std                | 6.34e+05      |\n",
      "|    value_loss         | 0.00133       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71000        |\n",
      "|    time_elapsed       | 1071         |\n",
      "|    total_timesteps    | 355000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70999        |\n",
      "|    policy_loss        | 0.771        |\n",
      "|    reward             | -0.011592924 |\n",
      "|    std                | 6.43e+05     |\n",
      "|    value_loss         | 0.000892     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 71100         |\n",
      "|    time_elapsed       | 1073          |\n",
      "|    total_timesteps    | 355500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71099         |\n",
      "|    policy_loss        | 0.566         |\n",
      "|    reward             | -0.0060525676 |\n",
      "|    std                | 6.52e+05      |\n",
      "|    value_loss         | 0.000554      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71200        |\n",
      "|    time_elapsed       | 1074         |\n",
      "|    total_timesteps    | 356000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71199        |\n",
      "|    policy_loss        | -0.0284      |\n",
      "|    reward             | -0.026225375 |\n",
      "|    std                | 6.71e+05     |\n",
      "|    value_loss         | 1.65e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71300        |\n",
      "|    time_elapsed       | 1076         |\n",
      "|    total_timesteps    | 356500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | -0.272       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71299        |\n",
      "|    policy_loss        | -0.106       |\n",
      "|    reward             | -0.009241693 |\n",
      "|    std                | 6.84e+05     |\n",
      "|    value_loss         | 8.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71400        |\n",
      "|    time_elapsed       | 1077         |\n",
      "|    total_timesteps    | 357000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 0.274        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71399        |\n",
      "|    policy_loss        | 1.77         |\n",
      "|    reward             | -0.047580793 |\n",
      "|    std                | 6.86e+05     |\n",
      "|    value_loss         | 0.00902      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 71500       |\n",
      "|    time_elapsed       | 1079        |\n",
      "|    total_timesteps    | 357500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71499       |\n",
      "|    policy_loss        | 1.66        |\n",
      "|    reward             | 0.005988967 |\n",
      "|    std                | 6.93e+05    |\n",
      "|    value_loss         | 0.00753     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 71600      |\n",
      "|    time_elapsed       | 1080       |\n",
      "|    total_timesteps    | 358000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71599      |\n",
      "|    policy_loss        | -0.732     |\n",
      "|    reward             | 0.06395968 |\n",
      "|    std                | 6.96e+05   |\n",
      "|    value_loss         | 0.00259    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 71700      |\n",
      "|    time_elapsed       | 1081       |\n",
      "|    total_timesteps    | 358500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71699      |\n",
      "|    policy_loss        | 7.02       |\n",
      "|    reward             | 0.10835907 |\n",
      "|    std                | 6.99e+05   |\n",
      "|    value_loss         | 0.0604     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71800        |\n",
      "|    time_elapsed       | 1083         |\n",
      "|    total_timesteps    | 359000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 0.258        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71799        |\n",
      "|    policy_loss        | -5.26        |\n",
      "|    reward             | -0.047687497 |\n",
      "|    std                | 7.03e+05     |\n",
      "|    value_loss         | 0.125        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 71900       |\n",
      "|    time_elapsed       | 1084        |\n",
      "|    total_timesteps    | 359500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.413       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71899       |\n",
      "|    policy_loss        | -0.567      |\n",
      "|    reward             | -0.43296412 |\n",
      "|    std                | 7.07e+05    |\n",
      "|    value_loss         | 0.0251      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 72000       |\n",
      "|    time_elapsed       | 1086        |\n",
      "|    total_timesteps    | 360000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71999       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | 0.017993223 |\n",
      "|    std                | 7.11e+05    |\n",
      "|    value_loss         | 0.0055      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 72100      |\n",
      "|    time_elapsed       | 1088       |\n",
      "|    total_timesteps    | 360500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72099      |\n",
      "|    policy_loss        | 1.23       |\n",
      "|    reward             | 0.06336801 |\n",
      "|    std                | 7.17e+05   |\n",
      "|    value_loss         | 0.00246    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72200        |\n",
      "|    time_elapsed       | 1089         |\n",
      "|    total_timesteps    | 361000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72199        |\n",
      "|    policy_loss        | 0.0571       |\n",
      "|    reward             | -0.027073625 |\n",
      "|    std                | 7.27e+05     |\n",
      "|    value_loss         | 0.00169      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 72300      |\n",
      "|    time_elapsed       | 1090       |\n",
      "|    total_timesteps    | 361500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.8      |\n",
      "|    explained_variance | 0.672      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72299      |\n",
      "|    policy_loss        | 2.2        |\n",
      "|    reward             | -0.1488439 |\n",
      "|    std                | 7.36e+05   |\n",
      "|    value_loss         | 0.00936    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 72400       |\n",
      "|    time_elapsed       | 1092        |\n",
      "|    total_timesteps    | 362000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0.52        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72399       |\n",
      "|    policy_loss        | 5.75        |\n",
      "|    reward             | -0.14742331 |\n",
      "|    std                | 7.48e+05    |\n",
      "|    value_loss         | 0.0523      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 72500       |\n",
      "|    time_elapsed       | 1093        |\n",
      "|    total_timesteps    | 362500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72499       |\n",
      "|    policy_loss        | 3.31        |\n",
      "|    reward             | -0.16993241 |\n",
      "|    std                | 7.48e+05    |\n",
      "|    value_loss         | 0.0453      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 72600       |\n",
      "|    time_elapsed       | 1094        |\n",
      "|    total_timesteps    | 363000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72599       |\n",
      "|    policy_loss        | 0.795       |\n",
      "|    reward             | 0.009056596 |\n",
      "|    std                | 7.47e+05    |\n",
      "|    value_loss         | 0.0037      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 1096         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | -0.195       |\n",
      "|    reward             | -0.003755249 |\n",
      "|    std                | 7.55e+05     |\n",
      "|    value_loss         | 0.000295     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72800        |\n",
      "|    time_elapsed       | 1098         |\n",
      "|    total_timesteps    | 364000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72799        |\n",
      "|    policy_loss        | 1.47         |\n",
      "|    reward             | -0.019481914 |\n",
      "|    std                | 7.66e+05     |\n",
      "|    value_loss         | 0.00318      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 72900         |\n",
      "|    time_elapsed       | 1099          |\n",
      "|    total_timesteps    | 364500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.9         |\n",
      "|    explained_variance | 0.506         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 72899         |\n",
      "|    policy_loss        | 0.217         |\n",
      "|    reward             | -0.0034539485 |\n",
      "|    std                | 7.8e+05       |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 73000      |\n",
      "|    time_elapsed       | 1101       |\n",
      "|    total_timesteps    | 365000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72999      |\n",
      "|    policy_loss        | 0.38       |\n",
      "|    reward             | 0.01788359 |\n",
      "|    std                | 8.04e+05   |\n",
      "|    value_loss         | 0.000626   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 73100      |\n",
      "|    time_elapsed       | 1102       |\n",
      "|    total_timesteps    | 365500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73099      |\n",
      "|    policy_loss        | 1.08       |\n",
      "|    reward             | 0.19920348 |\n",
      "|    std                | 8.14e+05   |\n",
      "|    value_loss         | 0.00896    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 73200     |\n",
      "|    time_elapsed       | 1104      |\n",
      "|    total_timesteps    | 366000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 73199     |\n",
      "|    policy_loss        | -0.524    |\n",
      "|    reward             | 0.1087998 |\n",
      "|    std                | 8.22e+05  |\n",
      "|    value_loss         | 0.00475   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 73300       |\n",
      "|    time_elapsed       | 1105        |\n",
      "|    total_timesteps    | 366500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73299       |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | -0.12805709 |\n",
      "|    std                | 8.24e+05    |\n",
      "|    value_loss         | 0.0028      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 73400         |\n",
      "|    time_elapsed       | 1107          |\n",
      "|    total_timesteps    | 367000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.1         |\n",
      "|    explained_variance | 0.419         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73399         |\n",
      "|    policy_loss        | -1.69         |\n",
      "|    reward             | -0.0004831989 |\n",
      "|    std                | 8.26e+05      |\n",
      "|    value_loss         | 0.00891       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 73500       |\n",
      "|    time_elapsed       | 1108        |\n",
      "|    total_timesteps    | 367500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0.0718      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73499       |\n",
      "|    policy_loss        | -16.5       |\n",
      "|    reward             | -0.16828933 |\n",
      "|    std                | 8.31e+05    |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 73600       |\n",
      "|    time_elapsed       | 1110        |\n",
      "|    total_timesteps    | 368000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 3.99e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73599       |\n",
      "|    policy_loss        | -5.46       |\n",
      "|    reward             | -0.18980996 |\n",
      "|    std                | 8.31e+05    |\n",
      "|    value_loss         | 0.0625      |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -253528.66\n",
      "total_reward: -263528.66\n",
      "total_cost: 107.82\n",
      "total_trades: 5666\n",
      "Sharpe: 0.268\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 73700       |\n",
      "|    time_elapsed       | 1111        |\n",
      "|    total_timesteps    | 368500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73699       |\n",
      "|    policy_loss        | 1.33        |\n",
      "|    reward             | 0.027529024 |\n",
      "|    std                | 8.42e+05    |\n",
      "|    value_loss         | 0.00305     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 73800        |\n",
      "|    time_elapsed       | 1113         |\n",
      "|    total_timesteps    | 369000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73799        |\n",
      "|    policy_loss        | 0.985        |\n",
      "|    reward             | -0.022267675 |\n",
      "|    std                | 8.5e+05      |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 73900     |\n",
      "|    time_elapsed       | 1114      |\n",
      "|    total_timesteps    | 369500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 73899     |\n",
      "|    policy_loss        | 0.457     |\n",
      "|    reward             | 0.0188392 |\n",
      "|    std                | 8.6e+05   |\n",
      "|    value_loss         | 0.00028   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74000        |\n",
      "|    time_elapsed       | 1116         |\n",
      "|    total_timesteps    | 370000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | -0.0326      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73999        |\n",
      "|    policy_loss        | 0.00212      |\n",
      "|    reward             | -0.010811228 |\n",
      "|    std                | 8.79e+05     |\n",
      "|    value_loss         | 0.000268     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74100        |\n",
      "|    time_elapsed       | 1117         |\n",
      "|    total_timesteps    | 370500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | 0.364        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74099        |\n",
      "|    policy_loss        | 0.402        |\n",
      "|    reward             | -0.006009074 |\n",
      "|    std                | 9.11e+05     |\n",
      "|    value_loss         | 0.000238     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74200        |\n",
      "|    time_elapsed       | 1118         |\n",
      "|    total_timesteps    | 371000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | -0.593       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74199        |\n",
      "|    policy_loss        | 0.352        |\n",
      "|    reward             | 0.0048815957 |\n",
      "|    std                | 9.25e+05     |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74300        |\n",
      "|    time_elapsed       | 1120         |\n",
      "|    total_timesteps    | 371500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74299        |\n",
      "|    policy_loss        | 6.6          |\n",
      "|    reward             | -0.040524814 |\n",
      "|    std                | 9.44e+05     |\n",
      "|    value_loss         | 0.0463       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74400        |\n",
      "|    time_elapsed       | 1121         |\n",
      "|    total_timesteps    | 372000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74399        |\n",
      "|    policy_loss        | -1.99        |\n",
      "|    reward             | -0.056482304 |\n",
      "|    std                | 9.6e+05      |\n",
      "|    value_loss         | 0.00465      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 74500       |\n",
      "|    time_elapsed       | 1123        |\n",
      "|    total_timesteps    | 372500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74499       |\n",
      "|    policy_loss        | 4.77        |\n",
      "|    reward             | -0.32075217 |\n",
      "|    std                | 9.79e+05    |\n",
      "|    value_loss         | 0.029       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 74600      |\n",
      "|    time_elapsed       | 1124       |\n",
      "|    total_timesteps    | 373000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74599      |\n",
      "|    policy_loss        | -7.2       |\n",
      "|    reward             | -0.1360112 |\n",
      "|    std                | 9.91e+05   |\n",
      "|    value_loss         | 0.066      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 74700      |\n",
      "|    time_elapsed       | 1126       |\n",
      "|    total_timesteps    | 373500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74699      |\n",
      "|    policy_loss        | 14.5       |\n",
      "|    reward             | 0.35442722 |\n",
      "|    std                | 9.79e+05   |\n",
      "|    value_loss         | 0.271      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 74800      |\n",
      "|    time_elapsed       | 1127       |\n",
      "|    total_timesteps    | 374000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74799      |\n",
      "|    policy_loss        | 22.7       |\n",
      "|    reward             | -1.3275725 |\n",
      "|    std                | 9.83e+05   |\n",
      "|    value_loss         | 0.603      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 74900       |\n",
      "|    time_elapsed       | 1129        |\n",
      "|    total_timesteps    | 374500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74899       |\n",
      "|    policy_loss        | 1.81        |\n",
      "|    reward             | 0.031877752 |\n",
      "|    std                | 9.86e+05    |\n",
      "|    value_loss         | 0.00506     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 75000         |\n",
      "|    time_elapsed       | 1131          |\n",
      "|    total_timesteps    | 375000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 74999         |\n",
      "|    policy_loss        | -0.125        |\n",
      "|    reward             | -0.0054611764 |\n",
      "|    std                | 1e+06         |\n",
      "|    value_loss         | 3.83e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 75100       |\n",
      "|    time_elapsed       | 1132        |\n",
      "|    total_timesteps    | 375500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | -0.605      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75099       |\n",
      "|    policy_loss        | 0.0873      |\n",
      "|    reward             | 0.026895342 |\n",
      "|    std                | 1.01e+06    |\n",
      "|    value_loss         | 0.000565    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 75200         |\n",
      "|    time_elapsed       | 1133          |\n",
      "|    total_timesteps    | 376000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.5         |\n",
      "|    explained_variance | -0.129        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75199         |\n",
      "|    policy_loss        | 0.602         |\n",
      "|    reward             | -0.0028921615 |\n",
      "|    std                | 1.02e+06      |\n",
      "|    value_loss         | 0.000487      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 75300        |\n",
      "|    time_elapsed       | 1135         |\n",
      "|    total_timesteps    | 376500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | -0.173       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75299        |\n",
      "|    policy_loss        | 1.9          |\n",
      "|    reward             | -0.017408632 |\n",
      "|    std                | 1.05e+06     |\n",
      "|    value_loss         | 0.00419      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 75400        |\n",
      "|    time_elapsed       | 1137         |\n",
      "|    total_timesteps    | 377000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75399        |\n",
      "|    policy_loss        | 2.65         |\n",
      "|    reward             | -0.016967934 |\n",
      "|    std                | 1.05e+06     |\n",
      "|    value_loss         | 0.00812      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 75500        |\n",
      "|    time_elapsed       | 1138         |\n",
      "|    total_timesteps    | 377500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75499        |\n",
      "|    policy_loss        | 4.22         |\n",
      "|    reward             | -0.026688438 |\n",
      "|    std                | 1.05e+06     |\n",
      "|    value_loss         | 0.0254       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 75600      |\n",
      "|    time_elapsed       | 1139       |\n",
      "|    total_timesteps    | 378000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75599      |\n",
      "|    policy_loss        | 1.84       |\n",
      "|    reward             | 0.03557277 |\n",
      "|    std                | 1.06e+06   |\n",
      "|    value_loss         | 0.00653    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 75700       |\n",
      "|    time_elapsed       | 1141        |\n",
      "|    total_timesteps    | 378500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | 0.628       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75699       |\n",
      "|    policy_loss        | 0.0674      |\n",
      "|    reward             | -0.19409235 |\n",
      "|    std                | 1.05e+06    |\n",
      "|    value_loss         | 0.0232      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 75800      |\n",
      "|    time_elapsed       | 1142       |\n",
      "|    total_timesteps    | 379000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75799      |\n",
      "|    policy_loss        | 11.2       |\n",
      "|    reward             | 0.13107234 |\n",
      "|    std                | 1.05e+06   |\n",
      "|    value_loss         | 0.163      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 75900       |\n",
      "|    time_elapsed       | 1144        |\n",
      "|    total_timesteps    | 379500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75899       |\n",
      "|    policy_loss        | -8.64       |\n",
      "|    reward             | -0.13710892 |\n",
      "|    std                | 1.05e+06    |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76000        |\n",
      "|    time_elapsed       | 1145         |\n",
      "|    total_timesteps    | 380000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75999        |\n",
      "|    policy_loss        | 1.51         |\n",
      "|    reward             | -0.042615633 |\n",
      "|    std                | 1.06e+06     |\n",
      "|    value_loss         | 0.00386      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 76100       |\n",
      "|    time_elapsed       | 1147        |\n",
      "|    total_timesteps    | 380500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76099       |\n",
      "|    policy_loss        | -0.596      |\n",
      "|    reward             | 0.029689834 |\n",
      "|    std                | 1.07e+06    |\n",
      "|    value_loss         | 0.000869    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76200        |\n",
      "|    time_elapsed       | 1148         |\n",
      "|    total_timesteps    | 381000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | -0.0156      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76199        |\n",
      "|    policy_loss        | -0.32        |\n",
      "|    reward             | -0.025011968 |\n",
      "|    std                | 1.09e+06     |\n",
      "|    value_loss         | 0.000295     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76300        |\n",
      "|    time_elapsed       | 1150         |\n",
      "|    total_timesteps    | 381500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | 0.0649       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76299        |\n",
      "|    policy_loss        | 1.39         |\n",
      "|    reward             | -0.018535601 |\n",
      "|    std                | 1.1e+06      |\n",
      "|    value_loss         | 0.00262      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76400        |\n",
      "|    time_elapsed       | 1151         |\n",
      "|    total_timesteps    | 382000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76399        |\n",
      "|    policy_loss        | 1.44         |\n",
      "|    reward             | -0.021880383 |\n",
      "|    std                | 1.11e+06     |\n",
      "|    value_loss         | 0.00403      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 76500    |\n",
      "|    time_elapsed       | 1153     |\n",
      "|    total_timesteps    | 382500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.7    |\n",
      "|    explained_variance | 0.328    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 76499    |\n",
      "|    policy_loss        | -0.361   |\n",
      "|    reward             | 0.427027 |\n",
      "|    std                | 1.13e+06 |\n",
      "|    value_loss         | 0.00798  |\n",
      "------------------------------------\n",
      "day: 2833, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -94833.99\n",
      "total_reward: -104833.99\n",
      "total_cost: 99.46\n",
      "total_trades: 5666\n",
      "Sharpe: 0.202\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 76600       |\n",
      "|    time_elapsed       | 1154        |\n",
      "|    total_timesteps    | 383000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76599       |\n",
      "|    policy_loss        | -0.663      |\n",
      "|    reward             | 0.009903786 |\n",
      "|    std                | 1.14e+06    |\n",
      "|    value_loss         | 0.000645    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 76700         |\n",
      "|    time_elapsed       | 1157          |\n",
      "|    total_timesteps    | 383500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 76699         |\n",
      "|    policy_loss        | 0.259         |\n",
      "|    reward             | -0.0024144792 |\n",
      "|    std                | 1.17e+06      |\n",
      "|    value_loss         | 0.000132      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 76800       |\n",
      "|    time_elapsed       | 1158        |\n",
      "|    total_timesteps    | 384000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76799       |\n",
      "|    policy_loss        | 0.263       |\n",
      "|    reward             | 0.008695855 |\n",
      "|    std                | 1.19e+06    |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76900        |\n",
      "|    time_elapsed       | 1160         |\n",
      "|    total_timesteps    | 384500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | -181         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76899        |\n",
      "|    policy_loss        | 0.212        |\n",
      "|    reward             | -0.006022942 |\n",
      "|    std                | 1.22e+06     |\n",
      "|    value_loss         | 0.000663     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 77000        |\n",
      "|    time_elapsed       | 1161         |\n",
      "|    total_timesteps    | 385000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | -2.26        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76999        |\n",
      "|    policy_loss        | -0.0743      |\n",
      "|    reward             | -0.006059897 |\n",
      "|    std                | 1.26e+06     |\n",
      "|    value_loss         | 6.42e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 77100        |\n",
      "|    time_elapsed       | 1163         |\n",
      "|    total_timesteps    | 385500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77099        |\n",
      "|    policy_loss        | -0.627       |\n",
      "|    reward             | 0.0066655846 |\n",
      "|    std                | 1.29e+06     |\n",
      "|    value_loss         | 0.000732     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 77200        |\n",
      "|    time_elapsed       | 1164         |\n",
      "|    total_timesteps    | 386000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77199        |\n",
      "|    policy_loss        | 1.84         |\n",
      "|    reward             | -0.031993438 |\n",
      "|    std                | 1.3e+06      |\n",
      "|    value_loss         | 0.00499      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 77300         |\n",
      "|    time_elapsed       | 1166          |\n",
      "|    total_timesteps    | 386500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31           |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77299         |\n",
      "|    policy_loss        | -0.695        |\n",
      "|    reward             | -0.0026526952 |\n",
      "|    std                | 1.31e+06      |\n",
      "|    value_loss         | 0.000635      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 77400       |\n",
      "|    time_elapsed       | 1167        |\n",
      "|    total_timesteps    | 387000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31         |\n",
      "|    explained_variance | -0.0173     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77399       |\n",
      "|    policy_loss        | 1.36        |\n",
      "|    reward             | -0.01138554 |\n",
      "|    std                | 1.35e+06    |\n",
      "|    value_loss         | 0.00407     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 77500         |\n",
      "|    time_elapsed       | 1169          |\n",
      "|    total_timesteps    | 387500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.1         |\n",
      "|    explained_variance | 1.55e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77499         |\n",
      "|    policy_loss        | 0.907         |\n",
      "|    reward             | -0.0020263703 |\n",
      "|    std                | 1.37e+06      |\n",
      "|    value_loss         | 0.00169       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 77600        |\n",
      "|    time_elapsed       | 1170         |\n",
      "|    total_timesteps    | 388000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77599        |\n",
      "|    policy_loss        | -2.03        |\n",
      "|    reward             | -0.018280072 |\n",
      "|    std                | 1.41e+06     |\n",
      "|    value_loss         | 0.00581      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 77700      |\n",
      "|    time_elapsed       | 1171       |\n",
      "|    total_timesteps    | 388500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77699      |\n",
      "|    policy_loss        | 2.54       |\n",
      "|    reward             | 0.01044679 |\n",
      "|    std                | 1.42e+06   |\n",
      "|    value_loss         | 0.00831    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 77800        |\n",
      "|    time_elapsed       | 1173         |\n",
      "|    total_timesteps    | 389000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77799        |\n",
      "|    policy_loss        | -1.16        |\n",
      "|    reward             | -0.022181178 |\n",
      "|    std                | 1.44e+06     |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 77900       |\n",
      "|    time_elapsed       | 1174        |\n",
      "|    total_timesteps    | 389500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.2       |\n",
      "|    explained_variance | -0.192      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77899       |\n",
      "|    policy_loss        | -1.54       |\n",
      "|    reward             | 0.028828423 |\n",
      "|    std                | 1.46e+06    |\n",
      "|    value_loss         | 0.00919     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 78000        |\n",
      "|    time_elapsed       | 1176         |\n",
      "|    total_timesteps    | 390000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.2        |\n",
      "|    explained_variance | 0.00057      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77999        |\n",
      "|    policy_loss        | 0.472        |\n",
      "|    reward             | -0.014592825 |\n",
      "|    std                | 1.48e+06     |\n",
      "|    value_loss         | 0.000506     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 78100        |\n",
      "|    time_elapsed       | 1177         |\n",
      "|    total_timesteps    | 390500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | -0.415       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78099        |\n",
      "|    policy_loss        | 0.442        |\n",
      "|    reward             | -0.036406226 |\n",
      "|    std                | 1.52e+06     |\n",
      "|    value_loss         | 0.000284     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 78200       |\n",
      "|    time_elapsed       | 1179        |\n",
      "|    total_timesteps    | 391000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78199       |\n",
      "|    policy_loss        | -3.93       |\n",
      "|    reward             | 0.055688832 |\n",
      "|    std                | 1.55e+06    |\n",
      "|    value_loss         | 0.0191      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 78300         |\n",
      "|    time_elapsed       | 1180          |\n",
      "|    total_timesteps    | 391500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 78299         |\n",
      "|    policy_loss        | -1.22         |\n",
      "|    reward             | -0.0016317418 |\n",
      "|    std                | 1.57e+06      |\n",
      "|    value_loss         | 0.00709       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 78400       |\n",
      "|    time_elapsed       | 1182        |\n",
      "|    total_timesteps    | 392000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78399       |\n",
      "|    policy_loss        | 0.58        |\n",
      "|    reward             | 0.111788146 |\n",
      "|    std                | 1.6e+06     |\n",
      "|    value_loss         | 0.000957    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 78500      |\n",
      "|    time_elapsed       | 1183       |\n",
      "|    total_timesteps    | 392500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.4      |\n",
      "|    explained_variance | -0.0203    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78499      |\n",
      "|    policy_loss        | 3.49       |\n",
      "|    reward             | 0.07607285 |\n",
      "|    std                | 1.61e+06   |\n",
      "|    value_loss         | 0.0363     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 78600       |\n",
      "|    time_elapsed       | 1185        |\n",
      "|    total_timesteps    | 393000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78599       |\n",
      "|    policy_loss        | 2.13        |\n",
      "|    reward             | -0.41121754 |\n",
      "|    std                | 1.63e+06    |\n",
      "|    value_loss         | 0.0151      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 78700       |\n",
      "|    time_elapsed       | 1186        |\n",
      "|    total_timesteps    | 393500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | -8.37       |\n",
      "|    reward             | -0.09662377 |\n",
      "|    std                | 1.63e+06    |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 78800        |\n",
      "|    time_elapsed       | 1188         |\n",
      "|    total_timesteps    | 394000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78799        |\n",
      "|    policy_loss        | 0.00459      |\n",
      "|    reward             | -0.019801274 |\n",
      "|    std                | 1.61e+06     |\n",
      "|    value_loss         | 0.000284     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 78900      |\n",
      "|    time_elapsed       | 1189       |\n",
      "|    total_timesteps    | 394500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78899      |\n",
      "|    policy_loss        | -0.958     |\n",
      "|    reward             | 0.01347734 |\n",
      "|    std                | 1.62e+06   |\n",
      "|    value_loss         | 0.00145    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 79000       |\n",
      "|    time_elapsed       | 1191        |\n",
      "|    total_timesteps    | 395000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78999       |\n",
      "|    policy_loss        | -1.08       |\n",
      "|    reward             | -0.01027158 |\n",
      "|    std                | 1.64e+06    |\n",
      "|    value_loss         | 0.00128     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 79100        |\n",
      "|    time_elapsed       | 1192         |\n",
      "|    total_timesteps    | 395500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79099        |\n",
      "|    policy_loss        | 2.14         |\n",
      "|    reward             | 0.0043691765 |\n",
      "|    std                | 1.66e+06     |\n",
      "|    value_loss         | 0.00455      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 1194        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | 1.36        |\n",
      "|    reward             | 0.035213392 |\n",
      "|    std                | 1.7e+06     |\n",
      "|    value_loss         | 0.00247     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 79300        |\n",
      "|    time_elapsed       | 1195         |\n",
      "|    total_timesteps    | 396500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 3.58e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79299        |\n",
      "|    policy_loss        | -0.423       |\n",
      "|    reward             | 0.0070276274 |\n",
      "|    std                | 1.73e+06     |\n",
      "|    value_loss         | 0.00664      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2833, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -47114.70\n",
      "total_reward: -57114.70\n",
      "total_cost: 95.42\n",
      "total_trades: 5666\n",
      "Sharpe: 0.546\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 79400        |\n",
      "|    time_elapsed       | 1197         |\n",
      "|    total_timesteps    | 397000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79399        |\n",
      "|    policy_loss        | -0.271       |\n",
      "|    reward             | 0.0066805105 |\n",
      "|    std                | 1.75e+06     |\n",
      "|    value_loss         | 0.000754     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 79500         |\n",
      "|    time_elapsed       | 1198          |\n",
      "|    total_timesteps    | 397500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79499         |\n",
      "|    policy_loss        | -0.639        |\n",
      "|    reward             | -0.0031200158 |\n",
      "|    std                | 1.77e+06      |\n",
      "|    value_loss         | 0.000504      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 79600       |\n",
      "|    time_elapsed       | 1200        |\n",
      "|    total_timesteps    | 398000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | -1.08       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79599       |\n",
      "|    policy_loss        | -3.33       |\n",
      "|    reward             | 0.023220912 |\n",
      "|    std                | 1.82e+06    |\n",
      "|    value_loss         | 0.015       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 79700        |\n",
      "|    time_elapsed       | 1201         |\n",
      "|    total_timesteps    | 398500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79699        |\n",
      "|    policy_loss        | -0.793       |\n",
      "|    reward             | -0.027777966 |\n",
      "|    std                | 1.85e+06     |\n",
      "|    value_loss         | 0.000743     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 79800       |\n",
      "|    time_elapsed       | 1203        |\n",
      "|    total_timesteps    | 399000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79799       |\n",
      "|    policy_loss        | -0.186      |\n",
      "|    reward             | 0.026564492 |\n",
      "|    std                | 1.88e+06    |\n",
      "|    value_loss         | 0.000266    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 79900       |\n",
      "|    time_elapsed       | 1204        |\n",
      "|    total_timesteps    | 399500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0.0609      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79899       |\n",
      "|    policy_loss        | -1.77       |\n",
      "|    reward             | -0.03059903 |\n",
      "|    std                | 1.94e+06    |\n",
      "|    value_loss         | 0.00321     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 80000        |\n",
      "|    time_elapsed       | 1206         |\n",
      "|    total_timesteps    | 400000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79999        |\n",
      "|    policy_loss        | 2.22         |\n",
      "|    reward             | -0.016856523 |\n",
      "|    std                | 1.97e+06     |\n",
      "|    value_loss         | 0.00531      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 80100         |\n",
      "|    time_elapsed       | 1207          |\n",
      "|    total_timesteps    | 400500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.8         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80099         |\n",
      "|    policy_loss        | 0.229         |\n",
      "|    reward             | 0.00026882172 |\n",
      "|    std                | 2.01e+06      |\n",
      "|    value_loss         | 0.000379      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 80200        |\n",
      "|    time_elapsed       | 1209         |\n",
      "|    total_timesteps    | 401000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | -0.192       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80199        |\n",
      "|    policy_loss        | -3.01        |\n",
      "|    reward             | -0.034343984 |\n",
      "|    std                | 2.02e+06     |\n",
      "|    value_loss         | 0.00966      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 80300       |\n",
      "|    time_elapsed       | 1211        |\n",
      "|    total_timesteps    | 401500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80299       |\n",
      "|    policy_loss        | 1.74        |\n",
      "|    reward             | 0.020470936 |\n",
      "|    std                | 2.04e+06    |\n",
      "|    value_loss         | 0.0046      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 80400       |\n",
      "|    time_elapsed       | 1212        |\n",
      "|    total_timesteps    | 402000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 0.213       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80399       |\n",
      "|    policy_loss        | -5.7        |\n",
      "|    reward             | 0.035179745 |\n",
      "|    std                | 2.07e+06    |\n",
      "|    value_loss         | 0.0353      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 80500       |\n",
      "|    time_elapsed       | 1213        |\n",
      "|    total_timesteps    | 402500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80499       |\n",
      "|    policy_loss        | -0.638      |\n",
      "|    reward             | -0.02957694 |\n",
      "|    std                | 2.08e+06    |\n",
      "|    value_loss         | 0.000733    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 80600      |\n",
      "|    time_elapsed       | 1215       |\n",
      "|    total_timesteps    | 403000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80599      |\n",
      "|    policy_loss        | -1.86      |\n",
      "|    reward             | 0.04641463 |\n",
      "|    std                | 2.12e+06   |\n",
      "|    value_loss         | 0.00366    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 80700       |\n",
      "|    time_elapsed       | 1216        |\n",
      "|    total_timesteps    | 403500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80699       |\n",
      "|    policy_loss        | 0.633       |\n",
      "|    reward             | 0.014386262 |\n",
      "|    std                | 2.17e+06    |\n",
      "|    value_loss         | 0.000548    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 80800       |\n",
      "|    time_elapsed       | 1218        |\n",
      "|    total_timesteps    | 404000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | -0.00178    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80799       |\n",
      "|    policy_loss        | 1.05        |\n",
      "|    reward             | -0.06335012 |\n",
      "|    std                | 2.22e+06    |\n",
      "|    value_loss         | 0.00128     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 80900      |\n",
      "|    time_elapsed       | 1219       |\n",
      "|    total_timesteps    | 404500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32        |\n",
      "|    explained_variance | 2.09e-06   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80899      |\n",
      "|    policy_loss        | 0.87       |\n",
      "|    reward             | 0.10005135 |\n",
      "|    std                | 2.28e+06   |\n",
      "|    value_loss         | 0.00221    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 81000      |\n",
      "|    time_elapsed       | 1221       |\n",
      "|    total_timesteps    | 405000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80999      |\n",
      "|    policy_loss        | 5.85       |\n",
      "|    reward             | 0.15296076 |\n",
      "|    std                | 2.35e+06   |\n",
      "|    value_loss         | 0.0535     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 81100        |\n",
      "|    time_elapsed       | 1222         |\n",
      "|    total_timesteps    | 405500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81099        |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | -0.014372956 |\n",
      "|    std                | 2.39e+06     |\n",
      "|    value_loss         | 0.00275      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 81200        |\n",
      "|    time_elapsed       | 1224         |\n",
      "|    total_timesteps    | 406000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81199        |\n",
      "|    policy_loss        | -0.253       |\n",
      "|    reward             | -0.007369875 |\n",
      "|    std                | 2.4e+06      |\n",
      "|    value_loss         | 0.000385     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 81300        |\n",
      "|    time_elapsed       | 1225         |\n",
      "|    total_timesteps    | 406500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | -0.00328     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81299        |\n",
      "|    policy_loss        | -0.058       |\n",
      "|    reward             | -0.012639547 |\n",
      "|    std                | 2.42e+06     |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 81400        |\n",
      "|    time_elapsed       | 1227         |\n",
      "|    total_timesteps    | 407000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81399        |\n",
      "|    policy_loss        | -1.36        |\n",
      "|    reward             | -0.031117536 |\n",
      "|    std                | 2.41e+06     |\n",
      "|    value_loss         | 0.00182      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 81500       |\n",
      "|    time_elapsed       | 1228        |\n",
      "|    total_timesteps    | 407500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81499       |\n",
      "|    policy_loss        | -1.84       |\n",
      "|    reward             | 0.046729114 |\n",
      "|    std                | 2.47e+06    |\n",
      "|    value_loss         | 0.00583     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 81600      |\n",
      "|    time_elapsed       | 1230       |\n",
      "|    total_timesteps    | 408000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81599      |\n",
      "|    policy_loss        | -0.919     |\n",
      "|    reward             | 0.06278094 |\n",
      "|    std                | 2.44e+06   |\n",
      "|    value_loss         | 0.00474    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 81700        |\n",
      "|    time_elapsed       | 1231         |\n",
      "|    total_timesteps    | 408500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81699        |\n",
      "|    policy_loss        | -2.02        |\n",
      "|    reward             | 0.0033722327 |\n",
      "|    std                | 2.45e+06     |\n",
      "|    value_loss         | 0.00515      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 81800       |\n",
      "|    time_elapsed       | 1233        |\n",
      "|    total_timesteps    | 409000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81799       |\n",
      "|    policy_loss        | 0.297       |\n",
      "|    reward             | 0.004214006 |\n",
      "|    std                | 2.49e+06    |\n",
      "|    value_loss         | 0.000231    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 81900        |\n",
      "|    time_elapsed       | 1234         |\n",
      "|    total_timesteps    | 409500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81899        |\n",
      "|    policy_loss        | -0.203       |\n",
      "|    reward             | -0.022289451 |\n",
      "|    std                | 2.52e+06     |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 82000        |\n",
      "|    time_elapsed       | 1236         |\n",
      "|    total_timesteps    | 410000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81999        |\n",
      "|    policy_loss        | 0.0792       |\n",
      "|    reward             | 0.0011929962 |\n",
      "|    std                | 2.59e+06     |\n",
      "|    value_loss         | 1.65e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 82100        |\n",
      "|    time_elapsed       | 1238         |\n",
      "|    total_timesteps    | 410500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | -1.08        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82099        |\n",
      "|    policy_loss        | -0.441       |\n",
      "|    reward             | 0.0046693473 |\n",
      "|    std                | 2.66e+06     |\n",
      "|    value_loss         | 0.00043      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13139.43\n",
      "total_reward: -23139.43\n",
      "total_cost: 437.95\n",
      "total_trades: 5666\n",
      "Sharpe: -0.328\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 82200        |\n",
      "|    time_elapsed       | 1239         |\n",
      "|    total_timesteps    | 411000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82199        |\n",
      "|    policy_loss        | 1.09         |\n",
      "|    reward             | -0.025670372 |\n",
      "|    std                | 2.72e+06     |\n",
      "|    value_loss         | 0.00151      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 82300        |\n",
      "|    time_elapsed       | 1240         |\n",
      "|    total_timesteps    | 411500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | -0.0247      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82299        |\n",
      "|    policy_loss        | 0.0915       |\n",
      "|    reward             | 0.0062166736 |\n",
      "|    std                | 2.79e+06     |\n",
      "|    value_loss         | 0.000529     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 82400         |\n",
      "|    time_elapsed       | 1242          |\n",
      "|    total_timesteps    | 412000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82399         |\n",
      "|    policy_loss        | 0.0783        |\n",
      "|    reward             | -0.0025701409 |\n",
      "|    std                | 2.82e+06      |\n",
      "|    value_loss         | 7.59e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 82500      |\n",
      "|    time_elapsed       | 1243       |\n",
      "|    total_timesteps    | 412500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.5      |\n",
      "|    explained_variance | 0.296      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 82499      |\n",
      "|    policy_loss        | -0.144     |\n",
      "|    reward             | 0.04333251 |\n",
      "|    std                | 2.9e+06    |\n",
      "|    value_loss         | 3.81e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 82600        |\n",
      "|    time_elapsed       | 1245         |\n",
      "|    total_timesteps    | 413000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.6        |\n",
      "|    explained_variance | -0.189       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82599        |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | 0.0050678854 |\n",
      "|    std                | 2.98e+06     |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 82700       |\n",
      "|    time_elapsed       | 1246        |\n",
      "|    total_timesteps    | 413500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | 0.0981      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | 0.262       |\n",
      "|    reward             | -0.01968007 |\n",
      "|    std                | 3.05e+06    |\n",
      "|    value_loss         | 0.000218    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 82800       |\n",
      "|    time_elapsed       | 1248        |\n",
      "|    total_timesteps    | 414000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82799       |\n",
      "|    policy_loss        | 0.713       |\n",
      "|    reward             | 0.021880519 |\n",
      "|    std                | 3.11e+06    |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 82900        |\n",
      "|    time_elapsed       | 1249         |\n",
      "|    total_timesteps    | 414500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82899        |\n",
      "|    policy_loss        | -0.0131      |\n",
      "|    reward             | -0.009660063 |\n",
      "|    std                | 3.17e+06     |\n",
      "|    value_loss         | 9.34e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 83000        |\n",
      "|    time_elapsed       | 1251         |\n",
      "|    total_timesteps    | 415000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82999        |\n",
      "|    policy_loss        | -0.329       |\n",
      "|    reward             | -0.008366063 |\n",
      "|    std                | 3.24e+06     |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 83100       |\n",
      "|    time_elapsed       | 1252        |\n",
      "|    total_timesteps    | 415500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83099       |\n",
      "|    policy_loss        | -0.074      |\n",
      "|    reward             | 0.004689188 |\n",
      "|    std                | 3.35e+06    |\n",
      "|    value_loss         | 1.36e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 83200         |\n",
      "|    time_elapsed       | 1253          |\n",
      "|    total_timesteps    | 416000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.9         |\n",
      "|    explained_variance | 0.279         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83199         |\n",
      "|    policy_loss        | -0.239        |\n",
      "|    reward             | -0.0067916242 |\n",
      "|    std                | 3.46e+06      |\n",
      "|    value_loss         | 6.8e-05       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 83300        |\n",
      "|    time_elapsed       | 1255         |\n",
      "|    total_timesteps    | 416500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83299        |\n",
      "|    policy_loss        | 0.0822       |\n",
      "|    reward             | -0.015795646 |\n",
      "|    std                | 3.59e+06     |\n",
      "|    value_loss         | 0.000241     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 83400       |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 417000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83399       |\n",
      "|    policy_loss        | 1.94        |\n",
      "|    reward             | 0.019287758 |\n",
      "|    std                | 3.73e+06    |\n",
      "|    value_loss         | 0.00643     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 83500       |\n",
      "|    time_elapsed       | 1258        |\n",
      "|    total_timesteps    | 417500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83499       |\n",
      "|    policy_loss        | 1.68        |\n",
      "|    reward             | 0.061399296 |\n",
      "|    std                | 3.79e+06    |\n",
      "|    value_loss         | 0.00577     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 83600     |\n",
      "|    time_elapsed       | 1259      |\n",
      "|    total_timesteps    | 418000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.1     |\n",
      "|    explained_variance | -0.00245  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 83599     |\n",
      "|    policy_loss        | -0.794    |\n",
      "|    reward             | 0.2564986 |\n",
      "|    std                | 3.83e+06  |\n",
      "|    value_loss         | 0.0163    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 83700        |\n",
      "|    time_elapsed       | 1261         |\n",
      "|    total_timesteps    | 418500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0.581        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83699        |\n",
      "|    policy_loss        | -0.475       |\n",
      "|    reward             | -0.017147535 |\n",
      "|    std                | 3.82e+06     |\n",
      "|    value_loss         | 0.00307      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 83800      |\n",
      "|    time_elapsed       | 1262       |\n",
      "|    total_timesteps    | 419000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83799      |\n",
      "|    policy_loss        | 3.4        |\n",
      "|    reward             | 0.09173302 |\n",
      "|    std                | 3.82e+06   |\n",
      "|    value_loss         | 0.055      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 83900       |\n",
      "|    time_elapsed       | 1264        |\n",
      "|    total_timesteps    | 419500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83899       |\n",
      "|    policy_loss        | 1.41        |\n",
      "|    reward             | -0.00165618 |\n",
      "|    std                | 3.84e+06    |\n",
      "|    value_loss         | 0.00249     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 84000       |\n",
      "|    time_elapsed       | 1265        |\n",
      "|    total_timesteps    | 420000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83999       |\n",
      "|    policy_loss        | 0.932       |\n",
      "|    reward             | 0.007585928 |\n",
      "|    std                | 3.88e+06    |\n",
      "|    value_loss         | 0.000844    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 84100        |\n",
      "|    time_elapsed       | 1267         |\n",
      "|    total_timesteps    | 420500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84099        |\n",
      "|    policy_loss        | 0.242        |\n",
      "|    reward             | -0.005692572 |\n",
      "|    std                | 3.94e+06     |\n",
      "|    value_loss         | 6.34e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 84200        |\n",
      "|    time_elapsed       | 1268         |\n",
      "|    total_timesteps    | 421000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84199        |\n",
      "|    policy_loss        | 0.257        |\n",
      "|    reward             | -0.012722354 |\n",
      "|    std                | 4.04e+06     |\n",
      "|    value_loss         | 0.000163     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 84300       |\n",
      "|    time_elapsed       | 1270        |\n",
      "|    total_timesteps    | 421500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84299       |\n",
      "|    policy_loss        | -0.29       |\n",
      "|    reward             | 0.008538121 |\n",
      "|    std                | 4.17e+06    |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 84400        |\n",
      "|    time_elapsed       | 1271         |\n",
      "|    total_timesteps    | 422000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.4        |\n",
      "|    explained_variance | -0.118       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84399        |\n",
      "|    policy_loss        | 0.123        |\n",
      "|    reward             | -0.008583344 |\n",
      "|    std                | 4.37e+06     |\n",
      "|    value_loss         | 5.95e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 84500      |\n",
      "|    time_elapsed       | 1273       |\n",
      "|    total_timesteps    | 422500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84499      |\n",
      "|    policy_loss        | -1.66      |\n",
      "|    reward             | 0.08490894 |\n",
      "|    std                | 4.54e+06   |\n",
      "|    value_loss         | 0.014      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 84600        |\n",
      "|    time_elapsed       | 1274         |\n",
      "|    total_timesteps    | 423000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84599        |\n",
      "|    policy_loss        | 4.33         |\n",
      "|    reward             | 0.0099046165 |\n",
      "|    std                | 4.57e+06     |\n",
      "|    value_loss         | 0.0199       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 84700      |\n",
      "|    time_elapsed       | 1276       |\n",
      "|    total_timesteps    | 423500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.5      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84699      |\n",
      "|    policy_loss        | -1.1       |\n",
      "|    reward             | -0.8432171 |\n",
      "|    std                | 4.66e+06   |\n",
      "|    value_loss         | 0.00285    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 84800       |\n",
      "|    time_elapsed       | 1277        |\n",
      "|    total_timesteps    | 424000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84799       |\n",
      "|    policy_loss        | 0.0466      |\n",
      "|    reward             | -0.10223438 |\n",
      "|    std                | 4.71e+06    |\n",
      "|    value_loss         | 0.00133     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 84900        |\n",
      "|    time_elapsed       | 1279         |\n",
      "|    total_timesteps    | 424500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84899        |\n",
      "|    policy_loss        | -3.87        |\n",
      "|    reward             | -0.033686362 |\n",
      "|    std                | 4.75e+06     |\n",
      "|    value_loss         | 0.0359       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 85000      |\n",
      "|    time_elapsed       | 1281       |\n",
      "|    total_timesteps    | 425000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.5      |\n",
      "|    explained_variance | 0.0708     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84999      |\n",
      "|    policy_loss        | -10.1      |\n",
      "|    reward             | 0.21919191 |\n",
      "|    std                | 4.77e+06   |\n",
      "|    value_loss         | 0.428      |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -262917.79\n",
      "total_reward: -272917.79\n",
      "total_cost: 104.65\n",
      "total_trades: 5666\n",
      "Sharpe: -0.312\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 85100      |\n",
      "|    time_elapsed       | 1282       |\n",
      "|    total_timesteps    | 425500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85099      |\n",
      "|    policy_loss        | -2.69      |\n",
      "|    reward             | 0.03883042 |\n",
      "|    std                | 4.79e+06   |\n",
      "|    value_loss         | 0.0104     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 85200       |\n",
      "|    time_elapsed       | 1284        |\n",
      "|    total_timesteps    | 426000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85199       |\n",
      "|    policy_loss        | -4.49       |\n",
      "|    reward             | 0.010272462 |\n",
      "|    std                | 4.8e+06     |\n",
      "|    value_loss         | 0.0194      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 85300      |\n",
      "|    time_elapsed       | 1285       |\n",
      "|    total_timesteps    | 426500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85299      |\n",
      "|    policy_loss        | -7.96      |\n",
      "|    reward             | -0.2233752 |\n",
      "|    std                | 4.8e+06    |\n",
      "|    value_loss         | 0.0607     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 85400      |\n",
      "|    time_elapsed       | 1287       |\n",
      "|    total_timesteps    | 427000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.6      |\n",
      "|    explained_variance | 0.0455     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85399      |\n",
      "|    policy_loss        | 2.78       |\n",
      "|    reward             | 0.19437908 |\n",
      "|    std                | 4.85e+06   |\n",
      "|    value_loss         | 0.0169     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 85500       |\n",
      "|    time_elapsed       | 1289        |\n",
      "|    total_timesteps    | 427500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.6       |\n",
      "|    explained_variance | 0.484       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85499       |\n",
      "|    policy_loss        | -0.947      |\n",
      "|    reward             | -0.03643159 |\n",
      "|    std                | 4.84e+06    |\n",
      "|    value_loss         | 0.0185      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 85600       |\n",
      "|    time_elapsed       | 1290        |\n",
      "|    total_timesteps    | 428000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85599       |\n",
      "|    policy_loss        | 5.8         |\n",
      "|    reward             | -0.07832353 |\n",
      "|    std                | 4.85e+06    |\n",
      "|    value_loss         | 0.0349      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 85700       |\n",
      "|    time_elapsed       | 1292        |\n",
      "|    total_timesteps    | 428500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85699       |\n",
      "|    policy_loss        | 1.72        |\n",
      "|    reward             | 0.038510427 |\n",
      "|    std                | 4.88e+06    |\n",
      "|    value_loss         | 0.00369     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 85800      |\n",
      "|    time_elapsed       | 1293       |\n",
      "|    total_timesteps    | 429000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85799      |\n",
      "|    policy_loss        | 0.395      |\n",
      "|    reward             | 0.00931089 |\n",
      "|    std                | 4.97e+06   |\n",
      "|    value_loss         | 0.000188   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 85900       |\n",
      "|    time_elapsed       | 1295        |\n",
      "|    total_timesteps    | 429500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.6       |\n",
      "|    explained_variance | -3.02e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85899       |\n",
      "|    policy_loss        | 2.01        |\n",
      "|    reward             | 0.003358897 |\n",
      "|    std                | 5.03e+06    |\n",
      "|    value_loss         | 0.00384     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 86000         |\n",
      "|    time_elapsed       | 1296          |\n",
      "|    total_timesteps    | 430000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.7         |\n",
      "|    explained_variance | -0.21         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85999         |\n",
      "|    policy_loss        | -0.989        |\n",
      "|    reward             | -0.0023288236 |\n",
      "|    std                | 5.17e+06      |\n",
      "|    value_loss         | 0.00215       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 86100      |\n",
      "|    time_elapsed       | 1298       |\n",
      "|    total_timesteps    | 430500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.7      |\n",
      "|    explained_variance | 0.00868    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86099      |\n",
      "|    policy_loss        | -3.24      |\n",
      "|    reward             | 0.18766944 |\n",
      "|    std                | 5.24e+06   |\n",
      "|    value_loss         | 0.0129     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 86200       |\n",
      "|    time_elapsed       | 1299        |\n",
      "|    total_timesteps    | 431000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86199       |\n",
      "|    policy_loss        | 1.53        |\n",
      "|    reward             | -0.04408708 |\n",
      "|    std                | 5.27e+06    |\n",
      "|    value_loss         | 0.00544     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 86300         |\n",
      "|    time_elapsed       | 1300          |\n",
      "|    total_timesteps    | 431500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86299         |\n",
      "|    policy_loss        | 1.1           |\n",
      "|    reward             | -0.0031253365 |\n",
      "|    std                | 5.3e+06       |\n",
      "|    value_loss         | 0.00123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 86400         |\n",
      "|    time_elapsed       | 1302          |\n",
      "|    total_timesteps    | 432000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86399         |\n",
      "|    policy_loss        | -0.571        |\n",
      "|    reward             | -0.0039505116 |\n",
      "|    std                | 5.43e+06      |\n",
      "|    value_loss         | 0.000395      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 86500        |\n",
      "|    time_elapsed       | 1303         |\n",
      "|    total_timesteps    | 432500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86499        |\n",
      "|    policy_loss        | -0.0387      |\n",
      "|    reward             | 0.0017948826 |\n",
      "|    std                | 5.59e+06     |\n",
      "|    value_loss         | 4.24e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 86600        |\n",
      "|    time_elapsed       | 1305         |\n",
      "|    total_timesteps    | 433000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.9        |\n",
      "|    explained_variance | 3.59e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86599        |\n",
      "|    policy_loss        | -0.116       |\n",
      "|    reward             | -0.003287378 |\n",
      "|    std                | 5.77e+06     |\n",
      "|    value_loss         | 1.66e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 86700        |\n",
      "|    time_elapsed       | 1306         |\n",
      "|    total_timesteps    | 433500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | 0.54         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86699        |\n",
      "|    policy_loss        | -0.324       |\n",
      "|    reward             | -0.011186702 |\n",
      "|    std                | 5.94e+06     |\n",
      "|    value_loss         | 0.000432     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 86800       |\n",
      "|    time_elapsed       | 1308        |\n",
      "|    total_timesteps    | 434000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86799       |\n",
      "|    policy_loss        | 3.56        |\n",
      "|    reward             | -0.05663471 |\n",
      "|    std                | 6.02e+06    |\n",
      "|    value_loss         | 0.0141      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 86900        |\n",
      "|    time_elapsed       | 1309         |\n",
      "|    total_timesteps    | 434500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86899        |\n",
      "|    policy_loss        | -2.58        |\n",
      "|    reward             | -0.009901932 |\n",
      "|    std                | 6.11e+06     |\n",
      "|    value_loss         | 0.00646      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 87000       |\n",
      "|    time_elapsed       | 1311        |\n",
      "|    total_timesteps    | 435000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34         |\n",
      "|    explained_variance | 5.23e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86999       |\n",
      "|    policy_loss        | 6.84        |\n",
      "|    reward             | -0.04228433 |\n",
      "|    std                | 6.13e+06    |\n",
      "|    value_loss         | 0.0426      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 87100       |\n",
      "|    time_elapsed       | 1312        |\n",
      "|    total_timesteps    | 435500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34         |\n",
      "|    explained_variance | 0.474       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87099       |\n",
      "|    policy_loss        | -3.83       |\n",
      "|    reward             | 0.041354485 |\n",
      "|    std                | 6.18e+06    |\n",
      "|    value_loss         | 0.0149      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1314        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34         |\n",
      "|    explained_variance | 0.0191      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | 2.19        |\n",
      "|    reward             | -0.06986681 |\n",
      "|    std                | 6.17e+06    |\n",
      "|    value_loss         | 0.0246      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87300        |\n",
      "|    time_elapsed       | 1315         |\n",
      "|    total_timesteps    | 436500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87299        |\n",
      "|    policy_loss        | 2.05         |\n",
      "|    reward             | 0.0039574914 |\n",
      "|    std                | 6.18e+06     |\n",
      "|    value_loss         | 0.00484      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87400        |\n",
      "|    time_elapsed       | 1317         |\n",
      "|    total_timesteps    | 437000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87399        |\n",
      "|    policy_loss        | -0.742       |\n",
      "|    reward             | -0.005101107 |\n",
      "|    std                | 6.25e+06     |\n",
      "|    value_loss         | 0.000551     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87500        |\n",
      "|    time_elapsed       | 1318         |\n",
      "|    total_timesteps    | 437500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87499        |\n",
      "|    policy_loss        | 0.0779       |\n",
      "|    reward             | 0.0047723604 |\n",
      "|    std                | 6.34e+06     |\n",
      "|    value_loss         | 3.01e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87600        |\n",
      "|    time_elapsed       | 1320         |\n",
      "|    total_timesteps    | 438000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87599        |\n",
      "|    policy_loss        | 0.472        |\n",
      "|    reward             | 0.0060008257 |\n",
      "|    std                | 6.46e+06     |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 87700         |\n",
      "|    time_elapsed       | 1321          |\n",
      "|    total_timesteps    | 438500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.2         |\n",
      "|    explained_variance | 0.502         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87699         |\n",
      "|    policy_loss        | -0.741        |\n",
      "|    reward             | -0.0018763565 |\n",
      "|    std                | 6.65e+06      |\n",
      "|    value_loss         | 0.000515      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 87800      |\n",
      "|    time_elapsed       | 1323       |\n",
      "|    total_timesteps    | 439000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.3      |\n",
      "|    explained_variance | 0.0164     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87799      |\n",
      "|    policy_loss        | -0.707     |\n",
      "|    reward             | 0.00573192 |\n",
      "|    std                | 6.89e+06   |\n",
      "|    value_loss         | 0.000497   |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -14482.57\n",
      "total_reward: -24482.57\n",
      "total_cost: 454.07\n",
      "total_trades: 5666\n",
      "Sharpe: 0.299\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 87900      |\n",
      "|    time_elapsed       | 1324       |\n",
      "|    total_timesteps    | 439500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.3      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87899      |\n",
      "|    policy_loss        | 2.82       |\n",
      "|    reward             | 0.08125515 |\n",
      "|    std                | 7.16e+06   |\n",
      "|    value_loss         | 0.00753    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88000       |\n",
      "|    time_elapsed       | 1326        |\n",
      "|    total_timesteps    | 440000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87999       |\n",
      "|    policy_loss        | 0.828       |\n",
      "|    reward             | 0.004059031 |\n",
      "|    std                | 7.21e+06    |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 88100        |\n",
      "|    time_elapsed       | 1327         |\n",
      "|    total_timesteps    | 440500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88099        |\n",
      "|    policy_loss        | -0.516       |\n",
      "|    reward             | -0.009377688 |\n",
      "|    std                | 7.36e+06     |\n",
      "|    value_loss         | 0.000266     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 88200        |\n",
      "|    time_elapsed       | 1329         |\n",
      "|    total_timesteps    | 441000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.4        |\n",
      "|    explained_variance | 0.0937       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88199        |\n",
      "|    policy_loss        | -0.136       |\n",
      "|    reward             | 0.0030793652 |\n",
      "|    std                | 7.56e+06     |\n",
      "|    value_loss         | 3.01e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 88300         |\n",
      "|    time_elapsed       | 1330          |\n",
      "|    total_timesteps    | 441500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88299         |\n",
      "|    policy_loss        | -0.255        |\n",
      "|    reward             | -0.0038820235 |\n",
      "|    std                | 7.9e+06       |\n",
      "|    value_loss         | 9.38e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 88400        |\n",
      "|    time_elapsed       | 1332         |\n",
      "|    total_timesteps    | 442000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.6        |\n",
      "|    explained_variance | 0.161        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88399        |\n",
      "|    policy_loss        | 1.22         |\n",
      "|    reward             | -0.019473335 |\n",
      "|    std                | 8.14e+06     |\n",
      "|    value_loss         | 0.00225      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88500       |\n",
      "|    time_elapsed       | 1333        |\n",
      "|    total_timesteps    | 442500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88499       |\n",
      "|    policy_loss        | -0.686      |\n",
      "|    reward             | 0.048667282 |\n",
      "|    std                | 8.31e+06    |\n",
      "|    value_loss         | 0.000542    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88600       |\n",
      "|    time_elapsed       | 1334        |\n",
      "|    total_timesteps    | 443000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88599       |\n",
      "|    policy_loss        | -0.0518     |\n",
      "|    reward             | 0.007668949 |\n",
      "|    std                | 8.44e+06    |\n",
      "|    value_loss         | 5.81e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 88700         |\n",
      "|    time_elapsed       | 1336          |\n",
      "|    total_timesteps    | 443500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88699         |\n",
      "|    policy_loss        | -0.0552       |\n",
      "|    reward             | 3.4784327e-05 |\n",
      "|    std                | 8.7e+06       |\n",
      "|    value_loss         | 4.74e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 88800         |\n",
      "|    time_elapsed       | 1337          |\n",
      "|    total_timesteps    | 444000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.8         |\n",
      "|    explained_variance | -5.83         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88799         |\n",
      "|    policy_loss        | -0.268        |\n",
      "|    reward             | -0.0058962745 |\n",
      "|    std                | 9e+06         |\n",
      "|    value_loss         | 6.32e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 88900      |\n",
      "|    time_elapsed       | 1339       |\n",
      "|    total_timesteps    | 444500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88899      |\n",
      "|    policy_loss        | 0.248      |\n",
      "|    reward             | 0.02174451 |\n",
      "|    std                | 9.51e+06   |\n",
      "|    value_loss         | 5.87e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89000        |\n",
      "|    time_elapsed       | 1340         |\n",
      "|    total_timesteps    | 445000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88999        |\n",
      "|    policy_loss        | 0.901        |\n",
      "|    reward             | 0.0055079185 |\n",
      "|    std                | 9.91e+06     |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89100        |\n",
      "|    time_elapsed       | 1342         |\n",
      "|    total_timesteps    | 445500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89099        |\n",
      "|    policy_loss        | -0.905       |\n",
      "|    reward             | -0.010807169 |\n",
      "|    std                | 1.01e+07     |\n",
      "|    value_loss         | 0.00081      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 89200         |\n",
      "|    time_elapsed       | 1343          |\n",
      "|    total_timesteps    | 446000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89199         |\n",
      "|    policy_loss        | 0.788         |\n",
      "|    reward             | -0.0126982955 |\n",
      "|    std                | 1.03e+07      |\n",
      "|    value_loss         | 0.000556      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89300        |\n",
      "|    time_elapsed       | 1345         |\n",
      "|    total_timesteps    | 446500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | 0.0133       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89299        |\n",
      "|    policy_loss        | -1.02        |\n",
      "|    reward             | 0.0005027458 |\n",
      "|    std                | 1.05e+07     |\n",
      "|    value_loss         | 0.00203      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89400       |\n",
      "|    time_elapsed       | 1346        |\n",
      "|    total_timesteps    | 447000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.1       |\n",
      "|    explained_variance | 0.000874    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89399       |\n",
      "|    policy_loss        | -2.5        |\n",
      "|    reward             | -0.03210744 |\n",
      "|    std                | 1.06e+07    |\n",
      "|    value_loss         | 0.00553     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89500       |\n",
      "|    time_elapsed       | 1348        |\n",
      "|    total_timesteps    | 447500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.1       |\n",
      "|    explained_variance | 0.0413      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89499       |\n",
      "|    policy_loss        | -4.82       |\n",
      "|    reward             | -0.07751257 |\n",
      "|    std                | 1.06e+07    |\n",
      "|    value_loss         | 0.0225      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89600        |\n",
      "|    time_elapsed       | 1349         |\n",
      "|    total_timesteps    | 448000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89599        |\n",
      "|    policy_loss        | 0.758        |\n",
      "|    reward             | -0.055135474 |\n",
      "|    std                | 1.06e+07     |\n",
      "|    value_loss         | 0.00269      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89700        |\n",
      "|    time_elapsed       | 1351         |\n",
      "|    total_timesteps    | 448500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89699        |\n",
      "|    policy_loss        | -0.81        |\n",
      "|    reward             | -0.029345168 |\n",
      "|    std                | 1.07e+07     |\n",
      "|    value_loss         | 0.000634     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89800       |\n",
      "|    time_elapsed       | 1352        |\n",
      "|    total_timesteps    | 449000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89799       |\n",
      "|    policy_loss        | -3.77       |\n",
      "|    reward             | 0.032315936 |\n",
      "|    std                | 1.08e+07    |\n",
      "|    value_loss         | 0.0166      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 89900         |\n",
      "|    time_elapsed       | 1354          |\n",
      "|    total_timesteps    | 449500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89899         |\n",
      "|    policy_loss        | -3.25         |\n",
      "|    reward             | -0.0066343355 |\n",
      "|    std                | 1.08e+07      |\n",
      "|    value_loss         | 0.0169        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 90000     |\n",
      "|    time_elapsed       | 1355      |\n",
      "|    total_timesteps    | 450000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -35.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 89999     |\n",
      "|    policy_loss        | -1.08     |\n",
      "|    reward             | 0.3317394 |\n",
      "|    std                | 1.08e+07  |\n",
      "|    value_loss         | 0.0118    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 90100       |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 450500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90099       |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | -0.52140254 |\n",
      "|    std                | 1.08e+07    |\n",
      "|    value_loss         | 0.0159      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 90200        |\n",
      "|    time_elapsed       | 1358         |\n",
      "|    total_timesteps    | 451000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90199        |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | -0.015618847 |\n",
      "|    std                | 1.08e+07     |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 1360        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | -0.1        |\n",
      "|    reward             | -0.01077954 |\n",
      "|    std                | 1.1e+07     |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 90400         |\n",
      "|    time_elapsed       | 1361          |\n",
      "|    total_timesteps    | 452000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 90399         |\n",
      "|    policy_loss        | -0.113        |\n",
      "|    reward             | -0.0050093974 |\n",
      "|    std                | 1.12e+07      |\n",
      "|    value_loss         | 5.57e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 90500         |\n",
      "|    time_elapsed       | 1363          |\n",
      "|    total_timesteps    | 452500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.3         |\n",
      "|    explained_variance | 0.176         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 90499         |\n",
      "|    policy_loss        | -0.155        |\n",
      "|    reward             | -0.0022344298 |\n",
      "|    std                | 1.16e+07      |\n",
      "|    value_loss         | 2.64e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 90600        |\n",
      "|    time_elapsed       | 1364         |\n",
      "|    total_timesteps    | 453000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.4        |\n",
      "|    explained_variance | 0.00142      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90599        |\n",
      "|    policy_loss        | 0.434        |\n",
      "|    reward             | -0.017030897 |\n",
      "|    std                | 1.2e+07      |\n",
      "|    value_loss         | 0.000267     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11547.23\n",
      "total_reward: -21547.23\n",
      "total_cost: 550.02\n",
      "total_trades: 5666\n",
      "Sharpe: 0.413\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 90700        |\n",
      "|    time_elapsed       | 1366         |\n",
      "|    total_timesteps    | 453500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90699        |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.015177989 |\n",
      "|    std                | 1.25e+07     |\n",
      "|    value_loss         | 0.00282      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 90800        |\n",
      "|    time_elapsed       | 1367         |\n",
      "|    total_timesteps    | 454000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90799        |\n",
      "|    policy_loss        | -0.495       |\n",
      "|    reward             | -0.019388877 |\n",
      "|    std                | 1.29e+07     |\n",
      "|    value_loss         | 0.000416     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 90900        |\n",
      "|    time_elapsed       | 1369         |\n",
      "|    total_timesteps    | 454500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90899        |\n",
      "|    policy_loss        | 0.269        |\n",
      "|    reward             | 0.0030865388 |\n",
      "|    std                | 1.3e+07      |\n",
      "|    value_loss         | 6.7e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 91000       |\n",
      "|    time_elapsed       | 1370        |\n",
      "|    total_timesteps    | 455000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.5       |\n",
      "|    explained_variance | 0.106       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90999       |\n",
      "|    policy_loss        | -2.98       |\n",
      "|    reward             | 0.015365718 |\n",
      "|    std                | 1.32e+07    |\n",
      "|    value_loss         | 0.00874     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 91100        |\n",
      "|    time_elapsed       | 1372         |\n",
      "|    total_timesteps    | 455500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | 0.624        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91099        |\n",
      "|    policy_loss        | -1.37        |\n",
      "|    reward             | -0.016231174 |\n",
      "|    std                | 1.34e+07     |\n",
      "|    value_loss         | 0.00209      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 91200       |\n",
      "|    time_elapsed       | 1373        |\n",
      "|    total_timesteps    | 456000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | 0.000251    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91199       |\n",
      "|    policy_loss        | -6.03       |\n",
      "|    reward             | -0.17232095 |\n",
      "|    std                | 1.36e+07    |\n",
      "|    value_loss         | 0.032       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 91300      |\n",
      "|    time_elapsed       | 1375       |\n",
      "|    total_timesteps    | 456500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91299      |\n",
      "|    policy_loss        | 1.66       |\n",
      "|    reward             | 0.07156638 |\n",
      "|    std                | 1.37e+07   |\n",
      "|    value_loss         | 0.00233    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 91400       |\n",
      "|    time_elapsed       | 1376        |\n",
      "|    total_timesteps    | 457000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91399       |\n",
      "|    policy_loss        | 0.265       |\n",
      "|    reward             | 0.014181915 |\n",
      "|    std                | 1.39e+07    |\n",
      "|    value_loss         | 6.28e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 91500         |\n",
      "|    time_elapsed       | 1378          |\n",
      "|    total_timesteps    | 457500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 91499         |\n",
      "|    policy_loss        | -0.213        |\n",
      "|    reward             | -0.0025926242 |\n",
      "|    std                | 1.42e+07      |\n",
      "|    value_loss         | 0.000129      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 91600        |\n",
      "|    time_elapsed       | 1379         |\n",
      "|    total_timesteps    | 458000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 7.75e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91599        |\n",
      "|    policy_loss        | -0.0331      |\n",
      "|    reward             | -0.003920551 |\n",
      "|    std                | 1.46e+07     |\n",
      "|    value_loss         | 3.11e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 91700        |\n",
      "|    time_elapsed       | 1380         |\n",
      "|    total_timesteps    | 458500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | 0.266        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91699        |\n",
      "|    policy_loss        | -0.413       |\n",
      "|    reward             | 0.0013112389 |\n",
      "|    std                | 1.5e+07      |\n",
      "|    value_loss         | 0.000187     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 91800       |\n",
      "|    time_elapsed       | 1382        |\n",
      "|    total_timesteps    | 459000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91799       |\n",
      "|    policy_loss        | 0.163       |\n",
      "|    reward             | 0.008723396 |\n",
      "|    std                | 1.56e+07    |\n",
      "|    value_loss         | 0.000108    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 91900      |\n",
      "|    time_elapsed       | 1383       |\n",
      "|    total_timesteps    | 459500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91899      |\n",
      "|    policy_loss        | -0.595     |\n",
      "|    reward             | 0.01798115 |\n",
      "|    std                | 1.58e+07   |\n",
      "|    value_loss         | 0.000474   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 92000        |\n",
      "|    time_elapsed       | 1385         |\n",
      "|    total_timesteps    | 460000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91999        |\n",
      "|    policy_loss        | 0.705        |\n",
      "|    reward             | -0.009840438 |\n",
      "|    std                | 1.63e+07     |\n",
      "|    value_loss         | 0.000436     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 92100         |\n",
      "|    time_elapsed       | 1386          |\n",
      "|    total_timesteps    | 460500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 92099         |\n",
      "|    policy_loss        | -0.55         |\n",
      "|    reward             | -0.0001539404 |\n",
      "|    std                | 1.68e+07      |\n",
      "|    value_loss         | 0.000353      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 92200         |\n",
      "|    time_elapsed       | 1388          |\n",
      "|    total_timesteps    | 461000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.1         |\n",
      "|    explained_variance | 0.0273        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 92199         |\n",
      "|    policy_loss        | 0.0122        |\n",
      "|    reward             | -0.0015540167 |\n",
      "|    std                | 1.75e+07      |\n",
      "|    value_loss         | 4.28e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 92300      |\n",
      "|    time_elapsed       | 1389       |\n",
      "|    total_timesteps    | 461500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.2      |\n",
      "|    explained_variance | -0.237     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92299      |\n",
      "|    policy_loss        | 0.657      |\n",
      "|    reward             | 0.01378592 |\n",
      "|    std                | 1.84e+07   |\n",
      "|    value_loss         | 0.000367   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 92400      |\n",
      "|    time_elapsed       | 1391       |\n",
      "|    total_timesteps    | 462000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92399      |\n",
      "|    policy_loss        | -1.13      |\n",
      "|    reward             | 0.03577507 |\n",
      "|    std                | 1.9e+07    |\n",
      "|    value_loss         | 0.00121    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 92500        |\n",
      "|    time_elapsed       | 1392         |\n",
      "|    total_timesteps    | 462500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92499        |\n",
      "|    policy_loss        | -0.525       |\n",
      "|    reward             | -0.009656464 |\n",
      "|    std                | 1.99e+07     |\n",
      "|    value_loss         | 0.000795     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 92600        |\n",
      "|    time_elapsed       | 1394         |\n",
      "|    total_timesteps    | 463000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92599        |\n",
      "|    policy_loss        | -0.162       |\n",
      "|    reward             | 0.0037600237 |\n",
      "|    std                | 2.06e+07     |\n",
      "|    value_loss         | 3.06e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 92700          |\n",
      "|    time_elapsed       | 1396           |\n",
      "|    total_timesteps    | 463500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -36.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 92699          |\n",
      "|    policy_loss        | 0.0875         |\n",
      "|    reward             | -0.00043912584 |\n",
      "|    std                | 2.13e+07       |\n",
      "|    value_loss         | 6.66e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 92800        |\n",
      "|    time_elapsed       | 1397         |\n",
      "|    total_timesteps    | 464000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.6        |\n",
      "|    explained_variance | 0.0224       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92799        |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | -0.001981603 |\n",
      "|    std                | 2.21e+07     |\n",
      "|    value_loss         | 4.41e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 92900        |\n",
      "|    time_elapsed       | 1398         |\n",
      "|    total_timesteps    | 464500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92899        |\n",
      "|    policy_loss        | -0.65        |\n",
      "|    reward             | -0.006375958 |\n",
      "|    std                | 2.34e+07     |\n",
      "|    value_loss         | 0.000416     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 93000        |\n",
      "|    time_elapsed       | 1400         |\n",
      "|    total_timesteps    | 465000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92999        |\n",
      "|    policy_loss        | -4.94        |\n",
      "|    reward             | -0.018187927 |\n",
      "|    std                | 2.39e+07     |\n",
      "|    value_loss         | 0.0204       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 93100       |\n",
      "|    time_elapsed       | 1401        |\n",
      "|    total_timesteps    | 465500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93099       |\n",
      "|    policy_loss        | 0.892       |\n",
      "|    reward             | 0.048812088 |\n",
      "|    std                | 2.44e+07    |\n",
      "|    value_loss         | 0.00181     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 93200       |\n",
      "|    time_elapsed       | 1403        |\n",
      "|    total_timesteps    | 466000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93199       |\n",
      "|    policy_loss        | -0.418      |\n",
      "|    reward             | -0.03853615 |\n",
      "|    std                | 2.47e+07    |\n",
      "|    value_loss         | 0.00674     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 93300        |\n",
      "|    time_elapsed       | 1404         |\n",
      "|    total_timesteps    | 466500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.8        |\n",
      "|    explained_variance | -0.00849     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93299        |\n",
      "|    policy_loss        | -4.88        |\n",
      "|    reward             | -0.015606772 |\n",
      "|    std                | 2.5e+07      |\n",
      "|    value_loss         | 0.0623       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 93400      |\n",
      "|    time_elapsed       | 1406       |\n",
      "|    total_timesteps    | 467000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.8      |\n",
      "|    explained_variance | 0.355      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93399      |\n",
      "|    policy_loss        | -12.4      |\n",
      "|    reward             | 0.06398108 |\n",
      "|    std                | 2.5e+07    |\n",
      "|    value_loss         | 0.123      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 93500     |\n",
      "|    time_elapsed       | 1407      |\n",
      "|    total_timesteps    | 467500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 93499     |\n",
      "|    policy_loss        | -16.2     |\n",
      "|    reward             | 0.9726439 |\n",
      "|    std                | 2.53e+07  |\n",
      "|    value_loss         | 0.232     |\n",
      "-------------------------------------\n",
      "day: 2833, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -243392.24\n",
      "total_reward: -253392.24\n",
      "total_cost: 101.34\n",
      "total_trades: 5666\n",
      "Sharpe: 0.418\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 93600       |\n",
      "|    time_elapsed       | 1409        |\n",
      "|    total_timesteps    | 468000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93599       |\n",
      "|    policy_loss        | -2.3        |\n",
      "|    reward             | 0.033932485 |\n",
      "|    std                | 2.56e+07    |\n",
      "|    value_loss         | 0.00485     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 93700        |\n",
      "|    time_elapsed       | 1410         |\n",
      "|    total_timesteps    | 468500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93699        |\n",
      "|    policy_loss        | 0.809        |\n",
      "|    reward             | -0.027994564 |\n",
      "|    std                | 2.59e+07     |\n",
      "|    value_loss         | 0.000521     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 93800       |\n",
      "|    time_elapsed       | 1412        |\n",
      "|    total_timesteps    | 469000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.9       |\n",
      "|    explained_variance | 0.222       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93799       |\n",
      "|    policy_loss        | 0.821       |\n",
      "|    reward             | 0.023146775 |\n",
      "|    std                | 2.64e+07    |\n",
      "|    value_loss         | 0.0019      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 93900       |\n",
      "|    time_elapsed       | 1413        |\n",
      "|    total_timesteps    | 469500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37         |\n",
      "|    explained_variance | -1.67e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93899       |\n",
      "|    policy_loss        | 3.59        |\n",
      "|    reward             | 0.011449593 |\n",
      "|    std                | 2.71e+07    |\n",
      "|    value_loss         | 0.0163      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 94000        |\n",
      "|    time_elapsed       | 1415         |\n",
      "|    total_timesteps    | 470000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93999        |\n",
      "|    policy_loss        | 0.853        |\n",
      "|    reward             | -0.034639306 |\n",
      "|    std                | 2.72e+07     |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 94100     |\n",
      "|    time_elapsed       | 1416      |\n",
      "|    total_timesteps    | 470500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -37       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 94099     |\n",
      "|    policy_loss        | -1.04     |\n",
      "|    reward             | 0.0400268 |\n",
      "|    std                | 2.72e+07  |\n",
      "|    value_loss         | 0.00102   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 94200       |\n",
      "|    time_elapsed       | 1418        |\n",
      "|    total_timesteps    | 471000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94199       |\n",
      "|    policy_loss        | -1.5        |\n",
      "|    reward             | 0.014926961 |\n",
      "|    std                | 2.77e+07    |\n",
      "|    value_loss         | 0.00358     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 94300        |\n",
      "|    time_elapsed       | 1419         |\n",
      "|    total_timesteps    | 471500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94299        |\n",
      "|    policy_loss        | -0.33        |\n",
      "|    reward             | 0.0028076805 |\n",
      "|    std                | 2.83e+07     |\n",
      "|    value_loss         | 9.27e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 94400        |\n",
      "|    time_elapsed       | 1421         |\n",
      "|    total_timesteps    | 472000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.1        |\n",
      "|    explained_variance | 0.399        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94399        |\n",
      "|    policy_loss        | 0.275        |\n",
      "|    reward             | -0.008116486 |\n",
      "|    std                | 2.92e+07     |\n",
      "|    value_loss         | 0.000139     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 94500        |\n",
      "|    time_elapsed       | 1422         |\n",
      "|    total_timesteps    | 472500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.2        |\n",
      "|    explained_variance | -0.132       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94499        |\n",
      "|    policy_loss        | 0.0808       |\n",
      "|    reward             | -0.030275172 |\n",
      "|    std                | 3.01e+07     |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 94600       |\n",
      "|    time_elapsed       | 1423        |\n",
      "|    total_timesteps    | 473000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.2       |\n",
      "|    explained_variance | 0.293       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | -1.83       |\n",
      "|    reward             | 0.017896598 |\n",
      "|    std                | 3.09e+07    |\n",
      "|    value_loss         | 0.0034      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 94700        |\n",
      "|    time_elapsed       | 1425         |\n",
      "|    total_timesteps    | 473500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.3        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94699        |\n",
      "|    policy_loss        | -1.4         |\n",
      "|    reward             | -0.018885326 |\n",
      "|    std                | 3.13e+07     |\n",
      "|    value_loss         | 0.00213      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 94800         |\n",
      "|    time_elapsed       | 1426          |\n",
      "|    total_timesteps    | 474000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.3         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 94799         |\n",
      "|    policy_loss        | -0.195        |\n",
      "|    reward             | -0.0014579834 |\n",
      "|    std                | 3.19e+07      |\n",
      "|    value_loss         | 8.82e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 94900       |\n",
      "|    time_elapsed       | 1428        |\n",
      "|    total_timesteps    | 474500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94899       |\n",
      "|    policy_loss        | 0.438       |\n",
      "|    reward             | 0.010533495 |\n",
      "|    std                | 3.25e+07    |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 95000        |\n",
      "|    time_elapsed       | 1429         |\n",
      "|    total_timesteps    | 475000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94999        |\n",
      "|    policy_loss        | -0.668       |\n",
      "|    reward             | 0.0015775135 |\n",
      "|    std                | 3.34e+07     |\n",
      "|    value_loss         | 0.00042      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 95100        |\n",
      "|    time_elapsed       | 1431         |\n",
      "|    total_timesteps    | 475500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.5        |\n",
      "|    explained_variance | -0.0865      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95099        |\n",
      "|    policy_loss        | -0.0494      |\n",
      "|    reward             | -0.013668544 |\n",
      "|    std                | 3.46e+07     |\n",
      "|    value_loss         | 4.37e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 95200        |\n",
      "|    time_elapsed       | 1432         |\n",
      "|    total_timesteps    | 476000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95199        |\n",
      "|    policy_loss        | 0.611        |\n",
      "|    reward             | 0.0034994248 |\n",
      "|    std                | 3.6e+07      |\n",
      "|    value_loss         | 0.000273     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 95300         |\n",
      "|    time_elapsed       | 1434          |\n",
      "|    total_timesteps    | 476500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95299         |\n",
      "|    policy_loss        | -1.72         |\n",
      "|    reward             | -0.0142607875 |\n",
      "|    std                | 3.57e+07      |\n",
      "|    value_loss         | 0.0066        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 95400       |\n",
      "|    time_elapsed       | 1435        |\n",
      "|    total_timesteps    | 477000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95399       |\n",
      "|    policy_loss        | -0.331      |\n",
      "|    reward             | -0.10616316 |\n",
      "|    std                | 3.6e+07     |\n",
      "|    value_loss         | 0.000807    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 95500      |\n",
      "|    time_elapsed       | 1437       |\n",
      "|    total_timesteps    | 477500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | 11.8       |\n",
      "|    reward             | 0.25017512 |\n",
      "|    std                | 3.68e+07   |\n",
      "|    value_loss         | 0.115      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 95600       |\n",
      "|    time_elapsed       | 1438        |\n",
      "|    total_timesteps    | 478000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95599       |\n",
      "|    policy_loss        | 18.1        |\n",
      "|    reward             | 0.021217033 |\n",
      "|    std                | 3.76e+07    |\n",
      "|    value_loss         | 0.297       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 95700      |\n",
      "|    time_elapsed       | 1440       |\n",
      "|    total_timesteps    | 478500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.6      |\n",
      "|    explained_variance | 2.98e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95699      |\n",
      "|    policy_loss        | 3          |\n",
      "|    reward             | -0.0728014 |\n",
      "|    std                | 3.75e+07   |\n",
      "|    value_loss         | 0.106      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 95800       |\n",
      "|    time_elapsed       | 1441        |\n",
      "|    total_timesteps    | 479000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95799       |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | 0.020784276 |\n",
      "|    std                | 3.74e+07    |\n",
      "|    value_loss         | 0.00102     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 95900       |\n",
      "|    time_elapsed       | 1442        |\n",
      "|    total_timesteps    | 479500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95899       |\n",
      "|    policy_loss        | 2.95        |\n",
      "|    reward             | -0.04180382 |\n",
      "|    std                | 3.76e+07    |\n",
      "|    value_loss         | 0.0153      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 96000        |\n",
      "|    time_elapsed       | 1444         |\n",
      "|    total_timesteps    | 480000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95999        |\n",
      "|    policy_loss        | -0.191       |\n",
      "|    reward             | 3.062172e-05 |\n",
      "|    std                | 3.78e+07     |\n",
      "|    value_loss         | 0.000219     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 96100      |\n",
      "|    time_elapsed       | 1446       |\n",
      "|    total_timesteps    | 480500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -37.6      |\n",
      "|    explained_variance | 0.737      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96099      |\n",
      "|    policy_loss        | -1.1       |\n",
      "|    reward             | -0.1872889 |\n",
      "|    std                | 3.77e+07   |\n",
      "|    value_loss         | 0.00275    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 96200        |\n",
      "|    time_elapsed       | 1447         |\n",
      "|    total_timesteps    | 481000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | 0.695        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96199        |\n",
      "|    policy_loss        | 1.64         |\n",
      "|    reward             | -0.000698806 |\n",
      "|    std                | 3.8e+07      |\n",
      "|    value_loss         | 0.00255      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 96300       |\n",
      "|    time_elapsed       | 1449        |\n",
      "|    total_timesteps    | 481500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.7       |\n",
      "|    explained_variance | 0.118       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96299       |\n",
      "|    policy_loss        | -6.48       |\n",
      "|    reward             | -0.16278586 |\n",
      "|    std                | 3.88e+07    |\n",
      "|    value_loss         | 0.0521      |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -152698.37\n",
      "total_reward: -162698.37\n",
      "total_cost: 109.76\n",
      "total_trades: 5666\n",
      "Sharpe: -0.641\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 96400         |\n",
      "|    time_elapsed       | 1450          |\n",
      "|    total_timesteps    | 482000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96399         |\n",
      "|    policy_loss        | -1.33         |\n",
      "|    reward             | -0.0095054805 |\n",
      "|    std                | 3.88e+07      |\n",
      "|    value_loss         | 0.00149       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 96500        |\n",
      "|    time_elapsed       | 1452         |\n",
      "|    total_timesteps    | 482500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96499        |\n",
      "|    policy_loss        | 0.422        |\n",
      "|    reward             | 0.0033090222 |\n",
      "|    std                | 3.93e+07     |\n",
      "|    value_loss         | 0.000166     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 96600        |\n",
      "|    time_elapsed       | 1453         |\n",
      "|    total_timesteps    | 483000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96599        |\n",
      "|    policy_loss        | 0.127        |\n",
      "|    reward             | -0.007426389 |\n",
      "|    std                | 4.01e+07     |\n",
      "|    value_loss         | 5.97e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 96700         |\n",
      "|    time_elapsed       | 1454          |\n",
      "|    total_timesteps    | 483500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96699         |\n",
      "|    policy_loss        | -0.598        |\n",
      "|    reward             | -0.0032829584 |\n",
      "|    std                | 4.14e+07      |\n",
      "|    value_loss         | 0.000285      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 96800       |\n",
      "|    time_elapsed       | 1456        |\n",
      "|    total_timesteps    | 484000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.9       |\n",
      "|    explained_variance | -39.6       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96799       |\n",
      "|    policy_loss        | 0.389       |\n",
      "|    reward             | 0.002422477 |\n",
      "|    std                | 4.23e+07    |\n",
      "|    value_loss         | 0.00115     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 96900         |\n",
      "|    time_elapsed       | 1458          |\n",
      "|    total_timesteps    | 484500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96899         |\n",
      "|    policy_loss        | -0.245        |\n",
      "|    reward             | -0.0016486847 |\n",
      "|    std                | 4.3e+07       |\n",
      "|    value_loss         | 0.000247      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 97000        |\n",
      "|    time_elapsed       | 1459         |\n",
      "|    total_timesteps    | 485000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96999        |\n",
      "|    policy_loss        | 2.5          |\n",
      "|    reward             | -0.013981286 |\n",
      "|    std                | 4.38e+07     |\n",
      "|    value_loss         | 0.0117       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 97100     |\n",
      "|    time_elapsed       | 1461      |\n",
      "|    total_timesteps    | 485500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -38       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 97099     |\n",
      "|    policy_loss        | -0.403    |\n",
      "|    reward             | 0.0323405 |\n",
      "|    std                | 4.42e+07  |\n",
      "|    value_loss         | 0.000135  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 97200        |\n",
      "|    time_elapsed       | 1462         |\n",
      "|    total_timesteps    | 486000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38          |\n",
      "|    explained_variance | 0.472        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97199        |\n",
      "|    policy_loss        | 0.409        |\n",
      "|    reward             | -0.023449803 |\n",
      "|    std                | 4.52e+07     |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 97300        |\n",
      "|    time_elapsed       | 1464         |\n",
      "|    total_timesteps    | 486500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | 0.352        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97299        |\n",
      "|    policy_loss        | 0.66         |\n",
      "|    reward             | -0.017400062 |\n",
      "|    std                | 4.62e+07     |\n",
      "|    value_loss         | 0.000357     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 97400      |\n",
      "|    time_elapsed       | 1465       |\n",
      "|    total_timesteps    | 487000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.1      |\n",
      "|    explained_variance | 0.000158   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97399      |\n",
      "|    policy_loss        | 0.821      |\n",
      "|    reward             | 0.05713677 |\n",
      "|    std                | 4.71e+07   |\n",
      "|    value_loss         | 0.00126    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 97500        |\n",
      "|    time_elapsed       | 1467         |\n",
      "|    total_timesteps    | 487500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97499        |\n",
      "|    policy_loss        | 2.29         |\n",
      "|    reward             | -0.024958381 |\n",
      "|    std                | 4.77e+07     |\n",
      "|    value_loss         | 0.00572      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 97600         |\n",
      "|    time_elapsed       | 1468          |\n",
      "|    total_timesteps    | 488000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97599         |\n",
      "|    policy_loss        | 2.77          |\n",
      "|    reward             | -0.0039732973 |\n",
      "|    std                | 4.83e+07      |\n",
      "|    value_loss         | 0.00539       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 97700         |\n",
      "|    time_elapsed       | 1470          |\n",
      "|    total_timesteps    | 488500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97699         |\n",
      "|    policy_loss        | -0.0364       |\n",
      "|    reward             | -0.0014334447 |\n",
      "|    std                | 4.93e+07      |\n",
      "|    value_loss         | 3.05e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 97800         |\n",
      "|    time_elapsed       | 1471          |\n",
      "|    total_timesteps    | 489000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97799         |\n",
      "|    policy_loss        | -0.574        |\n",
      "|    reward             | -0.0012248635 |\n",
      "|    std                | 5.09e+07      |\n",
      "|    value_loss         | 0.000254      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 97900         |\n",
      "|    time_elapsed       | 1473          |\n",
      "|    total_timesteps    | 489500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.3         |\n",
      "|    explained_variance | -0.119        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97899         |\n",
      "|    policy_loss        | 0.586         |\n",
      "|    reward             | -0.0025066137 |\n",
      "|    std                | 5.26e+07      |\n",
      "|    value_loss         | 0.00073       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 98000       |\n",
      "|    time_elapsed       | 1474        |\n",
      "|    total_timesteps    | 490000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.4       |\n",
      "|    explained_variance | -0.0723     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97999       |\n",
      "|    policy_loss        | -0.122      |\n",
      "|    reward             | 0.010215771 |\n",
      "|    std                | 5.53e+07    |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 98100        |\n",
      "|    time_elapsed       | 1475         |\n",
      "|    total_timesteps    | 490500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98099        |\n",
      "|    policy_loss        | 0.703        |\n",
      "|    reward             | -0.010972196 |\n",
      "|    std                | 5.72e+07     |\n",
      "|    value_loss         | 0.000813     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 98200        |\n",
      "|    time_elapsed       | 1477         |\n",
      "|    total_timesteps    | 491000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98199        |\n",
      "|    policy_loss        | -0.423       |\n",
      "|    reward             | 0.0073768096 |\n",
      "|    std                | 5.86e+07     |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 98300         |\n",
      "|    time_elapsed       | 1479          |\n",
      "|    total_timesteps    | 491500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 98299         |\n",
      "|    policy_loss        | 0.291         |\n",
      "|    reward             | -0.0119729685 |\n",
      "|    std                | 6.03e+07      |\n",
      "|    value_loss         | 8.83e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 98400        |\n",
      "|    time_elapsed       | 1480         |\n",
      "|    total_timesteps    | 492000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98399        |\n",
      "|    policy_loss        | -0.405       |\n",
      "|    reward             | -0.006133121 |\n",
      "|    std                | 6.24e+07     |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 98500        |\n",
      "|    time_elapsed       | 1482         |\n",
      "|    total_timesteps    | 492500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.8        |\n",
      "|    explained_variance | 0.533        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98499        |\n",
      "|    policy_loss        | 0.458        |\n",
      "|    reward             | -0.009872238 |\n",
      "|    std                | 6.52e+07     |\n",
      "|    value_loss         | 0.000157     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 98600       |\n",
      "|    time_elapsed       | 1483        |\n",
      "|    total_timesteps    | 493000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98599       |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | -0.02241569 |\n",
      "|    std                | 6.81e+07    |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 98700       |\n",
      "|    time_elapsed       | 1484        |\n",
      "|    total_timesteps    | 493500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98699       |\n",
      "|    policy_loss        | 3.35        |\n",
      "|    reward             | 0.092736796 |\n",
      "|    std                | 6.93e+07    |\n",
      "|    value_loss         | 0.00931     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 98800        |\n",
      "|    time_elapsed       | 1486         |\n",
      "|    total_timesteps    | 494000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98799        |\n",
      "|    policy_loss        | 0.0949       |\n",
      "|    reward             | -0.021686833 |\n",
      "|    std                | 7.01e+07     |\n",
      "|    value_loss         | 2.25e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 98900        |\n",
      "|    time_elapsed       | 1487         |\n",
      "|    total_timesteps    | 494500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98899        |\n",
      "|    policy_loss        | 0.879        |\n",
      "|    reward             | -0.026802188 |\n",
      "|    std                | 7.1e+07      |\n",
      "|    value_loss         | 0.00075      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 99000      |\n",
      "|    time_elapsed       | 1489       |\n",
      "|    total_timesteps    | 495000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39        |\n",
      "|    explained_variance | 0.916      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98999      |\n",
      "|    policy_loss        | 0.161      |\n",
      "|    reward             | 0.03231195 |\n",
      "|    std                | 7.27e+07   |\n",
      "|    value_loss         | 2.46e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 99100       |\n",
      "|    time_elapsed       | 1490        |\n",
      "|    total_timesteps    | 495500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99099       |\n",
      "|    policy_loss        | -0.855      |\n",
      "|    reward             | 0.013721447 |\n",
      "|    std                | 7.48e+07    |\n",
      "|    value_loss         | 0.00171     |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 175\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -47245.15\n",
      "total_reward: -57245.15\n",
      "total_cost: 71.93\n",
      "total_trades: 5666\n",
      "Sharpe: 0.218\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 99200       |\n",
      "|    time_elapsed       | 1491        |\n",
      "|    total_timesteps    | 496000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99199       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | 0.015575898 |\n",
      "|    std                | 7.56e+07    |\n",
      "|    value_loss         | 0.00244     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 99300       |\n",
      "|    time_elapsed       | 1493        |\n",
      "|    total_timesteps    | 496500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99299       |\n",
      "|    policy_loss        | -0.00616    |\n",
      "|    reward             | -0.07420561 |\n",
      "|    std                | 7.59e+07    |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 99400         |\n",
      "|    time_elapsed       | 1494          |\n",
      "|    total_timesteps    | 497000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.1         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99399         |\n",
      "|    policy_loss        | -0.857        |\n",
      "|    reward             | -0.0046552736 |\n",
      "|    std                | 7.7e+07       |\n",
      "|    value_loss         | 0.00123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 99500         |\n",
      "|    time_elapsed       | 1496          |\n",
      "|    total_timesteps    | 497500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.2         |\n",
      "|    explained_variance | 7.75e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99499         |\n",
      "|    policy_loss        | -2.23         |\n",
      "|    reward             | -0.0061725653 |\n",
      "|    std                | 7.84e+07      |\n",
      "|    value_loss         | 0.00351       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 99600       |\n",
      "|    time_elapsed       | 1497        |\n",
      "|    total_timesteps    | 498000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.2       |\n",
      "|    explained_variance | 0.15        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99599       |\n",
      "|    policy_loss        | 3.6         |\n",
      "|    reward             | -0.01790759 |\n",
      "|    std                | 8.04e+07    |\n",
      "|    value_loss         | 0.00969     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 99700       |\n",
      "|    time_elapsed       | 1499        |\n",
      "|    total_timesteps    | 498500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99699       |\n",
      "|    policy_loss        | 0.588       |\n",
      "|    reward             | 0.037075933 |\n",
      "|    std                | 8.17e+07    |\n",
      "|    value_loss         | 0.00443     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 99800       |\n",
      "|    time_elapsed       | 1500        |\n",
      "|    total_timesteps    | 499000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99799       |\n",
      "|    policy_loss        | -0.93       |\n",
      "|    reward             | -0.08689988 |\n",
      "|    std                | 8.36e+07    |\n",
      "|    value_loss         | 0.00236     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 99900        |\n",
      "|    time_elapsed       | 1501         |\n",
      "|    total_timesteps    | 499500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99899        |\n",
      "|    policy_loss        | -0.481       |\n",
      "|    reward             | -0.021912668 |\n",
      "|    std                | 8.49e+07     |\n",
      "|    value_loss         | 0.000344     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 100000    |\n",
      "|    time_elapsed       | 1503      |\n",
      "|    total_timesteps    | 500000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 99999     |\n",
      "|    policy_loss        | -4.92     |\n",
      "|    reward             | 0.1839552 |\n",
      "|    std                | 8.59e+07  |\n",
      "|    value_loss         | 0.0189    |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2021-07-06 to  2021-10-04\n",
      "A2C Sharpe Ratio:  -0.2099509943123526\n",
      "======Best Model Retraining from:  2010-04-01 to  2021-10-04\n",
      "======Trading from:  2021-10-04 to  2022-01-03\n",
      "[[ 1.3696495e+04  1.5139044e+02  4.5818878e+02 -1.8000000e+01\n",
      "  -6.0000000e+00 -3.0756192e+00 -1.5466502e-01  1.8381165e+02\n",
      "   4.9193372e+02  1.5252879e+02  4.6105875e+02  3.8965439e+01\n",
      "   4.6421928e+01 -2.4250763e+02 -1.6717520e+02  4.8588673e+01\n",
      "   2.3755117e+01  1.6987848e+02  4.7400714e+02  1.6155258e+02\n",
      "   4.6655853e+02]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "turbulence_threshold:  18.962641042223694\n",
      "======Model training from:  2010-04-01 to  2021-10-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_315_1\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.85        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0853      |\n",
      "|    reward             | -0.045984533 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.9        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.0425     |\n",
      "|    reward             | 0.042183142 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000675    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -0.249      |\n",
      "|    reward             | -0.13565633 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.031       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.9       |\n",
      "|    explained_variance | -0.488     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -0.274     |\n",
      "|    reward             | 0.06592125 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.0364     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.91     |\n",
      "|    explained_variance | 0.109     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 0.0291    |\n",
      "|    reward             | 1.0136185 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.107     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -2.95         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.0027       |\n",
      "|    reward             | 0.00015424214 |\n",
      "|    std                | 1.06          |\n",
      "|    value_loss         | 0.000195      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.98        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 0.0375       |\n",
      "|    reward             | -0.008791532 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.000103     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.03         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 0.0161        |\n",
      "|    reward             | -0.0014598273 |\n",
      "|    std                | 1.1           |\n",
      "|    value_loss         | 4.54e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.11         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.00306      |\n",
      "|    reward             | -0.0011318305 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 0.000123      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.19       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.0774      |\n",
      "|    reward             | 0.005422941 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.000721    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.23       |\n",
      "|    explained_variance | 0.636       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 1.63        |\n",
      "|    reward             | 0.017297933 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.27        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.0323       |\n",
      "|    reward             | 0.0019853802 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.32        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.0516      |\n",
      "|    reward             | -0.005721896 |\n",
      "|    std                | 1.28         |\n",
      "|    value_loss         | 0.000562     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.38       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -0.0831     |\n",
      "|    reward             | 0.019225085 |\n",
      "|    std                | 1.32        |\n",
      "|    value_loss         | 0.000815    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.46         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | 0.00104       |\n",
      "|    reward             | -0.0064093596 |\n",
      "|    std                | 1.37          |\n",
      "|    value_loss         | 4.8e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.51         |\n",
      "|    explained_variance | -3.75         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.409         |\n",
      "|    reward             | -0.0072141453 |\n",
      "|    std                | 1.4           |\n",
      "|    value_loss         | 0.0187        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.55         |\n",
      "|    explained_variance | -1.71         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | 0.0505        |\n",
      "|    reward             | -0.0004084134 |\n",
      "|    std                | 1.43          |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.61        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0484       |\n",
      "|    reward             | -0.035579905 |\n",
      "|    std                | 1.47         |\n",
      "|    value_loss         | 0.00034      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.65       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 0.0582      |\n",
      "|    reward             | 0.018424323 |\n",
      "|    std                | 1.51        |\n",
      "|    value_loss         | 0.000341    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.7          |\n",
      "|    explained_variance | -0.0104       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.106         |\n",
      "|    reward             | -0.0029282814 |\n",
      "|    std                | 1.55          |\n",
      "|    value_loss         | 0.00065       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.76        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 0.027        |\n",
      "|    reward             | 0.0018475213 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 4.66e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 2200          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 11000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.83         |\n",
      "|    explained_variance | -28.5         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 2199          |\n",
      "|    policy_loss        | -0.436        |\n",
      "|    reward             | -0.0020582336 |\n",
      "|    std                | 1.64          |\n",
      "|    value_loss         | 0.0139        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 34           |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.89        |\n",
      "|    explained_variance | 0.697        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | 0.0363       |\n",
      "|    reward             | -0.008214876 |\n",
      "|    std                | 1.69         |\n",
      "|    value_loss         | 0.000149     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.144       |\n",
      "|    reward             | 0.017708497 |\n",
      "|    std                | 1.71        |\n",
      "|    value_loss         | 0.00254     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.95        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -0.00273     |\n",
      "|    reward             | -0.001793212 |\n",
      "|    std                | 1.75         |\n",
      "|    value_loss         | 1.49e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.99       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | -0.074      |\n",
      "|    reward             | 0.010404187 |\n",
      "|    std                | 1.78        |\n",
      "|    value_loss         | 0.000302    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.06         |\n",
      "|    explained_variance | -9.77         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 2699          |\n",
      "|    policy_loss        | -0.0752       |\n",
      "|    reward             | -0.0011036245 |\n",
      "|    std                | 1.84          |\n",
      "|    value_loss         | 0.000797      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 42            |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.1          |\n",
      "|    explained_variance | -3.97         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | -0.00634      |\n",
      "|    reward             | -0.0030343984 |\n",
      "|    std                | 1.88          |\n",
      "|    value_loss         | 0.000169      |\n",
      "-----------------------------------------\n",
      "day: 2896, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -20745.20\n",
      "total_reward: -30745.20\n",
      "total_cost: 158.95\n",
      "total_trades: 5792\n",
      "Sharpe: 0.005\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 2900           |\n",
      "|    time_elapsed       | 43             |\n",
      "|    total_timesteps    | 14500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.13          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 2899           |\n",
      "|    policy_loss        | -0.213         |\n",
      "|    reward             | -0.00010871107 |\n",
      "|    std                | 1.91           |\n",
      "|    value_loss         | 0.00407        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 3000         |\n",
      "|    time_elapsed       | 45           |\n",
      "|    total_timesteps    | 15000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.2         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2999         |\n",
      "|    policy_loss        | 0.185        |\n",
      "|    reward             | -0.017423524 |\n",
      "|    std                | 1.98         |\n",
      "|    value_loss         | 0.00209      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 3100           |\n",
      "|    time_elapsed       | 46             |\n",
      "|    total_timesteps    | 15500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.25          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 3099           |\n",
      "|    policy_loss        | 0.13           |\n",
      "|    reward             | -0.00063901703 |\n",
      "|    std                | 2.02           |\n",
      "|    value_loss         | 0.00116        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 3200          |\n",
      "|    time_elapsed       | 48            |\n",
      "|    total_timesteps    | 16000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.31         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3199          |\n",
      "|    policy_loss        | -0.0412       |\n",
      "|    reward             | -0.0029938011 |\n",
      "|    std                | 2.09          |\n",
      "|    value_loss         | 0.000121      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 332            |\n",
      "|    iterations         | 3300           |\n",
      "|    time_elapsed       | 49             |\n",
      "|    total_timesteps    | 16500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.42          |\n",
      "|    explained_variance | -128           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 3299           |\n",
      "|    policy_loss        | 0.237          |\n",
      "|    reward             | -0.00064295135 |\n",
      "|    std                | 2.21           |\n",
      "|    value_loss         | 0.0153         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.46       |\n",
      "|    explained_variance | -13.6       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -0.0799     |\n",
      "|    reward             | -0.02262443 |\n",
      "|    std                | 2.24        |\n",
      "|    value_loss         | 0.00552     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.48        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 0.0905       |\n",
      "|    reward             | -0.015632242 |\n",
      "|    std                | 2.27         |\n",
      "|    value_loss         | 0.000649     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 54            |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.55         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | 0.046         |\n",
      "|    reward             | 0.00091551314 |\n",
      "|    std                | 2.35          |\n",
      "|    value_loss         | 0.000133      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 55           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.62        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.003863655 |\n",
      "|    std                | 2.43         |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.7         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.0142       |\n",
      "|    reward             | 0.0063307006 |\n",
      "|    std                | 2.54         |\n",
      "|    value_loss         | 3.85e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 58            |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.75         |\n",
      "|    explained_variance | -908          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | 0.128         |\n",
      "|    reward             | -0.0017178318 |\n",
      "|    std                | 2.6           |\n",
      "|    value_loss         | 0.0116        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 59            |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.82         |\n",
      "|    explained_variance | -0.211        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3999          |\n",
      "|    policy_loss        | 0.00961       |\n",
      "|    reward             | -0.0047592456 |\n",
      "|    std                | 2.69          |\n",
      "|    value_loss         | 3.49e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.86      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -0.887     |\n",
      "|    reward             | 0.06683986 |\n",
      "|    std                | 2.74       |\n",
      "|    value_loss         | 0.043      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 0.0362      |\n",
      "|    reward             | 0.015617684 |\n",
      "|    std                | 2.76        |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 0.721      |\n",
      "|    reward             | 0.05897871 |\n",
      "|    std                | 2.83       |\n",
      "|    value_loss         | 0.0246     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 65          |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.94       |\n",
      "|    explained_variance | -1.28       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | -2.68       |\n",
      "|    reward             | -0.15574586 |\n",
      "|    std                | 2.86        |\n",
      "|    value_loss         | 0.306       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.96       |\n",
      "|    explained_variance | 0.803       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | 0.0776      |\n",
      "|    reward             | 0.047850136 |\n",
      "|    std                | 2.89        |\n",
      "|    value_loss         | 0.00429     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.96       |\n",
      "|    explained_variance | -1.12       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -1.39       |\n",
      "|    reward             | 0.082787886 |\n",
      "|    std                | 2.89        |\n",
      "|    value_loss         | 0.0817      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -0.0701    |\n",
      "|    reward             | 0.02198609 |\n",
      "|    std                | 2.89       |\n",
      "|    value_loss         | 0.0004     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.97        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | -0.0582      |\n",
      "|    reward             | -0.006671572 |\n",
      "|    std                | 2.91         |\n",
      "|    value_loss         | 0.000209     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 336            |\n",
      "|    iterations         | 4900           |\n",
      "|    time_elapsed       | 72             |\n",
      "|    total_timesteps    | 24500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.02          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 4899           |\n",
      "|    policy_loss        | 0.148          |\n",
      "|    reward             | -0.00083424745 |\n",
      "|    std                | 2.97           |\n",
      "|    value_loss         | 0.000984       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.08      |\n",
      "|    explained_variance | -29.9      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 0.233      |\n",
      "|    reward             | 0.01128485 |\n",
      "|    std                | 3.07       |\n",
      "|    value_loss         | 0.00282    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 5100         |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 25500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.09        |\n",
      "|    explained_variance | 4.75e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5099         |\n",
      "|    policy_loss        | -0.0595      |\n",
      "|    reward             | -0.004162187 |\n",
      "|    std                | 3.09         |\n",
      "|    value_loss         | 0.000251     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.16        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.153       |\n",
      "|    reward             | -0.014234131 |\n",
      "|    std                | 3.2          |\n",
      "|    value_loss         | 0.00103      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.19       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | -0.334      |\n",
      "|    reward             | 0.047080588 |\n",
      "|    std                | 3.25        |\n",
      "|    value_loss         | 0.0057      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.25       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.0356     |\n",
      "|    reward             | -0.01961985 |\n",
      "|    std                | 3.34        |\n",
      "|    value_loss         | 7.24e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.31        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -0.0764      |\n",
      "|    reward             | 0.0013388481 |\n",
      "|    std                | 3.44         |\n",
      "|    value_loss         | 0.00037      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 5600         |\n",
      "|    time_elapsed       | 83           |\n",
      "|    total_timesteps    | 28000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.39        |\n",
      "|    explained_variance | -89.4        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5599         |\n",
      "|    policy_loss        | -0.0734      |\n",
      "|    reward             | -0.011463749 |\n",
      "|    std                | 3.59         |\n",
      "|    value_loss         | 0.000527     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.46       |\n",
      "|    explained_variance | -22.9       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.243      |\n",
      "|    reward             | 0.009727139 |\n",
      "|    std                | 3.71        |\n",
      "|    value_loss         | 0.00289     |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12936.67\n",
      "total_reward: -22936.67\n",
      "total_cost: 563.61\n",
      "total_trades: 5792\n",
      "Sharpe: 0.504\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.563       |\n",
      "|    reward             | 0.026500419 |\n",
      "|    std                | 3.76        |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.55        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -0.0478      |\n",
      "|    reward             | -0.008639675 |\n",
      "|    std                | 3.87         |\n",
      "|    value_loss         | 0.00269      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.58       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.622       |\n",
      "|    reward             | -0.10375054 |\n",
      "|    std                | 3.95        |\n",
      "|    value_loss         | 0.014       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.58      |\n",
      "|    explained_variance | -0.32      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | 0.742      |\n",
      "|    reward             | 0.05150543 |\n",
      "|    std                | 3.94       |\n",
      "|    value_loss         | 0.0176     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.59        |\n",
      "|    explained_variance | 0.77         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -0.427       |\n",
      "|    reward             | -0.006240083 |\n",
      "|    std                | 3.96         |\n",
      "|    value_loss         | 0.00945      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.62    |\n",
      "|    explained_variance | 0.22     |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -1.34    |\n",
      "|    reward             | 0.300146 |\n",
      "|    std                | 4.01     |\n",
      "|    value_loss         | 0.0608   |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 6400          |\n",
      "|    time_elapsed       | 95            |\n",
      "|    total_timesteps    | 32000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.62         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 6399          |\n",
      "|    policy_loss        | 0.0722        |\n",
      "|    reward             | -0.0019948615 |\n",
      "|    std                | 4.03          |\n",
      "|    value_loss         | 0.000234      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 6500          |\n",
      "|    time_elapsed       | 97            |\n",
      "|    total_timesteps    | 32500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.65         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 6499          |\n",
      "|    policy_loss        | 0.109         |\n",
      "|    reward             | -0.0027767573 |\n",
      "|    std                | 4.09          |\n",
      "|    value_loss         | 0.00041       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | 0.0126      |\n",
      "|    reward             | 0.011049884 |\n",
      "|    std                | 4.17        |\n",
      "|    value_loss         | 8.57e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 99            |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.76         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | -0.00528      |\n",
      "|    reward             | 5.4092947e-05 |\n",
      "|    std                | 4.31          |\n",
      "|    value_loss         | 3.79e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.83        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -0.1         |\n",
      "|    reward             | -0.011537282 |\n",
      "|    std                | 4.46         |\n",
      "|    value_loss         | 0.000475     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.88        |\n",
      "|    explained_variance | -5.67        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 0.156        |\n",
      "|    reward             | 0.0014685988 |\n",
      "|    std                | 4.59         |\n",
      "|    value_loss         | 0.00453      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.96       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | 0.111       |\n",
      "|    reward             | 0.018703712 |\n",
      "|    std                | 4.76        |\n",
      "|    value_loss         | 0.00156     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6          |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -0.00204    |\n",
      "|    reward             | -0.00954017 |\n",
      "|    std                | 4.86        |\n",
      "|    value_loss         | 8.83e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 107          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.05        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.052       |\n",
      "|    reward             | -0.008718103 |\n",
      "|    std                | 4.99         |\n",
      "|    value_loss         | 0.000111     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.11        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | -0.0159      |\n",
      "|    reward             | 0.0042837355 |\n",
      "|    std                | 5.15         |\n",
      "|    value_loss         | 1.7e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 110           |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.18         |\n",
      "|    explained_variance | -14.7         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | 0.107         |\n",
      "|    reward             | -0.0071404465 |\n",
      "|    std                | 5.34          |\n",
      "|    value_loss         | 0.000709      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 111           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.24         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 0.0156        |\n",
      "|    reward             | -0.0152174765 |\n",
      "|    std                | 5.48          |\n",
      "|    value_loss         | 0.000223      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.27     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 1.24      |\n",
      "|    reward             | 0.1581868 |\n",
      "|    std                | 5.58      |\n",
      "|    value_loss         | 0.0539    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.32        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.0116       |\n",
      "|    reward             | -0.045945257 |\n",
      "|    std                | 5.71         |\n",
      "|    value_loss         | 8.11e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.35       |\n",
      "|    explained_variance | -0.00491    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | 0.0884      |\n",
      "|    reward             | -0.02651568 |\n",
      "|    std                | 5.81        |\n",
      "|    value_loss         | 0.000243    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 7900          |\n",
      "|    time_elapsed       | 117           |\n",
      "|    total_timesteps    | 39500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.39         |\n",
      "|    explained_variance | -0.499        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7899          |\n",
      "|    policy_loss        | -0.228        |\n",
      "|    reward             | -0.0060298084 |\n",
      "|    std                | 5.93          |\n",
      "|    value_loss         | 0.00171       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 119        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.43      |\n",
      "|    explained_variance | 0.0427     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 0.442      |\n",
      "|    reward             | -0.0215752 |\n",
      "|    std                | 6.05       |\n",
      "|    value_loss         | 0.00594    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.45       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 0.107       |\n",
      "|    reward             | 0.009130635 |\n",
      "|    std                | 6.1         |\n",
      "|    value_loss         | 0.000581    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.45       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | -0.4        |\n",
      "|    reward             | 0.021607067 |\n",
      "|    std                | 6.08        |\n",
      "|    value_loss         | 0.00555     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 8300          |\n",
      "|    time_elapsed       | 123           |\n",
      "|    total_timesteps    | 41500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.47         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8299          |\n",
      "|    policy_loss        | -0.652        |\n",
      "|    reward             | -0.0023909176 |\n",
      "|    std                | 6.15          |\n",
      "|    value_loss         | 0.0508        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 125         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.47       |\n",
      "|    explained_variance | -4.24       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 1.66        |\n",
      "|    reward             | 0.023951586 |\n",
      "|    std                | 6.17        |\n",
      "|    value_loss         | 0.097       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.51       |\n",
      "|    explained_variance | 0.143       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    reward             | -0.26980823 |\n",
      "|    std                | 6.29        |\n",
      "|    value_loss         | 0.0719      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.49      |\n",
      "|    explained_variance | 0.0267     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 0.386      |\n",
      "|    reward             | -0.3687127 |\n",
      "|    std                | 6.22       |\n",
      "|    value_loss         | 0.0487     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -246919.66\n",
      "total_reward: -256919.66\n",
      "total_cost: 91.66\n",
      "total_trades: 5792\n",
      "Sharpe: 0.461\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.49        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | 0.031        |\n",
      "|    reward             | 0.0032284262 |\n",
      "|    std                | 6.22         |\n",
      "|    value_loss         | 0.00021      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.51       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -0.109      |\n",
      "|    reward             | 0.022579907 |\n",
      "|    std                | 6.29        |\n",
      "|    value_loss         | 0.000364    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 132          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.53        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 0.0948       |\n",
      "|    reward             | 0.0001490557 |\n",
      "|    std                | 6.36         |\n",
      "|    value_loss         | 0.000268     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.58        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | 0.0185       |\n",
      "|    reward             | -0.012033532 |\n",
      "|    std                | 6.5          |\n",
      "|    value_loss         | 3.14e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.65      |\n",
      "|    explained_variance | 0.625      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | -0.0629    |\n",
      "|    reward             | 0.00391131 |\n",
      "|    std                | 6.75       |\n",
      "|    value_loss         | 0.000115   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 137         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.71       |\n",
      "|    explained_variance | -6.2e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 0.12        |\n",
      "|    reward             | 0.016732004 |\n",
      "|    std                | 6.96        |\n",
      "|    value_loss         | 0.000636    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.79       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -0.0542     |\n",
      "|    reward             | 0.012939329 |\n",
      "|    std                | 7.23        |\n",
      "|    value_loss         | 7.76e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.84        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -0.141       |\n",
      "|    reward             | 0.0027130647 |\n",
      "|    std                | 7.42         |\n",
      "|    value_loss         | 0.000504     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.9        |\n",
      "|    explained_variance | -0.00288    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.195       |\n",
      "|    reward             | 0.012199163 |\n",
      "|    std                | 7.64        |\n",
      "|    value_loss         | 0.00214     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 142          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.97        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | -0.0455      |\n",
      "|    reward             | 0.0015780777 |\n",
      "|    std                | 7.91         |\n",
      "|    value_loss         | 6.03e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.07        |\n",
      "|    explained_variance | 0.33         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 0.0407       |\n",
      "|    reward             | 0.0130342785 |\n",
      "|    std                | 8.3          |\n",
      "|    value_loss         | 3.52e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.16        |\n",
      "|    explained_variance | 0.0617       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -0.107       |\n",
      "|    reward             | -0.012252974 |\n",
      "|    std                | 8.7          |\n",
      "|    value_loss         | 0.000368     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.22        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.148       |\n",
      "|    reward             | -0.013248114 |\n",
      "|    std                | 8.97         |\n",
      "|    value_loss         | 0.000731     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 336            |\n",
      "|    iterations         | 10000          |\n",
      "|    time_elapsed       | 148            |\n",
      "|    total_timesteps    | 50000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.28          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 9999           |\n",
      "|    policy_loss        | 0.0179         |\n",
      "|    reward             | -0.00078649656 |\n",
      "|    std                | 9.25           |\n",
      "|    value_loss         | 0.000104       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 10100        |\n",
      "|    time_elapsed       | 150          |\n",
      "|    total_timesteps    | 50500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.35        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10099        |\n",
      "|    policy_loss        | -0.122       |\n",
      "|    reward             | -0.003385028 |\n",
      "|    std                | 9.57         |\n",
      "|    value_loss         | 0.000296     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 10200      |\n",
      "|    time_elapsed       | 151        |\n",
      "|    total_timesteps    | 51000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.42      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10199      |\n",
      "|    policy_loss        | 0.00911    |\n",
      "|    reward             | 0.01214475 |\n",
      "|    std                | 9.93       |\n",
      "|    value_loss         | 9.87e-06   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 10300         |\n",
      "|    time_elapsed       | 153           |\n",
      "|    total_timesteps    | 51500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.51         |\n",
      "|    explained_variance | -31.6         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10299         |\n",
      "|    policy_loss        | -0.0469       |\n",
      "|    reward             | -0.0028634446 |\n",
      "|    std                | 10.4          |\n",
      "|    value_loss         | 0.0003        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.59      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | -0.173     |\n",
      "|    reward             | 0.03828946 |\n",
      "|    std                | 10.8       |\n",
      "|    value_loss         | 0.000856   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.65       |\n",
      "|    explained_variance | 3.58e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 0.694       |\n",
      "|    reward             | 0.015580004 |\n",
      "|    std                | 11.1        |\n",
      "|    value_loss         | 0.00942     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 10600         |\n",
      "|    time_elapsed       | 157           |\n",
      "|    total_timesteps    | 53000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.69         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10599         |\n",
      "|    policy_loss        | 0.0854        |\n",
      "|    reward             | -0.0072236843 |\n",
      "|    std                | 11.3          |\n",
      "|    value_loss         | 0.000151      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 10700       |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 53500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.75       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10699       |\n",
      "|    policy_loss        | 0.068       |\n",
      "|    reward             | 0.008744895 |\n",
      "|    std                | 11.7        |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 10800        |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 54000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.83        |\n",
      "|    explained_variance | 0.00218      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10799        |\n",
      "|    policy_loss        | 0.0327       |\n",
      "|    reward             | -0.008031324 |\n",
      "|    std                | 12.2         |\n",
      "|    value_loss         | 2.45e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 10900        |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 54500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.9         |\n",
      "|    explained_variance | -0.0125      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | 0.161        |\n",
      "|    reward             | -0.009827509 |\n",
      "|    std                | 12.6         |\n",
      "|    value_loss         | 0.000451     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 11000         |\n",
      "|    time_elapsed       | 163           |\n",
      "|    total_timesteps    | 55000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.95         |\n",
      "|    explained_variance | 4.53e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10999         |\n",
      "|    policy_loss        | 0.094         |\n",
      "|    reward             | -0.0065822173 |\n",
      "|    std                | 12.9          |\n",
      "|    value_loss         | 0.000203      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 11100       |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 55500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8          |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | -0.372      |\n",
      "|    reward             | -0.03201706 |\n",
      "|    std                | 13.3        |\n",
      "|    value_loss         | 0.00399     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 11200         |\n",
      "|    time_elapsed       | 166           |\n",
      "|    total_timesteps    | 56000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.01         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11199         |\n",
      "|    policy_loss        | 0.296         |\n",
      "|    reward             | 0.00093462586 |\n",
      "|    std                | 13.3          |\n",
      "|    value_loss         | 0.00188       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 11300        |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 56500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.01        |\n",
      "|    explained_variance | 0.041        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | 2.97         |\n",
      "|    reward             | -0.084093966 |\n",
      "|    std                | 13.3         |\n",
      "|    value_loss         | 0.175        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.01     |\n",
      "|    explained_variance | 0.00232   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -2.35     |\n",
      "|    reward             | 0.1382468 |\n",
      "|    std                | 13.3      |\n",
      "|    value_loss         | 0.0912    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 11500       |\n",
      "|    time_elapsed       | 171         |\n",
      "|    total_timesteps    | 57500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.06       |\n",
      "|    explained_variance | 2.54e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | 1.16        |\n",
      "|    reward             | 0.018495578 |\n",
      "|    std                | 13.6        |\n",
      "|    value_loss         | 0.0262      |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -254730.73\n",
      "total_reward: -264730.73\n",
      "total_cost: 107.34\n",
      "total_trades: 5792\n",
      "Sharpe: 0.009\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 11600        |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 58000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.05        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | -0.00694     |\n",
      "|    reward             | -0.013948458 |\n",
      "|    std                | 13.6         |\n",
      "|    value_loss         | 0.00098      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 11700        |\n",
      "|    time_elapsed       | 174          |\n",
      "|    total_timesteps    | 58500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.08        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11699        |\n",
      "|    policy_loss        | -0.0961      |\n",
      "|    reward             | -0.014902698 |\n",
      "|    std                | 13.8         |\n",
      "|    value_loss         | 0.000254     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 11800        |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 59000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.11        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | 0.0394       |\n",
      "|    reward             | 0.0011454357 |\n",
      "|    std                | 14           |\n",
      "|    value_loss         | 3.06e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 11900        |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 59500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.16        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | -0.236       |\n",
      "|    reward             | 0.0086923605 |\n",
      "|    std                | 14.4         |\n",
      "|    value_loss         | 0.000961     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 12000        |\n",
      "|    time_elapsed       | 178          |\n",
      "|    total_timesteps    | 60000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.18        |\n",
      "|    explained_variance | 0.573        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11999        |\n",
      "|    policy_loss        | -0.0662      |\n",
      "|    reward             | -0.006412904 |\n",
      "|    std                | 14.5         |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 180         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.21       |\n",
      "|    explained_variance | 0.0572      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -0.631      |\n",
      "|    reward             | -0.06661248 |\n",
      "|    std                | 14.7        |\n",
      "|    value_loss         | 0.00737     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 12200       |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 61000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.25       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | 0.00868     |\n",
      "|    reward             | -0.01140172 |\n",
      "|    std                | 15          |\n",
      "|    value_loss         | 0.000124    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 12300        |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 61500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.28        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | 0.092        |\n",
      "|    reward             | 0.0025415174 |\n",
      "|    std                | 15.3         |\n",
      "|    value_loss         | 0.000256     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 12400        |\n",
      "|    time_elapsed       | 184          |\n",
      "|    total_timesteps    | 62000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.34        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12399        |\n",
      "|    policy_loss        | -0.051       |\n",
      "|    reward             | -0.002151912 |\n",
      "|    std                | 15.7         |\n",
      "|    value_loss         | 0.000137     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 12500        |\n",
      "|    time_elapsed       | 186          |\n",
      "|    total_timesteps    | 62500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.4         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | 0.0871       |\n",
      "|    reward             | -0.019769281 |\n",
      "|    std                | 16.2         |\n",
      "|    value_loss         | 0.000233     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 12600         |\n",
      "|    time_elapsed       | 187           |\n",
      "|    total_timesteps    | 63000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.48         |\n",
      "|    explained_variance | 0.22          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12599         |\n",
      "|    policy_loss        | 0.0687        |\n",
      "|    reward             | -0.0073059737 |\n",
      "|    std                | 16.9          |\n",
      "|    value_loss         | 0.000191      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 12700      |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 63500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.54      |\n",
      "|    explained_variance | 0.00712    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12699      |\n",
      "|    policy_loss        | 0.102      |\n",
      "|    reward             | 0.03324774 |\n",
      "|    std                | 17.4       |\n",
      "|    value_loss         | 0.00018    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 12800        |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 64000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.61        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12799        |\n",
      "|    policy_loss        | 0.157        |\n",
      "|    reward             | -0.046038292 |\n",
      "|    std                | 18           |\n",
      "|    value_loss         | 0.000946     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 12900      |\n",
      "|    time_elapsed       | 191        |\n",
      "|    total_timesteps    | 64500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.63      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12899      |\n",
      "|    policy_loss        | -0.32      |\n",
      "|    reward             | 0.02528898 |\n",
      "|    std                | 18.2       |\n",
      "|    value_loss         | 0.00136    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 13000        |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 65000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.69        |\n",
      "|    explained_variance | -0.0153      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | 0.049        |\n",
      "|    reward             | 0.0035029538 |\n",
      "|    std                | 18.8         |\n",
      "|    value_loss         | 8.44e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 13100         |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 65500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.76         |\n",
      "|    explained_variance | 0.00895       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13099         |\n",
      "|    policy_loss        | 0.0309        |\n",
      "|    reward             | -0.0052750316 |\n",
      "|    std                | 19.4          |\n",
      "|    value_loss         | 1.6e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 13200        |\n",
      "|    time_elapsed       | 196          |\n",
      "|    total_timesteps    | 66000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.83        |\n",
      "|    explained_variance | -0.101       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | 0.231        |\n",
      "|    reward             | -0.010975453 |\n",
      "|    std                | 20.1         |\n",
      "|    value_loss         | 0.000984     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 13300       |\n",
      "|    time_elapsed       | 198         |\n",
      "|    total_timesteps    | 66500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.89       |\n",
      "|    explained_variance | -0.000919   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | -0.000891   |\n",
      "|    reward             | 0.026534246 |\n",
      "|    std                | 20.7        |\n",
      "|    value_loss         | 0.000417    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 13400      |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 67000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.92      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13399      |\n",
      "|    policy_loss        | 0.0838     |\n",
      "|    reward             | 0.03685588 |\n",
      "|    std                | 21         |\n",
      "|    value_loss         | 0.00537    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 13500       |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 67500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | 0.153       |\n",
      "|    reward             | 0.004327976 |\n",
      "|    std                | 21.2        |\n",
      "|    value_loss         | 0.000764    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 202         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.98       |\n",
      "|    explained_variance | 0.0071      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | 0.731       |\n",
      "|    reward             | 0.122344285 |\n",
      "|    std                | 21.5        |\n",
      "|    value_loss         | 0.2         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 13700      |\n",
      "|    time_elapsed       | 204        |\n",
      "|    total_timesteps    | 68500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9         |\n",
      "|    explained_variance | 0.32       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13699      |\n",
      "|    policy_loss        | 3.68       |\n",
      "|    reward             | -0.0341558 |\n",
      "|    std                | 21.8       |\n",
      "|    value_loss         | 0.19       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 13800       |\n",
      "|    time_elapsed       | 205         |\n",
      "|    total_timesteps    | 69000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.98       |\n",
      "|    explained_variance | 0.00986     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | -4.62       |\n",
      "|    reward             | -0.45005035 |\n",
      "|    std                | 21.7        |\n",
      "|    value_loss         | 0.438       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 13900       |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 69500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.01       |\n",
      "|    explained_variance | 0.246       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | 3.59        |\n",
      "|    reward             | 0.061815623 |\n",
      "|    std                | 22          |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | -0.0218     |\n",
      "|    reward             | 0.003602152 |\n",
      "|    std                | 22.1        |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 14100        |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 70500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.05        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | 0.051        |\n",
      "|    reward             | -0.015177075 |\n",
      "|    std                | 22.4         |\n",
      "|    value_loss         | 0.000164     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 14200      |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 71000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14199      |\n",
      "|    policy_loss        | -0.24      |\n",
      "|    reward             | 0.03165283 |\n",
      "|    std                | 22.9       |\n",
      "|    value_loss         | 0.000749   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 14300        |\n",
      "|    time_elapsed       | 212          |\n",
      "|    total_timesteps    | 71500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.14        |\n",
      "|    explained_variance | -25.2        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14299        |\n",
      "|    policy_loss        | -0.0367      |\n",
      "|    reward             | -0.011485466 |\n",
      "|    std                | 23.5         |\n",
      "|    value_loss         | 0.000231     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 14400        |\n",
      "|    time_elapsed       | 214          |\n",
      "|    total_timesteps    | 72000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.19        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | 0.0163       |\n",
      "|    reward             | -0.011840619 |\n",
      "|    std                | 24.1         |\n",
      "|    value_loss         | 1.27e-05     |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12619.07\n",
      "total_reward: -22619.07\n",
      "total_cost: 541.28\n",
      "total_trades: 5792\n",
      "Sharpe: -0.126\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 14500       |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 72500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.25       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14499       |\n",
      "|    policy_loss        | -0.532      |\n",
      "|    reward             | 0.017323365 |\n",
      "|    std                | 24.8        |\n",
      "|    value_loss         | 0.00501     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 14600       |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 73000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.29       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | -0.0599     |\n",
      "|    reward             | 0.030570455 |\n",
      "|    std                | 25.2        |\n",
      "|    value_loss         | 0.000878    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.3        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | -0.518      |\n",
      "|    reward             | 0.032003753 |\n",
      "|    std                | 25.5        |\n",
      "|    value_loss         | 0.00374     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 14800      |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 74000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.3       |\n",
      "|    explained_variance | 0.533      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14799      |\n",
      "|    policy_loss        | 2.54       |\n",
      "|    reward             | 0.07245332 |\n",
      "|    std                | 25.4       |\n",
      "|    value_loss         | 0.0747     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 14900       |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 74500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.35       |\n",
      "|    explained_variance | 0.344       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | 0.565       |\n",
      "|    reward             | 0.042335767 |\n",
      "|    std                | 26.1        |\n",
      "|    value_loss         | 0.00652     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 15000      |\n",
      "|    time_elapsed       | 223        |\n",
      "|    total_timesteps    | 75000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.38      |\n",
      "|    explained_variance | -9.56e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14999      |\n",
      "|    policy_loss        | -1.49      |\n",
      "|    reward             | 0.11866586 |\n",
      "|    std                | 26.4       |\n",
      "|    value_loss         | 0.0541     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 225         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.38       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | 1           |\n",
      "|    reward             | 0.012388535 |\n",
      "|    std                | 26.5        |\n",
      "|    value_loss         | 0.0134      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 15200         |\n",
      "|    time_elapsed       | 226           |\n",
      "|    total_timesteps    | 76000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.38         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15199         |\n",
      "|    policy_loss        | -0.0918       |\n",
      "|    reward             | -0.0140617555 |\n",
      "|    std                | 26.4          |\n",
      "|    value_loss         | 0.000496      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 15300       |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 76500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.4        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | -0.442      |\n",
      "|    reward             | -0.10815269 |\n",
      "|    std                | 26.8        |\n",
      "|    value_loss         | 0.00201     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 15400        |\n",
      "|    time_elapsed       | 229          |\n",
      "|    total_timesteps    | 77000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.44        |\n",
      "|    explained_variance | 0.728        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15399        |\n",
      "|    policy_loss        | -0.219       |\n",
      "|    reward             | -0.017456876 |\n",
      "|    std                | 27.3         |\n",
      "|    value_loss         | 0.000654     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 15500        |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 77500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.45        |\n",
      "|    explained_variance | 0.233        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | -0.26        |\n",
      "|    reward             | -0.004468543 |\n",
      "|    std                | 27.4         |\n",
      "|    value_loss         | 0.00789      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 15600       |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 78000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.46       |\n",
      "|    explained_variance | 1.2e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | 0.114       |\n",
      "|    reward             | 0.044430245 |\n",
      "|    std                | 27.6        |\n",
      "|    value_loss         | 0.00996     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 15700      |\n",
      "|    time_elapsed       | 234        |\n",
      "|    total_timesteps    | 78500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.49      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15699      |\n",
      "|    policy_loss        | 0.011      |\n",
      "|    reward             | 0.03316214 |\n",
      "|    std                | 28.1       |\n",
      "|    value_loss         | 0.000567   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 15800        |\n",
      "|    time_elapsed       | 235          |\n",
      "|    total_timesteps    | 79000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.51        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | 0.0558       |\n",
      "|    reward             | -0.011772838 |\n",
      "|    std                | 28.3         |\n",
      "|    value_loss         | 0.000294     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 15900       |\n",
      "|    time_elapsed       | 237         |\n",
      "|    total_timesteps    | 79500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.54       |\n",
      "|    explained_variance | 0.325       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | 0.383       |\n",
      "|    reward             | 0.038662456 |\n",
      "|    std                | 28.7        |\n",
      "|    value_loss         | 0.00247     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 16000       |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 80000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.59       |\n",
      "|    explained_variance | 0.405       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | -0.0761     |\n",
      "|    reward             | 0.021577597 |\n",
      "|    std                | 29.4        |\n",
      "|    value_loss         | 0.000228    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 16100       |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 80500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.64       |\n",
      "|    explained_variance | -0.00164    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16099       |\n",
      "|    policy_loss        | 0.124       |\n",
      "|    reward             | 0.010821381 |\n",
      "|    std                | 30.2        |\n",
      "|    value_loss         | 0.000672    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 16200      |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 81000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.66      |\n",
      "|    explained_variance | 2.02e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16199      |\n",
      "|    policy_loss        | 0.0427     |\n",
      "|    reward             | 0.05381466 |\n",
      "|    std                | 30.5       |\n",
      "|    value_loss         | 0.000352   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 16300       |\n",
      "|    time_elapsed       | 243         |\n",
      "|    total_timesteps    | 81500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.69       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | 0.209       |\n",
      "|    reward             | 0.021918308 |\n",
      "|    std                | 31          |\n",
      "|    value_loss         | 0.000524    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 16400        |\n",
      "|    time_elapsed       | 245          |\n",
      "|    total_timesteps    | 82000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.74        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16399        |\n",
      "|    policy_loss        | -0.000967    |\n",
      "|    reward             | -0.007240466 |\n",
      "|    std                | 31.8         |\n",
      "|    value_loss         | 1.27e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 16500        |\n",
      "|    time_elapsed       | 246          |\n",
      "|    total_timesteps    | 82500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.8         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16499        |\n",
      "|    policy_loss        | 0.124        |\n",
      "|    reward             | -0.017495992 |\n",
      "|    std                | 32.7         |\n",
      "|    value_loss         | 0.000275     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 16600       |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 83000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.89       |\n",
      "|    explained_variance | -49.9       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16599       |\n",
      "|    policy_loss        | 0.103       |\n",
      "|    reward             | 0.011230069 |\n",
      "|    std                | 34.2        |\n",
      "|    value_loss         | 0.000459    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 16700       |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 83500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.96       |\n",
      "|    explained_variance | -0.399      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | -0.0222     |\n",
      "|    reward             | 0.005277918 |\n",
      "|    std                | 35.5        |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 16800        |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 84000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10          |\n",
      "|    explained_variance | 0.355        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | 0.0352       |\n",
      "|    reward             | -0.014520034 |\n",
      "|    std                | 36.4         |\n",
      "|    value_loss         | 2.49e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 16900        |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 84500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | -0.106       |\n",
      "|    reward             | -0.014565072 |\n",
      "|    std                | 37.4         |\n",
      "|    value_loss         | 0.000182     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 17000       |\n",
      "|    time_elapsed       | 254         |\n",
      "|    total_timesteps    | 85000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | -0.207      |\n",
      "|    reward             | 0.001591308 |\n",
      "|    std                | 38.7        |\n",
      "|    value_loss         | 0.000454    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 333            |\n",
      "|    iterations         | 17100          |\n",
      "|    time_elapsed       | 256            |\n",
      "|    total_timesteps    | 85500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -10.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 17099          |\n",
      "|    policy_loss        | -0.176         |\n",
      "|    reward             | -0.00033084446 |\n",
      "|    std                | 39.9           |\n",
      "|    value_loss         | 0.000433       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 17200        |\n",
      "|    time_elapsed       | 257          |\n",
      "|    total_timesteps    | 86000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | -0.273       |\n",
      "|    reward             | 0.0014115568 |\n",
      "|    std                | 41.7         |\n",
      "|    value_loss         | 0.000911     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 17300         |\n",
      "|    time_elapsed       | 259           |\n",
      "|    total_timesteps    | 86500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17299         |\n",
      "|    policy_loss        | -0.0819       |\n",
      "|    reward             | -0.0072131217 |\n",
      "|    std                | 43.3          |\n",
      "|    value_loss         | 8.24e-05      |\n",
      "-----------------------------------------\n",
      "day: 2896, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11556.32\n",
      "total_reward: -21556.32\n",
      "total_cost: 499.90\n",
      "total_trades: 5792\n",
      "Sharpe: -0.466\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 17400       |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 87000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | 0.384       |\n",
      "|    reward             | 0.043471336 |\n",
      "|    std                | 44.4        |\n",
      "|    value_loss         | 0.00206     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 17500      |\n",
      "|    time_elapsed       | 262        |\n",
      "|    total_timesteps    | 87500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17499      |\n",
      "|    policy_loss        | 0.0988     |\n",
      "|    reward             | 0.01901538 |\n",
      "|    std                | 44.8       |\n",
      "|    value_loss         | 0.00345    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 17600       |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 88000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17599       |\n",
      "|    policy_loss        | 0.058       |\n",
      "|    reward             | 0.019105246 |\n",
      "|    std                | 45.3        |\n",
      "|    value_loss         | 0.000564    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.5        |\n",
      "|    explained_variance | -0.176       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | -0.0441      |\n",
      "|    reward             | -0.023552427 |\n",
      "|    std                | 46.4         |\n",
      "|    value_loss         | 7.17e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 17800        |\n",
      "|    time_elapsed       | 267          |\n",
      "|    total_timesteps    | 89000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.228        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17799        |\n",
      "|    policy_loss        | 0.934        |\n",
      "|    reward             | 0.0050525744 |\n",
      "|    std                | 47.7         |\n",
      "|    value_loss         | 0.00977      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 17900       |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 89500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | -0.215      |\n",
      "|    reward             | 0.008367693 |\n",
      "|    std                | 49.2        |\n",
      "|    value_loss         | 0.000558    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 18000        |\n",
      "|    time_elapsed       | 270          |\n",
      "|    total_timesteps    | 90000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | -0.0474      |\n",
      "|    reward             | 0.0010093971 |\n",
      "|    std                | 50.3         |\n",
      "|    value_loss         | 6.81e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 18100       |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 90500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | 0.0688      |\n",
      "|    reward             | -0.01931393 |\n",
      "|    std                | 51.2        |\n",
      "|    value_loss         | 6.11e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 18200         |\n",
      "|    time_elapsed       | 273           |\n",
      "|    total_timesteps    | 91000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18199         |\n",
      "|    policy_loss        | -0.162        |\n",
      "|    reward             | -0.0018081372 |\n",
      "|    std                | 52.6          |\n",
      "|    value_loss         | 0.000355      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 18300        |\n",
      "|    time_elapsed       | 275          |\n",
      "|    total_timesteps    | 91500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | -0.15        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | -0.009878866 |\n",
      "|    std                | 54.4         |\n",
      "|    value_loss         | 0.000632     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 18400       |\n",
      "|    time_elapsed       | 276         |\n",
      "|    total_timesteps    | 92000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0.0183      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 0.067       |\n",
      "|    reward             | 0.008484044 |\n",
      "|    std                | 56.9        |\n",
      "|    value_loss         | 0.000318    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 18500        |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 92500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18499        |\n",
      "|    policy_loss        | 0.0973       |\n",
      "|    reward             | -0.002715554 |\n",
      "|    std                | 58.6         |\n",
      "|    value_loss         | 0.000161     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 18600       |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 93000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | 0.0454      |\n",
      "|    reward             | 0.011265891 |\n",
      "|    std                | 60.1        |\n",
      "|    value_loss         | 0.00185     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 18700       |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 93500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18699       |\n",
      "|    policy_loss        | 0.124       |\n",
      "|    reward             | 0.005393047 |\n",
      "|    std                | 62          |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 18800       |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 94000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | -0.102      |\n",
      "|    reward             | -0.03037371 |\n",
      "|    std                | 63.6        |\n",
      "|    value_loss         | 0.000158    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | -0.027      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | -0.139      |\n",
      "|    reward             | 0.003549653 |\n",
      "|    std                | 66.2        |\n",
      "|    value_loss         | 0.000155    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 19000         |\n",
      "|    time_elapsed       | 286           |\n",
      "|    total_timesteps    | 95000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.3         |\n",
      "|    explained_variance | 0.22          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18999         |\n",
      "|    policy_loss        | 0.157         |\n",
      "|    reward             | 0.00051901425 |\n",
      "|    std                | 68.8          |\n",
      "|    value_loss         | 0.000287      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 19100         |\n",
      "|    time_elapsed       | 287           |\n",
      "|    total_timesteps    | 95500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19099         |\n",
      "|    policy_loss        | 0.522         |\n",
      "|    reward             | -0.0026686827 |\n",
      "|    std                | 69.8          |\n",
      "|    value_loss         | 0.00259       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 19200       |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 96000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19199       |\n",
      "|    policy_loss        | -0.273      |\n",
      "|    reward             | -0.01432245 |\n",
      "|    std                | 71.4        |\n",
      "|    value_loss         | 0.000663    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 19300         |\n",
      "|    time_elapsed       | 291           |\n",
      "|    total_timesteps    | 96500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19299         |\n",
      "|    policy_loss        | -0.241        |\n",
      "|    reward             | -0.0057834494 |\n",
      "|    std                | 73.5          |\n",
      "|    value_loss         | 0.000467      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 19400       |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 97000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | 0.0496      |\n",
      "|    reward             | 0.002960343 |\n",
      "|    std                | 76          |\n",
      "|    value_loss         | 4.36e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 19500        |\n",
      "|    time_elapsed       | 294          |\n",
      "|    total_timesteps    | 97500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 0.559        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19499        |\n",
      "|    policy_loss        | -0.0515      |\n",
      "|    reward             | 0.0019798493 |\n",
      "|    std                | 77.7         |\n",
      "|    value_loss         | 3.41e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 19600        |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 98000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19599        |\n",
      "|    policy_loss        | -0.124       |\n",
      "|    reward             | -0.014127552 |\n",
      "|    std                | 80           |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 19700       |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 98500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0.167       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19699       |\n",
      "|    policy_loss        | 0.709       |\n",
      "|    reward             | 0.007014961 |\n",
      "|    std                | 82.4        |\n",
      "|    value_loss         | 0.00462     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 19800       |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 99000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | 0.0495      |\n",
      "|    reward             | 0.024372997 |\n",
      "|    std                | 84.1        |\n",
      "|    value_loss         | 8.08e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -0.0702     |\n",
      "|    reward             | 0.006156905 |\n",
      "|    std                | 86.2        |\n",
      "|    value_loss         | 6.85e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 20000        |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 100000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19999        |\n",
      "|    policy_loss        | -0.142       |\n",
      "|    reward             | 0.0046620234 |\n",
      "|    std                | 88.4         |\n",
      "|    value_loss         | 0.000256     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 20100        |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 100500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | -0.434       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20099        |\n",
      "|    policy_loss        | -0.0875      |\n",
      "|    reward             | -0.009975304 |\n",
      "|    std                | 92.1         |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 20200      |\n",
      "|    time_elapsed       | 304        |\n",
      "|    total_timesteps    | 101000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12        |\n",
      "|    explained_variance | -0.713     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20199      |\n",
      "|    policy_loss        | -0.363     |\n",
      "|    reward             | 0.04033376 |\n",
      "|    std                | 96.4       |\n",
      "|    value_loss         | 0.00117    |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13248.68\n",
      "total_reward: -23248.68\n",
      "total_cost: 486.62\n",
      "total_trades: 5792\n",
      "Sharpe: 0.329\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 20300       |\n",
      "|    time_elapsed       | 306         |\n",
      "|    total_timesteps    | 101500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20299       |\n",
      "|    policy_loss        | 0.884       |\n",
      "|    reward             | 0.030238338 |\n",
      "|    std                | 101         |\n",
      "|    value_loss         | 0.00685     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 20400       |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 102000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20399       |\n",
      "|    policy_loss        | 1.46        |\n",
      "|    reward             | 0.011610537 |\n",
      "|    std                | 103         |\n",
      "|    value_loss         | 0.0153      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 20500        |\n",
      "|    time_elapsed       | 309          |\n",
      "|    total_timesteps    | 102500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20499        |\n",
      "|    policy_loss        | -0.369       |\n",
      "|    reward             | 0.0066338372 |\n",
      "|    std                | 104          |\n",
      "|    value_loss         | 0.000997     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 20600      |\n",
      "|    time_elapsed       | 310        |\n",
      "|    total_timesteps    | 103000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.1      |\n",
      "|    explained_variance | 0.00422    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20599      |\n",
      "|    policy_loss        | -0.211     |\n",
      "|    reward             | 0.01272704 |\n",
      "|    std                | 106        |\n",
      "|    value_loss         | 0.000374   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 20700       |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 103500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.000127    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20699       |\n",
      "|    policy_loss        | 0.00605     |\n",
      "|    reward             | 0.022468004 |\n",
      "|    std                | 109         |\n",
      "|    value_loss         | 0.000195    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 20800       |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 104000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20799       |\n",
      "|    policy_loss        | -0.0299     |\n",
      "|    reward             | 0.009908205 |\n",
      "|    std                | 111         |\n",
      "|    value_loss         | 0.000613    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 20900        |\n",
      "|    time_elapsed       | 315          |\n",
      "|    total_timesteps    | 104500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20899        |\n",
      "|    policy_loss        | 0.519        |\n",
      "|    reward             | -0.014436645 |\n",
      "|    std                | 112          |\n",
      "|    value_loss         | 0.00217      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 21000        |\n",
      "|    time_elapsed       | 316          |\n",
      "|    total_timesteps    | 105000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | -0.0686      |\n",
      "|    reward             | 0.0026911844 |\n",
      "|    std                | 113          |\n",
      "|    value_loss         | 8.19e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 21100         |\n",
      "|    time_elapsed       | 318           |\n",
      "|    total_timesteps    | 105500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21099         |\n",
      "|    policy_loss        | -0.0738       |\n",
      "|    reward             | -0.0005763962 |\n",
      "|    std                | 115           |\n",
      "|    value_loss         | 0.000211      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 21200       |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 106000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21199       |\n",
      "|    policy_loss        | 0.0898      |\n",
      "|    reward             | 0.006594687 |\n",
      "|    std                | 120         |\n",
      "|    value_loss         | 6.69e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 21300        |\n",
      "|    time_elapsed       | 321          |\n",
      "|    total_timesteps    | 106500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | 0.355        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21299        |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | -0.018850131 |\n",
      "|    std                | 124          |\n",
      "|    value_loss         | 0.000325     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -2.26e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | 0.0895       |\n",
      "|    reward             | 0.0144214425 |\n",
      "|    std                | 130          |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 21500       |\n",
      "|    time_elapsed       | 324         |\n",
      "|    total_timesteps    | 107500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21499       |\n",
      "|    policy_loss        | 0.746       |\n",
      "|    reward             | 0.018778129 |\n",
      "|    std                | 132         |\n",
      "|    value_loss         | 0.0037      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 21600        |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 108000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21599        |\n",
      "|    policy_loss        | -0.157       |\n",
      "|    reward             | -0.012433421 |\n",
      "|    std                | 135          |\n",
      "|    value_loss         | 0.000398     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 21700       |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 108500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | 0.0973      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21699       |\n",
      "|    policy_loss        | -0.0599     |\n",
      "|    reward             | 0.005367937 |\n",
      "|    std                | 138         |\n",
      "|    value_loss         | 0.000159    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 21800       |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 109000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | 0.0342      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21799       |\n",
      "|    policy_loss        | -0.434      |\n",
      "|    reward             | 0.004761045 |\n",
      "|    std                | 140         |\n",
      "|    value_loss         | 0.00152     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 21900       |\n",
      "|    time_elapsed       | 330         |\n",
      "|    total_timesteps    | 109500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | -0.0991     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21899       |\n",
      "|    policy_loss        | 0.277       |\n",
      "|    reward             | -0.01216815 |\n",
      "|    std                | 142         |\n",
      "|    value_loss         | 0.000555    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 22000        |\n",
      "|    time_elapsed       | 331          |\n",
      "|    total_timesteps    | 110000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21999        |\n",
      "|    policy_loss        | -0.661       |\n",
      "|    reward             | -0.017421108 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 0.00504      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 22100       |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 110500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22099       |\n",
      "|    policy_loss        | -0.266      |\n",
      "|    reward             | 0.110503994 |\n",
      "|    std                | 146         |\n",
      "|    value_loss         | 0.00486     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 22200       |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 111000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22199       |\n",
      "|    policy_loss        | 0.483       |\n",
      "|    reward             | -0.13656431 |\n",
      "|    std                | 149         |\n",
      "|    value_loss         | 0.00312     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 22300         |\n",
      "|    time_elapsed       | 335           |\n",
      "|    total_timesteps    | 111500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.8         |\n",
      "|    explained_variance | 0.00214       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22299         |\n",
      "|    policy_loss        | -0.0346       |\n",
      "|    reward             | -0.0013088167 |\n",
      "|    std                | 149           |\n",
      "|    value_loss         | 0.0126        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 22400       |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 112000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0.00167     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22399       |\n",
      "|    policy_loss        | -7.08       |\n",
      "|    reward             | -0.18084331 |\n",
      "|    std                | 151         |\n",
      "|    value_loss         | 0.359       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 22500       |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 112500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22499       |\n",
      "|    policy_loss        | -2.17       |\n",
      "|    reward             | -0.20073271 |\n",
      "|    std                | 152         |\n",
      "|    value_loss         | 0.0699      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 22600       |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 113000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22599       |\n",
      "|    policy_loss        | -0.821      |\n",
      "|    reward             | 0.068173274 |\n",
      "|    std                | 153         |\n",
      "|    value_loss         | 0.00651     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 22700       |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 113500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22699       |\n",
      "|    policy_loss        | -0.196      |\n",
      "|    reward             | 0.062657885 |\n",
      "|    std                | 154         |\n",
      "|    value_loss         | 0.00214     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 22800         |\n",
      "|    time_elapsed       | 343           |\n",
      "|    total_timesteps    | 114000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22799         |\n",
      "|    policy_loss        | 0.0205        |\n",
      "|    reward             | -0.0144838225 |\n",
      "|    std                | 155           |\n",
      "|    value_loss         | 0.00145       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 22900        |\n",
      "|    time_elapsed       | 344          |\n",
      "|    total_timesteps    | 114500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -0.126       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22899        |\n",
      "|    policy_loss        | 0.275        |\n",
      "|    reward             | -0.005412773 |\n",
      "|    std                | 156          |\n",
      "|    value_loss         | 0.0005       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 23000      |\n",
      "|    time_elapsed       | 346        |\n",
      "|    total_timesteps    | 115000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 0.000372   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22999      |\n",
      "|    policy_loss        | 0.223      |\n",
      "|    reward             | 0.05773447 |\n",
      "|    std                | 158        |\n",
      "|    value_loss         | 0.000813   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 23100      |\n",
      "|    time_elapsed       | 347        |\n",
      "|    total_timesteps    | 115500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 0.0238     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23099      |\n",
      "|    policy_loss        | -1.64      |\n",
      "|    reward             | 0.09162839 |\n",
      "|    std                | 159        |\n",
      "|    value_loss         | 0.0182     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -44692.70\n",
      "total_reward: -54692.70\n",
      "total_cost: 71.83\n",
      "total_trades: 5792\n",
      "Sharpe: -0.040\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 23200       |\n",
      "|    time_elapsed       | 349         |\n",
      "|    total_timesteps    | 116000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23199       |\n",
      "|    policy_loss        | 0.0819      |\n",
      "|    reward             | 0.005010585 |\n",
      "|    std                | 162         |\n",
      "|    value_loss         | 0.000717    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 23300        |\n",
      "|    time_elapsed       | 350          |\n",
      "|    total_timesteps    | 116500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23299        |\n",
      "|    policy_loss        | -0.154       |\n",
      "|    reward             | -0.013080745 |\n",
      "|    std                | 163          |\n",
      "|    value_loss         | 0.000496     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 23400       |\n",
      "|    time_elapsed       | 352         |\n",
      "|    total_timesteps    | 117000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23399       |\n",
      "|    policy_loss        | -0.697      |\n",
      "|    reward             | 0.008035097 |\n",
      "|    std                | 166         |\n",
      "|    value_loss         | 0.00497     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 23500       |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 117500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0.00132     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23499       |\n",
      "|    policy_loss        | 0.0811      |\n",
      "|    reward             | 0.011202565 |\n",
      "|    std                | 170         |\n",
      "|    value_loss         | 0.000115    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 23600       |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 118000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0.0699      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | -0.22       |\n",
      "|    reward             | -0.01768492 |\n",
      "|    std                | 172         |\n",
      "|    value_loss         | 0.000377    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 23700        |\n",
      "|    time_elapsed       | 356          |\n",
      "|    total_timesteps    | 118500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 6.74e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23699        |\n",
      "|    policy_loss        | 0.307        |\n",
      "|    reward             | 0.0069025625 |\n",
      "|    std                | 174          |\n",
      "|    value_loss         | 0.00068      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 23800       |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 119000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23799       |\n",
      "|    policy_loss        | -0.398      |\n",
      "|    reward             | 0.004297442 |\n",
      "|    std                | 178         |\n",
      "|    value_loss         | 0.00264     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 23900         |\n",
      "|    time_elapsed       | 359           |\n",
      "|    total_timesteps    | 119500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23899         |\n",
      "|    policy_loss        | 0.105         |\n",
      "|    reward             | -0.0033642694 |\n",
      "|    std                | 182           |\n",
      "|    value_loss         | 9.47e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 24000        |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 120000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23999        |\n",
      "|    policy_loss        | -0.0286      |\n",
      "|    reward             | -0.020534983 |\n",
      "|    std                | 188          |\n",
      "|    value_loss         | 6.53e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 24100        |\n",
      "|    time_elapsed       | 362          |\n",
      "|    total_timesteps    | 120500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24099        |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | -0.007504025 |\n",
      "|    std                | 194          |\n",
      "|    value_loss         | 0.00041      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 24200        |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 121000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -8.67        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24199        |\n",
      "|    policy_loss        | 0.0769       |\n",
      "|    reward             | 0.0006687977 |\n",
      "|    std                | 198          |\n",
      "|    value_loss         | 0.00043      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 24300       |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 121500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24299       |\n",
      "|    policy_loss        | -0.115      |\n",
      "|    reward             | 0.008901183 |\n",
      "|    std                | 207         |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 24400      |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 122000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24399      |\n",
      "|    policy_loss        | 1.05       |\n",
      "|    reward             | 0.04067636 |\n",
      "|    std                | 214        |\n",
      "|    value_loss         | 0.00691    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 24500        |\n",
      "|    time_elapsed       | 368          |\n",
      "|    total_timesteps    | 122500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24499        |\n",
      "|    policy_loss        | 0.0644       |\n",
      "|    reward             | 0.0066428385 |\n",
      "|    std                | 218          |\n",
      "|    value_loss         | 6.94e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 24600        |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 123000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24599        |\n",
      "|    policy_loss        | 0.0949       |\n",
      "|    reward             | 0.0059825955 |\n",
      "|    std                | 226          |\n",
      "|    value_loss         | 0.000244     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 24700       |\n",
      "|    time_elapsed       | 371         |\n",
      "|    total_timesteps    | 123500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0.0429      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | 0.118       |\n",
      "|    reward             | 0.006430237 |\n",
      "|    std                | 234         |\n",
      "|    value_loss         | 8.39e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 24800         |\n",
      "|    time_elapsed       | 373           |\n",
      "|    total_timesteps    | 124000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0.602         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24799         |\n",
      "|    policy_loss        | -0.0954       |\n",
      "|    reward             | -0.0090785995 |\n",
      "|    std                | 244           |\n",
      "|    value_loss         | 0.000125      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 24900        |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 124500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24899        |\n",
      "|    policy_loss        | 0.104        |\n",
      "|    reward             | -0.005553073 |\n",
      "|    std                | 251          |\n",
      "|    value_loss         | 0.000159     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 25000      |\n",
      "|    time_elapsed       | 376        |\n",
      "|    total_timesteps    | 125000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24999      |\n",
      "|    policy_loss        | -0.874     |\n",
      "|    reward             | 0.10192307 |\n",
      "|    std                | 256        |\n",
      "|    value_loss         | 0.00847    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 25100        |\n",
      "|    time_elapsed       | 377          |\n",
      "|    total_timesteps    | 125500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25099        |\n",
      "|    policy_loss        | 0.152        |\n",
      "|    reward             | -0.011597371 |\n",
      "|    std                | 259          |\n",
      "|    value_loss         | 0.000185     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 25200        |\n",
      "|    time_elapsed       | 379          |\n",
      "|    total_timesteps    | 126000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0.245        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25199        |\n",
      "|    policy_loss        | -0.594       |\n",
      "|    reward             | -0.031488016 |\n",
      "|    std                | 263          |\n",
      "|    value_loss         | 0.0019       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 25300        |\n",
      "|    time_elapsed       | 380          |\n",
      "|    total_timesteps    | 126500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0.00138      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25299        |\n",
      "|    policy_loss        | -0.838       |\n",
      "|    reward             | -0.005877914 |\n",
      "|    std                | 265          |\n",
      "|    value_loss         | 0.00421      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | -0.192      |\n",
      "|    reward             | -0.01714076 |\n",
      "|    std                | 270         |\n",
      "|    value_loss         | 0.000387    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 25500      |\n",
      "|    time_elapsed       | 383        |\n",
      "|    total_timesteps    | 127500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25499      |\n",
      "|    policy_loss        | -1.02      |\n",
      "|    reward             | 0.09546615 |\n",
      "|    std                | 275        |\n",
      "|    value_loss         | 0.00999    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 25600       |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 128000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25599       |\n",
      "|    policy_loss        | 1.6         |\n",
      "|    reward             | 0.015832286 |\n",
      "|    std                | 276         |\n",
      "|    value_loss         | 0.0127      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25699       |\n",
      "|    policy_loss        | -0.502      |\n",
      "|    reward             | -0.06574222 |\n",
      "|    std                | 278         |\n",
      "|    value_loss         | 0.0124      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 25800      |\n",
      "|    time_elapsed       | 388        |\n",
      "|    total_timesteps    | 129000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.1      |\n",
      "|    explained_variance | 0.579      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25799      |\n",
      "|    policy_loss        | 0.142      |\n",
      "|    reward             | 0.12897474 |\n",
      "|    std                | 278        |\n",
      "|    value_loss         | 0.00209    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 25900       |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 129500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25899       |\n",
      "|    policy_loss        | 6.88        |\n",
      "|    reward             | -0.10515744 |\n",
      "|    std                | 278         |\n",
      "|    value_loss         | 0.252       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 26000       |\n",
      "|    time_elapsed       | 390         |\n",
      "|    total_timesteps    | 130000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0.0413      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25999       |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    reward             | 0.051904395 |\n",
      "|    std                | 279         |\n",
      "|    value_loss         | 0.0565      |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -269432.50\n",
      "total_reward: -279432.50\n",
      "total_cost: 103.82\n",
      "total_trades: 5792\n",
      "Sharpe: 0.026\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 26100        |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 130500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26099        |\n",
      "|    policy_loss        | 0.384        |\n",
      "|    reward             | -0.005498805 |\n",
      "|    std                | 279          |\n",
      "|    value_loss         | 0.000933     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 26200        |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 131000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26199        |\n",
      "|    policy_loss        | -0.142       |\n",
      "|    reward             | 0.0026313078 |\n",
      "|    std                | 282          |\n",
      "|    value_loss         | 0.00167      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 26300        |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 131500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26299        |\n",
      "|    policy_loss        | 0.227        |\n",
      "|    reward             | -0.011136396 |\n",
      "|    std                | 284          |\n",
      "|    value_loss         | 0.00086      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 26400         |\n",
      "|    time_elapsed       | 396           |\n",
      "|    total_timesteps    | 132000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | -0.0598       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 26399         |\n",
      "|    policy_loss        | 0.0935        |\n",
      "|    reward             | -0.0031364358 |\n",
      "|    std                | 288           |\n",
      "|    value_loss         | 0.000473      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 26500      |\n",
      "|    time_elapsed       | 398        |\n",
      "|    total_timesteps    | 132500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | 7.15e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26499      |\n",
      "|    policy_loss        | 0.0765     |\n",
      "|    reward             | -0.0087858 |\n",
      "|    std                | 292        |\n",
      "|    value_loss         | 0.00241    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 26600      |\n",
      "|    time_elapsed       | 399        |\n",
      "|    total_timesteps    | 133000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | 0.169      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26599      |\n",
      "|    policy_loss        | -0.304     |\n",
      "|    reward             | 0.08651861 |\n",
      "|    std                | 295        |\n",
      "|    value_loss         | 0.00418    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 401          |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | -0.473       |\n",
      "|    reward             | -0.027122483 |\n",
      "|    std                | 299          |\n",
      "|    value_loss         | 0.00968      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 26800        |\n",
      "|    time_elapsed       | 402          |\n",
      "|    total_timesteps    | 134000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26799        |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.018039696 |\n",
      "|    std                | 301          |\n",
      "|    value_loss         | 0.0013       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 26900       |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 134500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26899       |\n",
      "|    policy_loss        | -0.266      |\n",
      "|    reward             | -0.05508307 |\n",
      "|    std                | 305         |\n",
      "|    value_loss         | 0.00253     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 27000       |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 135000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26999       |\n",
      "|    policy_loss        | -1.94       |\n",
      "|    reward             | -0.12363534 |\n",
      "|    std                | 306         |\n",
      "|    value_loss         | 0.0199      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 27100      |\n",
      "|    time_elapsed       | 406        |\n",
      "|    total_timesteps    | 135500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | 0.00899    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27099      |\n",
      "|    policy_loss        | -3.14      |\n",
      "|    reward             | 0.19705093 |\n",
      "|    std                | 305        |\n",
      "|    value_loss         | 0.078      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 27200      |\n",
      "|    time_elapsed       | 408        |\n",
      "|    total_timesteps    | 136000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27199      |\n",
      "|    policy_loss        | -2.27      |\n",
      "|    reward             | 0.30603996 |\n",
      "|    std                | 304        |\n",
      "|    value_loss         | 0.0778     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 27300      |\n",
      "|    time_elapsed       | 409        |\n",
      "|    total_timesteps    | 136500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27299      |\n",
      "|    policy_loss        | 1.13       |\n",
      "|    reward             | 0.10417922 |\n",
      "|    std                | 308        |\n",
      "|    value_loss         | 0.00851    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 27400       |\n",
      "|    time_elapsed       | 411         |\n",
      "|    total_timesteps    | 137000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27399       |\n",
      "|    policy_loss        | 0.255       |\n",
      "|    reward             | 0.007504637 |\n",
      "|    std                | 311         |\n",
      "|    value_loss         | 0.000349    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 27500         |\n",
      "|    time_elapsed       | 412           |\n",
      "|    total_timesteps    | 137500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 27499         |\n",
      "|    policy_loss        | 0.0643        |\n",
      "|    reward             | -0.0026355498 |\n",
      "|    std                | 316           |\n",
      "|    value_loss         | 5.84e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 27600       |\n",
      "|    time_elapsed       | 414         |\n",
      "|    total_timesteps    | 138000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27599       |\n",
      "|    policy_loss        | -0.0703     |\n",
      "|    reward             | 0.004402599 |\n",
      "|    std                | 325         |\n",
      "|    value_loss         | 6.77e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 27700        |\n",
      "|    time_elapsed       | 416          |\n",
      "|    total_timesteps    | 138500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | -0.4         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27699        |\n",
      "|    policy_loss        | -0.03        |\n",
      "|    reward             | -0.009037246 |\n",
      "|    std                | 336          |\n",
      "|    value_loss         | 2.54e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 27800      |\n",
      "|    time_elapsed       | 417        |\n",
      "|    total_timesteps    | 139000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27799      |\n",
      "|    policy_loss        | 0.0709     |\n",
      "|    reward             | 0.00419456 |\n",
      "|    std                | 345        |\n",
      "|    value_loss         | 3.8e-05    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 27900       |\n",
      "|    time_elapsed       | 419         |\n",
      "|    total_timesteps    | 139500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27899       |\n",
      "|    policy_loss        | -0.637      |\n",
      "|    reward             | 0.024289086 |\n",
      "|    std                | 357         |\n",
      "|    value_loss         | 0.00358     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 28000         |\n",
      "|    time_elapsed       | 421           |\n",
      "|    total_timesteps    | 140000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | -0.0711       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 27999         |\n",
      "|    policy_loss        | 0.0805        |\n",
      "|    reward             | -0.0037103782 |\n",
      "|    std                | 363           |\n",
      "|    value_loss         | 0.0013        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 28100        |\n",
      "|    time_elapsed       | 422          |\n",
      "|    total_timesteps    | 140500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -6.32e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28099        |\n",
      "|    policy_loss        | 0.735        |\n",
      "|    reward             | -0.002134954 |\n",
      "|    std                | 372          |\n",
      "|    value_loss         | 0.00323      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 28200       |\n",
      "|    time_elapsed       | 424         |\n",
      "|    total_timesteps    | 141000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -2.39       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28199       |\n",
      "|    policy_loss        | 0.274       |\n",
      "|    reward             | 0.006171809 |\n",
      "|    std                | 382         |\n",
      "|    value_loss         | 0.00128     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 28300       |\n",
      "|    time_elapsed       | 425         |\n",
      "|    total_timesteps    | 141500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -1.04       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28299       |\n",
      "|    policy_loss        | -0.668      |\n",
      "|    reward             | -0.09469082 |\n",
      "|    std                | 386         |\n",
      "|    value_loss         | 0.00499     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 28400      |\n",
      "|    time_elapsed       | 427        |\n",
      "|    total_timesteps    | 142000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28399      |\n",
      "|    policy_loss        | -0.494     |\n",
      "|    reward             | 0.01771583 |\n",
      "|    std                | 391        |\n",
      "|    value_loss         | 0.00428    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 28500      |\n",
      "|    time_elapsed       | 428        |\n",
      "|    total_timesteps    | 142500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28499      |\n",
      "|    policy_loss        | -1.01      |\n",
      "|    reward             | 0.14321567 |\n",
      "|    std                | 395        |\n",
      "|    value_loss         | 0.00809    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 28600        |\n",
      "|    time_elapsed       | 430          |\n",
      "|    total_timesteps    | 143000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28599        |\n",
      "|    policy_loss        | -0.172       |\n",
      "|    reward             | 0.0012863345 |\n",
      "|    std                | 399          |\n",
      "|    value_loss         | 0.000231     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 28700        |\n",
      "|    time_elapsed       | 431          |\n",
      "|    total_timesteps    | 143500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | -0.431       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28699        |\n",
      "|    policy_loss        | -0.252       |\n",
      "|    reward             | -0.017970823 |\n",
      "|    std                | 403          |\n",
      "|    value_loss         | 0.000335     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 28800         |\n",
      "|    time_elapsed       | 433           |\n",
      "|    total_timesteps    | 144000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0.459         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28799         |\n",
      "|    policy_loss        | -0.593        |\n",
      "|    reward             | -0.0016579636 |\n",
      "|    std                | 411           |\n",
      "|    value_loss         | 0.00184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 28900        |\n",
      "|    time_elapsed       | 434          |\n",
      "|    total_timesteps    | 144500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28899        |\n",
      "|    policy_loss        | -0.853       |\n",
      "|    reward             | -0.038214024 |\n",
      "|    std                | 419          |\n",
      "|    value_loss         | 0.00396      |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -45681.85\n",
      "total_reward: -55681.85\n",
      "total_cost: 77.54\n",
      "total_trades: 5792\n",
      "Sharpe: -0.498\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 29000         |\n",
      "|    time_elapsed       | 436           |\n",
      "|    total_timesteps    | 145000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28999         |\n",
      "|    policy_loss        | -0.277        |\n",
      "|    reward             | -0.0122511545 |\n",
      "|    std                | 424           |\n",
      "|    value_loss         | 0.000451      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 29100        |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 145500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29099        |\n",
      "|    policy_loss        | 0.3          |\n",
      "|    reward             | 0.0005114284 |\n",
      "|    std                | 434          |\n",
      "|    value_loss         | 0.00046      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 29200        |\n",
      "|    time_elapsed       | 439          |\n",
      "|    total_timesteps    | 146000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29199        |\n",
      "|    policy_loss        | -0.454       |\n",
      "|    reward             | -0.004461618 |\n",
      "|    std                | 447          |\n",
      "|    value_loss         | 0.00103      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 29300        |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 146500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29299        |\n",
      "|    policy_loss        | 0.333        |\n",
      "|    reward             | -0.004097129 |\n",
      "|    std                | 466          |\n",
      "|    value_loss         | 0.000537     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 29400       |\n",
      "|    time_elapsed       | 442         |\n",
      "|    total_timesteps    | 147000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | -0.126      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29399       |\n",
      "|    policy_loss        | 0.328       |\n",
      "|    reward             | 0.003647797 |\n",
      "|    std                | 479         |\n",
      "|    value_loss         | 0.000553    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 29500        |\n",
      "|    time_elapsed       | 444          |\n",
      "|    total_timesteps    | 147500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0.148        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29499        |\n",
      "|    policy_loss        | 0.181        |\n",
      "|    reward             | -0.010059641 |\n",
      "|    std                | 503          |\n",
      "|    value_loss         | 0.000191     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 29600        |\n",
      "|    time_elapsed       | 445          |\n",
      "|    total_timesteps    | 148000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29599        |\n",
      "|    policy_loss        | 0.0243       |\n",
      "|    reward             | -0.009350456 |\n",
      "|    std                | 517          |\n",
      "|    value_loss         | 3.77e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 29700       |\n",
      "|    time_elapsed       | 447         |\n",
      "|    total_timesteps    | 148500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29699       |\n",
      "|    policy_loss        | 0.107       |\n",
      "|    reward             | 0.015467052 |\n",
      "|    std                | 529         |\n",
      "|    value_loss         | 7.83e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 29800       |\n",
      "|    time_elapsed       | 448         |\n",
      "|    total_timesteps    | 149000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29799       |\n",
      "|    policy_loss        | -0.197      |\n",
      "|    reward             | 0.024446087 |\n",
      "|    std                | 546         |\n",
      "|    value_loss         | 0.000211    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 29900         |\n",
      "|    time_elapsed       | 450           |\n",
      "|    total_timesteps    | 149500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29899         |\n",
      "|    policy_loss        | -0.133        |\n",
      "|    reward             | 0.00064090476 |\n",
      "|    std                | 568           |\n",
      "|    value_loss         | 9.12e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 30000        |\n",
      "|    time_elapsed       | 451          |\n",
      "|    total_timesteps    | 150000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0.238        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29999        |\n",
      "|    policy_loss        | 0.353        |\n",
      "|    reward             | -0.028145416 |\n",
      "|    std                | 585          |\n",
      "|    value_loss         | 0.000556     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.178       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30099       |\n",
      "|    policy_loss        | 0.638       |\n",
      "|    reward             | 0.006358638 |\n",
      "|    std                | 612         |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 30200        |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 151000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30199        |\n",
      "|    policy_loss        | 1.73         |\n",
      "|    reward             | -0.053069316 |\n",
      "|    std                | 626          |\n",
      "|    value_loss         | 0.0155       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 30300         |\n",
      "|    time_elapsed       | 456           |\n",
      "|    total_timesteps    | 151500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30299         |\n",
      "|    policy_loss        | 0.181         |\n",
      "|    reward             | -0.0055073444 |\n",
      "|    std                | 643           |\n",
      "|    value_loss         | 0.000177      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 30400       |\n",
      "|    time_elapsed       | 457         |\n",
      "|    total_timesteps    | 152000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30399       |\n",
      "|    policy_loss        | 0.163       |\n",
      "|    reward             | 0.023974253 |\n",
      "|    std                | 658         |\n",
      "|    value_loss         | 0.000157    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 30500         |\n",
      "|    time_elapsed       | 458           |\n",
      "|    total_timesteps    | 152500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | -0.247        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30499         |\n",
      "|    policy_loss        | -0.0047       |\n",
      "|    reward             | -0.0021654333 |\n",
      "|    std                | 684           |\n",
      "|    value_loss         | 1.63e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 30600       |\n",
      "|    time_elapsed       | 460         |\n",
      "|    total_timesteps    | 153000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0.43        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30599       |\n",
      "|    policy_loss        | 0.56        |\n",
      "|    reward             | 0.009388375 |\n",
      "|    std                | 712         |\n",
      "|    value_loss         | 0.00133     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 30700         |\n",
      "|    time_elapsed       | 461           |\n",
      "|    total_timesteps    | 153500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30699         |\n",
      "|    policy_loss        | -0.18         |\n",
      "|    reward             | -0.0039001447 |\n",
      "|    std                | 737           |\n",
      "|    value_loss         | 0.000202      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 30800       |\n",
      "|    time_elapsed       | 463         |\n",
      "|    total_timesteps    | 154000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30799       |\n",
      "|    policy_loss        | -2.28       |\n",
      "|    reward             | 0.007216475 |\n",
      "|    std                | 758         |\n",
      "|    value_loss         | 0.027       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 30900       |\n",
      "|    time_elapsed       | 464         |\n",
      "|    total_timesteps    | 154500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30899       |\n",
      "|    policy_loss        | -2.79       |\n",
      "|    reward             | 0.072918184 |\n",
      "|    std                | 774         |\n",
      "|    value_loss         | 0.0356      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 31000         |\n",
      "|    time_elapsed       | 465           |\n",
      "|    total_timesteps    | 155000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.1         |\n",
      "|    explained_variance | -0.0353       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30999         |\n",
      "|    policy_loss        | 4.54          |\n",
      "|    reward             | -0.0050059417 |\n",
      "|    std                | 773           |\n",
      "|    value_loss         | 0.145         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 31100        |\n",
      "|    time_elapsed       | 467          |\n",
      "|    total_timesteps    | 155500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0.045        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31099        |\n",
      "|    policy_loss        | -4.76        |\n",
      "|    reward             | -0.029258598 |\n",
      "|    std                | 787          |\n",
      "|    value_loss         | 0.129        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 31200      |\n",
      "|    time_elapsed       | 468        |\n",
      "|    total_timesteps    | 156000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.1      |\n",
      "|    explained_variance | 0.314      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31199      |\n",
      "|    policy_loss        | 1.47       |\n",
      "|    reward             | 0.17683697 |\n",
      "|    std                | 784        |\n",
      "|    value_loss         | 0.0214     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 31300        |\n",
      "|    time_elapsed       | 470          |\n",
      "|    total_timesteps    | 156500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31299        |\n",
      "|    policy_loss        | 1.07         |\n",
      "|    reward             | 0.0028242955 |\n",
      "|    std                | 777          |\n",
      "|    value_loss         | 0.0062       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 31400        |\n",
      "|    time_elapsed       | 471          |\n",
      "|    total_timesteps    | 157000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31399        |\n",
      "|    policy_loss        | -0.394       |\n",
      "|    reward             | -0.010206921 |\n",
      "|    std                | 791          |\n",
      "|    value_loss         | 0.000656     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 31500       |\n",
      "|    time_elapsed       | 472         |\n",
      "|    total_timesteps    | 157500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31499       |\n",
      "|    policy_loss        | 0.318       |\n",
      "|    reward             | -0.01131836 |\n",
      "|    std                | 805         |\n",
      "|    value_loss         | 0.000426    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 31600         |\n",
      "|    time_elapsed       | 474           |\n",
      "|    total_timesteps    | 158000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31599         |\n",
      "|    policy_loss        | -0.306        |\n",
      "|    reward             | 0.00041657963 |\n",
      "|    std                | 812           |\n",
      "|    value_loss         | 0.00105       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 31700       |\n",
      "|    time_elapsed       | 475         |\n",
      "|    total_timesteps    | 158500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0.345       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31699       |\n",
      "|    policy_loss        | -0.798      |\n",
      "|    reward             | -0.02752214 |\n",
      "|    std                | 824         |\n",
      "|    value_loss         | 0.00289     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 31800       |\n",
      "|    time_elapsed       | 477         |\n",
      "|    total_timesteps    | 159000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31799       |\n",
      "|    policy_loss        | -1.98       |\n",
      "|    reward             | -0.06574269 |\n",
      "|    std                | 823         |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -61904.79\n",
      "total_reward: -71904.79\n",
      "total_cost: 94.66\n",
      "total_trades: 5792\n",
      "Sharpe: -0.210\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 31900        |\n",
      "|    time_elapsed       | 478          |\n",
      "|    total_timesteps    | 159500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31899        |\n",
      "|    policy_loss        | 0.471        |\n",
      "|    reward             | -0.024089511 |\n",
      "|    std                | 827          |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 32000       |\n",
      "|    time_elapsed       | 480         |\n",
      "|    total_timesteps    | 160000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31999       |\n",
      "|    policy_loss        | 0.606       |\n",
      "|    reward             | 0.009967085 |\n",
      "|    std                | 843         |\n",
      "|    value_loss         | 0.00192     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 32100        |\n",
      "|    time_elapsed       | 481          |\n",
      "|    total_timesteps    | 160500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32099        |\n",
      "|    policy_loss        | 0.229        |\n",
      "|    reward             | -0.014983997 |\n",
      "|    std                | 854          |\n",
      "|    value_loss         | 0.000287     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 32200       |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 161000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0.321       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32199       |\n",
      "|    policy_loss        | -0.125      |\n",
      "|    reward             | 0.014579796 |\n",
      "|    std                | 870         |\n",
      "|    value_loss         | 0.000118    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 32300       |\n",
      "|    time_elapsed       | 485         |\n",
      "|    total_timesteps    | 161500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 4.77e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32299       |\n",
      "|    policy_loss        | 1.06        |\n",
      "|    reward             | 0.003904116 |\n",
      "|    std                | 894         |\n",
      "|    value_loss         | 0.00577     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 32400       |\n",
      "|    time_elapsed       | 486         |\n",
      "|    total_timesteps    | 162000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0.0386      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32399       |\n",
      "|    policy_loss        | 0.434       |\n",
      "|    reward             | 0.030799994 |\n",
      "|    std                | 914         |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 32500       |\n",
      "|    time_elapsed       | 488         |\n",
      "|    total_timesteps    | 162500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32499       |\n",
      "|    policy_loss        | 0.0776      |\n",
      "|    reward             | 0.024500081 |\n",
      "|    std                | 929         |\n",
      "|    value_loss         | 0.000838    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 32600        |\n",
      "|    time_elapsed       | 489          |\n",
      "|    total_timesteps    | 163000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32599        |\n",
      "|    policy_loss        | 0.604        |\n",
      "|    reward             | -0.008400778 |\n",
      "|    std                | 946          |\n",
      "|    value_loss         | 0.00166      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 32700       |\n",
      "|    time_elapsed       | 491         |\n",
      "|    total_timesteps    | 163500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | -11.9       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32699       |\n",
      "|    policy_loss        | -0.39       |\n",
      "|    reward             | 0.008161191 |\n",
      "|    std                | 976         |\n",
      "|    value_loss         | 0.000723    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 32800       |\n",
      "|    time_elapsed       | 492         |\n",
      "|    total_timesteps    | 164000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0.0139      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32799       |\n",
      "|    policy_loss        | 0.503       |\n",
      "|    reward             | 0.003542392 |\n",
      "|    std                | 992         |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 32900       |\n",
      "|    time_elapsed       | 494         |\n",
      "|    total_timesteps    | 164500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32899       |\n",
      "|    policy_loss        | -0.921      |\n",
      "|    reward             | -0.03180882 |\n",
      "|    std                | 1.01e+03    |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 33000       |\n",
      "|    time_elapsed       | 495         |\n",
      "|    total_timesteps    | 165000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32999       |\n",
      "|    policy_loss        | 3.35        |\n",
      "|    reward             | -0.11396794 |\n",
      "|    std                | 1.02e+03    |\n",
      "|    value_loss         | 0.0503      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 33100      |\n",
      "|    time_elapsed       | 497        |\n",
      "|    total_timesteps    | 165500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33099      |\n",
      "|    policy_loss        | -2.22      |\n",
      "|    reward             | 0.08215113 |\n",
      "|    std                | 1.03e+03   |\n",
      "|    value_loss         | 0.0205     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 33200        |\n",
      "|    time_elapsed       | 498          |\n",
      "|    total_timesteps    | 166000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33199        |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.072147354 |\n",
      "|    std                | 1.04e+03     |\n",
      "|    value_loss         | 0.00451      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 33300      |\n",
      "|    time_elapsed       | 500        |\n",
      "|    total_timesteps    | 166500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33299      |\n",
      "|    policy_loss        | 1.01       |\n",
      "|    reward             | -0.1178318 |\n",
      "|    std                | 1.06e+03   |\n",
      "|    value_loss         | 0.0272     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 33400        |\n",
      "|    time_elapsed       | 501          |\n",
      "|    total_timesteps    | 167000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0.364        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33399        |\n",
      "|    policy_loss        | 4.9          |\n",
      "|    reward             | -0.019905707 |\n",
      "|    std                | 1.07e+03     |\n",
      "|    value_loss         | 0.144        |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 332      |\n",
      "|    iterations         | 33500    |\n",
      "|    time_elapsed       | 503      |\n",
      "|    total_timesteps    | 167500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 33499    |\n",
      "|    policy_loss        | 4.5      |\n",
      "|    reward             | 0.452186 |\n",
      "|    std                | 1.06e+03 |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 33600       |\n",
      "|    time_elapsed       | 504         |\n",
      "|    total_timesteps    | 168000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33599       |\n",
      "|    policy_loss        | 6.69        |\n",
      "|    reward             | -0.13366766 |\n",
      "|    std                | 1.07e+03    |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 33700       |\n",
      "|    time_elapsed       | 505         |\n",
      "|    total_timesteps    | 168500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33699       |\n",
      "|    policy_loss        | -0.0823     |\n",
      "|    reward             | -0.03284449 |\n",
      "|    std                | 1.07e+03    |\n",
      "|    value_loss         | 0.000513    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 33800        |\n",
      "|    time_elapsed       | 507          |\n",
      "|    total_timesteps    | 169000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33799        |\n",
      "|    policy_loss        | -0.102       |\n",
      "|    reward             | -0.005864592 |\n",
      "|    std                | 1.09e+03     |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 33900        |\n",
      "|    time_elapsed       | 508          |\n",
      "|    total_timesteps    | 169500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33899        |\n",
      "|    policy_loss        | -0.159       |\n",
      "|    reward             | -0.004274559 |\n",
      "|    std                | 1.1e+03      |\n",
      "|    value_loss         | 0.000678     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 34000      |\n",
      "|    time_elapsed       | 510        |\n",
      "|    total_timesteps    | 170000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.8      |\n",
      "|    explained_variance | 0.247      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33999      |\n",
      "|    policy_loss        | 0.0562     |\n",
      "|    reward             | 0.03944779 |\n",
      "|    std                | 1.12e+03   |\n",
      "|    value_loss         | 0.000298   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 34100       |\n",
      "|    time_elapsed       | 512         |\n",
      "|    total_timesteps    | 170500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34099       |\n",
      "|    policy_loss        | -0.249      |\n",
      "|    reward             | 0.061992615 |\n",
      "|    std                | 1.13e+03    |\n",
      "|    value_loss         | 0.000431    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 34200      |\n",
      "|    time_elapsed       | 513        |\n",
      "|    total_timesteps    | 171000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34199      |\n",
      "|    policy_loss        | -0.46      |\n",
      "|    reward             | -0.0677219 |\n",
      "|    std                | 1.14e+03   |\n",
      "|    value_loss         | 0.000818   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 34300       |\n",
      "|    time_elapsed       | 515         |\n",
      "|    total_timesteps    | 171500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34299       |\n",
      "|    policy_loss        | 1.38        |\n",
      "|    reward             | 0.014848353 |\n",
      "|    std                | 1.17e+03    |\n",
      "|    value_loss         | 0.00722     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 34400        |\n",
      "|    time_elapsed       | 516          |\n",
      "|    total_timesteps    | 172000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34399        |\n",
      "|    policy_loss        | -0.139       |\n",
      "|    reward             | -0.011372038 |\n",
      "|    std                | 1.19e+03     |\n",
      "|    value_loss         | 0.000383     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 34500         |\n",
      "|    time_elapsed       | 517           |\n",
      "|    total_timesteps    | 172500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | 0.0712        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34499         |\n",
      "|    policy_loss        | -0.173        |\n",
      "|    reward             | -0.0012584088 |\n",
      "|    std                | 1.22e+03      |\n",
      "|    value_loss         | 0.00182       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 34600       |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 173000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0.677       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34599       |\n",
      "|    policy_loss        | 1.11        |\n",
      "|    reward             | 0.005175303 |\n",
      "|    std                | 1.25e+03    |\n",
      "|    value_loss         | 0.00393     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 34700       |\n",
      "|    time_elapsed       | 520         |\n",
      "|    total_timesteps    | 173500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34699       |\n",
      "|    policy_loss        | 0.233       |\n",
      "|    reward             | 0.021506172 |\n",
      "|    std                | 1.27e+03    |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -43773.37\n",
      "total_reward: -53773.37\n",
      "total_cost: 92.78\n",
      "total_trades: 5792\n",
      "Sharpe: 0.501\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 34800        |\n",
      "|    time_elapsed       | 522          |\n",
      "|    total_timesteps    | 174000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34799        |\n",
      "|    policy_loss        | -0.255       |\n",
      "|    reward             | -0.053438954 |\n",
      "|    std                | 1.27e+03     |\n",
      "|    value_loss         | 0.000436     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 34900        |\n",
      "|    time_elapsed       | 523          |\n",
      "|    total_timesteps    | 174500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34899        |\n",
      "|    policy_loss        | 0.0321       |\n",
      "|    reward             | -0.007009153 |\n",
      "|    std                | 1.29e+03     |\n",
      "|    value_loss         | 1.77e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 35000      |\n",
      "|    time_elapsed       | 525        |\n",
      "|    total_timesteps    | 175000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34999      |\n",
      "|    policy_loss        | 0.266      |\n",
      "|    reward             | 0.02035368 |\n",
      "|    std                | 1.33e+03   |\n",
      "|    value_loss         | 0.00028    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 35100       |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 175500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | -0.136      |\n",
      "|    reward             | 0.021705853 |\n",
      "|    std                | 1.37e+03    |\n",
      "|    value_loss         | 8.79e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 35200         |\n",
      "|    time_elapsed       | 527           |\n",
      "|    total_timesteps    | 176000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.3         |\n",
      "|    explained_variance | 0.0784        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 35199         |\n",
      "|    policy_loss        | 0.119         |\n",
      "|    reward             | -0.0013620708 |\n",
      "|    std                | 1.41e+03      |\n",
      "|    value_loss         | 0.000164      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 35300        |\n",
      "|    time_elapsed       | 529          |\n",
      "|    total_timesteps    | 176500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35299        |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | -0.010124272 |\n",
      "|    std                | 1.45e+03     |\n",
      "|    value_loss         | 0.000326     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 35400       |\n",
      "|    time_elapsed       | 530         |\n",
      "|    total_timesteps    | 177000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35399       |\n",
      "|    policy_loss        | -1.62       |\n",
      "|    reward             | 0.033501584 |\n",
      "|    std                | 1.49e+03    |\n",
      "|    value_loss         | 0.011       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 35500       |\n",
      "|    time_elapsed       | 532         |\n",
      "|    total_timesteps    | 177500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35499       |\n",
      "|    policy_loss        | -0.578      |\n",
      "|    reward             | 0.018337497 |\n",
      "|    std                | 1.51e+03    |\n",
      "|    value_loss         | 0.00132     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 35600       |\n",
      "|    time_elapsed       | 533         |\n",
      "|    total_timesteps    | 178000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 0.00157     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35599       |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | -0.08503634 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 0.00564     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 35700        |\n",
      "|    time_elapsed       | 535          |\n",
      "|    total_timesteps    | 178500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0.00202      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35699        |\n",
      "|    policy_loss        | -1.47        |\n",
      "|    reward             | -0.057624176 |\n",
      "|    std                | 1.56e+03     |\n",
      "|    value_loss         | 0.00874      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 35800        |\n",
      "|    time_elapsed       | 536          |\n",
      "|    total_timesteps    | 179000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0.19         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35799        |\n",
      "|    policy_loss        | 1.61         |\n",
      "|    reward             | -0.032751262 |\n",
      "|    std                | 1.59e+03     |\n",
      "|    value_loss         | 0.0092       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 35900       |\n",
      "|    time_elapsed       | 538         |\n",
      "|    total_timesteps    | 179500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35899       |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | 0.066411674 |\n",
      "|    std                | 1.59e+03    |\n",
      "|    value_loss         | 0.00684     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 36000       |\n",
      "|    time_elapsed       | 539         |\n",
      "|    total_timesteps    | 180000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35999       |\n",
      "|    policy_loss        | 0.384       |\n",
      "|    reward             | -0.00798658 |\n",
      "|    std                | 1.6e+03     |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 36100       |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 180500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36099       |\n",
      "|    policy_loss        | -0.0943     |\n",
      "|    reward             | 0.010923572 |\n",
      "|    std                | 1.63e+03    |\n",
      "|    value_loss         | 3.13e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 36200        |\n",
      "|    time_elapsed       | 542          |\n",
      "|    total_timesteps    | 181000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36199        |\n",
      "|    policy_loss        | 0.0769       |\n",
      "|    reward             | -0.012151167 |\n",
      "|    std                | 1.67e+03     |\n",
      "|    value_loss         | 9.15e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 36300        |\n",
      "|    time_elapsed       | 544          |\n",
      "|    total_timesteps    | 181500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.176        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36299        |\n",
      "|    policy_loss        | 0.18         |\n",
      "|    reward             | -0.006762861 |\n",
      "|    std                | 1.72e+03     |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 36400       |\n",
      "|    time_elapsed       | 546         |\n",
      "|    total_timesteps    | 182000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36399       |\n",
      "|    policy_loss        | 0.141       |\n",
      "|    reward             | 0.013172797 |\n",
      "|    std                | 1.78e+03    |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 36500         |\n",
      "|    time_elapsed       | 547           |\n",
      "|    total_timesteps    | 182500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 36499         |\n",
      "|    policy_loss        | 0.207         |\n",
      "|    reward             | -0.0016888592 |\n",
      "|    std                | 1.85e+03      |\n",
      "|    value_loss         | 0.000194      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 36600        |\n",
      "|    time_elapsed       | 548          |\n",
      "|    total_timesteps    | 183000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36599        |\n",
      "|    policy_loss        | 0.444        |\n",
      "|    reward             | -0.015964659 |\n",
      "|    std                | 1.87e+03     |\n",
      "|    value_loss         | 0.000884     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 36700       |\n",
      "|    time_elapsed       | 550         |\n",
      "|    total_timesteps    | 183500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36699       |\n",
      "|    policy_loss        | -0.348      |\n",
      "|    reward             | 0.021857787 |\n",
      "|    std                | 1.89e+03    |\n",
      "|    value_loss         | 0.001       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 36800       |\n",
      "|    time_elapsed       | 551         |\n",
      "|    total_timesteps    | 184000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36799       |\n",
      "|    policy_loss        | -0.202      |\n",
      "|    reward             | 0.009995818 |\n",
      "|    std                | 1.93e+03    |\n",
      "|    value_loss         | 0.000425    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 36900       |\n",
      "|    time_elapsed       | 553         |\n",
      "|    total_timesteps    | 184500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0.0612      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36899       |\n",
      "|    policy_loss        | -1.26       |\n",
      "|    reward             | 0.009491974 |\n",
      "|    std                | 1.96e+03    |\n",
      "|    value_loss         | 0.0103      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 37000      |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 185000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 36999      |\n",
      "|    policy_loss        | -0.919     |\n",
      "|    reward             | 0.04649147 |\n",
      "|    std                | 1.98e+03   |\n",
      "|    value_loss         | 0.00446    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 37100        |\n",
      "|    time_elapsed       | 556          |\n",
      "|    total_timesteps    | 185500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37099        |\n",
      "|    policy_loss        | -1.27        |\n",
      "|    reward             | 0.0010189192 |\n",
      "|    std                | 1.97e+03     |\n",
      "|    value_loss         | 0.0054       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 37200        |\n",
      "|    time_elapsed       | 558          |\n",
      "|    total_timesteps    | 186000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37199        |\n",
      "|    policy_loss        | -1.7         |\n",
      "|    reward             | 0.0019436656 |\n",
      "|    std                | 1.96e+03     |\n",
      "|    value_loss         | 0.0142       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 37300        |\n",
      "|    time_elapsed       | 559          |\n",
      "|    total_timesteps    | 186500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37299        |\n",
      "|    policy_loss        | 4.18         |\n",
      "|    reward             | -0.063316084 |\n",
      "|    std                | 1.98e+03     |\n",
      "|    value_loss         | 0.0738       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 37400      |\n",
      "|    time_elapsed       | 560        |\n",
      "|    total_timesteps    | 187000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37399      |\n",
      "|    policy_loss        | 1.64       |\n",
      "|    reward             | 0.07751834 |\n",
      "|    std                | 1.97e+03   |\n",
      "|    value_loss         | 0.00959    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 37500       |\n",
      "|    time_elapsed       | 562         |\n",
      "|    total_timesteps    | 187500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37499       |\n",
      "|    policy_loss        | 15.5        |\n",
      "|    reward             | -0.04629679 |\n",
      "|    std                | 1.97e+03    |\n",
      "|    value_loss         | 2.04        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 37600       |\n",
      "|    time_elapsed       | 564         |\n",
      "|    total_timesteps    | 188000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37599       |\n",
      "|    policy_loss        | 8.6         |\n",
      "|    reward             | -0.29096237 |\n",
      "|    std                | 1.96e+03    |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2896, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -339640.01\n",
      "total_reward: -349640.01\n",
      "total_cost: 112.51\n",
      "total_trades: 5792\n",
      "Sharpe: 0.257\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 37700         |\n",
      "|    time_elapsed       | 565           |\n",
      "|    total_timesteps    | 188500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37699         |\n",
      "|    policy_loss        | 0.457         |\n",
      "|    reward             | 0.00029253005 |\n",
      "|    std                | 1.96e+03      |\n",
      "|    value_loss         | 0.000785      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 37800        |\n",
      "|    time_elapsed       | 566          |\n",
      "|    total_timesteps    | 189000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37799        |\n",
      "|    policy_loss        | 0.0942       |\n",
      "|    reward             | -0.008077081 |\n",
      "|    std                | 1.98e+03     |\n",
      "|    value_loss         | 6.94e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 37900        |\n",
      "|    time_elapsed       | 568          |\n",
      "|    total_timesteps    | 189500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37899        |\n",
      "|    policy_loss        | -0.453       |\n",
      "|    reward             | 0.0009151489 |\n",
      "|    std                | 2.01e+03     |\n",
      "|    value_loss         | 0.0008       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 38000        |\n",
      "|    time_elapsed       | 569          |\n",
      "|    total_timesteps    | 190000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37999        |\n",
      "|    policy_loss        | -0.189       |\n",
      "|    reward             | 0.0037336075 |\n",
      "|    std                | 2.06e+03     |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 38100        |\n",
      "|    time_elapsed       | 571          |\n",
      "|    total_timesteps    | 190500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -0.469       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38099        |\n",
      "|    policy_loss        | -0.479       |\n",
      "|    reward             | 0.0142995175 |\n",
      "|    std                | 2.1e+03      |\n",
      "|    value_loss         | 0.000898     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 333            |\n",
      "|    iterations         | 38200          |\n",
      "|    time_elapsed       | 572            |\n",
      "|    total_timesteps    | 191000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 38199          |\n",
      "|    policy_loss        | -0.258         |\n",
      "|    reward             | -0.00094526197 |\n",
      "|    std                | 2.15e+03       |\n",
      "|    value_loss         | 0.000278       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 38300        |\n",
      "|    time_elapsed       | 574          |\n",
      "|    total_timesteps    | 191500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38299        |\n",
      "|    policy_loss        | -0.144       |\n",
      "|    reward             | -0.021533227 |\n",
      "|    std                | 2.2e+03      |\n",
      "|    value_loss         | 0.000271     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 38400         |\n",
      "|    time_elapsed       | 575           |\n",
      "|    total_timesteps    | 192000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38399         |\n",
      "|    policy_loss        | -0.0151       |\n",
      "|    reward             | -0.0051568854 |\n",
      "|    std                | 2.25e+03      |\n",
      "|    value_loss         | 6.67e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 38500        |\n",
      "|    time_elapsed       | 577          |\n",
      "|    total_timesteps    | 192500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38499        |\n",
      "|    policy_loss        | -0.0041      |\n",
      "|    reward             | -0.008430905 |\n",
      "|    std                | 2.33e+03     |\n",
      "|    value_loss         | 2.02e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 38600        |\n",
      "|    time_elapsed       | 578          |\n",
      "|    total_timesteps    | 193000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | -6.3         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38599        |\n",
      "|    policy_loss        | -0.277       |\n",
      "|    reward             | -0.014675426 |\n",
      "|    std                | 2.41e+03     |\n",
      "|    value_loss         | 0.000287     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 580         |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0.00445     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | 0.584       |\n",
      "|    reward             | 0.021437706 |\n",
      "|    std                | 2.52e+03    |\n",
      "|    value_loss         | 0.00104     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 38800        |\n",
      "|    time_elapsed       | 581          |\n",
      "|    total_timesteps    | 194000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0.0748       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38799        |\n",
      "|    policy_loss        | 0.207        |\n",
      "|    reward             | -0.017066957 |\n",
      "|    std                | 2.6e+03      |\n",
      "|    value_loss         | 0.000363     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 38900       |\n",
      "|    time_elapsed       | 583         |\n",
      "|    total_timesteps    | 194500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38899       |\n",
      "|    policy_loss        | 0.0226      |\n",
      "|    reward             | 0.046190064 |\n",
      "|    std                | 2.65e+03    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 39000        |\n",
      "|    time_elapsed       | 584          |\n",
      "|    total_timesteps    | 195000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38999        |\n",
      "|    policy_loss        | -0.275       |\n",
      "|    reward             | -0.006648672 |\n",
      "|    std                | 2.7e+03      |\n",
      "|    value_loss         | 0.000688     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 39100        |\n",
      "|    time_elapsed       | 586          |\n",
      "|    total_timesteps    | 195500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39099        |\n",
      "|    policy_loss        | -0.254       |\n",
      "|    reward             | -0.029309344 |\n",
      "|    std                | 2.78e+03     |\n",
      "|    value_loss         | 0.000342     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 39200        |\n",
      "|    time_elapsed       | 587          |\n",
      "|    total_timesteps    | 196000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0.17         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39199        |\n",
      "|    policy_loss        | -0.454       |\n",
      "|    reward             | -0.009668726 |\n",
      "|    std                | 2.85e+03     |\n",
      "|    value_loss         | 0.000669     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 39300       |\n",
      "|    time_elapsed       | 589         |\n",
      "|    total_timesteps    | 196500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0.000425    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39299       |\n",
      "|    policy_loss        | 0.876       |\n",
      "|    reward             | -0.04807748 |\n",
      "|    std                | 2.88e+03    |\n",
      "|    value_loss         | 0.00285     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 39400        |\n",
      "|    time_elapsed       | 590          |\n",
      "|    total_timesteps    | 197000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 0.0556       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39399        |\n",
      "|    policy_loss        | 2.64         |\n",
      "|    reward             | 0.0008196703 |\n",
      "|    std                | 2.96e+03     |\n",
      "|    value_loss         | 0.033        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 39500        |\n",
      "|    time_elapsed       | 592          |\n",
      "|    total_timesteps    | 197500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39499        |\n",
      "|    policy_loss        | 0.279        |\n",
      "|    reward             | -0.033002313 |\n",
      "|    std                | 2.99e+03     |\n",
      "|    value_loss         | 0.000361     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 39600      |\n",
      "|    time_elapsed       | 593        |\n",
      "|    total_timesteps    | 198000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39599      |\n",
      "|    policy_loss        | 0.324      |\n",
      "|    reward             | -0.0454036 |\n",
      "|    std                | 3.03e+03   |\n",
      "|    value_loss         | 0.0011     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 39700       |\n",
      "|    time_elapsed       | 595         |\n",
      "|    total_timesteps    | 198500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | -0.011      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39699       |\n",
      "|    policy_loss        | -0.878      |\n",
      "|    reward             | 0.042366017 |\n",
      "|    std                | 3.08e+03    |\n",
      "|    value_loss         | 0.00548     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 39800      |\n",
      "|    time_elapsed       | 596        |\n",
      "|    total_timesteps    | 199000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.9      |\n",
      "|    explained_variance | 0.103      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39799      |\n",
      "|    policy_loss        | -5.54      |\n",
      "|    reward             | 0.22918096 |\n",
      "|    std                | 3.1e+03    |\n",
      "|    value_loss         | 0.0871     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 39900       |\n",
      "|    time_elapsed       | 598         |\n",
      "|    total_timesteps    | 199500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | 8.92e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39899       |\n",
      "|    policy_loss        | 5.14        |\n",
      "|    reward             | -0.43204224 |\n",
      "|    std                | 3.14e+03    |\n",
      "|    value_loss         | 0.0925      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 40000        |\n",
      "|    time_elapsed       | 599          |\n",
      "|    total_timesteps    | 200000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39999        |\n",
      "|    policy_loss        | 0.479        |\n",
      "|    reward             | -0.025973149 |\n",
      "|    std                | 3.17e+03     |\n",
      "|    value_loss         | 0.00188      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 40100       |\n",
      "|    time_elapsed       | 601         |\n",
      "|    total_timesteps    | 200500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40099       |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | 0.023726435 |\n",
      "|    std                | 3.19e+03    |\n",
      "|    value_loss         | 0.00576     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 40200       |\n",
      "|    time_elapsed       | 602         |\n",
      "|    total_timesteps    | 201000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40199       |\n",
      "|    policy_loss        | -2.99       |\n",
      "|    reward             | 0.023697974 |\n",
      "|    std                | 3.22e+03    |\n",
      "|    value_loss         | 0.0299      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 40300        |\n",
      "|    time_elapsed       | 604          |\n",
      "|    total_timesteps    | 201500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0.162        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40299        |\n",
      "|    policy_loss        | -1.5         |\n",
      "|    reward             | -0.023441607 |\n",
      "|    std                | 3.22e+03     |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 40400      |\n",
      "|    time_elapsed       | 605        |\n",
      "|    total_timesteps    | 202000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19        |\n",
      "|    explained_variance | -0.224     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40399      |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | 0.16914344 |\n",
      "|    std                | 3.24e+03   |\n",
      "|    value_loss         | 0.0283     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 40500       |\n",
      "|    time_elapsed       | 607         |\n",
      "|    total_timesteps    | 202500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0.763       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40499       |\n",
      "|    policy_loss        | -5.37       |\n",
      "|    reward             | -0.06639201 |\n",
      "|    std                | 3.22e+03    |\n",
      "|    value_loss         | 0.0828      |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -273831.15\n",
      "total_reward: -283831.15\n",
      "total_cost: 101.53\n",
      "total_trades: 5792\n",
      "Sharpe: 0.361\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 40600       |\n",
      "|    time_elapsed       | 608         |\n",
      "|    total_timesteps    | 203000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40599       |\n",
      "|    policy_loss        | 0.604       |\n",
      "|    reward             | -0.06565491 |\n",
      "|    std                | 3.23e+03    |\n",
      "|    value_loss         | 0.00421     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 40700         |\n",
      "|    time_elapsed       | 609           |\n",
      "|    total_timesteps    | 203500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40699         |\n",
      "|    policy_loss        | -0.146        |\n",
      "|    reward             | -0.0037770565 |\n",
      "|    std                | 3.26e+03      |\n",
      "|    value_loss         | 0.000248      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 40800        |\n",
      "|    time_elapsed       | 611          |\n",
      "|    total_timesteps    | 204000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40799        |\n",
      "|    policy_loss        | -0.511       |\n",
      "|    reward             | -0.028542666 |\n",
      "|    std                | 3.3e+03      |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 40900       |\n",
      "|    time_elapsed       | 612         |\n",
      "|    total_timesteps    | 204500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | -0.0488     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40899       |\n",
      "|    policy_loss        | -1.1        |\n",
      "|    reward             | 0.013011743 |\n",
      "|    std                | 3.37e+03    |\n",
      "|    value_loss         | 0.00383     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41000        |\n",
      "|    time_elapsed       | 614          |\n",
      "|    total_timesteps    | 205000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | -0.00238     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40999        |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | -0.014448931 |\n",
      "|    std                | 3.43e+03     |\n",
      "|    value_loss         | 0.0108       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41100        |\n",
      "|    time_elapsed       | 615          |\n",
      "|    total_timesteps    | 205500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41099        |\n",
      "|    policy_loss        | 0.619        |\n",
      "|    reward             | -0.054597303 |\n",
      "|    std                | 3.44e+03     |\n",
      "|    value_loss         | 0.00134      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41200        |\n",
      "|    time_elapsed       | 617          |\n",
      "|    total_timesteps    | 206000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41199        |\n",
      "|    policy_loss        | -0.842       |\n",
      "|    reward             | -0.058128968 |\n",
      "|    std                | 3.46e+03     |\n",
      "|    value_loss         | 0.00266      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41300        |\n",
      "|    time_elapsed       | 619          |\n",
      "|    total_timesteps    | 206500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41299        |\n",
      "|    policy_loss        | -0.38        |\n",
      "|    reward             | -0.004811858 |\n",
      "|    std                | 3.52e+03     |\n",
      "|    value_loss         | 0.000427     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41400        |\n",
      "|    time_elapsed       | 620          |\n",
      "|    total_timesteps    | 207000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41399        |\n",
      "|    policy_loss        | 0.173        |\n",
      "|    reward             | 0.0037449007 |\n",
      "|    std                | 3.61e+03     |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41500        |\n",
      "|    time_elapsed       | 622          |\n",
      "|    total_timesteps    | 207500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | -2.3         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41499        |\n",
      "|    policy_loss        | -0.652       |\n",
      "|    reward             | 0.0022532498 |\n",
      "|    std                | 3.72e+03     |\n",
      "|    value_loss         | 0.00139      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 41600         |\n",
      "|    time_elapsed       | 623           |\n",
      "|    total_timesteps    | 208000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.3         |\n",
      "|    explained_variance | -20.4         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41599         |\n",
      "|    policy_loss        | -0.331        |\n",
      "|    reward             | -0.0028853149 |\n",
      "|    std                | 3.88e+03      |\n",
      "|    value_loss         | 0.000407      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41700        |\n",
      "|    time_elapsed       | 625          |\n",
      "|    total_timesteps    | 208500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0.0472       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41699        |\n",
      "|    policy_loss        | -0.506       |\n",
      "|    reward             | -0.020755183 |\n",
      "|    std                | 4.01e+03     |\n",
      "|    value_loss         | 0.000736     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 41800        |\n",
      "|    time_elapsed       | 626          |\n",
      "|    total_timesteps    | 209000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41799        |\n",
      "|    policy_loss        | -0.101       |\n",
      "|    reward             | 0.0028785386 |\n",
      "|    std                | 4.11e+03     |\n",
      "|    value_loss         | 0.000293     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 41900       |\n",
      "|    time_elapsed       | 628         |\n",
      "|    total_timesteps    | 209500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41899       |\n",
      "|    policy_loss        | -0.0487     |\n",
      "|    reward             | 0.008829373 |\n",
      "|    std                | 4.25e+03    |\n",
      "|    value_loss         | 6.25e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 42000       |\n",
      "|    time_elapsed       | 629         |\n",
      "|    total_timesteps    | 210000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41999       |\n",
      "|    policy_loss        | -0.244      |\n",
      "|    reward             | 0.011647882 |\n",
      "|    std                | 4.42e+03    |\n",
      "|    value_loss         | 0.000179    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 42100         |\n",
      "|    time_elapsed       | 631           |\n",
      "|    total_timesteps    | 210500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42099         |\n",
      "|    policy_loss        | -0.143        |\n",
      "|    reward             | -0.0006957362 |\n",
      "|    std                | 4.57e+03      |\n",
      "|    value_loss         | 0.000165      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 42200         |\n",
      "|    time_elapsed       | 632           |\n",
      "|    total_timesteps    | 211000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.7         |\n",
      "|    explained_variance | -0.22         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42199         |\n",
      "|    policy_loss        | -0.168        |\n",
      "|    reward             | -0.0040206295 |\n",
      "|    std                | 4.77e+03      |\n",
      "|    value_loss         | 0.000141      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 42300        |\n",
      "|    time_elapsed       | 634          |\n",
      "|    total_timesteps    | 211500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42299        |\n",
      "|    policy_loss        | -0.247       |\n",
      "|    reward             | -0.025130598 |\n",
      "|    std                | 4.92e+03     |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 42400      |\n",
      "|    time_elapsed       | 635        |\n",
      "|    total_timesteps    | 212000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42399      |\n",
      "|    policy_loss        | 0.37       |\n",
      "|    reward             | 0.02237039 |\n",
      "|    std                | 5.05e+03   |\n",
      "|    value_loss         | 0.000471   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 42500        |\n",
      "|    time_elapsed       | 637          |\n",
      "|    total_timesteps    | 212500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42499        |\n",
      "|    policy_loss        | 0.561        |\n",
      "|    reward             | -0.006071883 |\n",
      "|    std                | 5.16e+03     |\n",
      "|    value_loss         | 0.000879     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 42600        |\n",
      "|    time_elapsed       | 638          |\n",
      "|    total_timesteps    | 213000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42599        |\n",
      "|    policy_loss        | 0.184        |\n",
      "|    reward             | 0.0006115629 |\n",
      "|    std                | 5.3e+03      |\n",
      "|    value_loss         | 0.000123     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 42700      |\n",
      "|    time_elapsed       | 640        |\n",
      "|    total_timesteps    | 213500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20        |\n",
      "|    explained_variance | 0.16       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42699      |\n",
      "|    policy_loss        | 0.106      |\n",
      "|    reward             | -0.0156457 |\n",
      "|    std                | 5.44e+03   |\n",
      "|    value_loss         | 0.000196   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 42800        |\n",
      "|    time_elapsed       | 641          |\n",
      "|    total_timesteps    | 214000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | -0.032       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42799        |\n",
      "|    policy_loss        | -0.874       |\n",
      "|    reward             | 0.0122661805 |\n",
      "|    std                | 5.69e+03     |\n",
      "|    value_loss         | 0.00425      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 643         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42899       |\n",
      "|    policy_loss        | -2.14       |\n",
      "|    reward             | -0.05838732 |\n",
      "|    std                | 5.8e+03     |\n",
      "|    value_loss         | 0.0127      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 43000         |\n",
      "|    time_elapsed       | 645           |\n",
      "|    total_timesteps    | 215000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42999         |\n",
      "|    policy_loss        | 1.12          |\n",
      "|    reward             | -0.0021693073 |\n",
      "|    std                | 5.84e+03      |\n",
      "|    value_loss         | 0.00516       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 43100        |\n",
      "|    time_elapsed       | 646          |\n",
      "|    total_timesteps    | 215500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43099        |\n",
      "|    policy_loss        | -1.51        |\n",
      "|    reward             | -0.064197205 |\n",
      "|    std                | 5.97e+03     |\n",
      "|    value_loss         | 0.00858      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 43200      |\n",
      "|    time_elapsed       | 648        |\n",
      "|    total_timesteps    | 216000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43199      |\n",
      "|    policy_loss        | 0.412      |\n",
      "|    reward             | 0.35162452 |\n",
      "|    std                | 6.01e+03   |\n",
      "|    value_loss         | 0.0011     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 43300       |\n",
      "|    time_elapsed       | 649         |\n",
      "|    total_timesteps    | 216500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | 0.193       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | -3.28       |\n",
      "|    reward             | -0.08908356 |\n",
      "|    std                | 6.09e+03    |\n",
      "|    value_loss         | 0.0385      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 43400        |\n",
      "|    time_elapsed       | 651          |\n",
      "|    total_timesteps    | 217000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43399        |\n",
      "|    policy_loss        | -4.1         |\n",
      "|    reward             | -0.121894814 |\n",
      "|    std                | 6.18e+03     |\n",
      "|    value_loss         | 0.0406       |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -269615.57\n",
      "total_reward: -279615.57\n",
      "total_cost: 98.56\n",
      "total_trades: 5792\n",
      "Sharpe: -0.366\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 43500       |\n",
      "|    time_elapsed       | 652         |\n",
      "|    total_timesteps    | 217500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43499       |\n",
      "|    policy_loss        | -0.415      |\n",
      "|    reward             | 0.033498604 |\n",
      "|    std                | 6.26e+03    |\n",
      "|    value_loss         | 0.000529    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 43600       |\n",
      "|    time_elapsed       | 654         |\n",
      "|    total_timesteps    | 218000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43599       |\n",
      "|    policy_loss        | 0.105       |\n",
      "|    reward             | -0.00943719 |\n",
      "|    std                | 6.37e+03    |\n",
      "|    value_loss         | 3.94e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 43700        |\n",
      "|    time_elapsed       | 655          |\n",
      "|    total_timesteps    | 218500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43699        |\n",
      "|    policy_loss        | -0.271       |\n",
      "|    reward             | -0.012362496 |\n",
      "|    std                | 6.45e+03     |\n",
      "|    value_loss         | 0.000258     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 43800         |\n",
      "|    time_elapsed       | 656           |\n",
      "|    total_timesteps    | 219000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | 2.38e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43799         |\n",
      "|    policy_loss        | 0.016         |\n",
      "|    reward             | -0.0015530416 |\n",
      "|    std                | 6.58e+03      |\n",
      "|    value_loss         | 5.28e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 43900         |\n",
      "|    time_elapsed       | 658           |\n",
      "|    total_timesteps    | 219500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43899         |\n",
      "|    policy_loss        | -0.182        |\n",
      "|    reward             | -0.0036514984 |\n",
      "|    std                | 6.8e+03       |\n",
      "|    value_loss         | 0.000141      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 44000        |\n",
      "|    time_elapsed       | 659          |\n",
      "|    total_timesteps    | 220000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | 0.445        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43999        |\n",
      "|    policy_loss        | -0.133       |\n",
      "|    reward             | -0.019263005 |\n",
      "|    std                | 7.04e+03     |\n",
      "|    value_loss         | 7.77e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 44100       |\n",
      "|    time_elapsed       | 661         |\n",
      "|    total_timesteps    | 220500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44099       |\n",
      "|    policy_loss        | 4.17        |\n",
      "|    reward             | 0.005298376 |\n",
      "|    std                | 7.12e+03    |\n",
      "|    value_loss         | 0.0589      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 44200        |\n",
      "|    time_elapsed       | 662          |\n",
      "|    total_timesteps    | 221000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44199        |\n",
      "|    policy_loss        | -0.752       |\n",
      "|    reward             | 0.0073965783 |\n",
      "|    std                | 7.2e+03      |\n",
      "|    value_loss         | 0.00151      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 44300        |\n",
      "|    time_elapsed       | 663          |\n",
      "|    total_timesteps    | 221500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -0.02        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44299        |\n",
      "|    policy_loss        | 0.0436       |\n",
      "|    reward             | -0.008008769 |\n",
      "|    std                | 7.3e+03      |\n",
      "|    value_loss         | 0.000187     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 44400         |\n",
      "|    time_elapsed       | 665           |\n",
      "|    total_timesteps    | 222000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 44399         |\n",
      "|    policy_loss        | 0.437         |\n",
      "|    reward             | -0.0010445145 |\n",
      "|    std                | 7.39e+03      |\n",
      "|    value_loss         | 0.00109       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 44500       |\n",
      "|    time_elapsed       | 666         |\n",
      "|    total_timesteps    | 222500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.248       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44499       |\n",
      "|    policy_loss        | 0.226       |\n",
      "|    reward             | 0.019336011 |\n",
      "|    std                | 7.55e+03    |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 44600       |\n",
      "|    time_elapsed       | 668         |\n",
      "|    total_timesteps    | 223000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44599       |\n",
      "|    policy_loss        | 0.795       |\n",
      "|    reward             | 0.017092159 |\n",
      "|    std                | 7.57e+03    |\n",
      "|    value_loss         | 0.00209     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 44700       |\n",
      "|    time_elapsed       | 669         |\n",
      "|    total_timesteps    | 223500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44699       |\n",
      "|    policy_loss        | -0.343      |\n",
      "|    reward             | 0.024999278 |\n",
      "|    std                | 7.68e+03    |\n",
      "|    value_loss         | 0.000585    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 44800       |\n",
      "|    time_elapsed       | 671         |\n",
      "|    total_timesteps    | 224000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44799       |\n",
      "|    policy_loss        | 0.328       |\n",
      "|    reward             | 0.015483498 |\n",
      "|    std                | 7.73e+03    |\n",
      "|    value_loss         | 0.000266    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 44900        |\n",
      "|    time_elapsed       | 672          |\n",
      "|    total_timesteps    | 224500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.7        |\n",
      "|    explained_variance | 0.0889       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44899        |\n",
      "|    policy_loss        | -0.773       |\n",
      "|    reward             | -0.010465018 |\n",
      "|    std                | 7.82e+03     |\n",
      "|    value_loss         | 0.00192      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 45000      |\n",
      "|    time_elapsed       | 674        |\n",
      "|    total_timesteps    | 225000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.8      |\n",
      "|    explained_variance | -0.0384    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44999      |\n",
      "|    policy_loss        | -0.385     |\n",
      "|    reward             | -0.0800102 |\n",
      "|    std                | 8.01e+03   |\n",
      "|    value_loss         | 0.0026     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 45100      |\n",
      "|    time_elapsed       | 675        |\n",
      "|    total_timesteps    | 225500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.8      |\n",
      "|    explained_variance | 0.00795    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45099      |\n",
      "|    policy_loss        | -1.51      |\n",
      "|    reward             | 0.03524962 |\n",
      "|    std                | 8.18e+03   |\n",
      "|    value_loss         | 0.00628    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 45200       |\n",
      "|    time_elapsed       | 677         |\n",
      "|    total_timesteps    | 226000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45199       |\n",
      "|    policy_loss        | 0.147       |\n",
      "|    reward             | 0.015048885 |\n",
      "|    std                | 8.24e+03    |\n",
      "|    value_loss         | 0.000272    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 45300        |\n",
      "|    time_elapsed       | 678          |\n",
      "|    total_timesteps    | 226500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45299        |\n",
      "|    policy_loss        | 0.745        |\n",
      "|    reward             | 0.0019174503 |\n",
      "|    std                | 8.4e+03      |\n",
      "|    value_loss         | 0.00156      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 45400        |\n",
      "|    time_elapsed       | 680          |\n",
      "|    total_timesteps    | 227000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45399        |\n",
      "|    policy_loss        | -0.332       |\n",
      "|    reward             | -0.015645431 |\n",
      "|    std                | 8.63e+03     |\n",
      "|    value_loss         | 0.000355     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 45500         |\n",
      "|    time_elapsed       | 681           |\n",
      "|    total_timesteps    | 227500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21           |\n",
      "|    explained_variance | 0.149         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45499         |\n",
      "|    policy_loss        | 0.283         |\n",
      "|    reward             | -0.0049411226 |\n",
      "|    std                | 8.91e+03      |\n",
      "|    value_loss         | 0.000196      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 45600         |\n",
      "|    time_elapsed       | 683           |\n",
      "|    total_timesteps    | 228000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.1         |\n",
      "|    explained_variance | 0.0264        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45599         |\n",
      "|    policy_loss        | 0.626         |\n",
      "|    reward             | -0.0040540677 |\n",
      "|    std                | 9.24e+03      |\n",
      "|    value_loss         | 0.00105       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 45700        |\n",
      "|    time_elapsed       | 685          |\n",
      "|    total_timesteps    | 228500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45699        |\n",
      "|    policy_loss        | 0.222        |\n",
      "|    reward             | -0.007604432 |\n",
      "|    std                | 9.58e+03     |\n",
      "|    value_loss         | 0.000228     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 45800         |\n",
      "|    time_elapsed       | 686           |\n",
      "|    total_timesteps    | 229000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45799         |\n",
      "|    policy_loss        | 0.0269        |\n",
      "|    reward             | -0.0069852322 |\n",
      "|    std                | 9.91e+03      |\n",
      "|    value_loss         | 6.25e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 45900        |\n",
      "|    time_elapsed       | 688          |\n",
      "|    total_timesteps    | 229500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45899        |\n",
      "|    policy_loss        | -0.235       |\n",
      "|    reward             | 0.0077625574 |\n",
      "|    std                | 1.03e+04     |\n",
      "|    value_loss         | 0.000245     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 46000      |\n",
      "|    time_elapsed       | 689        |\n",
      "|    total_timesteps    | 230000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45999      |\n",
      "|    policy_loss        | 0.147      |\n",
      "|    reward             | 0.01688793 |\n",
      "|    std                | 1.06e+04   |\n",
      "|    value_loss         | 9.04e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 46100         |\n",
      "|    time_elapsed       | 690           |\n",
      "|    total_timesteps    | 230500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 46099         |\n",
      "|    policy_loss        | -0.0467       |\n",
      "|    reward             | -0.0058179284 |\n",
      "|    std                | 1.11e+04      |\n",
      "|    value_loss         | 2.06e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 46200        |\n",
      "|    time_elapsed       | 692          |\n",
      "|    total_timesteps    | 231000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | -0.121       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46199        |\n",
      "|    policy_loss        | -0.265       |\n",
      "|    reward             | 0.0034726744 |\n",
      "|    std                | 1.16e+04     |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 46300        |\n",
      "|    time_elapsed       | 693          |\n",
      "|    total_timesteps    | 231500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -0.000118    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46299        |\n",
      "|    policy_loss        | -0.359       |\n",
      "|    reward             | -0.011845305 |\n",
      "|    std                | 1.18e+04     |\n",
      "|    value_loss         | 0.000339     |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -10848.25\n",
      "total_reward: -20848.25\n",
      "total_cost: 579.36\n",
      "total_trades: 5792\n",
      "Sharpe: -0.170\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 46400        |\n",
      "|    time_elapsed       | 695          |\n",
      "|    total_timesteps    | 232000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46399        |\n",
      "|    policy_loss        | -0.779       |\n",
      "|    reward             | 0.0142905405 |\n",
      "|    std                | 1.21e+04     |\n",
      "|    value_loss         | 0.00454      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 46500        |\n",
      "|    time_elapsed       | 696          |\n",
      "|    total_timesteps    | 232500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46499        |\n",
      "|    policy_loss        | -0.915       |\n",
      "|    reward             | -0.010683978 |\n",
      "|    std                | 1.23e+04     |\n",
      "|    value_loss         | 0.00228      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 46600      |\n",
      "|    time_elapsed       | 698        |\n",
      "|    total_timesteps    | 233000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46599      |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | 0.13469288 |\n",
      "|    std                | 1.26e+04   |\n",
      "|    value_loss         | 0.382      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 46700       |\n",
      "|    time_elapsed       | 699         |\n",
      "|    total_timesteps    | 233500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46699       |\n",
      "|    policy_loss        | -4.85       |\n",
      "|    reward             | -0.18743457 |\n",
      "|    std                | 1.27e+04    |\n",
      "|    value_loss         | 0.0652      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 46800      |\n",
      "|    time_elapsed       | 701        |\n",
      "|    total_timesteps    | 234000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46799      |\n",
      "|    policy_loss        | -0.982     |\n",
      "|    reward             | 0.17224984 |\n",
      "|    std                | 1.27e+04   |\n",
      "|    value_loss         | 0.0113     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 46900       |\n",
      "|    time_elapsed       | 702         |\n",
      "|    total_timesteps    | 234500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46899       |\n",
      "|    policy_loss        | -7.39       |\n",
      "|    reward             | -0.32594618 |\n",
      "|    std                | 1.31e+04    |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 47000       |\n",
      "|    time_elapsed       | 704         |\n",
      "|    total_timesteps    | 235000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46999       |\n",
      "|    policy_loss        | 1.3         |\n",
      "|    reward             | 0.039728653 |\n",
      "|    std                | 1.31e+04    |\n",
      "|    value_loss         | 0.00639     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 47100        |\n",
      "|    time_elapsed       | 705          |\n",
      "|    total_timesteps    | 235500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47099        |\n",
      "|    policy_loss        | 0.321        |\n",
      "|    reward             | -0.011795785 |\n",
      "|    std                | 1.32e+04     |\n",
      "|    value_loss         | 0.0003       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 47200         |\n",
      "|    time_elapsed       | 706           |\n",
      "|    total_timesteps    | 236000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.8         |\n",
      "|    explained_variance | -6.89         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47199         |\n",
      "|    policy_loss        | -3.02         |\n",
      "|    reward             | -0.0055295895 |\n",
      "|    std                | 1.35e+04      |\n",
      "|    value_loss         | 0.0257        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 47300       |\n",
      "|    time_elapsed       | 708         |\n",
      "|    total_timesteps    | 236500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 8.05e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47299       |\n",
      "|    policy_loss        | -0.0113     |\n",
      "|    reward             | 0.043244366 |\n",
      "|    std                | 1.38e+04    |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 47400        |\n",
      "|    time_elapsed       | 709          |\n",
      "|    total_timesteps    | 237000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47399        |\n",
      "|    policy_loss        | -0.0295      |\n",
      "|    reward             | -0.020834047 |\n",
      "|    std                | 1.41e+04     |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 47500      |\n",
      "|    time_elapsed       | 711        |\n",
      "|    total_timesteps    | 237500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47499      |\n",
      "|    policy_loss        | -2.22      |\n",
      "|    reward             | 0.03493964 |\n",
      "|    std                | 1.42e+04   |\n",
      "|    value_loss         | 0.0122     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 47600        |\n",
      "|    time_elapsed       | 712          |\n",
      "|    total_timesteps    | 238000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47599        |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | -0.010592167 |\n",
      "|    std                | 1.45e+04     |\n",
      "|    value_loss         | 0.00116      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 47700        |\n",
      "|    time_elapsed       | 714          |\n",
      "|    total_timesteps    | 238500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47699        |\n",
      "|    policy_loss        | 0.0884       |\n",
      "|    reward             | -0.019643597 |\n",
      "|    std                | 1.47e+04     |\n",
      "|    value_loss         | 0.000301     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 47800        |\n",
      "|    time_elapsed       | 715          |\n",
      "|    total_timesteps    | 239000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47799        |\n",
      "|    policy_loss        | -0.119       |\n",
      "|    reward             | -0.015441256 |\n",
      "|    std                | 1.51e+04     |\n",
      "|    value_loss         | 0.00022      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 47900       |\n",
      "|    time_elapsed       | 717         |\n",
      "|    total_timesteps    | 239500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0.374       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47899       |\n",
      "|    policy_loss        | 0.29        |\n",
      "|    reward             | 0.009586156 |\n",
      "|    std                | 1.55e+04    |\n",
      "|    value_loss         | 0.000182    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 48000         |\n",
      "|    time_elapsed       | 718           |\n",
      "|    total_timesteps    | 240000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.2         |\n",
      "|    explained_variance | 0.199         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47999         |\n",
      "|    policy_loss        | -0.949        |\n",
      "|    reward             | -0.0011103028 |\n",
      "|    std                | 1.59e+04      |\n",
      "|    value_loss         | 0.00214       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 48100        |\n",
      "|    time_elapsed       | 720          |\n",
      "|    total_timesteps    | 240500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48099        |\n",
      "|    policy_loss        | 2.81         |\n",
      "|    reward             | -0.020549629 |\n",
      "|    std                | 1.58e+04     |\n",
      "|    value_loss         | 0.0181       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 48200        |\n",
      "|    time_elapsed       | 722          |\n",
      "|    total_timesteps    | 241000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48199        |\n",
      "|    policy_loss        | -2.31        |\n",
      "|    reward             | -0.040610176 |\n",
      "|    std                | 1.6e+04      |\n",
      "|    value_loss         | 0.0129       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 48300         |\n",
      "|    time_elapsed       | 723           |\n",
      "|    total_timesteps    | 241500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 48299         |\n",
      "|    policy_loss        | -0.728        |\n",
      "|    reward             | -0.0051244893 |\n",
      "|    std                | 1.61e+04      |\n",
      "|    value_loss         | 0.00147       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 333            |\n",
      "|    iterations         | 48400          |\n",
      "|    time_elapsed       | 724            |\n",
      "|    total_timesteps    | 242000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -22.2          |\n",
      "|    explained_variance | 0.0116         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 48399          |\n",
      "|    policy_loss        | -0.51          |\n",
      "|    reward             | -0.00012378387 |\n",
      "|    std                | 1.64e+04       |\n",
      "|    value_loss         | 0.000836       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 726         |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | 0.089       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48499       |\n",
      "|    policy_loss        | 2.77        |\n",
      "|    reward             | 0.016267035 |\n",
      "|    std                | 1.69e+04    |\n",
      "|    value_loss         | 0.0155      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 48600        |\n",
      "|    time_elapsed       | 727          |\n",
      "|    total_timesteps    | 243000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | 0.0601       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48599        |\n",
      "|    policy_loss        | -2.35        |\n",
      "|    reward             | -0.088606656 |\n",
      "|    std                | 1.73e+04     |\n",
      "|    value_loss         | 0.013        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 48700        |\n",
      "|    time_elapsed       | 729          |\n",
      "|    total_timesteps    | 243500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48699        |\n",
      "|    policy_loss        | -0.418       |\n",
      "|    reward             | -0.011697786 |\n",
      "|    std                | 1.75e+04     |\n",
      "|    value_loss         | 0.000369     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 48800        |\n",
      "|    time_elapsed       | 730          |\n",
      "|    total_timesteps    | 244000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48799        |\n",
      "|    policy_loss        | 0.398        |\n",
      "|    reward             | -0.027173316 |\n",
      "|    std                | 1.77e+04     |\n",
      "|    value_loss         | 0.000521     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 48900        |\n",
      "|    time_elapsed       | 732          |\n",
      "|    total_timesteps    | 244500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48899        |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | -0.017258318 |\n",
      "|    std                | 1.81e+04     |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 733         |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | 0.302       |\n",
      "|    reward             | 0.004453103 |\n",
      "|    std                | 1.86e+04    |\n",
      "|    value_loss         | 0.00033     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49100       |\n",
      "|    time_elapsed       | 734         |\n",
      "|    total_timesteps    | 245500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0.519       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49099       |\n",
      "|    policy_loss        | -0.0488     |\n",
      "|    reward             | 0.002553728 |\n",
      "|    std                | 1.93e+04    |\n",
      "|    value_loss         | 4.75e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49200       |\n",
      "|    time_elapsed       | 736         |\n",
      "|    total_timesteps    | 246000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49199       |\n",
      "|    policy_loss        | 0.0452      |\n",
      "|    reward             | 0.001280101 |\n",
      "|    std                | 1.99e+04    |\n",
      "|    value_loss         | 9.34e-05    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -14729.14\n",
      "total_reward: -24729.14\n",
      "total_cost: 391.71\n",
      "total_trades: 5792\n",
      "Sharpe: 0.490\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49300       |\n",
      "|    time_elapsed       | 737         |\n",
      "|    total_timesteps    | 246500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.7       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49299       |\n",
      "|    policy_loss        | -0.592      |\n",
      "|    reward             | -0.06306131 |\n",
      "|    std                | 2.05e+04    |\n",
      "|    value_loss         | 0.000873    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49400       |\n",
      "|    time_elapsed       | 739         |\n",
      "|    total_timesteps    | 247000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49399       |\n",
      "|    policy_loss        | -0.00705    |\n",
      "|    reward             | 0.014558434 |\n",
      "|    std                | 2.1e+04     |\n",
      "|    value_loss         | 0.000382    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49500       |\n",
      "|    time_elapsed       | 740         |\n",
      "|    total_timesteps    | 247500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | -0.17       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49499       |\n",
      "|    policy_loss        | -0.404      |\n",
      "|    reward             | -0.01998926 |\n",
      "|    std                | 2.15e+04    |\n",
      "|    value_loss         | 0.000565    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 49600        |\n",
      "|    time_elapsed       | 742          |\n",
      "|    total_timesteps    | 248000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | -0.967       |\n",
      "|    reward             | -0.012848966 |\n",
      "|    std                | 2.21e+04     |\n",
      "|    value_loss         | 0.00199      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49700       |\n",
      "|    time_elapsed       | 743         |\n",
      "|    total_timesteps    | 248500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0.247       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | -0.319      |\n",
      "|    reward             | -0.02183525 |\n",
      "|    std                | 2.23e+04    |\n",
      "|    value_loss         | 0.000723    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 49800       |\n",
      "|    time_elapsed       | 745         |\n",
      "|    total_timesteps    | 249000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | 0.085       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49799       |\n",
      "|    policy_loss        | 3.91        |\n",
      "|    reward             | 0.016182879 |\n",
      "|    std                | 2.29e+04    |\n",
      "|    value_loss         | 0.0416      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 49900         |\n",
      "|    time_elapsed       | 746           |\n",
      "|    total_timesteps    | 249500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49899         |\n",
      "|    policy_loss        | -1.22         |\n",
      "|    reward             | -0.0025134822 |\n",
      "|    std                | 2.32e+04      |\n",
      "|    value_loss         | 0.00384       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 50000        |\n",
      "|    time_elapsed       | 748          |\n",
      "|    total_timesteps    | 250000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49999        |\n",
      "|    policy_loss        | 0.00367      |\n",
      "|    reward             | -0.016913217 |\n",
      "|    std                | 2.36e+04     |\n",
      "|    value_loss         | 1.48e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 50100       |\n",
      "|    time_elapsed       | 749         |\n",
      "|    total_timesteps    | 250500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50099       |\n",
      "|    policy_loss        | 0.0256      |\n",
      "|    reward             | 0.021550396 |\n",
      "|    std                | 2.44e+04    |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 50200       |\n",
      "|    time_elapsed       | 751         |\n",
      "|    total_timesteps    | 251000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.1       |\n",
      "|    explained_variance | 0.257       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50199       |\n",
      "|    policy_loss        | 0.567       |\n",
      "|    reward             | 0.015623844 |\n",
      "|    std                | 2.52e+04    |\n",
      "|    value_loss         | 0.000626    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 50300      |\n",
      "|    time_elapsed       | 752        |\n",
      "|    total_timesteps    | 251500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.2      |\n",
      "|    explained_variance | -0.0791    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50299      |\n",
      "|    policy_loss        | 0.18       |\n",
      "|    reward             | 0.02568482 |\n",
      "|    std                | 2.64e+04   |\n",
      "|    value_loss         | 0.000345   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 50400        |\n",
      "|    time_elapsed       | 753          |\n",
      "|    total_timesteps    | 252000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50399        |\n",
      "|    policy_loss        | -0.169       |\n",
      "|    reward             | -0.002664557 |\n",
      "|    std                | 2.78e+04     |\n",
      "|    value_loss         | 0.000125     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 50500         |\n",
      "|    time_elapsed       | 755           |\n",
      "|    total_timesteps    | 252500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50499         |\n",
      "|    policy_loss        | -0.256        |\n",
      "|    reward             | -0.0020093985 |\n",
      "|    std                | 2.85e+04      |\n",
      "|    value_loss         | 0.000636      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 50600         |\n",
      "|    time_elapsed       | 756           |\n",
      "|    total_timesteps    | 253000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50599         |\n",
      "|    policy_loss        | -0.174        |\n",
      "|    reward             | -0.0019666096 |\n",
      "|    std                | 2.93e+04      |\n",
      "|    value_loss         | 0.000187      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 50700         |\n",
      "|    time_elapsed       | 758           |\n",
      "|    total_timesteps    | 253500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50699         |\n",
      "|    policy_loss        | 0.919         |\n",
      "|    reward             | -0.0015052964 |\n",
      "|    std                | 3.01e+04      |\n",
      "|    value_loss         | 0.00173       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 50800        |\n",
      "|    time_elapsed       | 759          |\n",
      "|    total_timesteps    | 254000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0.132        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50799        |\n",
      "|    policy_loss        | -0.346       |\n",
      "|    reward             | 0.0036029958 |\n",
      "|    std                | 3.14e+04     |\n",
      "|    value_loss         | 0.000376     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 50900        |\n",
      "|    time_elapsed       | 761          |\n",
      "|    total_timesteps    | 254500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50899        |\n",
      "|    policy_loss        | 0.244        |\n",
      "|    reward             | 0.0055544577 |\n",
      "|    std                | 3.31e+04     |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 51000       |\n",
      "|    time_elapsed       | 762         |\n",
      "|    total_timesteps    | 255000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50999       |\n",
      "|    policy_loss        | 2.8         |\n",
      "|    reward             | 0.018471114 |\n",
      "|    std                | 3.39e+04    |\n",
      "|    value_loss         | 0.0186      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 51100        |\n",
      "|    time_elapsed       | 764          |\n",
      "|    total_timesteps    | 255500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51099        |\n",
      "|    policy_loss        | -1.55        |\n",
      "|    reward             | -0.015932007 |\n",
      "|    std                | 3.47e+04     |\n",
      "|    value_loss         | 0.00477      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 51200       |\n",
      "|    time_elapsed       | 765         |\n",
      "|    total_timesteps    | 256000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51199       |\n",
      "|    policy_loss        | 0.0898      |\n",
      "|    reward             | 0.011985942 |\n",
      "|    std                | 3.56e+04    |\n",
      "|    value_loss         | 0.000133    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 51300       |\n",
      "|    time_elapsed       | 767         |\n",
      "|    total_timesteps    | 256500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51299       |\n",
      "|    policy_loss        | 0.57        |\n",
      "|    reward             | 0.008213894 |\n",
      "|    std                | 3.6e+04     |\n",
      "|    value_loss         | 0.000549    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 51400        |\n",
      "|    time_elapsed       | 768          |\n",
      "|    total_timesteps    | 257000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0.076        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51399        |\n",
      "|    policy_loss        | -1.44        |\n",
      "|    reward             | -0.005812358 |\n",
      "|    std                | 3.71e+04     |\n",
      "|    value_loss         | 0.00402      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 770         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | -0.035      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | -1.87       |\n",
      "|    reward             | 0.016912367 |\n",
      "|    std                | 3.8e+04     |\n",
      "|    value_loss         | 0.00704     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 51600      |\n",
      "|    time_elapsed       | 771        |\n",
      "|    total_timesteps    | 258000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51599      |\n",
      "|    policy_loss        | -0.115     |\n",
      "|    reward             | 0.01962016 |\n",
      "|    std                | 3.91e+04   |\n",
      "|    value_loss         | 0.000556   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 51700      |\n",
      "|    time_elapsed       | 772        |\n",
      "|    total_timesteps    | 258500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51699      |\n",
      "|    policy_loss        | 0.443      |\n",
      "|    reward             | -0.0179732 |\n",
      "|    std                | 3.93e+04   |\n",
      "|    value_loss         | 0.000366   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 51800        |\n",
      "|    time_elapsed       | 774          |\n",
      "|    total_timesteps    | 259000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51799        |\n",
      "|    policy_loss        | -0.0548      |\n",
      "|    reward             | -0.009727352 |\n",
      "|    std                | 4.01e+04     |\n",
      "|    value_loss         | 4.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 51900        |\n",
      "|    time_elapsed       | 775          |\n",
      "|    total_timesteps    | 259500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51899        |\n",
      "|    policy_loss        | -0.237       |\n",
      "|    reward             | 0.0055064266 |\n",
      "|    std                | 4.12e+04     |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 52000        |\n",
      "|    time_elapsed       | 777          |\n",
      "|    total_timesteps    | 260000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 0.0728       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51999        |\n",
      "|    policy_loss        | -0.665       |\n",
      "|    reward             | -0.020606602 |\n",
      "|    std                | 4.27e+04     |\n",
      "|    value_loss         | 0.00086      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 52100        |\n",
      "|    time_elapsed       | 778          |\n",
      "|    total_timesteps    | 260500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0.0989       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52099        |\n",
      "|    policy_loss        | 0.442        |\n",
      "|    reward             | -0.012474433 |\n",
      "|    std                | 4.4e+04      |\n",
      "|    value_loss         | 0.000411     |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -14599.54\n",
      "total_reward: -24599.54\n",
      "total_cost: 435.28\n",
      "total_trades: 5792\n",
      "Sharpe: -0.236\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 52200        |\n",
      "|    time_elapsed       | 780          |\n",
      "|    total_timesteps    | 261000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52199        |\n",
      "|    policy_loss        | -0.0783      |\n",
      "|    reward             | -0.029025327 |\n",
      "|    std                | 4.53e+04     |\n",
      "|    value_loss         | 0.00036      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 52300         |\n",
      "|    time_elapsed       | 781           |\n",
      "|    total_timesteps    | 261500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 52299         |\n",
      "|    policy_loss        | 0.883         |\n",
      "|    reward             | -0.0043975958 |\n",
      "|    std                | 4.6e+04       |\n",
      "|    value_loss         | 0.00142       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 52400        |\n",
      "|    time_elapsed       | 783          |\n",
      "|    total_timesteps    | 262000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52399        |\n",
      "|    policy_loss        | 0.0985       |\n",
      "|    reward             | -0.004950323 |\n",
      "|    std                | 4.73e+04     |\n",
      "|    value_loss         | 2.82e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 52500       |\n",
      "|    time_elapsed       | 785         |\n",
      "|    total_timesteps    | 262500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52499       |\n",
      "|    policy_loss        | 0.229       |\n",
      "|    reward             | 0.015892109 |\n",
      "|    std                | 4.87e+04    |\n",
      "|    value_loss         | 0.000106    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 52600        |\n",
      "|    time_elapsed       | 786          |\n",
      "|    total_timesteps    | 263000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.5        |\n",
      "|    explained_variance | 0.0601       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52599        |\n",
      "|    policy_loss        | -0.0337      |\n",
      "|    reward             | 0.0021864579 |\n",
      "|    std                | 5.06e+04     |\n",
      "|    value_loss         | 2.97e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 52700       |\n",
      "|    time_elapsed       | 787         |\n",
      "|    total_timesteps    | 263500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0.0276      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52699       |\n",
      "|    policy_loss        | -0.734      |\n",
      "|    reward             | -0.02705741 |\n",
      "|    std                | 5.23e+04    |\n",
      "|    value_loss         | 0.00108     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 52800       |\n",
      "|    time_elapsed       | 789         |\n",
      "|    total_timesteps    | 264000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52799       |\n",
      "|    policy_loss        | -3.07       |\n",
      "|    reward             | 0.088358395 |\n",
      "|    std                | 5.27e+04    |\n",
      "|    value_loss         | 0.0203      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 790         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | -0.011      |\n",
      "|    reward             | -0.01457456 |\n",
      "|    std                | 5.34e+04    |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 53000        |\n",
      "|    time_elapsed       | 792          |\n",
      "|    total_timesteps    | 265000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | -0.00379     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52999        |\n",
      "|    policy_loss        | -0.899       |\n",
      "|    reward             | -0.022989148 |\n",
      "|    std                | 5.49e+04     |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 53100       |\n",
      "|    time_elapsed       | 793         |\n",
      "|    total_timesteps    | 265500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0.0978      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53099       |\n",
      "|    policy_loss        | -0.887      |\n",
      "|    reward             | 0.013737123 |\n",
      "|    std                | 5.61e+04    |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 53200       |\n",
      "|    time_elapsed       | 795         |\n",
      "|    total_timesteps    | 266000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0.0494      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53199       |\n",
      "|    policy_loss        | 0.758       |\n",
      "|    reward             | -0.07420017 |\n",
      "|    std                | 5.77e+04    |\n",
      "|    value_loss         | 0.00321     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 53300        |\n",
      "|    time_elapsed       | 796          |\n",
      "|    total_timesteps    | 266500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53299        |\n",
      "|    policy_loss        | -1.94        |\n",
      "|    reward             | -0.051383905 |\n",
      "|    std                | 5.83e+04     |\n",
      "|    value_loss         | 0.00765      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 53400       |\n",
      "|    time_elapsed       | 798         |\n",
      "|    total_timesteps    | 267000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53399       |\n",
      "|    policy_loss        | 1.16        |\n",
      "|    reward             | 0.014372503 |\n",
      "|    std                | 5.85e+04    |\n",
      "|    value_loss         | 0.00255     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 53500         |\n",
      "|    time_elapsed       | 799           |\n",
      "|    total_timesteps    | 267500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53499         |\n",
      "|    policy_loss        | -1.04         |\n",
      "|    reward             | -0.0007460148 |\n",
      "|    std                | 5.95e+04      |\n",
      "|    value_loss         | 0.00314       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 53600     |\n",
      "|    time_elapsed       | 801       |\n",
      "|    total_timesteps    | 268000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24.8     |\n",
      "|    explained_variance | 6.97e-06  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 53599     |\n",
      "|    policy_loss        | -0.419    |\n",
      "|    reward             | 0.0196793 |\n",
      "|    std                | 6.01e+04  |\n",
      "|    value_loss         | 0.000806  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 53700       |\n",
      "|    time_elapsed       | 802         |\n",
      "|    total_timesteps    | 268500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0.104       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53699       |\n",
      "|    policy_loss        | 1.52        |\n",
      "|    reward             | -0.04445451 |\n",
      "|    std                | 6.11e+04    |\n",
      "|    value_loss         | 0.00419     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 53800       |\n",
      "|    time_elapsed       | 804         |\n",
      "|    total_timesteps    | 269000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53799       |\n",
      "|    policy_loss        | 1.98        |\n",
      "|    reward             | 0.008487616 |\n",
      "|    std                | 6.13e+04    |\n",
      "|    value_loss         | 0.00662     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 334            |\n",
      "|    iterations         | 53900          |\n",
      "|    time_elapsed       | 805            |\n",
      "|    total_timesteps    | 269500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -24.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 53899          |\n",
      "|    policy_loss        | 0.734          |\n",
      "|    reward             | -9.3894305e-05 |\n",
      "|    std                | 6.09e+04       |\n",
      "|    value_loss         | 0.00149        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 54000        |\n",
      "|    time_elapsed       | 807          |\n",
      "|    total_timesteps    | 270000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53999        |\n",
      "|    policy_loss        | 1.48         |\n",
      "|    reward             | -0.032866415 |\n",
      "|    std                | 6.18e+04     |\n",
      "|    value_loss         | 0.00551      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 54100        |\n",
      "|    time_elapsed       | 808          |\n",
      "|    total_timesteps    | 270500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54099        |\n",
      "|    policy_loss        | 0.447        |\n",
      "|    reward             | -0.004815953 |\n",
      "|    std                | 6.33e+04     |\n",
      "|    value_loss         | 0.000459     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 54200       |\n",
      "|    time_elapsed       | 810         |\n",
      "|    total_timesteps    | 271000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0.131       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54199       |\n",
      "|    policy_loss        | -0.795      |\n",
      "|    reward             | -0.01087456 |\n",
      "|    std                | 6.42e+04    |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 54300       |\n",
      "|    time_elapsed       | 811         |\n",
      "|    total_timesteps    | 271500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0.365       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54299       |\n",
      "|    policy_loss        | 1.63        |\n",
      "|    reward             | -0.03897058 |\n",
      "|    std                | 6.6e+04     |\n",
      "|    value_loss         | 0.00496     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 54400        |\n",
      "|    time_elapsed       | 813          |\n",
      "|    total_timesteps    | 272000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54399        |\n",
      "|    policy_loss        | -0.0532      |\n",
      "|    reward             | -0.045365985 |\n",
      "|    std                | 6.69e+04     |\n",
      "|    value_loss         | 0.000677     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 54500        |\n",
      "|    time_elapsed       | 814          |\n",
      "|    total_timesteps    | 272500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54499        |\n",
      "|    policy_loss        | -0.641       |\n",
      "|    reward             | 0.0016611923 |\n",
      "|    std                | 6.75e+04     |\n",
      "|    value_loss         | 0.000847     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 54600       |\n",
      "|    time_elapsed       | 816         |\n",
      "|    total_timesteps    | 273000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54599       |\n",
      "|    policy_loss        | 0.402       |\n",
      "|    reward             | 0.026165694 |\n",
      "|    std                | 6.82e+04    |\n",
      "|    value_loss         | 0.000274    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 54700      |\n",
      "|    time_elapsed       | 817        |\n",
      "|    total_timesteps    | 273500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54699      |\n",
      "|    policy_loss        | -0.126     |\n",
      "|    reward             | 0.02281801 |\n",
      "|    std                | 6.98e+04   |\n",
      "|    value_loss         | 0.00012    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 54800        |\n",
      "|    time_elapsed       | 819          |\n",
      "|    total_timesteps    | 274000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54799        |\n",
      "|    policy_loss        | 0.242        |\n",
      "|    reward             | -0.007459258 |\n",
      "|    std                | 7.13e+04     |\n",
      "|    value_loss         | 0.000116     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 54900        |\n",
      "|    time_elapsed       | 820          |\n",
      "|    total_timesteps    | 274500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.516        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54899        |\n",
      "|    policy_loss        | -0.0994      |\n",
      "|    reward             | -0.001336171 |\n",
      "|    std                | 7.4e+04      |\n",
      "|    value_loss         | 8.42e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 55000       |\n",
      "|    time_elapsed       | 822         |\n",
      "|    total_timesteps    | 275000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0.0666      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54999       |\n",
      "|    policy_loss        | -0.231      |\n",
      "|    reward             | -0.02196049 |\n",
      "|    std                | 7.61e+04    |\n",
      "|    value_loss         | 0.000155    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -16782.87\n",
      "total_reward: -26782.87\n",
      "total_cost: 230.62\n",
      "total_trades: 5792\n",
      "Sharpe: -0.071\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 55100       |\n",
      "|    time_elapsed       | 824         |\n",
      "|    total_timesteps    | 275500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55099       |\n",
      "|    policy_loss        | -1.36       |\n",
      "|    reward             | -0.01869284 |\n",
      "|    std                | 7.81e+04    |\n",
      "|    value_loss         | 0.00521     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 55200        |\n",
      "|    time_elapsed       | 825          |\n",
      "|    total_timesteps    | 276000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55199        |\n",
      "|    policy_loss        | -0.992       |\n",
      "|    reward             | -0.023449197 |\n",
      "|    std                | 8.03e+04     |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 55300        |\n",
      "|    time_elapsed       | 827          |\n",
      "|    total_timesteps    | 276500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.5        |\n",
      "|    explained_variance | 0.397        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55299        |\n",
      "|    policy_loss        | 0.0842       |\n",
      "|    reward             | 0.0008301956 |\n",
      "|    std                | 8.26e+04     |\n",
      "|    value_loss         | 5.86e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 55400         |\n",
      "|    time_elapsed       | 828           |\n",
      "|    total_timesteps    | 277000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.5         |\n",
      "|    explained_variance | -0.147        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55399         |\n",
      "|    policy_loss        | -0.504        |\n",
      "|    reward             | -0.0011471191 |\n",
      "|    std                | 8.45e+04      |\n",
      "|    value_loss         | 0.000582      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 55500       |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 277500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0.194       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55499       |\n",
      "|    policy_loss        | 0.506       |\n",
      "|    reward             | 0.009590106 |\n",
      "|    std                | 8.66e+04    |\n",
      "|    value_loss         | 0.000582    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 55600        |\n",
      "|    time_elapsed       | 832          |\n",
      "|    total_timesteps    | 278000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0.59         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55599        |\n",
      "|    policy_loss        | 1.67         |\n",
      "|    reward             | -0.027937658 |\n",
      "|    std                | 8.85e+04     |\n",
      "|    value_loss         | 0.00427      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 55700      |\n",
      "|    time_elapsed       | 833        |\n",
      "|    total_timesteps    | 278500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55699      |\n",
      "|    policy_loss        | -0.835     |\n",
      "|    reward             | 0.01212805 |\n",
      "|    std                | 9.08e+04   |\n",
      "|    value_loss         | 0.00132    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 55800        |\n",
      "|    time_elapsed       | 835          |\n",
      "|    total_timesteps    | 279000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55799        |\n",
      "|    policy_loss        | 0.164        |\n",
      "|    reward             | -0.018003825 |\n",
      "|    std                | 9.32e+04     |\n",
      "|    value_loss         | 4.42e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 55900      |\n",
      "|    time_elapsed       | 836        |\n",
      "|    total_timesteps    | 279500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55899      |\n",
      "|    policy_loss        | 0.51       |\n",
      "|    reward             | 0.01746996 |\n",
      "|    std                | 9.58e+04   |\n",
      "|    value_loss         | 0.000465   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 56000         |\n",
      "|    time_elapsed       | 838           |\n",
      "|    total_timesteps    | 280000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.8         |\n",
      "|    explained_variance | -0.00311      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55999         |\n",
      "|    policy_loss        | 0.381         |\n",
      "|    reward             | -0.0005253113 |\n",
      "|    std                | 9.96e+04      |\n",
      "|    value_loss         | 0.000273      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 56100         |\n",
      "|    time_elapsed       | 839           |\n",
      "|    total_timesteps    | 280500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.9         |\n",
      "|    explained_variance | -0.205        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56099         |\n",
      "|    policy_loss        | 0.0863        |\n",
      "|    reward             | -0.0021345809 |\n",
      "|    std                | 1.03e+05      |\n",
      "|    value_loss         | 0.000126      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 334            |\n",
      "|    iterations         | 56200          |\n",
      "|    time_elapsed       | 841            |\n",
      "|    total_timesteps    | 281000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -26            |\n",
      "|    explained_variance | 0.0685         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 56199          |\n",
      "|    policy_loss        | 0.541          |\n",
      "|    reward             | -0.00012893982 |\n",
      "|    std                | 1.09e+05       |\n",
      "|    value_loss         | 0.000569       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 56300       |\n",
      "|    time_elapsed       | 842         |\n",
      "|    total_timesteps    | 281500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56299       |\n",
      "|    policy_loss        | 3.48        |\n",
      "|    reward             | -0.09355649 |\n",
      "|    std                | 1.13e+05    |\n",
      "|    value_loss         | 0.0225      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 56400       |\n",
      "|    time_elapsed       | 844         |\n",
      "|    total_timesteps    | 282000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56399       |\n",
      "|    policy_loss        | -2.99       |\n",
      "|    reward             | 0.053027637 |\n",
      "|    std                | 1.15e+05    |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 56500       |\n",
      "|    time_elapsed       | 845         |\n",
      "|    total_timesteps    | 282500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | 0.0101      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56499       |\n",
      "|    policy_loss        | -2.11       |\n",
      "|    reward             | -0.37333503 |\n",
      "|    std                | 1.17e+05    |\n",
      "|    value_loss         | 0.00979     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 56600      |\n",
      "|    time_elapsed       | 847        |\n",
      "|    total_timesteps    | 283000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0.105      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56599      |\n",
      "|    policy_loss        | 0.828      |\n",
      "|    reward             | 0.23990318 |\n",
      "|    std                | 1.17e+05   |\n",
      "|    value_loss         | 0.00867    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 333       |\n",
      "|    iterations         | 56700     |\n",
      "|    time_elapsed       | 848       |\n",
      "|    total_timesteps    | 283500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -26.2     |\n",
      "|    explained_variance | 0.157     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 56699     |\n",
      "|    policy_loss        | 11.1      |\n",
      "|    reward             | 0.4523298 |\n",
      "|    std                | 1.18e+05  |\n",
      "|    value_loss         | 0.218     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 56800        |\n",
      "|    time_elapsed       | 850          |\n",
      "|    total_timesteps    | 284000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56799        |\n",
      "|    policy_loss        | -1.63        |\n",
      "|    reward             | -0.023813723 |\n",
      "|    std                | 1.19e+05     |\n",
      "|    value_loss         | 0.00507      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 56900        |\n",
      "|    time_elapsed       | 851          |\n",
      "|    total_timesteps    | 284500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56899        |\n",
      "|    policy_loss        | -1.87        |\n",
      "|    reward             | -0.011905327 |\n",
      "|    std                | 1.21e+05     |\n",
      "|    value_loss         | 0.0115       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 57000        |\n",
      "|    time_elapsed       | 853          |\n",
      "|    total_timesteps    | 285000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56999        |\n",
      "|    policy_loss        | 2            |\n",
      "|    reward             | -0.014323201 |\n",
      "|    std                | 1.22e+05     |\n",
      "|    value_loss         | 0.0195       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 57100      |\n",
      "|    time_elapsed       | 854        |\n",
      "|    total_timesteps    | 285500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0.647      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57099      |\n",
      "|    policy_loss        | 2.4        |\n",
      "|    reward             | -0.0854749 |\n",
      "|    std                | 1.22e+05   |\n",
      "|    value_loss         | 0.0104     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 57200      |\n",
      "|    time_elapsed       | 855        |\n",
      "|    total_timesteps    | 286000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57199      |\n",
      "|    policy_loss        | -4.87      |\n",
      "|    reward             | 0.16208975 |\n",
      "|    std                | 1.22e+05   |\n",
      "|    value_loss         | 0.0681     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 57300       |\n",
      "|    time_elapsed       | 857         |\n",
      "|    total_timesteps    | 286500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | 0.00545     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57299       |\n",
      "|    policy_loss        | 7.44        |\n",
      "|    reward             | 0.032683995 |\n",
      "|    std                | 1.21e+05    |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 57400        |\n",
      "|    time_elapsed       | 859          |\n",
      "|    total_timesteps    | 287000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57399        |\n",
      "|    policy_loss        | 0.95         |\n",
      "|    reward             | -0.023541613 |\n",
      "|    std                | 1.21e+05     |\n",
      "|    value_loss         | 0.00153      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 57500        |\n",
      "|    time_elapsed       | 860          |\n",
      "|    total_timesteps    | 287500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57499        |\n",
      "|    policy_loss        | -0.275       |\n",
      "|    reward             | 0.0053862957 |\n",
      "|    std                | 1.23e+05     |\n",
      "|    value_loss         | 0.000124     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 57600       |\n",
      "|    time_elapsed       | 862         |\n",
      "|    total_timesteps    | 288000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57599       |\n",
      "|    policy_loss        | 0.0648      |\n",
      "|    reward             | 0.003795296 |\n",
      "|    std                | 1.25e+05    |\n",
      "|    value_loss         | 6.02e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 57700         |\n",
      "|    time_elapsed       | 863           |\n",
      "|    total_timesteps    | 288500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 57699         |\n",
      "|    policy_loss        | 0.0639        |\n",
      "|    reward             | -0.0032141597 |\n",
      "|    std                | 1.28e+05      |\n",
      "|    value_loss         | 1.53e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 57800        |\n",
      "|    time_elapsed       | 865          |\n",
      "|    total_timesteps    | 289000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | -1.59        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57799        |\n",
      "|    policy_loss        | -0.0718      |\n",
      "|    reward             | 0.0056673614 |\n",
      "|    std                | 1.3e+05      |\n",
      "|    value_loss         | 0.000726     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 57900         |\n",
      "|    time_elapsed       | 866           |\n",
      "|    total_timesteps    | 289500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.4         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 57899         |\n",
      "|    policy_loss        | -0.16         |\n",
      "|    reward             | -0.0082226135 |\n",
      "|    std                | 1.34e+05      |\n",
      "|    value_loss         | 0.000221      |\n",
      "-----------------------------------------\n",
      "day: 2896, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13950.31\n",
      "total_reward: -23950.31\n",
      "total_cost: 410.20\n",
      "total_trades: 5792\n",
      "Sharpe: 0.266\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 58000        |\n",
      "|    time_elapsed       | 868          |\n",
      "|    total_timesteps    | 290000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57999        |\n",
      "|    policy_loss        | 0.513        |\n",
      "|    reward             | -0.014885809 |\n",
      "|    std                | 1.36e+05     |\n",
      "|    value_loss         | 0.000466     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 58100         |\n",
      "|    time_elapsed       | 869           |\n",
      "|    total_timesteps    | 290500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58099         |\n",
      "|    policy_loss        | -0.77         |\n",
      "|    reward             | -0.0011026333 |\n",
      "|    std                | 1.4e+05       |\n",
      "|    value_loss         | 0.00089       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 58200        |\n",
      "|    time_elapsed       | 871          |\n",
      "|    total_timesteps    | 291000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58199        |\n",
      "|    policy_loss        | 0.158        |\n",
      "|    reward             | 0.0034943866 |\n",
      "|    std                | 1.44e+05     |\n",
      "|    value_loss         | 4.48e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 58300         |\n",
      "|    time_elapsed       | 873           |\n",
      "|    total_timesteps    | 291500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58299         |\n",
      "|    policy_loss        | 0.104         |\n",
      "|    reward             | -0.0025041073 |\n",
      "|    std                | 1.49e+05      |\n",
      "|    value_loss         | 7.75e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 58400       |\n",
      "|    time_elapsed       | 874         |\n",
      "|    total_timesteps    | 292000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.7       |\n",
      "|    explained_variance | -0.00656    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58399       |\n",
      "|    policy_loss        | 1.05        |\n",
      "|    reward             | 0.008580598 |\n",
      "|    std                | 1.53e+05    |\n",
      "|    value_loss         | 0.00155     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 58500        |\n",
      "|    time_elapsed       | 876          |\n",
      "|    total_timesteps    | 292500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58499        |\n",
      "|    policy_loss        | 0.64         |\n",
      "|    reward             | 0.0064820573 |\n",
      "|    std                | 1.59e+05     |\n",
      "|    value_loss         | 0.000617     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 58600        |\n",
      "|    time_elapsed       | 877          |\n",
      "|    total_timesteps    | 293000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58599        |\n",
      "|    policy_loss        | -0.415       |\n",
      "|    reward             | -0.083920926 |\n",
      "|    std                | 1.62e+05     |\n",
      "|    value_loss         | 0.00138      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 58700        |\n",
      "|    time_elapsed       | 879          |\n",
      "|    total_timesteps    | 293500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58699        |\n",
      "|    policy_loss        | 0.731        |\n",
      "|    reward             | -0.010148193 |\n",
      "|    std                | 1.65e+05     |\n",
      "|    value_loss         | 0.00108      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 58800       |\n",
      "|    time_elapsed       | 880         |\n",
      "|    total_timesteps    | 294000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.9       |\n",
      "|    explained_variance | 0.544       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58799       |\n",
      "|    policy_loss        | -0.387      |\n",
      "|    reward             | 0.016258622 |\n",
      "|    std                | 1.71e+05    |\n",
      "|    value_loss         | 0.000567    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 58900         |\n",
      "|    time_elapsed       | 882           |\n",
      "|    total_timesteps    | 294500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27           |\n",
      "|    explained_variance | 0.0381        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58899         |\n",
      "|    policy_loss        | 0.163         |\n",
      "|    reward             | -0.0029735046 |\n",
      "|    std                | 1.74e+05      |\n",
      "|    value_loss         | 0.000207      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 59000        |\n",
      "|    time_elapsed       | 883          |\n",
      "|    total_timesteps    | 295000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27          |\n",
      "|    explained_variance | 0.000712     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58999        |\n",
      "|    policy_loss        | 0.339        |\n",
      "|    reward             | -0.005847583 |\n",
      "|    std                | 1.77e+05     |\n",
      "|    value_loss         | 0.00246      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 59100         |\n",
      "|    time_elapsed       | 885           |\n",
      "|    total_timesteps    | 295500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27           |\n",
      "|    explained_variance | -0.0333       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59099         |\n",
      "|    policy_loss        | 15.4          |\n",
      "|    reward             | -0.0005958718 |\n",
      "|    std                | 1.81e+05      |\n",
      "|    value_loss         | 0.383         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 59200       |\n",
      "|    time_elapsed       | 886         |\n",
      "|    total_timesteps    | 296000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59199       |\n",
      "|    policy_loss        | -0.63       |\n",
      "|    reward             | 0.011519677 |\n",
      "|    std                | 1.82e+05    |\n",
      "|    value_loss         | 0.000692    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 59300        |\n",
      "|    time_elapsed       | 888          |\n",
      "|    total_timesteps    | 296500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59299        |\n",
      "|    policy_loss        | 0.42         |\n",
      "|    reward             | -0.014044178 |\n",
      "|    std                | 1.85e+05     |\n",
      "|    value_loss         | 0.000526     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 59400         |\n",
      "|    time_elapsed       | 889           |\n",
      "|    total_timesteps    | 297000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59399         |\n",
      "|    policy_loss        | -0.75         |\n",
      "|    reward             | -0.0016273529 |\n",
      "|    std                | 1.89e+05      |\n",
      "|    value_loss         | 0.000861      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 59500       |\n",
      "|    time_elapsed       | 891         |\n",
      "|    total_timesteps    | 297500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0.0674      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59499       |\n",
      "|    policy_loss        | -1          |\n",
      "|    reward             | -0.04486687 |\n",
      "|    std                | 1.93e+05    |\n",
      "|    value_loss         | 0.00372     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 59600       |\n",
      "|    time_elapsed       | 892         |\n",
      "|    total_timesteps    | 298000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0.000522    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59599       |\n",
      "|    policy_loss        | 3.21        |\n",
      "|    reward             | -0.15909065 |\n",
      "|    std                | 1.97e+05    |\n",
      "|    value_loss         | 0.0329      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 59700       |\n",
      "|    time_elapsed       | 894         |\n",
      "|    total_timesteps    | 298500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59699       |\n",
      "|    policy_loss        | 0.97        |\n",
      "|    reward             | 0.032856297 |\n",
      "|    std                | 1.97e+05    |\n",
      "|    value_loss         | 0.0013      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 59800        |\n",
      "|    time_elapsed       | 895          |\n",
      "|    total_timesteps    | 299000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59799        |\n",
      "|    policy_loss        | 0.327        |\n",
      "|    reward             | -0.015016706 |\n",
      "|    std                | 2.02e+05     |\n",
      "|    value_loss         | 0.000666     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 59900         |\n",
      "|    time_elapsed       | 897           |\n",
      "|    total_timesteps    | 299500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59899         |\n",
      "|    policy_loss        | -1.17         |\n",
      "|    reward             | -0.0014506336 |\n",
      "|    std                | 2.03e+05      |\n",
      "|    value_loss         | 0.00288       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 60000        |\n",
      "|    time_elapsed       | 899          |\n",
      "|    total_timesteps    | 300000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59999        |\n",
      "|    policy_loss        | -1.6         |\n",
      "|    reward             | -0.014031337 |\n",
      "|    std                | 2.07e+05     |\n",
      "|    value_loss         | 0.00387      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 60100        |\n",
      "|    time_elapsed       | 900          |\n",
      "|    total_timesteps    | 300500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60099        |\n",
      "|    policy_loss        | 0.905        |\n",
      "|    reward             | -0.039457392 |\n",
      "|    std                | 2.09e+05     |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 60200       |\n",
      "|    time_elapsed       | 902         |\n",
      "|    total_timesteps    | 301000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | 0.0847      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60199       |\n",
      "|    policy_loss        | -4.52       |\n",
      "|    reward             | -0.17188902 |\n",
      "|    std                | 2.12e+05    |\n",
      "|    value_loss         | 0.0391      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 60300      |\n",
      "|    time_elapsed       | 904        |\n",
      "|    total_timesteps    | 301500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60299      |\n",
      "|    policy_loss        | 0.0907     |\n",
      "|    reward             | 0.04001507 |\n",
      "|    std                | 2.12e+05   |\n",
      "|    value_loss         | 0.000162   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 60400        |\n",
      "|    time_elapsed       | 905          |\n",
      "|    total_timesteps    | 302000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60399        |\n",
      "|    policy_loss        | -0.0755      |\n",
      "|    reward             | -0.031554177 |\n",
      "|    std                | 2.14e+05     |\n",
      "|    value_loss         | 0.000544     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 60500      |\n",
      "|    time_elapsed       | 907        |\n",
      "|    total_timesteps    | 302500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60499      |\n",
      "|    policy_loss        | -0.14      |\n",
      "|    reward             | 0.01083386 |\n",
      "|    std                | 2.17e+05   |\n",
      "|    value_loss         | 0.0064     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 60600        |\n",
      "|    time_elapsed       | 909          |\n",
      "|    total_timesteps    | 303000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60599        |\n",
      "|    policy_loss        | -2.55        |\n",
      "|    reward             | -0.018370029 |\n",
      "|    std                | 2.15e+05     |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 60700       |\n",
      "|    time_elapsed       | 910         |\n",
      "|    total_timesteps    | 303500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.4       |\n",
      "|    explained_variance | 0.000194    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60699       |\n",
      "|    policy_loss        | 8.13        |\n",
      "|    reward             | -0.28807348 |\n",
      "|    std                | 2.15e+05    |\n",
      "|    value_loss         | 0.358       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 60800       |\n",
      "|    time_elapsed       | 912         |\n",
      "|    total_timesteps    | 304000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60799       |\n",
      "|    policy_loss        | -9.85       |\n",
      "|    reward             | -0.13133319 |\n",
      "|    std                | 2.14e+05    |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -286129.62\n",
      "total_reward: -296129.62\n",
      "total_cost: 107.19\n",
      "total_trades: 5792\n",
      "Sharpe: -0.162\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 60900        |\n",
      "|    time_elapsed       | 913          |\n",
      "|    total_timesteps    | 304500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60899        |\n",
      "|    policy_loss        | -0.925       |\n",
      "|    reward             | -0.013154181 |\n",
      "|    std                | 2.16e+05     |\n",
      "|    value_loss         | 0.00181      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 61000        |\n",
      "|    time_elapsed       | 915          |\n",
      "|    total_timesteps    | 305000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60999        |\n",
      "|    policy_loss        | 0.704        |\n",
      "|    reward             | -0.006554216 |\n",
      "|    std                | 2.19e+05     |\n",
      "|    value_loss         | 0.00073      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 61100        |\n",
      "|    time_elapsed       | 916          |\n",
      "|    total_timesteps    | 305500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61099        |\n",
      "|    policy_loss        | 0.134        |\n",
      "|    reward             | 0.0053779045 |\n",
      "|    std                | 2.23e+05     |\n",
      "|    value_loss         | 4.97e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 61200         |\n",
      "|    time_elapsed       | 918           |\n",
      "|    total_timesteps    | 306000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.5         |\n",
      "|    explained_variance | 0.0108        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61199         |\n",
      "|    policy_loss        | 0.793         |\n",
      "|    reward             | 0.00056211534 |\n",
      "|    std                | 2.28e+05      |\n",
      "|    value_loss         | 0.000873      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 61300         |\n",
      "|    time_elapsed       | 920           |\n",
      "|    total_timesteps    | 306500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.5         |\n",
      "|    explained_variance | -143          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61299         |\n",
      "|    policy_loss        | 1.4           |\n",
      "|    reward             | -0.0025522013 |\n",
      "|    std                | 2.35e+05      |\n",
      "|    value_loss         | 0.0114        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 61400        |\n",
      "|    time_elapsed       | 921          |\n",
      "|    total_timesteps    | 307000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0.348        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61399        |\n",
      "|    policy_loss        | -0.0199      |\n",
      "|    reward             | -0.004621509 |\n",
      "|    std                | 2.4e+05      |\n",
      "|    value_loss         | 0.000121     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 61500        |\n",
      "|    time_elapsed       | 923          |\n",
      "|    total_timesteps    | 307500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61499        |\n",
      "|    policy_loss        | 1.07         |\n",
      "|    reward             | 0.0022642338 |\n",
      "|    std                | 2.47e+05     |\n",
      "|    value_loss         | 0.00151      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 61600        |\n",
      "|    time_elapsed       | 925          |\n",
      "|    total_timesteps    | 308000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61599        |\n",
      "|    policy_loss        | 0.422        |\n",
      "|    reward             | -0.006602356 |\n",
      "|    std                | 2.54e+05     |\n",
      "|    value_loss         | 0.000288     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 61700        |\n",
      "|    time_elapsed       | 927          |\n",
      "|    total_timesteps    | 308500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61699        |\n",
      "|    policy_loss        | 0.348        |\n",
      "|    reward             | -0.012295833 |\n",
      "|    std                | 2.58e+05     |\n",
      "|    value_loss         | 0.000237     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 61800        |\n",
      "|    time_elapsed       | 928          |\n",
      "|    total_timesteps    | 309000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.8        |\n",
      "|    explained_variance | 0.0238       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61799        |\n",
      "|    policy_loss        | -0.486       |\n",
      "|    reward             | 0.0039582853 |\n",
      "|    std                | 2.65e+05     |\n",
      "|    value_loss         | 0.000308     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 61900        |\n",
      "|    time_elapsed       | 930          |\n",
      "|    total_timesteps    | 309500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0.0894       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61899        |\n",
      "|    policy_loss        | -0.109       |\n",
      "|    reward             | 0.0012536895 |\n",
      "|    std                | 2.79e+05     |\n",
      "|    value_loss         | 4.09e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 62000       |\n",
      "|    time_elapsed       | 931         |\n",
      "|    total_timesteps    | 310000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61999       |\n",
      "|    policy_loss        | -0.373      |\n",
      "|    reward             | -0.06856667 |\n",
      "|    std                | 2.9e+05     |\n",
      "|    value_loss         | 0.000974    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 62100       |\n",
      "|    time_elapsed       | 933         |\n",
      "|    total_timesteps    | 310500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62099       |\n",
      "|    policy_loss        | 0.491       |\n",
      "|    reward             | -0.18022324 |\n",
      "|    std                | 2.98e+05    |\n",
      "|    value_loss         | 0.00148     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 62200       |\n",
      "|    time_elapsed       | 935         |\n",
      "|    total_timesteps    | 311000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62199       |\n",
      "|    policy_loss        | 2.21        |\n",
      "|    reward             | -0.06592822 |\n",
      "|    std                | 3.03e+05    |\n",
      "|    value_loss         | 0.0148      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 62300       |\n",
      "|    time_elapsed       | 936         |\n",
      "|    total_timesteps    | 311500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | -1.11       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62299       |\n",
      "|    policy_loss        | 3.45        |\n",
      "|    reward             | -0.02137472 |\n",
      "|    std                | 3.06e+05    |\n",
      "|    value_loss         | 0.0203      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 62400      |\n",
      "|    time_elapsed       | 937        |\n",
      "|    total_timesteps    | 312000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.1      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 62399      |\n",
      "|    policy_loss        | -1.39      |\n",
      "|    reward             | 0.02971336 |\n",
      "|    std                | 3.08e+05   |\n",
      "|    value_loss         | 0.0305     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 62500       |\n",
      "|    time_elapsed       | 939         |\n",
      "|    total_timesteps    | 312500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62499       |\n",
      "|    policy_loss        | -11         |\n",
      "|    reward             | -0.03771126 |\n",
      "|    std                | 3.1e+05     |\n",
      "|    value_loss         | 0.516       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 62600        |\n",
      "|    time_elapsed       | 940          |\n",
      "|    total_timesteps    | 313000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62599        |\n",
      "|    policy_loss        | -0.772       |\n",
      "|    reward             | -0.017021215 |\n",
      "|    std                | 3.15e+05     |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 62700      |\n",
      "|    time_elapsed       | 942        |\n",
      "|    total_timesteps    | 313500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 62699      |\n",
      "|    policy_loss        | 0.0575     |\n",
      "|    reward             | 0.02306219 |\n",
      "|    std                | 3.16e+05   |\n",
      "|    value_loss         | 0.000106   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 62800         |\n",
      "|    time_elapsed       | 943           |\n",
      "|    total_timesteps    | 314000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62799         |\n",
      "|    policy_loss        | 0.0191        |\n",
      "|    reward             | -0.0055696606 |\n",
      "|    std                | 3.21e+05      |\n",
      "|    value_loss         | 5.44e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 62900        |\n",
      "|    time_elapsed       | 945          |\n",
      "|    total_timesteps    | 314500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62899        |\n",
      "|    policy_loss        | 0.456        |\n",
      "|    reward             | 0.0045882105 |\n",
      "|    std                | 3.31e+05     |\n",
      "|    value_loss         | 0.000288     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 63000        |\n",
      "|    time_elapsed       | 947          |\n",
      "|    total_timesteps    | 315000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | -0.137       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62999        |\n",
      "|    policy_loss        | -0.273       |\n",
      "|    reward             | -0.028485684 |\n",
      "|    std                | 3.39e+05     |\n",
      "|    value_loss         | 0.000192     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 63100        |\n",
      "|    time_elapsed       | 948          |\n",
      "|    total_timesteps    | 315500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63099        |\n",
      "|    policy_loss        | -0.242       |\n",
      "|    reward             | -0.031295314 |\n",
      "|    std                | 3.46e+05     |\n",
      "|    value_loss         | 7.84e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 63200       |\n",
      "|    time_elapsed       | 949         |\n",
      "|    total_timesteps    | 316000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63199       |\n",
      "|    policy_loss        | -1.57       |\n",
      "|    reward             | -0.23178852 |\n",
      "|    std                | 3.52e+05    |\n",
      "|    value_loss         | 0.00505     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 63300      |\n",
      "|    time_elapsed       | 951        |\n",
      "|    total_timesteps    | 316500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63299      |\n",
      "|    policy_loss        | 0.236      |\n",
      "|    reward             | 0.07200431 |\n",
      "|    std                | 3.59e+05   |\n",
      "|    value_loss         | 0.000326   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 63400       |\n",
      "|    time_elapsed       | 952         |\n",
      "|    total_timesteps    | 317000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63399       |\n",
      "|    policy_loss        | 3.69        |\n",
      "|    reward             | -0.04036668 |\n",
      "|    std                | 3.67e+05    |\n",
      "|    value_loss         | 0.0199      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 63500       |\n",
      "|    time_elapsed       | 954         |\n",
      "|    total_timesteps    | 317500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63499       |\n",
      "|    policy_loss        | -0.00605    |\n",
      "|    reward             | 0.063350976 |\n",
      "|    std                | 3.72e+05    |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 63600       |\n",
      "|    time_elapsed       | 955         |\n",
      "|    total_timesteps    | 318000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63599       |\n",
      "|    policy_loss        | -7.99       |\n",
      "|    reward             | -0.29531896 |\n",
      "|    std                | 3.76e+05    |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 63700      |\n",
      "|    time_elapsed       | 957        |\n",
      "|    total_timesteps    | 318500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63699      |\n",
      "|    policy_loss        | -5.44      |\n",
      "|    reward             | -0.8461319 |\n",
      "|    std                | 3.75e+05   |\n",
      "|    value_loss         | 0.173      |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -274733.13\n",
      "total_reward: -284733.13\n",
      "total_cost: 107.12\n",
      "total_trades: 5792\n",
      "Sharpe: -0.364\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 63800        |\n",
      "|    time_elapsed       | 958          |\n",
      "|    total_timesteps    | 319000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63799        |\n",
      "|    policy_loss        | 1.62         |\n",
      "|    reward             | -0.013595936 |\n",
      "|    std                | 3.78e+05     |\n",
      "|    value_loss         | 0.0073       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 63900        |\n",
      "|    time_elapsed       | 960          |\n",
      "|    total_timesteps    | 319500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63899        |\n",
      "|    policy_loss        | -0.69        |\n",
      "|    reward             | -0.009480329 |\n",
      "|    std                | 3.8e+05      |\n",
      "|    value_loss         | 0.00094      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 64000       |\n",
      "|    time_elapsed       | 963         |\n",
      "|    total_timesteps    | 320000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | -4.76       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63999       |\n",
      "|    policy_loss        | 4.01        |\n",
      "|    reward             | 0.009335203 |\n",
      "|    std                | 3.84e+05    |\n",
      "|    value_loss         | 0.0218      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 64100        |\n",
      "|    time_elapsed       | 964          |\n",
      "|    total_timesteps    | 320500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | 4.23e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64099        |\n",
      "|    policy_loss        | 2.22         |\n",
      "|    reward             | -0.024944663 |\n",
      "|    std                | 3.87e+05     |\n",
      "|    value_loss         | 0.00895      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 64200      |\n",
      "|    time_elapsed       | 966        |\n",
      "|    total_timesteps    | 321000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64199      |\n",
      "|    policy_loss        | -2.36      |\n",
      "|    reward             | 0.03700633 |\n",
      "|    std                | 3.97e+05   |\n",
      "|    value_loss         | 0.00741    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 64300        |\n",
      "|    time_elapsed       | 967          |\n",
      "|    total_timesteps    | 321500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64299        |\n",
      "|    policy_loss        | 0.434        |\n",
      "|    reward             | -0.063000865 |\n",
      "|    std                | 3.98e+05     |\n",
      "|    value_loss         | 0.00259      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 64400        |\n",
      "|    time_elapsed       | 969          |\n",
      "|    total_timesteps    | 322000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64399        |\n",
      "|    policy_loss        | 1.79         |\n",
      "|    reward             | -0.012196153 |\n",
      "|    std                | 4.03e+05     |\n",
      "|    value_loss         | 0.00508      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 64500        |\n",
      "|    time_elapsed       | 971          |\n",
      "|    total_timesteps    | 322500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64499        |\n",
      "|    policy_loss        | -2.73        |\n",
      "|    reward             | 0.0064047384 |\n",
      "|    std                | 4.04e+05     |\n",
      "|    value_loss         | 0.0133       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 64600      |\n",
      "|    time_elapsed       | 972        |\n",
      "|    total_timesteps    | 323000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.6      |\n",
      "|    explained_variance | 0.162      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64599      |\n",
      "|    policy_loss        | -0.759     |\n",
      "|    reward             | 0.08939904 |\n",
      "|    std                | 4.11e+05   |\n",
      "|    value_loss         | 0.00339    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 64700      |\n",
      "|    time_elapsed       | 974        |\n",
      "|    total_timesteps    | 323500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.7      |\n",
      "|    explained_variance | -0.00113   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64699      |\n",
      "|    policy_loss        | -8.55      |\n",
      "|    reward             | 0.36405805 |\n",
      "|    std                | 4.14e+05   |\n",
      "|    value_loss         | 0.103      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 64800      |\n",
      "|    time_elapsed       | 975        |\n",
      "|    total_timesteps    | 324000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.7      |\n",
      "|    explained_variance | 0.00894    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64799      |\n",
      "|    policy_loss        | -2.67      |\n",
      "|    reward             | 0.10571559 |\n",
      "|    std                | 4.12e+05   |\n",
      "|    value_loss         | 0.0268     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 64900       |\n",
      "|    time_elapsed       | 977         |\n",
      "|    total_timesteps    | 324500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64899       |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | 0.022164926 |\n",
      "|    std                | 4.11e+05    |\n",
      "|    value_loss         | 0.00191     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 65000       |\n",
      "|    time_elapsed       | 979         |\n",
      "|    total_timesteps    | 325000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64999       |\n",
      "|    policy_loss        | 2.08        |\n",
      "|    reward             | 0.016614389 |\n",
      "|    std                | 4.14e+05    |\n",
      "|    value_loss         | 0.00865     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 65100       |\n",
      "|    time_elapsed       | 980         |\n",
      "|    total_timesteps    | 325500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65099       |\n",
      "|    policy_loss        | -1.11       |\n",
      "|    reward             | 0.010742199 |\n",
      "|    std                | 4.22e+05    |\n",
      "|    value_loss         | 0.00217     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 65200         |\n",
      "|    time_elapsed       | 982           |\n",
      "|    total_timesteps    | 326000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.7         |\n",
      "|    explained_variance | 0.368         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 65199         |\n",
      "|    policy_loss        | 1.14          |\n",
      "|    reward             | -0.0037344703 |\n",
      "|    std                | 4.27e+05      |\n",
      "|    value_loss         | 0.00206       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 65300       |\n",
      "|    time_elapsed       | 983         |\n",
      "|    total_timesteps    | 326500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | 0.15        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65299       |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | 0.029680746 |\n",
      "|    std                | 4.32e+05    |\n",
      "|    value_loss         | 0.00461     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 65400       |\n",
      "|    time_elapsed       | 985         |\n",
      "|    total_timesteps    | 327000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65399       |\n",
      "|    policy_loss        | -0.193      |\n",
      "|    reward             | -0.15659882 |\n",
      "|    std                | 4.32e+05    |\n",
      "|    value_loss         | 0.00696     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 65500      |\n",
      "|    time_elapsed       | 986        |\n",
      "|    total_timesteps    | 327500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65499      |\n",
      "|    policy_loss        | 1.05       |\n",
      "|    reward             | 0.02864166 |\n",
      "|    std                | 4.35e+05   |\n",
      "|    value_loss         | 0.00154    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 65600        |\n",
      "|    time_elapsed       | 988          |\n",
      "|    total_timesteps    | 328000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65599        |\n",
      "|    policy_loss        | 0.38         |\n",
      "|    reward             | -0.017485537 |\n",
      "|    std                | 4.4e+05      |\n",
      "|    value_loss         | 0.000255     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 65700      |\n",
      "|    time_elapsed       | 989        |\n",
      "|    total_timesteps    | 328500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65699      |\n",
      "|    policy_loss        | 3.51       |\n",
      "|    reward             | 0.08370559 |\n",
      "|    std                | 4.48e+05   |\n",
      "|    value_loss         | 0.015      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 65800       |\n",
      "|    time_elapsed       | 990         |\n",
      "|    total_timesteps    | 329000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65799       |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | 0.023115888 |\n",
      "|    std                | 4.53e+05    |\n",
      "|    value_loss         | 0.00257     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 65900         |\n",
      "|    time_elapsed       | 992           |\n",
      "|    total_timesteps    | 329500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.9         |\n",
      "|    explained_variance | -1.91e-06     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 65899         |\n",
      "|    policy_loss        | -5.4          |\n",
      "|    reward             | -0.0030889283 |\n",
      "|    std                | 4.64e+05      |\n",
      "|    value_loss         | 0.0428        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 66000        |\n",
      "|    time_elapsed       | 994          |\n",
      "|    total_timesteps    | 330000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65999        |\n",
      "|    policy_loss        | -1.11        |\n",
      "|    reward             | -0.014925888 |\n",
      "|    std                | 4.66e+05     |\n",
      "|    value_loss         | 0.00742      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 66100        |\n",
      "|    time_elapsed       | 995          |\n",
      "|    total_timesteps    | 330500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66099        |\n",
      "|    policy_loss        | 0.953        |\n",
      "|    reward             | 0.0026627237 |\n",
      "|    std                | 4.69e+05     |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 66200        |\n",
      "|    time_elapsed       | 997          |\n",
      "|    total_timesteps    | 331000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66199        |\n",
      "|    policy_loss        | -0.528       |\n",
      "|    reward             | -0.008631961 |\n",
      "|    std                | 4.76e+05     |\n",
      "|    value_loss         | 0.00042      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 998         |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66299       |\n",
      "|    policy_loss        | -0.453      |\n",
      "|    reward             | 0.014203234 |\n",
      "|    std                | 4.83e+05    |\n",
      "|    value_loss         | 0.000851    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 66400        |\n",
      "|    time_elapsed       | 1000         |\n",
      "|    total_timesteps    | 332000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66399        |\n",
      "|    policy_loss        | 0.102        |\n",
      "|    reward             | -0.004942084 |\n",
      "|    std                | 4.98e+05     |\n",
      "|    value_loss         | 2.25e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 66500         |\n",
      "|    time_elapsed       | 1001          |\n",
      "|    total_timesteps    | 332500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.1         |\n",
      "|    explained_variance | -648          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66499         |\n",
      "|    policy_loss        | 2.28          |\n",
      "|    reward             | -0.0041412194 |\n",
      "|    std                | 5.14e+05      |\n",
      "|    value_loss         | 0.0144        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 66600       |\n",
      "|    time_elapsed       | 1003        |\n",
      "|    total_timesteps    | 333000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66599       |\n",
      "|    policy_loss        | -0.533      |\n",
      "|    reward             | 0.009302936 |\n",
      "|    std                | 5.31e+05    |\n",
      "|    value_loss         | 0.000421    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -11665.04\n",
      "total_reward: -21665.04\n",
      "total_cost: 533.58\n",
      "total_trades: 5792\n",
      "Sharpe: 0.414\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 66700        |\n",
      "|    time_elapsed       | 1004         |\n",
      "|    total_timesteps    | 333500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66699        |\n",
      "|    policy_loss        | 4.87         |\n",
      "|    reward             | -0.033944696 |\n",
      "|    std                | 5.39e+05     |\n",
      "|    value_loss         | 0.0321       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 66800       |\n",
      "|    time_elapsed       | 1006        |\n",
      "|    total_timesteps    | 334000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66799       |\n",
      "|    policy_loss        | -0.599      |\n",
      "|    reward             | 0.010116894 |\n",
      "|    std                | 5.48e+05    |\n",
      "|    value_loss         | 0.000503    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 66900        |\n",
      "|    time_elapsed       | 1008         |\n",
      "|    total_timesteps    | 334500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0.295        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66899        |\n",
      "|    policy_loss        | 0.0215       |\n",
      "|    reward             | -0.012644095 |\n",
      "|    std                | 5.59e+05     |\n",
      "|    value_loss         | 0.000416     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 67000      |\n",
      "|    time_elapsed       | 1009       |\n",
      "|    total_timesteps    | 335000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66999      |\n",
      "|    policy_loss        | 0.115      |\n",
      "|    reward             | 0.03623516 |\n",
      "|    std                | 5.73e+05   |\n",
      "|    value_loss         | 0.00017    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 67100      |\n",
      "|    time_elapsed       | 1011       |\n",
      "|    total_timesteps    | 335500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67099      |\n",
      "|    policy_loss        | -0.0113    |\n",
      "|    reward             | -0.0012681 |\n",
      "|    std                | 5.82e+05   |\n",
      "|    value_loss         | 0.000527   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 67200      |\n",
      "|    time_elapsed       | 1012       |\n",
      "|    total_timesteps    | 336000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.4      |\n",
      "|    explained_variance | 0.08       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67199      |\n",
      "|    policy_loss        | -0.0263    |\n",
      "|    reward             | -0.1047574 |\n",
      "|    std                | 5.95e+05   |\n",
      "|    value_loss         | 0.00321    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67300        |\n",
      "|    time_elapsed       | 1014         |\n",
      "|    total_timesteps    | 336500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67299        |\n",
      "|    policy_loss        | 0.4          |\n",
      "|    reward             | -0.051304832 |\n",
      "|    std                | 5.94e+05     |\n",
      "|    value_loss         | 0.00178      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67400        |\n",
      "|    time_elapsed       | 1016         |\n",
      "|    total_timesteps    | 337000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67399        |\n",
      "|    policy_loss        | -0.39        |\n",
      "|    reward             | -0.043787822 |\n",
      "|    std                | 6e+05        |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 67500      |\n",
      "|    time_elapsed       | 1017       |\n",
      "|    total_timesteps    | 337500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.4      |\n",
      "|    explained_variance | -0.000103  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67499      |\n",
      "|    policy_loss        | -5.27      |\n",
      "|    reward             | 0.13219287 |\n",
      "|    std                | 5.95e+05   |\n",
      "|    value_loss         | 0.0507     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 67600     |\n",
      "|    time_elapsed       | 1019      |\n",
      "|    total_timesteps    | 338000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 67599     |\n",
      "|    policy_loss        | -7.28     |\n",
      "|    reward             | 0.2523475 |\n",
      "|    std                | 5.97e+05  |\n",
      "|    value_loss         | 0.0772    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 67700     |\n",
      "|    time_elapsed       | 1020      |\n",
      "|    total_timesteps    | 338500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.4     |\n",
      "|    explained_variance | 0.119     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 67699     |\n",
      "|    policy_loss        | 6.43      |\n",
      "|    reward             | 0.1132934 |\n",
      "|    std                | 6.05e+05  |\n",
      "|    value_loss         | 0.135     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 67800        |\n",
      "|    time_elapsed       | 1022         |\n",
      "|    total_timesteps    | 339000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67799        |\n",
      "|    policy_loss        | 2.3          |\n",
      "|    reward             | -0.034495093 |\n",
      "|    std                | 6.08e+05     |\n",
      "|    value_loss         | 0.00823      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 67900         |\n",
      "|    time_elapsed       | 1023          |\n",
      "|    total_timesteps    | 339500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.5         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 67899         |\n",
      "|    policy_loss        | 0.454         |\n",
      "|    reward             | -0.0024793677 |\n",
      "|    std                | 6.15e+05      |\n",
      "|    value_loss         | 0.000383      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 68000      |\n",
      "|    time_elapsed       | 1025       |\n",
      "|    total_timesteps    | 340000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67999      |\n",
      "|    policy_loss        | -0.227     |\n",
      "|    reward             | -0.0082741 |\n",
      "|    std                | 6.25e+05   |\n",
      "|    value_loss         | 0.000111   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 68100         |\n",
      "|    time_elapsed       | 1026          |\n",
      "|    total_timesteps    | 340500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68099         |\n",
      "|    policy_loss        | -0.3          |\n",
      "|    reward             | -0.0026636128 |\n",
      "|    std                | 6.37e+05      |\n",
      "|    value_loss         | 0.000156      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 68200         |\n",
      "|    time_elapsed       | 1028          |\n",
      "|    total_timesteps    | 341000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.6         |\n",
      "|    explained_variance | 0.356         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68199         |\n",
      "|    policy_loss        | 0.346         |\n",
      "|    reward             | -0.0021206762 |\n",
      "|    std                | 6.57e+05      |\n",
      "|    value_loss         | 0.000435      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 68300        |\n",
      "|    time_elapsed       | 1029         |\n",
      "|    total_timesteps    | 341500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68299        |\n",
      "|    policy_loss        | 0.00747      |\n",
      "|    reward             | -0.008599826 |\n",
      "|    std                | 6.78e+05     |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68400       |\n",
      "|    time_elapsed       | 1031        |\n",
      "|    total_timesteps    | 342000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68399       |\n",
      "|    policy_loss        | -0.354      |\n",
      "|    reward             | 0.051668014 |\n",
      "|    std                | 6.88e+05    |\n",
      "|    value_loss         | 0.000405    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 68500        |\n",
      "|    time_elapsed       | 1032         |\n",
      "|    total_timesteps    | 342500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68499        |\n",
      "|    policy_loss        | -0.273       |\n",
      "|    reward             | -0.028460843 |\n",
      "|    std                | 6.97e+05     |\n",
      "|    value_loss         | 0.000613     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68600       |\n",
      "|    time_elapsed       | 1034        |\n",
      "|    total_timesteps    | 343000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68599       |\n",
      "|    policy_loss        | -0.841      |\n",
      "|    reward             | 0.013948961 |\n",
      "|    std                | 7.11e+05    |\n",
      "|    value_loss         | 0.00141     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68700       |\n",
      "|    time_elapsed       | 1035        |\n",
      "|    total_timesteps    | 343500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.162       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68699       |\n",
      "|    policy_loss        | -0.235      |\n",
      "|    reward             | 0.055915087 |\n",
      "|    std                | 7.34e+05    |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 68800       |\n",
      "|    time_elapsed       | 1037        |\n",
      "|    total_timesteps    | 344000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0.112       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68799       |\n",
      "|    policy_loss        | 1.59        |\n",
      "|    reward             | 0.025815126 |\n",
      "|    std                | 7.55e+05    |\n",
      "|    value_loss         | 0.00661     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 68900         |\n",
      "|    time_elapsed       | 1038          |\n",
      "|    total_timesteps    | 344500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68899         |\n",
      "|    policy_loss        | -1.39         |\n",
      "|    reward             | -0.0042889602 |\n",
      "|    std                | 7.65e+05      |\n",
      "|    value_loss         | 0.00339       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 69000      |\n",
      "|    time_elapsed       | 1040       |\n",
      "|    total_timesteps    | 345000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 68999      |\n",
      "|    policy_loss        | 0.569      |\n",
      "|    reward             | 0.03242712 |\n",
      "|    std                | 7.86e+05   |\n",
      "|    value_loss         | 0.000677   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 69100      |\n",
      "|    time_elapsed       | 1041       |\n",
      "|    total_timesteps    | 345500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69099      |\n",
      "|    policy_loss        | -0.496     |\n",
      "|    reward             | 0.01700793 |\n",
      "|    std                | 7.93e+05   |\n",
      "|    value_loss         | 0.000351   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 69200      |\n",
      "|    time_elapsed       | 1043       |\n",
      "|    total_timesteps    | 346000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69199      |\n",
      "|    policy_loss        | -0.792     |\n",
      "|    reward             | 0.17127264 |\n",
      "|    std                | 8.05e+05   |\n",
      "|    value_loss         | 0.00815    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 69300      |\n",
      "|    time_elapsed       | 1044       |\n",
      "|    total_timesteps    | 346500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | -0.0186    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69299      |\n",
      "|    policy_loss        | 4.42       |\n",
      "|    reward             | -0.0903865 |\n",
      "|    std                | 8.17e+05   |\n",
      "|    value_loss         | 0.0261     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 69400      |\n",
      "|    time_elapsed       | 1046       |\n",
      "|    total_timesteps    | 347000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69399      |\n",
      "|    policy_loss        | 0.244      |\n",
      "|    reward             | -0.2809856 |\n",
      "|    std                | 8.14e+05   |\n",
      "|    value_loss         | 0.0132     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 69500       |\n",
      "|    time_elapsed       | 1047        |\n",
      "|    total_timesteps    | 347500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69499       |\n",
      "|    policy_loss        | 13.1        |\n",
      "|    reward             | -0.35856608 |\n",
      "|    std                | 8.24e+05    |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -268143.98\n",
      "total_reward: -278143.98\n",
      "total_cost: 107.24\n",
      "total_trades: 5792\n",
      "Sharpe: 0.436\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 69600       |\n",
      "|    time_elapsed       | 1049        |\n",
      "|    total_timesteps    | 348000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69599       |\n",
      "|    policy_loss        | -5.18       |\n",
      "|    reward             | 0.056830436 |\n",
      "|    std                | 8.25e+05    |\n",
      "|    value_loss         | 0.0493      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 69700      |\n",
      "|    time_elapsed       | 1051       |\n",
      "|    total_timesteps    | 348500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69699      |\n",
      "|    policy_loss        | -0.308     |\n",
      "|    reward             | 0.02875217 |\n",
      "|    std                | 8.39e+05   |\n",
      "|    value_loss         | 0.000266   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 69800      |\n",
      "|    time_elapsed       | 1052       |\n",
      "|    total_timesteps    | 349000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.1      |\n",
      "|    explained_variance | -0.0309    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69799      |\n",
      "|    policy_loss        | 3.92       |\n",
      "|    reward             | -0.3673844 |\n",
      "|    std                | 8.51e+05   |\n",
      "|    value_loss         | 0.0231     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 69900        |\n",
      "|    time_elapsed       | 1054         |\n",
      "|    total_timesteps    | 349500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | -0.000989    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69899        |\n",
      "|    policy_loss        | -3.32        |\n",
      "|    reward             | -0.015835794 |\n",
      "|    std                | 8.6e+05      |\n",
      "|    value_loss         | 0.0634       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70000       |\n",
      "|    time_elapsed       | 1055        |\n",
      "|    total_timesteps    | 350000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | -4.77e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69999       |\n",
      "|    policy_loss        | -5.63       |\n",
      "|    reward             | -0.26563355 |\n",
      "|    std                | 8.58e+05    |\n",
      "|    value_loss         | 0.0865      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70100       |\n",
      "|    time_elapsed       | 1057        |\n",
      "|    total_timesteps    | 350500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70099       |\n",
      "|    policy_loss        | -4.23       |\n",
      "|    reward             | -0.06842143 |\n",
      "|    std                | 8.64e+05    |\n",
      "|    value_loss         | 0.0399      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70200        |\n",
      "|    time_elapsed       | 1058         |\n",
      "|    total_timesteps    | 351000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70199        |\n",
      "|    policy_loss        | -1.41        |\n",
      "|    reward             | -0.052485686 |\n",
      "|    std                | 8.73e+05     |\n",
      "|    value_loss         | 0.0025       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70300       |\n",
      "|    time_elapsed       | 1059        |\n",
      "|    total_timesteps    | 351500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70299       |\n",
      "|    policy_loss        | -0.2        |\n",
      "|    reward             | 0.008230529 |\n",
      "|    std                | 8.88e+05    |\n",
      "|    value_loss         | 6.8e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70400        |\n",
      "|    time_elapsed       | 1061         |\n",
      "|    total_timesteps    | 352000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70399        |\n",
      "|    policy_loss        | 0.802        |\n",
      "|    reward             | 0.0032726256 |\n",
      "|    std                | 9.06e+05     |\n",
      "|    value_loss         | 0.000846     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 70500         |\n",
      "|    time_elapsed       | 1062          |\n",
      "|    total_timesteps    | 352500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70499         |\n",
      "|    policy_loss        | 0.324         |\n",
      "|    reward             | -0.0059359465 |\n",
      "|    std                | 9.27e+05      |\n",
      "|    value_loss         | 0.000125      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70600        |\n",
      "|    time_elapsed       | 1064         |\n",
      "|    total_timesteps    | 353000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | 0.153        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70599        |\n",
      "|    policy_loss        | 0.315        |\n",
      "|    reward             | -0.012835311 |\n",
      "|    std                | 9.47e+05     |\n",
      "|    value_loss         | 0.000157     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 70700        |\n",
      "|    time_elapsed       | 1065         |\n",
      "|    total_timesteps    | 353500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70699        |\n",
      "|    policy_loss        | 2.36         |\n",
      "|    reward             | -0.063958436 |\n",
      "|    std                | 9.75e+05     |\n",
      "|    value_loss         | 0.00766      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 70800       |\n",
      "|    time_elapsed       | 1067        |\n",
      "|    total_timesteps    | 354000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70799       |\n",
      "|    policy_loss        | 0.379       |\n",
      "|    reward             | 0.035564538 |\n",
      "|    std                | 9.86e+05    |\n",
      "|    value_loss         | 0.00134     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 70900     |\n",
      "|    time_elapsed       | 1068      |\n",
      "|    total_timesteps    | 354500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 70899     |\n",
      "|    policy_loss        | 0.739     |\n",
      "|    reward             | 0.0225039 |\n",
      "|    std                | 1.01e+06  |\n",
      "|    value_loss         | 0.000744  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 71000       |\n",
      "|    time_elapsed       | 1070        |\n",
      "|    total_timesteps    | 355000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | -0.484      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70999       |\n",
      "|    policy_loss        | 4           |\n",
      "|    reward             | 0.023153685 |\n",
      "|    std                | 1.02e+06    |\n",
      "|    value_loss         | 0.0225      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71100        |\n",
      "|    time_elapsed       | 1071         |\n",
      "|    total_timesteps    | 355500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 4.17e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71099        |\n",
      "|    policy_loss        | 1.19         |\n",
      "|    reward             | -0.036761586 |\n",
      "|    std                | 1.03e+06     |\n",
      "|    value_loss         | 0.00755      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 71200      |\n",
      "|    time_elapsed       | 1073       |\n",
      "|    total_timesteps    | 356000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.5      |\n",
      "|    explained_variance | 0.0183     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71199      |\n",
      "|    policy_loss        | -10.5      |\n",
      "|    reward             | 0.55163693 |\n",
      "|    std                | 1.03e+06   |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71300        |\n",
      "|    time_elapsed       | 1075         |\n",
      "|    total_timesteps    | 356500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71299        |\n",
      "|    policy_loss        | -0.0657      |\n",
      "|    reward             | -0.024661269 |\n",
      "|    std                | 1.04e+06     |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 71400         |\n",
      "|    time_elapsed       | 1076          |\n",
      "|    total_timesteps    | 357000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71399         |\n",
      "|    policy_loss        | -0.284        |\n",
      "|    reward             | 0.00029262944 |\n",
      "|    std                | 1.06e+06      |\n",
      "|    value_loss         | 0.000189      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 71500         |\n",
      "|    time_elapsed       | 1078          |\n",
      "|    total_timesteps    | 357500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71499         |\n",
      "|    policy_loss        | -0.0421       |\n",
      "|    reward             | -0.0065000462 |\n",
      "|    std                | 1.07e+06      |\n",
      "|    value_loss         | 3.05e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71600        |\n",
      "|    time_elapsed       | 1079         |\n",
      "|    total_timesteps    | 358000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71599        |\n",
      "|    policy_loss        | -0.729       |\n",
      "|    reward             | -0.006412442 |\n",
      "|    std                | 1.1e+06      |\n",
      "|    value_loss         | 0.000665     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 71700       |\n",
      "|    time_elapsed       | 1080        |\n",
      "|    total_timesteps    | 358500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71699       |\n",
      "|    policy_loss        | -0.49       |\n",
      "|    reward             | 0.003993557 |\n",
      "|    std                | 1.14e+06    |\n",
      "|    value_loss         | 0.000569    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 71800       |\n",
      "|    time_elapsed       | 1082        |\n",
      "|    total_timesteps    | 359000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | -0.00794    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71799       |\n",
      "|    policy_loss        | 1.4         |\n",
      "|    reward             | -0.02682469 |\n",
      "|    std                | 1.16e+06    |\n",
      "|    value_loss         | 0.00265     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 71900        |\n",
      "|    time_elapsed       | 1083         |\n",
      "|    total_timesteps    | 359500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71899        |\n",
      "|    policy_loss        | -1.22        |\n",
      "|    reward             | -0.020914093 |\n",
      "|    std                | 1.2e+06      |\n",
      "|    value_loss         | 0.00202      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 72000     |\n",
      "|    time_elapsed       | 1085      |\n",
      "|    total_timesteps    | 360000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 71999     |\n",
      "|    policy_loss        | 1.82      |\n",
      "|    reward             | 0.0222513 |\n",
      "|    std                | 1.21e+06  |\n",
      "|    value_loss         | 0.00483   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72100        |\n",
      "|    time_elapsed       | 1086         |\n",
      "|    total_timesteps    | 360500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72099        |\n",
      "|    policy_loss        | 0.393        |\n",
      "|    reward             | -0.020421999 |\n",
      "|    std                | 1.24e+06     |\n",
      "|    value_loss         | 0.000281     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72200        |\n",
      "|    time_elapsed       | 1087         |\n",
      "|    total_timesteps    | 361000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | 0.00066      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72199        |\n",
      "|    policy_loss        | 0.263        |\n",
      "|    reward             | -0.022562472 |\n",
      "|    std                | 1.27e+06     |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72300        |\n",
      "|    time_elapsed       | 1089         |\n",
      "|    total_timesteps    | 361500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | -1.97e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72299        |\n",
      "|    policy_loss        | 0.438        |\n",
      "|    reward             | -0.003958052 |\n",
      "|    std                | 1.29e+06     |\n",
      "|    value_loss         | 0.00047      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 72400      |\n",
      "|    time_elapsed       | 1090       |\n",
      "|    total_timesteps    | 362000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31        |\n",
      "|    explained_variance | 0.108      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72399      |\n",
      "|    policy_loss        | 1.93       |\n",
      "|    reward             | 0.02409825 |\n",
      "|    std                | 1.32e+06   |\n",
      "|    value_loss         | 0.00727    |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -42213.55\n",
      "total_reward: -52213.55\n",
      "total_cost: 89.83\n",
      "total_trades: 5792\n",
      "Sharpe: 0.426\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72500        |\n",
      "|    time_elapsed       | 1092         |\n",
      "|    total_timesteps    | 362500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72499        |\n",
      "|    policy_loss        | -0.496       |\n",
      "|    reward             | 0.0006475167 |\n",
      "|    std                | 1.34e+06     |\n",
      "|    value_loss         | 0.00103      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 72600        |\n",
      "|    time_elapsed       | 1093         |\n",
      "|    total_timesteps    | 363000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72599        |\n",
      "|    policy_loss        | 0.00723      |\n",
      "|    reward             | 0.0014919229 |\n",
      "|    std                | 1.37e+06     |\n",
      "|    value_loss         | 1.93e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 72700       |\n",
      "|    time_elapsed       | 1095        |\n",
      "|    total_timesteps    | 363500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72699       |\n",
      "|    policy_loss        | -0.402      |\n",
      "|    reward             | 0.003737406 |\n",
      "|    std                | 1.4e+06     |\n",
      "|    value_loss         | 0.000292    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 72800         |\n",
      "|    time_elapsed       | 1096          |\n",
      "|    total_timesteps    | 364000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.2         |\n",
      "|    explained_variance | 0.548         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 72799         |\n",
      "|    policy_loss        | -0.0774       |\n",
      "|    reward             | 0.00058713707 |\n",
      "|    std                | 1.45e+06      |\n",
      "|    value_loss         | 4.12e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 72900          |\n",
      "|    time_elapsed       | 1097           |\n",
      "|    total_timesteps    | 364500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -31.2          |\n",
      "|    explained_variance | -0.564         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 72899          |\n",
      "|    policy_loss        | -0.573         |\n",
      "|    reward             | -0.00049965054 |\n",
      "|    std                | 1.5e+06        |\n",
      "|    value_loss         | 0.000432       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 73000       |\n",
      "|    time_elapsed       | 1099        |\n",
      "|    total_timesteps    | 365000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72999       |\n",
      "|    policy_loss        | -0.777      |\n",
      "|    reward             | 0.004734018 |\n",
      "|    std                | 1.56e+06    |\n",
      "|    value_loss         | 0.000829    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 73100        |\n",
      "|    time_elapsed       | 1100         |\n",
      "|    total_timesteps    | 365500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73099        |\n",
      "|    policy_loss        | 0.956        |\n",
      "|    reward             | -0.027222475 |\n",
      "|    std                | 1.61e+06     |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 73200        |\n",
      "|    time_elapsed       | 1102         |\n",
      "|    total_timesteps    | 366000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73199        |\n",
      "|    policy_loss        | -0.714       |\n",
      "|    reward             | -0.016251653 |\n",
      "|    std                | 1.65e+06     |\n",
      "|    value_loss         | 0.000676     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 73300        |\n",
      "|    time_elapsed       | 1103         |\n",
      "|    total_timesteps    | 366500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73299        |\n",
      "|    policy_loss        | 1.76         |\n",
      "|    reward             | -0.019617138 |\n",
      "|    std                | 1.72e+06     |\n",
      "|    value_loss         | 0.00323      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 73400       |\n",
      "|    time_elapsed       | 1105        |\n",
      "|    total_timesteps    | 367000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0.301       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73399       |\n",
      "|    policy_loss        | 0.343       |\n",
      "|    reward             | 0.028545888 |\n",
      "|    std                | 1.79e+06    |\n",
      "|    value_loss         | 0.000136    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 73500         |\n",
      "|    time_elapsed       | 1106          |\n",
      "|    total_timesteps    | 367500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.7         |\n",
      "|    explained_variance | 0.303         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73499         |\n",
      "|    policy_loss        | 0.411         |\n",
      "|    reward             | -0.0147218555 |\n",
      "|    std                | 1.85e+06      |\n",
      "|    value_loss         | 0.000255      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 73600      |\n",
      "|    time_elapsed       | 1108       |\n",
      "|    total_timesteps    | 368000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.7      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73599      |\n",
      "|    policy_loss        | 1.77       |\n",
      "|    reward             | 0.05783044 |\n",
      "|    std                | 1.9e+06    |\n",
      "|    value_loss         | 0.00462    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 73700      |\n",
      "|    time_elapsed       | 1110       |\n",
      "|    total_timesteps    | 368500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73699      |\n",
      "|    policy_loss        | 0.751      |\n",
      "|    reward             | 0.06178088 |\n",
      "|    std                | 1.94e+06   |\n",
      "|    value_loss         | 0.00315    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 73800       |\n",
      "|    time_elapsed       | 1111        |\n",
      "|    total_timesteps    | 369000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73799       |\n",
      "|    policy_loss        | 2.43        |\n",
      "|    reward             | -0.17725052 |\n",
      "|    std                | 1.97e+06    |\n",
      "|    value_loss         | 0.00861     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 73900       |\n",
      "|    time_elapsed       | 1113        |\n",
      "|    total_timesteps    | 369500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0.165       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73899       |\n",
      "|    policy_loss        | 3.44        |\n",
      "|    reward             | 0.052653763 |\n",
      "|    std                | 1.97e+06    |\n",
      "|    value_loss         | 0.0213      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74000        |\n",
      "|    time_elapsed       | 1114         |\n",
      "|    total_timesteps    | 370000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0.0799       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73999        |\n",
      "|    policy_loss        | 11.9         |\n",
      "|    reward             | 0.0031680327 |\n",
      "|    std                | 1.98e+06     |\n",
      "|    value_loss         | 0.195        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 74100       |\n",
      "|    time_elapsed       | 1116        |\n",
      "|    total_timesteps    | 370500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74099       |\n",
      "|    policy_loss        | 3.31        |\n",
      "|    reward             | -0.14314573 |\n",
      "|    std                | 2e+06       |\n",
      "|    value_loss         | 0.0668      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74200        |\n",
      "|    time_elapsed       | 1117         |\n",
      "|    total_timesteps    | 371000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74199        |\n",
      "|    policy_loss        | 0.528        |\n",
      "|    reward             | -0.010733395 |\n",
      "|    std                | 2.01e+06     |\n",
      "|    value_loss         | 0.000371     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74300        |\n",
      "|    time_elapsed       | 1119         |\n",
      "|    total_timesteps    | 371500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74299        |\n",
      "|    policy_loss        | -0.44        |\n",
      "|    reward             | -0.011004303 |\n",
      "|    std                | 2.04e+06     |\n",
      "|    value_loss         | 0.000221     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 74400       |\n",
      "|    time_elapsed       | 1121        |\n",
      "|    total_timesteps    | 372000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74399       |\n",
      "|    policy_loss        | -0.808      |\n",
      "|    reward             | 0.011230789 |\n",
      "|    std                | 2.08e+06    |\n",
      "|    value_loss         | 0.000846    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74500        |\n",
      "|    time_elapsed       | 1122         |\n",
      "|    total_timesteps    | 372500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74499        |\n",
      "|    policy_loss        | 0.487        |\n",
      "|    reward             | -0.008278645 |\n",
      "|    std                | 2.12e+06     |\n",
      "|    value_loss         | 0.000263     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74600        |\n",
      "|    time_elapsed       | 1124         |\n",
      "|    total_timesteps    | 373000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74599        |\n",
      "|    policy_loss        | -0.59        |\n",
      "|    reward             | -0.018011795 |\n",
      "|    std                | 2.18e+06     |\n",
      "|    value_loss         | 0.000463     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 74700         |\n",
      "|    time_elapsed       | 1125          |\n",
      "|    total_timesteps    | 373500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 74699         |\n",
      "|    policy_loss        | 0.0816        |\n",
      "|    reward             | -0.0036097122 |\n",
      "|    std                | 2.3e+06       |\n",
      "|    value_loss         | 0.000107      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 74800       |\n",
      "|    time_elapsed       | 1127        |\n",
      "|    total_timesteps    | 374000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74799       |\n",
      "|    policy_loss        | 1.1         |\n",
      "|    reward             | 0.042508885 |\n",
      "|    std                | 2.33e+06    |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 74900        |\n",
      "|    time_elapsed       | 1128         |\n",
      "|    total_timesteps    | 374500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74899        |\n",
      "|    policy_loss        | -2.78        |\n",
      "|    reward             | -0.019898808 |\n",
      "|    std                | 2.36e+06     |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 75000        |\n",
      "|    time_elapsed       | 1130         |\n",
      "|    total_timesteps    | 375000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74999        |\n",
      "|    policy_loss        | 4.14         |\n",
      "|    reward             | -0.007785513 |\n",
      "|    std                | 2.38e+06     |\n",
      "|    value_loss         | 0.0323       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 75100      |\n",
      "|    time_elapsed       | 1132       |\n",
      "|    total_timesteps    | 375500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.2      |\n",
      "|    explained_variance | -0.951     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75099      |\n",
      "|    policy_loss        | 1.64       |\n",
      "|    reward             | 0.06502418 |\n",
      "|    std                | 2.4e+06    |\n",
      "|    value_loss         | 0.00753    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 75200         |\n",
      "|    time_elapsed       | 1133          |\n",
      "|    total_timesteps    | 376000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.2         |\n",
      "|    explained_variance | 0.364         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75199         |\n",
      "|    policy_loss        | 4.83          |\n",
      "|    reward             | -0.0047494643 |\n",
      "|    std                | 2.43e+06      |\n",
      "|    value_loss         | 0.032         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 75300     |\n",
      "|    time_elapsed       | 1135      |\n",
      "|    total_timesteps    | 376500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.2     |\n",
      "|    explained_variance | 0.34      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 75299     |\n",
      "|    policy_loss        | 16.5      |\n",
      "|    reward             | 0.3927875 |\n",
      "|    std                | 2.41e+06  |\n",
      "|    value_loss         | 0.455     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2896, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -275550.38\n",
      "total_reward: -285550.38\n",
      "total_cost: 104.65\n",
      "total_trades: 5792\n",
      "Sharpe: 0.212\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 75400       |\n",
      "|    time_elapsed       | 1136        |\n",
      "|    total_timesteps    | 377000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | -1.75       |\n",
      "|    reward             | 0.026298376 |\n",
      "|    std                | 2.45e+06    |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 75500        |\n",
      "|    time_elapsed       | 1138         |\n",
      "|    total_timesteps    | 377500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75499        |\n",
      "|    policy_loss        | 0.488        |\n",
      "|    reward             | -0.016218653 |\n",
      "|    std                | 2.49e+06     |\n",
      "|    value_loss         | 0.000244     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 75600       |\n",
      "|    time_elapsed       | 1139        |\n",
      "|    total_timesteps    | 378000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | -0.14       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75599       |\n",
      "|    policy_loss        | 0.395       |\n",
      "|    reward             | 0.002385775 |\n",
      "|    std                | 2.53e+06    |\n",
      "|    value_loss         | 0.000502    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 75700        |\n",
      "|    time_elapsed       | 1141         |\n",
      "|    total_timesteps    | 378500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | 0.322        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75699        |\n",
      "|    policy_loss        | 1.14         |\n",
      "|    reward             | 0.0007873276 |\n",
      "|    std                | 2.57e+06     |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 75800        |\n",
      "|    time_elapsed       | 1143         |\n",
      "|    total_timesteps    | 379000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 1.19e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75799        |\n",
      "|    policy_loss        | -0.187       |\n",
      "|    reward             | -0.011852382 |\n",
      "|    std                | 2.64e+06     |\n",
      "|    value_loss         | 9.17e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 75900       |\n",
      "|    time_elapsed       | 1144        |\n",
      "|    total_timesteps    | 379500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 1.91e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75899       |\n",
      "|    policy_loss        | 0.0803      |\n",
      "|    reward             | -0.01947803 |\n",
      "|    std                | 2.68e+06    |\n",
      "|    value_loss         | 0.000527    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 76000       |\n",
      "|    time_elapsed       | 1146        |\n",
      "|    total_timesteps    | 380000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75999       |\n",
      "|    policy_loss        | -0.228      |\n",
      "|    reward             | -0.06844402 |\n",
      "|    std                | 2.68e+06    |\n",
      "|    value_loss         | 0.00581     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 76100      |\n",
      "|    time_elapsed       | 1147       |\n",
      "|    total_timesteps    | 380500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76099      |\n",
      "|    policy_loss        | -2.41      |\n",
      "|    reward             | 0.03744763 |\n",
      "|    std                | 2.71e+06   |\n",
      "|    value_loss         | 0.00741    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 76200      |\n",
      "|    time_elapsed       | 1149       |\n",
      "|    total_timesteps    | 381000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.4      |\n",
      "|    explained_variance | 0.846      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76199      |\n",
      "|    policy_loss        | -8.74      |\n",
      "|    reward             | 0.18516356 |\n",
      "|    std                | 2.73e+06   |\n",
      "|    value_loss         | 0.0692     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 76300      |\n",
      "|    time_elapsed       | 1150       |\n",
      "|    total_timesteps    | 381500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76299      |\n",
      "|    policy_loss        | -4.21      |\n",
      "|    reward             | -0.3479842 |\n",
      "|    std                | 2.72e+06   |\n",
      "|    value_loss         | 0.0221     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 76400      |\n",
      "|    time_elapsed       | 1152       |\n",
      "|    total_timesteps    | 382000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.5      |\n",
      "|    explained_variance | 0.332      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76399      |\n",
      "|    policy_loss        | 11.7       |\n",
      "|    reward             | 0.60170525 |\n",
      "|    std                | 2.76e+06   |\n",
      "|    value_loss         | 0.178      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76500        |\n",
      "|    time_elapsed       | 1154         |\n",
      "|    total_timesteps    | 382500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76499        |\n",
      "|    policy_loss        | 5.28         |\n",
      "|    reward             | -0.023842385 |\n",
      "|    std                | 2.78e+06     |\n",
      "|    value_loss         | 0.0273       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 76600       |\n",
      "|    time_elapsed       | 1155        |\n",
      "|    total_timesteps    | 383000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76599       |\n",
      "|    policy_loss        | -0.875      |\n",
      "|    reward             | 0.009209615 |\n",
      "|    std                | 2.81e+06    |\n",
      "|    value_loss         | 0.000891    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76700        |\n",
      "|    time_elapsed       | 1157         |\n",
      "|    total_timesteps    | 383500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76699        |\n",
      "|    policy_loss        | 0.0623       |\n",
      "|    reward             | -0.019150699 |\n",
      "|    std                | 2.85e+06     |\n",
      "|    value_loss         | 0.000174     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 76800        |\n",
      "|    time_elapsed       | 1158         |\n",
      "|    total_timesteps    | 384000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76799        |\n",
      "|    policy_loss        | -1.86        |\n",
      "|    reward             | -0.016453166 |\n",
      "|    std                | 2.86e+06     |\n",
      "|    value_loss         | 0.00375      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 76900       |\n",
      "|    time_elapsed       | 1160        |\n",
      "|    total_timesteps    | 384500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76899       |\n",
      "|    policy_loss        | -4.37       |\n",
      "|    reward             | -0.05064753 |\n",
      "|    std                | 2.86e+06    |\n",
      "|    value_loss         | 0.0187      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 77000      |\n",
      "|    time_elapsed       | 1162       |\n",
      "|    total_timesteps    | 385000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.6      |\n",
      "|    explained_variance | -0.0708    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76999      |\n",
      "|    policy_loss        | 0.239      |\n",
      "|    reward             | 0.08319644 |\n",
      "|    std                | 2.9e+06    |\n",
      "|    value_loss         | 0.00246    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 77100         |\n",
      "|    time_elapsed       | 1164          |\n",
      "|    total_timesteps    | 385500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77099         |\n",
      "|    policy_loss        | 0.122         |\n",
      "|    reward             | -0.0063817343 |\n",
      "|    std                | 2.92e+06      |\n",
      "|    value_loss         | 0.000588      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 77200        |\n",
      "|    time_elapsed       | 1166         |\n",
      "|    total_timesteps    | 386000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77199        |\n",
      "|    policy_loss        | -1.22        |\n",
      "|    reward             | -0.020197328 |\n",
      "|    std                | 2.96e+06     |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 77300       |\n",
      "|    time_elapsed       | 1168        |\n",
      "|    total_timesteps    | 386500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77299       |\n",
      "|    policy_loss        | 0.221       |\n",
      "|    reward             | 0.013709574 |\n",
      "|    std                | 3e+06       |\n",
      "|    value_loss         | 7.94e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 77400         |\n",
      "|    time_elapsed       | 1170          |\n",
      "|    total_timesteps    | 387000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77399         |\n",
      "|    policy_loss        | -0.234        |\n",
      "|    reward             | 0.00032631226 |\n",
      "|    std                | 3.07e+06      |\n",
      "|    value_loss         | 8.86e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 77500       |\n",
      "|    time_elapsed       | 1172        |\n",
      "|    total_timesteps    | 387500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77499       |\n",
      "|    policy_loss        | 0.925       |\n",
      "|    reward             | -0.07345799 |\n",
      "|    std                | 3.15e+06    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 77600        |\n",
      "|    time_elapsed       | 1174         |\n",
      "|    total_timesteps    | 388000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 3.81e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77599        |\n",
      "|    policy_loss        | 0.604        |\n",
      "|    reward             | -0.042232648 |\n",
      "|    std                | 3.27e+06     |\n",
      "|    value_loss         | 0.000594     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 77700       |\n",
      "|    time_elapsed       | 1176        |\n",
      "|    total_timesteps    | 388500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77699       |\n",
      "|    policy_loss        | 3.69        |\n",
      "|    reward             | 0.036649924 |\n",
      "|    std                | 3.32e+06    |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 77800      |\n",
      "|    time_elapsed       | 1178       |\n",
      "|    total_timesteps    | 389000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77799      |\n",
      "|    policy_loss        | -3.16      |\n",
      "|    reward             | 0.03274703 |\n",
      "|    std                | 3.32e+06   |\n",
      "|    value_loss         | 0.0203     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 77900      |\n",
      "|    time_elapsed       | 1180       |\n",
      "|    total_timesteps    | 389500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77899      |\n",
      "|    policy_loss        | -13.1      |\n",
      "|    reward             | 0.08973789 |\n",
      "|    std                | 3.4e+06    |\n",
      "|    value_loss         | 0.196      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 78000       |\n",
      "|    time_elapsed       | 1182        |\n",
      "|    total_timesteps    | 390000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0.151       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77999       |\n",
      "|    policy_loss        | -1.72       |\n",
      "|    reward             | 0.050702427 |\n",
      "|    std                | 3.4e+06     |\n",
      "|    value_loss         | 0.0252      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 78100      |\n",
      "|    time_elapsed       | 1184       |\n",
      "|    total_timesteps    | 390500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.9      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78099      |\n",
      "|    policy_loss        | 17.8       |\n",
      "|    reward             | 0.18442735 |\n",
      "|    std                | 3.41e+06   |\n",
      "|    value_loss         | 0.342      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 78200       |\n",
      "|    time_elapsed       | 1185        |\n",
      "|    total_timesteps    | 391000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78199       |\n",
      "|    policy_loss        | 39          |\n",
      "|    reward             | -0.41560507 |\n",
      "|    std                | 3.44e+06    |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -264901.07\n",
      "total_reward: -274901.07\n",
      "total_cost: 103.74\n",
      "total_trades: 5792\n",
      "Sharpe: -0.312\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 78300        |\n",
      "|    time_elapsed       | 1187         |\n",
      "|    total_timesteps    | 391500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78299        |\n",
      "|    policy_loss        | 0.56         |\n",
      "|    reward             | -0.010424993 |\n",
      "|    std                | 3.47e+06     |\n",
      "|    value_loss         | 0.000614     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 78400        |\n",
      "|    time_elapsed       | 1188         |\n",
      "|    total_timesteps    | 392000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33          |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78399        |\n",
      "|    policy_loss        | 0.283        |\n",
      "|    reward             | -0.003149772 |\n",
      "|    std                | 3.53e+06     |\n",
      "|    value_loss         | 0.000166     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 78500       |\n",
      "|    time_elapsed       | 1190        |\n",
      "|    total_timesteps    | 392500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78499       |\n",
      "|    policy_loss        | -0.467      |\n",
      "|    reward             | 0.014673787 |\n",
      "|    std                | 3.59e+06    |\n",
      "|    value_loss         | 0.000197    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 78600        |\n",
      "|    time_elapsed       | 1191         |\n",
      "|    total_timesteps    | 393000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78599        |\n",
      "|    policy_loss        | 0.443        |\n",
      "|    reward             | -0.004921191 |\n",
      "|    std                | 3.69e+06     |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 78700         |\n",
      "|    time_elapsed       | 1193          |\n",
      "|    total_timesteps    | 393500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.1         |\n",
      "|    explained_variance | -0.0177       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 78699         |\n",
      "|    policy_loss        | -1.35         |\n",
      "|    reward             | -0.0069160475 |\n",
      "|    std                | 3.84e+06      |\n",
      "|    value_loss         | 0.00181       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 78800       |\n",
      "|    time_elapsed       | 1194        |\n",
      "|    total_timesteps    | 394000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.2       |\n",
      "|    explained_variance | 0.0747      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78799       |\n",
      "|    policy_loss        | 0.723       |\n",
      "|    reward             | -0.08138563 |\n",
      "|    std                | 3.98e+06    |\n",
      "|    value_loss         | 0.000748    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 78900        |\n",
      "|    time_elapsed       | 1196         |\n",
      "|    total_timesteps    | 394500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78899        |\n",
      "|    policy_loss        | 0.637        |\n",
      "|    reward             | -0.017685696 |\n",
      "|    std                | 4.01e+06     |\n",
      "|    value_loss         | 0.000746     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 79000       |\n",
      "|    time_elapsed       | 1197        |\n",
      "|    total_timesteps    | 395000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78999       |\n",
      "|    policy_loss        | 1.42        |\n",
      "|    reward             | 0.015872702 |\n",
      "|    std                | 4.12e+06    |\n",
      "|    value_loss         | 0.00264     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 79100        |\n",
      "|    time_elapsed       | 1199         |\n",
      "|    total_timesteps    | 395500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79099        |\n",
      "|    policy_loss        | -1.43        |\n",
      "|    reward             | -0.028364716 |\n",
      "|    std                | 4.18e+06     |\n",
      "|    value_loss         | 0.00235      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 1201        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | 0.017       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | 2.86        |\n",
      "|    reward             | 0.025587795 |\n",
      "|    std                | 4.25e+06    |\n",
      "|    value_loss         | 0.00902     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 79300       |\n",
      "|    time_elapsed       | 1202        |\n",
      "|    total_timesteps    | 396500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | -0.118      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79299       |\n",
      "|    policy_loss        | 19          |\n",
      "|    reward             | -0.27499434 |\n",
      "|    std                | 4.34e+06    |\n",
      "|    value_loss         | 0.352       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 79400        |\n",
      "|    time_elapsed       | 1204         |\n",
      "|    total_timesteps    | 397000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79399        |\n",
      "|    policy_loss        | -0.596       |\n",
      "|    reward             | 0.0051432983 |\n",
      "|    std                | 4.36e+06     |\n",
      "|    value_loss         | 0.000368     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 79500         |\n",
      "|    time_elapsed       | 1205          |\n",
      "|    total_timesteps    | 397500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.4         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79499         |\n",
      "|    policy_loss        | -0.103        |\n",
      "|    reward             | -0.0062888986 |\n",
      "|    std                | 4.4e+06       |\n",
      "|    value_loss         | 3.23e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 79600        |\n",
      "|    time_elapsed       | 1207         |\n",
      "|    total_timesteps    | 398000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79599        |\n",
      "|    policy_loss        | 0.128        |\n",
      "|    reward             | -0.028381603 |\n",
      "|    std                | 4.51e+06     |\n",
      "|    value_loss         | 2.68e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 79700       |\n",
      "|    time_elapsed       | 1209        |\n",
      "|    total_timesteps    | 398500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79699       |\n",
      "|    policy_loss        | 0.0775      |\n",
      "|    reward             | 0.011272205 |\n",
      "|    std                | 4.63e+06    |\n",
      "|    value_loss         | 1.48e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 79800       |\n",
      "|    time_elapsed       | 1211        |\n",
      "|    total_timesteps    | 399000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79799       |\n",
      "|    policy_loss        | 0.453       |\n",
      "|    reward             | 0.005329148 |\n",
      "|    std                | 4.8e+06     |\n",
      "|    value_loss         | 0.000227    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 79900       |\n",
      "|    time_elapsed       | 1212        |\n",
      "|    total_timesteps    | 399500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.7       |\n",
      "|    explained_variance | 0.659       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79899       |\n",
      "|    policy_loss        | 0.115       |\n",
      "|    reward             | 0.008412133 |\n",
      "|    std                | 5.02e+06    |\n",
      "|    value_loss         | 2.77e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 80000        |\n",
      "|    time_elapsed       | 1214         |\n",
      "|    total_timesteps    | 400000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79999        |\n",
      "|    policy_loss        | 1.75         |\n",
      "|    reward             | -0.080122195 |\n",
      "|    std                | 5.13e+06     |\n",
      "|    value_loss         | 0.00283      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 80100        |\n",
      "|    time_elapsed       | 1215         |\n",
      "|    total_timesteps    | 400500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80099        |\n",
      "|    policy_loss        | -0.0957      |\n",
      "|    reward             | -0.012565097 |\n",
      "|    std                | 5.24e+06     |\n",
      "|    value_loss         | 2.37e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 80200      |\n",
      "|    time_elapsed       | 1217       |\n",
      "|    total_timesteps    | 401000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80199      |\n",
      "|    policy_loss        | 0.00562    |\n",
      "|    reward             | 0.00609273 |\n",
      "|    std                | 5.36e+06   |\n",
      "|    value_loss         | 4.96e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 80300        |\n",
      "|    time_elapsed       | 1218         |\n",
      "|    total_timesteps    | 401500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80299        |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | 0.0015761814 |\n",
      "|    std                | 5.53e+06     |\n",
      "|    value_loss         | 3.26e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 80400         |\n",
      "|    time_elapsed       | 1220          |\n",
      "|    total_timesteps    | 402000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80399         |\n",
      "|    policy_loss        | -0.89         |\n",
      "|    reward             | -0.0089543965 |\n",
      "|    std                | 5.76e+06      |\n",
      "|    value_loss         | 0.000951      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 80500          |\n",
      "|    time_elapsed       | 1222           |\n",
      "|    total_timesteps    | 402500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -34            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 80499          |\n",
      "|    policy_loss        | 0.32           |\n",
      "|    reward             | -0.00065958634 |\n",
      "|    std                | 6e+06          |\n",
      "|    value_loss         | 0.000164       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 80600        |\n",
      "|    time_elapsed       | 1223         |\n",
      "|    total_timesteps    | 403000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80599        |\n",
      "|    policy_loss        | -0.447       |\n",
      "|    reward             | -0.010132902 |\n",
      "|    std                | 6.15e+06     |\n",
      "|    value_loss         | 0.0025       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 80700        |\n",
      "|    time_elapsed       | 1225         |\n",
      "|    total_timesteps    | 403500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80699        |\n",
      "|    policy_loss        | 1.4          |\n",
      "|    reward             | -0.011969718 |\n",
      "|    std                | 6.27e+06     |\n",
      "|    value_loss         | 0.00216      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 80800       |\n",
      "|    time_elapsed       | 1226        |\n",
      "|    total_timesteps    | 404000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.2       |\n",
      "|    explained_variance | 0.351       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80799       |\n",
      "|    policy_loss        | 0.0043      |\n",
      "|    reward             | 0.006342828 |\n",
      "|    std                | 6.48e+06    |\n",
      "|    value_loss         | 4.43e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 80900       |\n",
      "|    time_elapsed       | 1228        |\n",
      "|    total_timesteps    | 404500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.2       |\n",
      "|    explained_variance | 0.0897      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80899       |\n",
      "|    policy_loss        | 2.27        |\n",
      "|    reward             | 0.010002269 |\n",
      "|    std                | 6.63e+06    |\n",
      "|    value_loss         | 0.00675     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 81000         |\n",
      "|    time_elapsed       | 1230          |\n",
      "|    total_timesteps    | 405000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80999         |\n",
      "|    policy_loss        | -3.62         |\n",
      "|    reward             | -0.0038380586 |\n",
      "|    std                | 6.77e+06      |\n",
      "|    value_loss         | 0.015         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 81100       |\n",
      "|    time_elapsed       | 1231        |\n",
      "|    total_timesteps    | 405500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.3       |\n",
      "|    explained_variance | 0.205       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81099       |\n",
      "|    policy_loss        | 1.63        |\n",
      "|    reward             | -0.06906289 |\n",
      "|    std                | 6.98e+06    |\n",
      "|    value_loss         | 0.00398     |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -55160.70\n",
      "total_reward: -65160.70\n",
      "total_cost: 92.88\n",
      "total_trades: 5792\n",
      "Sharpe: 0.342\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 81200         |\n",
      "|    time_elapsed       | 1233          |\n",
      "|    total_timesteps    | 406000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81199         |\n",
      "|    policy_loss        | 2             |\n",
      "|    reward             | -0.0015996824 |\n",
      "|    std                | 7.11e+06      |\n",
      "|    value_loss         | 0.00385       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 81300      |\n",
      "|    time_elapsed       | 1235       |\n",
      "|    total_timesteps    | 406500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.4      |\n",
      "|    explained_variance | 0.0232     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81299      |\n",
      "|    policy_loss        | -0.271     |\n",
      "|    reward             | 0.00214781 |\n",
      "|    std                | 7.24e+06   |\n",
      "|    value_loss         | 0.000248   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 81400        |\n",
      "|    time_elapsed       | 1236         |\n",
      "|    total_timesteps    | 407000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81399        |\n",
      "|    policy_loss        | 0.498        |\n",
      "|    reward             | 0.0096710175 |\n",
      "|    std                | 7.39e+06     |\n",
      "|    value_loss         | 0.000332     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 81500         |\n",
      "|    time_elapsed       | 1238          |\n",
      "|    total_timesteps    | 407500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.5         |\n",
      "|    explained_variance | 0.241         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81499         |\n",
      "|    policy_loss        | -0.0194       |\n",
      "|    reward             | 0.00068645447 |\n",
      "|    std                | 7.68e+06      |\n",
      "|    value_loss         | 5.53e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 81600          |\n",
      "|    time_elapsed       | 1239           |\n",
      "|    total_timesteps    | 408000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -34.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 81599          |\n",
      "|    policy_loss        | -0.449         |\n",
      "|    reward             | -0.00012601243 |\n",
      "|    std                | 7.94e+06       |\n",
      "|    value_loss         | 0.000188       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 81700       |\n",
      "|    time_elapsed       | 1241        |\n",
      "|    total_timesteps    | 408500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81699       |\n",
      "|    policy_loss        | 1.64        |\n",
      "|    reward             | 0.057107117 |\n",
      "|    std                | 8.26e+06    |\n",
      "|    value_loss         | 0.00329     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 81800       |\n",
      "|    time_elapsed       | 1242        |\n",
      "|    total_timesteps    | 409000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81799       |\n",
      "|    policy_loss        | 7.97        |\n",
      "|    reward             | 0.028620165 |\n",
      "|    std                | 8.33e+06    |\n",
      "|    value_loss         | 0.0543      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 81900      |\n",
      "|    time_elapsed       | 1244       |\n",
      "|    total_timesteps    | 409500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81899      |\n",
      "|    policy_loss        | -3.36      |\n",
      "|    reward             | 0.18424366 |\n",
      "|    std                | 8.51e+06   |\n",
      "|    value_loss         | 0.0105     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 82000       |\n",
      "|    time_elapsed       | 1245        |\n",
      "|    total_timesteps    | 410000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | -1.05       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81999       |\n",
      "|    policy_loss        | -1.42       |\n",
      "|    reward             | -0.09927138 |\n",
      "|    std                | 8.52e+06    |\n",
      "|    value_loss         | 0.0103      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 82100        |\n",
      "|    time_elapsed       | 1247         |\n",
      "|    total_timesteps    | 410500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82099        |\n",
      "|    policy_loss        | -0.745       |\n",
      "|    reward             | -0.124063455 |\n",
      "|    std                | 8.66e+06     |\n",
      "|    value_loss         | 0.0424       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 82200     |\n",
      "|    time_elapsed       | 1248      |\n",
      "|    total_timesteps    | 411000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 82199     |\n",
      "|    policy_loss        | -2.69     |\n",
      "|    reward             | 0.3382989 |\n",
      "|    std                | 8.63e+06  |\n",
      "|    value_loss         | 0.159     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 82300        |\n",
      "|    time_elapsed       | 1250         |\n",
      "|    total_timesteps    | 411500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82299        |\n",
      "|    policy_loss        | 0.0944       |\n",
      "|    reward             | -0.025137242 |\n",
      "|    std                | 8.73e+06     |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 82400        |\n",
      "|    time_elapsed       | 1251         |\n",
      "|    total_timesteps    | 412000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82399        |\n",
      "|    policy_loss        | -0.512       |\n",
      "|    reward             | 0.0117400605 |\n",
      "|    std                | 8.82e+06     |\n",
      "|    value_loss         | 0.000279     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 82500       |\n",
      "|    time_elapsed       | 1253        |\n",
      "|    total_timesteps    | 412500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82499       |\n",
      "|    policy_loss        | 0.418       |\n",
      "|    reward             | 0.013078926 |\n",
      "|    std                | 8.94e+06    |\n",
      "|    value_loss         | 0.000143    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 82600        |\n",
      "|    time_elapsed       | 1254         |\n",
      "|    total_timesteps    | 413000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.9        |\n",
      "|    explained_variance | -3.45        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82599        |\n",
      "|    policy_loss        | 0.675        |\n",
      "|    reward             | -0.011969276 |\n",
      "|    std                | 9.15e+06     |\n",
      "|    value_loss         | 0.000661     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 82700       |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 413500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.9       |\n",
      "|    explained_variance | 0.359       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | 0.0794      |\n",
      "|    reward             | 0.013013421 |\n",
      "|    std                | 9.4e+06     |\n",
      "|    value_loss         | 2.49e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 82800        |\n",
      "|    time_elapsed       | 1257         |\n",
      "|    total_timesteps    | 414000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35          |\n",
      "|    explained_variance | 0.362        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82799        |\n",
      "|    policy_loss        | -0.578       |\n",
      "|    reward             | -0.006098297 |\n",
      "|    std                | 9.49e+06     |\n",
      "|    value_loss         | 0.000311     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 82900        |\n",
      "|    time_elapsed       | 1259         |\n",
      "|    total_timesteps    | 414500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82899        |\n",
      "|    policy_loss        | 0.257        |\n",
      "|    reward             | 0.0074233203 |\n",
      "|    std                | 9.8e+06      |\n",
      "|    value_loss         | 0.000184     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 83000       |\n",
      "|    time_elapsed       | 1260        |\n",
      "|    total_timesteps    | 415000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82999       |\n",
      "|    policy_loss        | 0.895       |\n",
      "|    reward             | 0.015142984 |\n",
      "|    std                | 1e+07       |\n",
      "|    value_loss         | 0.000648    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 83100        |\n",
      "|    time_elapsed       | 1262         |\n",
      "|    total_timesteps    | 415500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83099        |\n",
      "|    policy_loss        | -0.238       |\n",
      "|    reward             | 0.0006852867 |\n",
      "|    std                | 1.04e+07     |\n",
      "|    value_loss         | 9.34e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 83200         |\n",
      "|    time_elapsed       | 1263          |\n",
      "|    total_timesteps    | 416000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83199         |\n",
      "|    policy_loss        | -0.221        |\n",
      "|    reward             | -0.0029530863 |\n",
      "|    std                | 1.09e+07      |\n",
      "|    value_loss         | 6.75e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 83300        |\n",
      "|    time_elapsed       | 1265         |\n",
      "|    total_timesteps    | 416500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83299        |\n",
      "|    policy_loss        | 0.00909      |\n",
      "|    reward             | -0.008210123 |\n",
      "|    std                | 1.13e+07     |\n",
      "|    value_loss         | 2.49e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 83400       |\n",
      "|    time_elapsed       | 1267        |\n",
      "|    total_timesteps    | 417000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83399       |\n",
      "|    policy_loss        | 2.16        |\n",
      "|    reward             | 0.017418591 |\n",
      "|    std                | 1.17e+07    |\n",
      "|    value_loss         | 0.00393     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 83500         |\n",
      "|    time_elapsed       | 1268          |\n",
      "|    total_timesteps    | 417500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83499         |\n",
      "|    policy_loss        | -0.864        |\n",
      "|    reward             | -0.0145471115 |\n",
      "|    std                | 1.22e+07      |\n",
      "|    value_loss         | 0.00099       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 83600       |\n",
      "|    time_elapsed       | 1270        |\n",
      "|    total_timesteps    | 418000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83599       |\n",
      "|    policy_loss        | -0.624      |\n",
      "|    reward             | 0.007430308 |\n",
      "|    std                | 1.25e+07    |\n",
      "|    value_loss         | 0.000524    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 83700       |\n",
      "|    time_elapsed       | 1271        |\n",
      "|    total_timesteps    | 418500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.5       |\n",
      "|    explained_variance | 0.408       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83699       |\n",
      "|    policy_loss        | 0.501       |\n",
      "|    reward             | 0.013951248 |\n",
      "|    std                | 1.26e+07    |\n",
      "|    value_loss         | 0.00209     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 83800        |\n",
      "|    time_elapsed       | 1273         |\n",
      "|    total_timesteps    | 419000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | 0.538        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83799        |\n",
      "|    policy_loss        | 0.53         |\n",
      "|    reward             | -0.065353535 |\n",
      "|    std                | 1.28e+07     |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 83900        |\n",
      "|    time_elapsed       | 1275         |\n",
      "|    total_timesteps    | 419500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | 0.116        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83899        |\n",
      "|    policy_loss        | -7.43        |\n",
      "|    reward             | -0.002311722 |\n",
      "|    std                | 1.3e+07      |\n",
      "|    value_loss         | 0.0459       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 84000      |\n",
      "|    time_elapsed       | 1276       |\n",
      "|    total_timesteps    | 420000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.6      |\n",
      "|    explained_variance | 0.218      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83999      |\n",
      "|    policy_loss        | -1.63      |\n",
      "|    reward             | 0.08552757 |\n",
      "|    std                | 1.29e+07   |\n",
      "|    value_loss         | 0.00312    |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -74120.57\n",
      "total_reward: -84120.57\n",
      "total_cost: 94.73\n",
      "total_trades: 5792\n",
      "Sharpe: -0.299\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 84100      |\n",
      "|    time_elapsed       | 1278       |\n",
      "|    total_timesteps    | 420500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84099      |\n",
      "|    policy_loss        | 2.67       |\n",
      "|    reward             | -0.0595086 |\n",
      "|    std                | 1.3e+07    |\n",
      "|    value_loss         | 0.00709    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 84200        |\n",
      "|    time_elapsed       | 1280         |\n",
      "|    total_timesteps    | 421000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84199        |\n",
      "|    policy_loss        | -0.324       |\n",
      "|    reward             | -0.064262316 |\n",
      "|    std                | 1.31e+07     |\n",
      "|    value_loss         | 0.000648     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 84300       |\n",
      "|    time_elapsed       | 1281        |\n",
      "|    total_timesteps    | 421500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | -0.86       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84299       |\n",
      "|    policy_loss        | -1.73       |\n",
      "|    reward             | 0.019471828 |\n",
      "|    std                | 1.34e+07    |\n",
      "|    value_loss         | 0.00262     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 84400        |\n",
      "|    time_elapsed       | 1283         |\n",
      "|    total_timesteps    | 422000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84399        |\n",
      "|    policy_loss        | 1.46         |\n",
      "|    reward             | -0.007956272 |\n",
      "|    std                | 1.37e+07     |\n",
      "|    value_loss         | 0.00183      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 84500       |\n",
      "|    time_elapsed       | 1285        |\n",
      "|    total_timesteps    | 422500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84499       |\n",
      "|    policy_loss        | -0.985      |\n",
      "|    reward             | 0.017463181 |\n",
      "|    std                | 1.4e+07     |\n",
      "|    value_loss         | 0.000884    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 84600       |\n",
      "|    time_elapsed       | 1286        |\n",
      "|    total_timesteps    | 423000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84599       |\n",
      "|    policy_loss        | 1.63        |\n",
      "|    reward             | -0.04244334 |\n",
      "|    std                | 1.43e+07    |\n",
      "|    value_loss         | 0.0028      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 84700       |\n",
      "|    time_elapsed       | 1288        |\n",
      "|    total_timesteps    | 423500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84699       |\n",
      "|    policy_loss        | 0.879       |\n",
      "|    reward             | 0.008854604 |\n",
      "|    std                | 1.44e+07    |\n",
      "|    value_loss         | 0.000846    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 84800        |\n",
      "|    time_elapsed       | 1290         |\n",
      "|    total_timesteps    | 424000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84799        |\n",
      "|    policy_loss        | -0.463       |\n",
      "|    reward             | -0.010940376 |\n",
      "|    std                | 1.47e+07     |\n",
      "|    value_loss         | 0.00057      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 84900         |\n",
      "|    time_elapsed       | 1291          |\n",
      "|    total_timesteps    | 424500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.9         |\n",
      "|    explained_variance | 3.58e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84899         |\n",
      "|    policy_loss        | 1.38          |\n",
      "|    reward             | -0.0008346138 |\n",
      "|    std                | 1.49e+07      |\n",
      "|    value_loss         | 0.00178       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 85000       |\n",
      "|    time_elapsed       | 1293        |\n",
      "|    total_timesteps    | 425000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84999       |\n",
      "|    policy_loss        | 0.513       |\n",
      "|    reward             | -0.03389812 |\n",
      "|    std                | 1.5e+07     |\n",
      "|    value_loss         | 0.000496    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 85100       |\n",
      "|    time_elapsed       | 1294        |\n",
      "|    total_timesteps    | 425500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.9       |\n",
      "|    explained_variance | 0.079       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85099       |\n",
      "|    policy_loss        | -1.08       |\n",
      "|    reward             | 0.097424194 |\n",
      "|    std                | 1.53e+07    |\n",
      "|    value_loss         | 0.00386     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 85200        |\n",
      "|    time_elapsed       | 1296         |\n",
      "|    total_timesteps    | 426000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85199        |\n",
      "|    policy_loss        | -0.702       |\n",
      "|    reward             | 0.0015934822 |\n",
      "|    std                | 1.54e+07     |\n",
      "|    value_loss         | 0.000458     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 85300         |\n",
      "|    time_elapsed       | 1298          |\n",
      "|    total_timesteps    | 426500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85299         |\n",
      "|    policy_loss        | 1.15          |\n",
      "|    reward             | -0.0033672268 |\n",
      "|    std                | 1.55e+07      |\n",
      "|    value_loss         | 0.00103       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 85400       |\n",
      "|    time_elapsed       | 1299        |\n",
      "|    total_timesteps    | 427000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85399       |\n",
      "|    policy_loss        | 0.534       |\n",
      "|    reward             | 0.028240446 |\n",
      "|    std                | 1.56e+07    |\n",
      "|    value_loss         | 0.000489    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 85500        |\n",
      "|    time_elapsed       | 1301         |\n",
      "|    total_timesteps    | 427500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36          |\n",
      "|    explained_variance | 0.139        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85499        |\n",
      "|    policy_loss        | 0.0163       |\n",
      "|    reward             | -0.004936717 |\n",
      "|    std                | 1.57e+07     |\n",
      "|    value_loss         | 4.82e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 85600         |\n",
      "|    time_elapsed       | 1303          |\n",
      "|    total_timesteps    | 428000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85599         |\n",
      "|    policy_loss        | -0.446        |\n",
      "|    reward             | -0.0035596604 |\n",
      "|    std                | 1.6e+07       |\n",
      "|    value_loss         | 0.000692      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 85700       |\n",
      "|    time_elapsed       | 1304        |\n",
      "|    total_timesteps    | 428500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85699       |\n",
      "|    policy_loss        | 2.44        |\n",
      "|    reward             | -0.07160369 |\n",
      "|    std                | 1.64e+07    |\n",
      "|    value_loss         | 0.00495     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 85800        |\n",
      "|    time_elapsed       | 1306         |\n",
      "|    total_timesteps    | 429000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85799        |\n",
      "|    policy_loss        | 1.45         |\n",
      "|    reward             | -0.034831204 |\n",
      "|    std                | 1.67e+07     |\n",
      "|    value_loss         | 0.0021       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 85900       |\n",
      "|    time_elapsed       | 1307        |\n",
      "|    total_timesteps    | 429500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85899       |\n",
      "|    policy_loss        | -0.196      |\n",
      "|    reward             | 0.012016507 |\n",
      "|    std                | 1.72e+07    |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 86000        |\n",
      "|    time_elapsed       | 1309         |\n",
      "|    total_timesteps    | 430000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.2        |\n",
      "|    explained_variance | -0.14        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85999        |\n",
      "|    policy_loss        | 0.136        |\n",
      "|    reward             | -0.005935109 |\n",
      "|    std                | 1.76e+07     |\n",
      "|    value_loss         | 4.41e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 86100         |\n",
      "|    time_elapsed       | 1311          |\n",
      "|    total_timesteps    | 430500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.3         |\n",
      "|    explained_variance | 0.178         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86099         |\n",
      "|    policy_loss        | 0.218         |\n",
      "|    reward             | -0.0017324224 |\n",
      "|    std                | 1.82e+07      |\n",
      "|    value_loss         | 4.15e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 86200        |\n",
      "|    time_elapsed       | 1312         |\n",
      "|    total_timesteps    | 431000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86199        |\n",
      "|    policy_loss        | 0.171        |\n",
      "|    reward             | 0.0018946838 |\n",
      "|    std                | 1.89e+07     |\n",
      "|    value_loss         | 5.87e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 86300       |\n",
      "|    time_elapsed       | 1314        |\n",
      "|    total_timesteps    | 431500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86299       |\n",
      "|    policy_loss        | 0.144       |\n",
      "|    reward             | 0.052598063 |\n",
      "|    std                | 1.95e+07    |\n",
      "|    value_loss         | 0.000205    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 86400      |\n",
      "|    time_elapsed       | 1315       |\n",
      "|    total_timesteps    | 432000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86399      |\n",
      "|    policy_loss        | 2.21       |\n",
      "|    reward             | 0.02429244 |\n",
      "|    std                | 2.01e+07   |\n",
      "|    value_loss         | 0.00804    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 86500         |\n",
      "|    time_elapsed       | 1317          |\n",
      "|    total_timesteps    | 432500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86499         |\n",
      "|    policy_loss        | -0.0586       |\n",
      "|    reward             | -0.0063628783 |\n",
      "|    std                | 2.07e+07      |\n",
      "|    value_loss         | 6.4e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 86600        |\n",
      "|    time_elapsed       | 1318         |\n",
      "|    total_timesteps    | 433000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86599        |\n",
      "|    policy_loss        | -0.0523      |\n",
      "|    reward             | 0.0030879204 |\n",
      "|    std                | 2.16e+07     |\n",
      "|    value_loss         | 6.93e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 86700        |\n",
      "|    time_elapsed       | 1320         |\n",
      "|    total_timesteps    | 433500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86699        |\n",
      "|    policy_loss        | 0.292        |\n",
      "|    reward             | -0.008109912 |\n",
      "|    std                | 2.24e+07     |\n",
      "|    value_loss         | 7.4e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 86800       |\n",
      "|    time_elapsed       | 1321        |\n",
      "|    total_timesteps    | 434000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.7       |\n",
      "|    explained_variance | -1.54       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86799       |\n",
      "|    policy_loss        | -0.689      |\n",
      "|    reward             | 0.003372161 |\n",
      "|    std                | 2.3e+07     |\n",
      "|    value_loss         | 0.000385    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 86900        |\n",
      "|    time_elapsed       | 1322         |\n",
      "|    total_timesteps    | 434500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86899        |\n",
      "|    policy_loss        | 0.877        |\n",
      "|    reward             | -0.018499967 |\n",
      "|    std                | 2.38e+07     |\n",
      "|    value_loss         | 0.000613     |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -13785.15\n",
      "total_reward: -23785.15\n",
      "total_cost: 454.79\n",
      "total_trades: 5792\n",
      "Sharpe: -0.074\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 87000         |\n",
      "|    time_elapsed       | 1324          |\n",
      "|    total_timesteps    | 435000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86999         |\n",
      "|    policy_loss        | -0.655        |\n",
      "|    reward             | -0.0117597375 |\n",
      "|    std                | 2.48e+07      |\n",
      "|    value_loss         | 0.000434      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 87100        |\n",
      "|    time_elapsed       | 1326         |\n",
      "|    total_timesteps    | 435500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87099        |\n",
      "|    policy_loss        | 0.585        |\n",
      "|    reward             | 0.0038842752 |\n",
      "|    std                | 2.56e+07     |\n",
      "|    value_loss         | 0.000265     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1327        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | -0.18       |\n",
      "|    reward             | 0.009482638 |\n",
      "|    std                | 2.65e+07    |\n",
      "|    value_loss         | 9.26e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 87300         |\n",
      "|    time_elapsed       | 1329          |\n",
      "|    total_timesteps    | 436500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.1         |\n",
      "|    explained_variance | -0.0158       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87299         |\n",
      "|    policy_loss        | -0.183        |\n",
      "|    reward             | -0.0025732194 |\n",
      "|    std                | 2.76e+07      |\n",
      "|    value_loss         | 6.3e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 87400         |\n",
      "|    time_elapsed       | 1330          |\n",
      "|    total_timesteps    | 437000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87399         |\n",
      "|    policy_loss        | -0.036        |\n",
      "|    reward             | -0.0011208069 |\n",
      "|    std                | 2.91e+07      |\n",
      "|    value_loss         | 4.64e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 87500        |\n",
      "|    time_elapsed       | 1332         |\n",
      "|    total_timesteps    | 437500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87499        |\n",
      "|    policy_loss        | -1.27        |\n",
      "|    reward             | -0.023927825 |\n",
      "|    std                | 2.99e+07     |\n",
      "|    value_loss         | 0.00197      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 87600       |\n",
      "|    time_elapsed       | 1333        |\n",
      "|    total_timesteps    | 438000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87599       |\n",
      "|    policy_loss        | 4.23        |\n",
      "|    reward             | 0.027765894 |\n",
      "|    std                | 3.04e+07    |\n",
      "|    value_loss         | 0.0156      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 87700       |\n",
      "|    time_elapsed       | 1335        |\n",
      "|    total_timesteps    | 438500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87699       |\n",
      "|    policy_loss        | -0.278      |\n",
      "|    reward             | -0.00436798 |\n",
      "|    std                | 3.12e+07    |\n",
      "|    value_loss         | 8.29e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 328            |\n",
      "|    iterations         | 87800          |\n",
      "|    time_elapsed       | 1336           |\n",
      "|    total_timesteps    | 439000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -37.4          |\n",
      "|    explained_variance | 0.147          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 87799          |\n",
      "|    policy_loss        | -2.24          |\n",
      "|    reward             | -0.00079974177 |\n",
      "|    std                | 3.18e+07       |\n",
      "|    value_loss         | 0.00429        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 87900       |\n",
      "|    time_elapsed       | 1338        |\n",
      "|    total_timesteps    | 439500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.4       |\n",
      "|    explained_variance | 0.146       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87899       |\n",
      "|    policy_loss        | 0.273       |\n",
      "|    reward             | 0.015666483 |\n",
      "|    std                | 3.24e+07    |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 88000       |\n",
      "|    time_elapsed       | 1340        |\n",
      "|    total_timesteps    | 440000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87999       |\n",
      "|    policy_loss        | 3.18        |\n",
      "|    reward             | -0.06034232 |\n",
      "|    std                | 3.28e+07    |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 88100        |\n",
      "|    time_elapsed       | 1341         |\n",
      "|    total_timesteps    | 440500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88099        |\n",
      "|    policy_loss        | -1.32        |\n",
      "|    reward             | -0.015410772 |\n",
      "|    std                | 3.31e+07     |\n",
      "|    value_loss         | 0.00124      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 88200       |\n",
      "|    time_elapsed       | 1343        |\n",
      "|    total_timesteps    | 441000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88199       |\n",
      "|    policy_loss        | 0.154       |\n",
      "|    reward             | 0.022487674 |\n",
      "|    std                | 3.36e+07    |\n",
      "|    value_loss         | 4.03e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 88300        |\n",
      "|    time_elapsed       | 1344         |\n",
      "|    total_timesteps    | 441500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88299        |\n",
      "|    policy_loss        | -0.283       |\n",
      "|    reward             | -0.013686325 |\n",
      "|    std                | 3.43e+07     |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 88400       |\n",
      "|    time_elapsed       | 1346        |\n",
      "|    total_timesteps    | 442000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88399       |\n",
      "|    policy_loss        | -0.315      |\n",
      "|    reward             | 0.001051504 |\n",
      "|    std                | 3.55e+07    |\n",
      "|    value_loss         | 8.69e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 88500        |\n",
      "|    time_elapsed       | 1347         |\n",
      "|    total_timesteps    | 442500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.7        |\n",
      "|    explained_variance | -0.0508      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88499        |\n",
      "|    policy_loss        | -0.25        |\n",
      "|    reward             | 0.0080053955 |\n",
      "|    std                | 3.68e+07     |\n",
      "|    value_loss         | 0.000323     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 88600       |\n",
      "|    time_elapsed       | 1349        |\n",
      "|    total_timesteps    | 443000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88599       |\n",
      "|    policy_loss        | -0.766      |\n",
      "|    reward             | 0.009499847 |\n",
      "|    std                | 3.79e+07    |\n",
      "|    value_loss         | 0.000489    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 88700       |\n",
      "|    time_elapsed       | 1350        |\n",
      "|    total_timesteps    | 443500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -37.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88699       |\n",
      "|    policy_loss        | 1.41        |\n",
      "|    reward             | 0.014557849 |\n",
      "|    std                | 3.89e+07    |\n",
      "|    value_loss         | 0.00151     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 88800         |\n",
      "|    time_elapsed       | 1352          |\n",
      "|    total_timesteps    | 444000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88799         |\n",
      "|    policy_loss        | 1.17          |\n",
      "|    reward             | -0.0030557807 |\n",
      "|    std                | 4.01e+07      |\n",
      "|    value_loss         | 0.00102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 88900         |\n",
      "|    time_elapsed       | 1354          |\n",
      "|    total_timesteps    | 444500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.9         |\n",
      "|    explained_variance | 0.00566       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88899         |\n",
      "|    policy_loss        | 1.73          |\n",
      "|    reward             | -0.0018214027 |\n",
      "|    std                | 4.08e+07      |\n",
      "|    value_loss         | 0.00295       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 89000        |\n",
      "|    time_elapsed       | 1355         |\n",
      "|    total_timesteps    | 445000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88999        |\n",
      "|    policy_loss        | 1.88         |\n",
      "|    reward             | -0.012502312 |\n",
      "|    std                | 4.13e+07     |\n",
      "|    value_loss         | 0.0026       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 89100         |\n",
      "|    time_elapsed       | 1357          |\n",
      "|    total_timesteps    | 445500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -37.9         |\n",
      "|    explained_variance | 0.28          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89099         |\n",
      "|    policy_loss        | -3.58         |\n",
      "|    reward             | -0.0028557265 |\n",
      "|    std                | 4.23e+07      |\n",
      "|    value_loss         | 0.0105        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 89200      |\n",
      "|    time_elapsed       | 1358       |\n",
      "|    total_timesteps    | 446000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89199      |\n",
      "|    policy_loss        | -4.41      |\n",
      "|    reward             | 0.12178164 |\n",
      "|    std                | 4.28e+07   |\n",
      "|    value_loss         | 0.018      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 89300       |\n",
      "|    time_elapsed       | 1360        |\n",
      "|    total_timesteps    | 446500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89299       |\n",
      "|    policy_loss        | -2.03       |\n",
      "|    reward             | -0.03430542 |\n",
      "|    std                | 4.37e+07    |\n",
      "|    value_loss         | 0.00395     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 89400         |\n",
      "|    time_elapsed       | 1361          |\n",
      "|    total_timesteps    | 447000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89399         |\n",
      "|    policy_loss        | 0.276         |\n",
      "|    reward             | -0.0135174515 |\n",
      "|    std                | 4.5e+07       |\n",
      "|    value_loss         | 6.54e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 89500        |\n",
      "|    time_elapsed       | 1363         |\n",
      "|    total_timesteps    | 447500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89499        |\n",
      "|    policy_loss        | 1.89         |\n",
      "|    reward             | -0.002955495 |\n",
      "|    std                | 4.62e+07     |\n",
      "|    value_loss         | 0.00261      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 89600         |\n",
      "|    time_elapsed       | 1364          |\n",
      "|    total_timesteps    | 448000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89599         |\n",
      "|    policy_loss        | -0.815        |\n",
      "|    reward             | -0.0007175216 |\n",
      "|    std                | 4.8e+07       |\n",
      "|    value_loss         | 0.000535      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 89700        |\n",
      "|    time_elapsed       | 1366         |\n",
      "|    total_timesteps    | 448500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.3        |\n",
      "|    explained_variance | 0.00151      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89699        |\n",
      "|    policy_loss        | -0.463       |\n",
      "|    reward             | 0.0008875615 |\n",
      "|    std                | 4.98e+07     |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 89800         |\n",
      "|    time_elapsed       | 1368          |\n",
      "|    total_timesteps    | 449000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89799         |\n",
      "|    policy_loss        | -0.00808      |\n",
      "|    reward             | -0.0064005675 |\n",
      "|    std                | 5.17e+07      |\n",
      "|    value_loss         | 4.59e-06      |\n",
      "-----------------------------------------\n",
      "day: 2896, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12140.75\n",
      "total_reward: -22140.75\n",
      "total_cost: 553.95\n",
      "total_trades: 5792\n",
      "Sharpe: 0.384\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 89900       |\n",
      "|    time_elapsed       | 1369        |\n",
      "|    total_timesteps    | 449500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89899       |\n",
      "|    policy_loss        | -0.381      |\n",
      "|    reward             | -0.06444764 |\n",
      "|    std                | 5.29e+07    |\n",
      "|    value_loss         | 0.00208     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 90000       |\n",
      "|    time_elapsed       | 1371        |\n",
      "|    total_timesteps    | 450000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89999       |\n",
      "|    policy_loss        | 3.41        |\n",
      "|    reward             | 0.035099342 |\n",
      "|    std                | 5.33e+07    |\n",
      "|    value_loss         | 0.00843     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 90100       |\n",
      "|    time_elapsed       | 1372        |\n",
      "|    total_timesteps    | 450500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.4       |\n",
      "|    explained_variance | -0.0641     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90099       |\n",
      "|    policy_loss        | 0.262       |\n",
      "|    reward             | 0.013797865 |\n",
      "|    std                | 5.47e+07    |\n",
      "|    value_loss         | 0.000379    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 90200        |\n",
      "|    time_elapsed       | 1374         |\n",
      "|    total_timesteps    | 451000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.5        |\n",
      "|    explained_variance | 0.611        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90199        |\n",
      "|    policy_loss        | -0.443       |\n",
      "|    reward             | 0.0050442964 |\n",
      "|    std                | 5.57e+07     |\n",
      "|    value_loss         | 0.000201     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 1375        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.5       |\n",
      "|    explained_variance | 0.667       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | -0.162      |\n",
      "|    reward             | -0.02765087 |\n",
      "|    std                | 5.63e+07    |\n",
      "|    value_loss         | 0.000199    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 90400        |\n",
      "|    time_elapsed       | 1377         |\n",
      "|    total_timesteps    | 452000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90399        |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | -0.009480364 |\n",
      "|    std                | 5.72e+07     |\n",
      "|    value_loss         | 0.00169      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 90500       |\n",
      "|    time_elapsed       | 1378        |\n",
      "|    total_timesteps    | 452500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90499       |\n",
      "|    policy_loss        | 1.88        |\n",
      "|    reward             | 0.017265236 |\n",
      "|    std                | 5.82e+07    |\n",
      "|    value_loss         | 0.00261     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 90600       |\n",
      "|    time_elapsed       | 1380        |\n",
      "|    total_timesteps    | 453000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90599       |\n",
      "|    policy_loss        | 0.455       |\n",
      "|    reward             | -0.01845867 |\n",
      "|    std                | 5.89e+07    |\n",
      "|    value_loss         | 0.000184    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 90700      |\n",
      "|    time_elapsed       | 1381       |\n",
      "|    total_timesteps    | 453500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90699      |\n",
      "|    policy_loss        | 0.767      |\n",
      "|    reward             | -0.0341335 |\n",
      "|    std                | 5.99e+07   |\n",
      "|    value_loss         | 0.000978   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 90800       |\n",
      "|    time_elapsed       | 1383        |\n",
      "|    total_timesteps    | 454000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -38.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90799       |\n",
      "|    policy_loss        | -0.124      |\n",
      "|    reward             | 0.014996419 |\n",
      "|    std                | 6.11e+07    |\n",
      "|    value_loss         | 0.000554    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 90900        |\n",
      "|    time_elapsed       | 1385         |\n",
      "|    total_timesteps    | 454500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90899        |\n",
      "|    policy_loss        | -3.95        |\n",
      "|    reward             | -0.043487914 |\n",
      "|    std                | 6.22e+07     |\n",
      "|    value_loss         | 0.0172       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 91000      |\n",
      "|    time_elapsed       | 1386       |\n",
      "|    total_timesteps    | 455000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -38.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90999      |\n",
      "|    policy_loss        | -0.703     |\n",
      "|    reward             | 0.01125127 |\n",
      "|    std                | 6.33e+07   |\n",
      "|    value_loss         | 0.000452   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 91100        |\n",
      "|    time_elapsed       | 1388         |\n",
      "|    total_timesteps    | 455500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91099        |\n",
      "|    policy_loss        | 0.0754       |\n",
      "|    reward             | -0.008758622 |\n",
      "|    std                | 6.47e+07     |\n",
      "|    value_loss         | 9.55e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 91200         |\n",
      "|    time_elapsed       | 1389          |\n",
      "|    total_timesteps    | 456000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.8         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 91199         |\n",
      "|    policy_loss        | -0.0167       |\n",
      "|    reward             | -0.0030126285 |\n",
      "|    std                | 6.6e+07       |\n",
      "|    value_loss         | 9.26e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 91300        |\n",
      "|    time_elapsed       | 1391         |\n",
      "|    total_timesteps    | 456500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -38.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91299        |\n",
      "|    policy_loss        | -0.0762      |\n",
      "|    reward             | 0.0036610183 |\n",
      "|    std                | 6.84e+07     |\n",
      "|    value_loss         | 0.0001       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 91400         |\n",
      "|    time_elapsed       | 1392          |\n",
      "|    total_timesteps    | 457000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39           |\n",
      "|    explained_variance | 0.00628       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 91399         |\n",
      "|    policy_loss        | -0.428        |\n",
      "|    reward             | -0.0013177615 |\n",
      "|    std                | 7.12e+07      |\n",
      "|    value_loss         | 0.000165      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 91500        |\n",
      "|    time_elapsed       | 1394         |\n",
      "|    total_timesteps    | 457500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91499        |\n",
      "|    policy_loss        | 0.0293       |\n",
      "|    reward             | 0.0068130502 |\n",
      "|    std                | 7.43e+07     |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 91600       |\n",
      "|    time_elapsed       | 1395        |\n",
      "|    total_timesteps    | 458000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91599       |\n",
      "|    policy_loss        | -1.37       |\n",
      "|    reward             | 0.009784779 |\n",
      "|    std                | 7.62e+07    |\n",
      "|    value_loss         | 0.00234     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 91700        |\n",
      "|    time_elapsed       | 1397         |\n",
      "|    total_timesteps    | 458500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.1        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91699        |\n",
      "|    policy_loss        | -0.163       |\n",
      "|    reward             | 0.0066556283 |\n",
      "|    std                | 7.8e+07      |\n",
      "|    value_loss         | 0.000516     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 91800       |\n",
      "|    time_elapsed       | 1398        |\n",
      "|    total_timesteps    | 459000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91799       |\n",
      "|    policy_loss        | 0.651       |\n",
      "|    reward             | 0.011462617 |\n",
      "|    std                | 8.03e+07    |\n",
      "|    value_loss         | 0.000302    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 328            |\n",
      "|    iterations         | 91900          |\n",
      "|    time_elapsed       | 1400           |\n",
      "|    total_timesteps    | 459500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -39.3          |\n",
      "|    explained_variance | -1.57          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 91899          |\n",
      "|    policy_loss        | 0.112          |\n",
      "|    reward             | -0.00091991335 |\n",
      "|    std                | 8.36e+07       |\n",
      "|    value_loss         | 1.2e-05        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 92000        |\n",
      "|    time_elapsed       | 1401         |\n",
      "|    total_timesteps    | 460000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91999        |\n",
      "|    policy_loss        | 0.196        |\n",
      "|    reward             | 0.0037646454 |\n",
      "|    std                | 8.75e+07     |\n",
      "|    value_loss         | 5.86e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 92100         |\n",
      "|    time_elapsed       | 1403          |\n",
      "|    total_timesteps    | 460500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.5         |\n",
      "|    explained_variance | 0.243         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 92099         |\n",
      "|    policy_loss        | -1.03         |\n",
      "|    reward             | -0.0068210633 |\n",
      "|    std                | 9.07e+07      |\n",
      "|    value_loss         | 0.000929      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 92200      |\n",
      "|    time_elapsed       | 1405       |\n",
      "|    total_timesteps    | 461000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92199      |\n",
      "|    policy_loss        | 3.08       |\n",
      "|    reward             | 0.07779686 |\n",
      "|    std                | 9.31e+07   |\n",
      "|    value_loss         | 0.00652    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 92300       |\n",
      "|    time_elapsed       | 1406        |\n",
      "|    total_timesteps    | 461500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92299       |\n",
      "|    policy_loss        | -1.3        |\n",
      "|    reward             | 0.002723655 |\n",
      "|    std                | 9.5e+07     |\n",
      "|    value_loss         | 0.00115     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 92400        |\n",
      "|    time_elapsed       | 1408         |\n",
      "|    total_timesteps    | 462000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.6        |\n",
      "|    explained_variance | 0.00949      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92399        |\n",
      "|    policy_loss        | -0.976       |\n",
      "|    reward             | 0.0026066164 |\n",
      "|    std                | 9.75e+07     |\n",
      "|    value_loss         | 0.00135      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 92500        |\n",
      "|    time_elapsed       | 1409         |\n",
      "|    total_timesteps    | 462500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.6        |\n",
      "|    explained_variance | 0.416        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92499        |\n",
      "|    policy_loss        | 1.13         |\n",
      "|    reward             | -0.007037282 |\n",
      "|    std                | 1e+08        |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 92600        |\n",
      "|    time_elapsed       | 1411         |\n",
      "|    total_timesteps    | 463000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.6        |\n",
      "|    explained_variance | 4.95e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92599        |\n",
      "|    policy_loss        | -1.22        |\n",
      "|    reward             | -0.047439475 |\n",
      "|    std                | 1e+08        |\n",
      "|    value_loss         | 0.00193      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 92700        |\n",
      "|    time_elapsed       | 1412         |\n",
      "|    total_timesteps    | 463500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.7        |\n",
      "|    explained_variance | 0.315        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92699        |\n",
      "|    policy_loss        | -4.4         |\n",
      "|    reward             | -0.057372525 |\n",
      "|    std                | 1.02e+08     |\n",
      "|    value_loss         | 0.0133       |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -53625.61\n",
      "total_reward: -63625.61\n",
      "total_cost: 95.92\n",
      "total_trades: 5792\n",
      "Sharpe: 0.344\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 92800        |\n",
      "|    time_elapsed       | 1414         |\n",
      "|    total_timesteps    | 464000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92799        |\n",
      "|    policy_loss        | 0.0717       |\n",
      "|    reward             | -0.037538435 |\n",
      "|    std                | 1.04e+08     |\n",
      "|    value_loss         | 0.000478     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 92900       |\n",
      "|    time_elapsed       | 1416        |\n",
      "|    total_timesteps    | 464500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92899       |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | -0.03838396 |\n",
      "|    std                | 1.05e+08    |\n",
      "|    value_loss         | 0.00222     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 93000      |\n",
      "|    time_elapsed       | 1417       |\n",
      "|    total_timesteps    | 465000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | 0.359      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92999      |\n",
      "|    policy_loss        | 5.91       |\n",
      "|    reward             | 0.08346143 |\n",
      "|    std                | 1.08e+08   |\n",
      "|    value_loss         | 0.0335     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 93100      |\n",
      "|    time_elapsed       | 1419       |\n",
      "|    total_timesteps    | 465500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93099      |\n",
      "|    policy_loss        | 14.3       |\n",
      "|    reward             | -0.2107119 |\n",
      "|    std                | 1.11e+08   |\n",
      "|    value_loss         | 0.139      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 93200      |\n",
      "|    time_elapsed       | 1420       |\n",
      "|    total_timesteps    | 466000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | 0.247      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93199      |\n",
      "|    policy_loss        | 12.2       |\n",
      "|    reward             | 0.12293881 |\n",
      "|    std                | 1.12e+08   |\n",
      "|    value_loss         | 0.101      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 93300        |\n",
      "|    time_elapsed       | 1421         |\n",
      "|    total_timesteps    | 466500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93299        |\n",
      "|    policy_loss        | -2.48        |\n",
      "|    reward             | 0.0062430706 |\n",
      "|    std                | 1.13e+08     |\n",
      "|    value_loss         | 0.00528      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 93400       |\n",
      "|    time_elapsed       | 1423        |\n",
      "|    total_timesteps    | 467000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -39.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93399       |\n",
      "|    policy_loss        | 0.472       |\n",
      "|    reward             | 0.033852357 |\n",
      "|    std                | 1.13e+08    |\n",
      "|    value_loss         | 0.0011      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 93500         |\n",
      "|    time_elapsed       | 1425          |\n",
      "|    total_timesteps    | 467500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -39.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 93499         |\n",
      "|    policy_loss        | 1.15          |\n",
      "|    reward             | -0.0054292507 |\n",
      "|    std                | 1.15e+08      |\n",
      "|    value_loss         | 0.00154       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 93600        |\n",
      "|    time_elapsed       | 1426         |\n",
      "|    total_timesteps    | 468000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.9        |\n",
      "|    explained_variance | -0.463       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93599        |\n",
      "|    policy_loss        | 2.08         |\n",
      "|    reward             | -0.015024017 |\n",
      "|    std                | 1.16e+08     |\n",
      "|    value_loss         | 0.0209       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 93700      |\n",
      "|    time_elapsed       | 1428       |\n",
      "|    total_timesteps    | 468500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -39.9      |\n",
      "|    explained_variance | 0.306      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93699      |\n",
      "|    policy_loss        | 10.3       |\n",
      "|    reward             | 0.33711016 |\n",
      "|    std                | 1.15e+08   |\n",
      "|    value_loss         | 0.0905     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 328       |\n",
      "|    iterations         | 93800     |\n",
      "|    time_elapsed       | 1429      |\n",
      "|    total_timesteps    | 469000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.9     |\n",
      "|    explained_variance | 0.146     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 93799     |\n",
      "|    policy_loss        | 0.158     |\n",
      "|    reward             | 0.2861019 |\n",
      "|    std                | 1.15e+08  |\n",
      "|    value_loss         | 0.02      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 93900        |\n",
      "|    time_elapsed       | 1430         |\n",
      "|    total_timesteps    | 469500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93899        |\n",
      "|    policy_loss        | -2.43        |\n",
      "|    reward             | -0.039866198 |\n",
      "|    std                | 1.16e+08     |\n",
      "|    value_loss         | 0.00409      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 94000        |\n",
      "|    time_elapsed       | 1432         |\n",
      "|    total_timesteps    | 470000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93999        |\n",
      "|    policy_loss        | -0.193       |\n",
      "|    reward             | -0.011974101 |\n",
      "|    std                | 1.17e+08     |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 94100       |\n",
      "|    time_elapsed       | 1433        |\n",
      "|    total_timesteps    | 470500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94099       |\n",
      "|    policy_loss        | -0.254      |\n",
      "|    reward             | 0.005022175 |\n",
      "|    std                | 1.19e+08    |\n",
      "|    value_loss         | 0.000408    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 94200        |\n",
      "|    time_elapsed       | 1435         |\n",
      "|    total_timesteps    | 471000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40          |\n",
      "|    explained_variance | -0.475       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94199        |\n",
      "|    policy_loss        | 0.839        |\n",
      "|    reward             | -0.023622353 |\n",
      "|    std                | 1.21e+08     |\n",
      "|    value_loss         | 0.000744     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 94300       |\n",
      "|    time_elapsed       | 1436        |\n",
      "|    total_timesteps    | 471500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.1       |\n",
      "|    explained_variance | 0.481       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94299       |\n",
      "|    policy_loss        | -0.345      |\n",
      "|    reward             | 0.011657622 |\n",
      "|    std                | 1.25e+08    |\n",
      "|    value_loss         | 9.71e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 94400       |\n",
      "|    time_elapsed       | 1438        |\n",
      "|    total_timesteps    | 472000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94399       |\n",
      "|    policy_loss        | -0.643      |\n",
      "|    reward             | 0.002865123 |\n",
      "|    std                | 1.28e+08    |\n",
      "|    value_loss         | 0.00035     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 94500       |\n",
      "|    time_elapsed       | 1439        |\n",
      "|    total_timesteps    | 472500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94499       |\n",
      "|    policy_loss        | 2.05        |\n",
      "|    reward             | 0.017503308 |\n",
      "|    std                | 1.31e+08    |\n",
      "|    value_loss         | 0.00335     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 94600       |\n",
      "|    time_elapsed       | 1441        |\n",
      "|    total_timesteps    | 473000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | -0.458      |\n",
      "|    reward             | -0.02085427 |\n",
      "|    std                | 1.33e+08    |\n",
      "|    value_loss         | 0.000426    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 94700       |\n",
      "|    time_elapsed       | 1442        |\n",
      "|    total_timesteps    | 473500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.2       |\n",
      "|    explained_variance | 0.341       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94699       |\n",
      "|    policy_loss        | -0.569      |\n",
      "|    reward             | -0.00824613 |\n",
      "|    std                | 1.37e+08    |\n",
      "|    value_loss         | 0.00066     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 94800        |\n",
      "|    time_elapsed       | 1444         |\n",
      "|    total_timesteps    | 474000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.3        |\n",
      "|    explained_variance | 3.04e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94799        |\n",
      "|    policy_loss        | -0.744       |\n",
      "|    reward             | -0.018364558 |\n",
      "|    std                | 1.38e+08     |\n",
      "|    value_loss         | 0.000551     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 94900      |\n",
      "|    time_elapsed       | 1446       |\n",
      "|    total_timesteps    | 474500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | -0.172     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94899      |\n",
      "|    policy_loss        | -1.72      |\n",
      "|    reward             | 0.06751833 |\n",
      "|    std                | 1.38e+08   |\n",
      "|    value_loss         | 0.00213    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 95000      |\n",
      "|    time_elapsed       | 1447       |\n",
      "|    total_timesteps    | 475000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.3      |\n",
      "|    explained_variance | 0.242      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94999      |\n",
      "|    policy_loss        | -1.65      |\n",
      "|    reward             | 0.10592212 |\n",
      "|    std                | 1.39e+08   |\n",
      "|    value_loss         | 0.00937    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 95100       |\n",
      "|    time_elapsed       | 1449        |\n",
      "|    total_timesteps    | 475500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95099       |\n",
      "|    policy_loss        | -0.55       |\n",
      "|    reward             | 0.017898219 |\n",
      "|    std                | 1.42e+08    |\n",
      "|    value_loss         | 0.000348    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 95200       |\n",
      "|    time_elapsed       | 1450        |\n",
      "|    total_timesteps    | 476000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95199       |\n",
      "|    policy_loss        | 0.816       |\n",
      "|    reward             | -0.01216715 |\n",
      "|    std                | 1.44e+08    |\n",
      "|    value_loss         | 0.000471    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 95300        |\n",
      "|    time_elapsed       | 1452         |\n",
      "|    total_timesteps    | 476500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95299        |\n",
      "|    policy_loss        | -0.669       |\n",
      "|    reward             | 0.0003342594 |\n",
      "|    std                | 1.48e+08     |\n",
      "|    value_loss         | 0.000405     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 328           |\n",
      "|    iterations         | 95400         |\n",
      "|    time_elapsed       | 1454          |\n",
      "|    total_timesteps    | 477000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.4         |\n",
      "|    explained_variance | -0.0626       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95399         |\n",
      "|    policy_loss        | 0.0897        |\n",
      "|    reward             | -0.0012915961 |\n",
      "|    std                | 1.52e+08      |\n",
      "|    value_loss         | 3.83e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 95500      |\n",
      "|    time_elapsed       | 1455       |\n",
      "|    total_timesteps    | 477500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.5      |\n",
      "|    explained_variance | -0.702     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | 0.809      |\n",
      "|    reward             | 0.01264319 |\n",
      "|    std                | 1.6e+08    |\n",
      "|    value_loss         | 0.00046    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 95600       |\n",
      "|    time_elapsed       | 1457        |\n",
      "|    total_timesteps    | 478000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -40.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95599       |\n",
      "|    policy_loss        | 0.632       |\n",
      "|    reward             | 0.023387285 |\n",
      "|    std                | 1.64e+08    |\n",
      "|    value_loss         | 0.000271    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -12084.36\n",
      "total_reward: -22084.36\n",
      "total_cost: 538.50\n",
      "total_trades: 5792\n",
      "Sharpe: 0.343\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 95700        |\n",
      "|    time_elapsed       | 1458         |\n",
      "|    total_timesteps    | 478500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95699        |\n",
      "|    policy_loss        | -0.303       |\n",
      "|    reward             | 0.0022554651 |\n",
      "|    std                | 1.71e+08     |\n",
      "|    value_loss         | 0.000386     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 95800        |\n",
      "|    time_elapsed       | 1460         |\n",
      "|    total_timesteps    | 479000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95799        |\n",
      "|    policy_loss        | 0.159        |\n",
      "|    reward             | -0.006714285 |\n",
      "|    std                | 1.75e+08     |\n",
      "|    value_loss         | 6.2e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 95900        |\n",
      "|    time_elapsed       | 1461         |\n",
      "|    total_timesteps    | 479500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95899        |\n",
      "|    policy_loss        | -0.687       |\n",
      "|    reward             | -0.004149424 |\n",
      "|    std                | 1.81e+08     |\n",
      "|    value_loss         | 0.000411     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 96000        |\n",
      "|    time_elapsed       | 1463         |\n",
      "|    total_timesteps    | 480000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -40.9        |\n",
      "|    explained_variance | -0.594       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95999        |\n",
      "|    policy_loss        | 0.255        |\n",
      "|    reward             | -0.008652717 |\n",
      "|    std                | 1.88e+08     |\n",
      "|    value_loss         | 4.56e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 96100        |\n",
      "|    time_elapsed       | 1465         |\n",
      "|    total_timesteps    | 480500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41          |\n",
      "|    explained_variance | 0.939        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96099        |\n",
      "|    policy_loss        | 1.64         |\n",
      "|    reward             | -0.039458223 |\n",
      "|    std                | 1.98e+08     |\n",
      "|    value_loss         | 0.00162      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 96200       |\n",
      "|    time_elapsed       | 1466        |\n",
      "|    total_timesteps    | 481000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96199       |\n",
      "|    policy_loss        | 4.68        |\n",
      "|    reward             | 0.003971987 |\n",
      "|    std                | 2.05e+08    |\n",
      "|    value_loss         | 0.0179      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 96300        |\n",
      "|    time_elapsed       | 1468         |\n",
      "|    total_timesteps    | 481500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96299        |\n",
      "|    policy_loss        | -1.34        |\n",
      "|    reward             | 0.0031519805 |\n",
      "|    std                | 2.11e+08     |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 96400         |\n",
      "|    time_elapsed       | 1470          |\n",
      "|    total_timesteps    | 482000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.2         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96399         |\n",
      "|    policy_loss        | 0.659         |\n",
      "|    reward             | -7.791405e-05 |\n",
      "|    std                | 2.18e+08      |\n",
      "|    value_loss         | 0.000354      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 96500       |\n",
      "|    time_elapsed       | 1472        |\n",
      "|    total_timesteps    | 482500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96499       |\n",
      "|    policy_loss        | 0.267       |\n",
      "|    reward             | -0.03788347 |\n",
      "|    std                | 2.19e+08    |\n",
      "|    value_loss         | 0.000584    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 96600      |\n",
      "|    time_elapsed       | 1474       |\n",
      "|    total_timesteps    | 483000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 0.202      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96599      |\n",
      "|    policy_loss        | -6.13      |\n",
      "|    reward             | 0.06333846 |\n",
      "|    std                | 2.19e+08   |\n",
      "|    value_loss         | 0.0235     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 96700      |\n",
      "|    time_elapsed       | 1475       |\n",
      "|    total_timesteps    | 483500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96699      |\n",
      "|    policy_loss        | -0.733     |\n",
      "|    reward             | 0.08169677 |\n",
      "|    std                | 2.16e+08   |\n",
      "|    value_loss         | 0.000999   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 96800      |\n",
      "|    time_elapsed       | 1477       |\n",
      "|    total_timesteps    | 484000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96799      |\n",
      "|    policy_loss        | -2.76      |\n",
      "|    reward             | 0.09922254 |\n",
      "|    std                | 2.19e+08   |\n",
      "|    value_loss         | 0.00487    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 96900        |\n",
      "|    time_elapsed       | 1478         |\n",
      "|    total_timesteps    | 484500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96899        |\n",
      "|    policy_loss        | -1.05        |\n",
      "|    reward             | -0.019993639 |\n",
      "|    std                | 2.22e+08     |\n",
      "|    value_loss         | 0.00408      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 97000       |\n",
      "|    time_elapsed       | 1480        |\n",
      "|    total_timesteps    | 485000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96999       |\n",
      "|    policy_loss        | 2.01        |\n",
      "|    reward             | -0.34973568 |\n",
      "|    std                | 2.26e+08    |\n",
      "|    value_loss         | 0.00251     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 97100       |\n",
      "|    time_elapsed       | 1481        |\n",
      "|    total_timesteps    | 485500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97099       |\n",
      "|    policy_loss        | -0.961      |\n",
      "|    reward             | -0.10082527 |\n",
      "|    std                | 2.29e+08    |\n",
      "|    value_loss         | 0.00552     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 97200       |\n",
      "|    time_elapsed       | 1483        |\n",
      "|    total_timesteps    | 486000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 0.418       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97199       |\n",
      "|    policy_loss        | 20.5        |\n",
      "|    reward             | -0.16741504 |\n",
      "|    std                | 2.31e+08    |\n",
      "|    value_loss         | 0.284       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 97300      |\n",
      "|    time_elapsed       | 1484       |\n",
      "|    total_timesteps    | 486500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | 0.0991     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97299      |\n",
      "|    policy_loss        | -10.4      |\n",
      "|    reward             | -0.2817525 |\n",
      "|    std                | 2.32e+08   |\n",
      "|    value_loss         | 0.225      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 97400       |\n",
      "|    time_elapsed       | 1486        |\n",
      "|    total_timesteps    | 487000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97399       |\n",
      "|    policy_loss        | 0.581       |\n",
      "|    reward             | 0.019633317 |\n",
      "|    std                | 2.34e+08    |\n",
      "|    value_loss         | 0.000265    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 97500       |\n",
      "|    time_elapsed       | 1488        |\n",
      "|    total_timesteps    | 487500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97499       |\n",
      "|    policy_loss        | 0.412       |\n",
      "|    reward             | 0.006718524 |\n",
      "|    std                | 2.39e+08    |\n",
      "|    value_loss         | 0.000201    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 97600       |\n",
      "|    time_elapsed       | 1489        |\n",
      "|    total_timesteps    | 488000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97599       |\n",
      "|    policy_loss        | -0.0821     |\n",
      "|    reward             | 0.011781273 |\n",
      "|    std                | 2.43e+08    |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 97700       |\n",
      "|    time_elapsed       | 1491        |\n",
      "|    total_timesteps    | 488500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97699       |\n",
      "|    policy_loss        | -0.836      |\n",
      "|    reward             | 0.002879062 |\n",
      "|    std                | 2.49e+08    |\n",
      "|    value_loss         | 0.000437    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 97800         |\n",
      "|    time_elapsed       | 1492          |\n",
      "|    total_timesteps    | 489000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.5         |\n",
      "|    explained_variance | -1.74         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97799         |\n",
      "|    policy_loss        | 2.42          |\n",
      "|    reward             | -0.0007031015 |\n",
      "|    std                | 2.6e+08       |\n",
      "|    value_loss         | 0.00462       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 97900        |\n",
      "|    time_elapsed       | 1494         |\n",
      "|    total_timesteps    | 489500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97899        |\n",
      "|    policy_loss        | -0.11        |\n",
      "|    reward             | 0.0043969178 |\n",
      "|    std                | 2.67e+08     |\n",
      "|    value_loss         | 0.000491     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 98000      |\n",
      "|    time_elapsed       | 1495       |\n",
      "|    total_timesteps    | 490000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97999      |\n",
      "|    policy_loss        | 2.72       |\n",
      "|    reward             | 0.09258823 |\n",
      "|    std                | 2.76e+08   |\n",
      "|    value_loss         | 0.00542    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 98100         |\n",
      "|    time_elapsed       | 1497          |\n",
      "|    total_timesteps    | 490500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 98099         |\n",
      "|    policy_loss        | 0.969         |\n",
      "|    reward             | -0.0070766225 |\n",
      "|    std                | 2.8e+08       |\n",
      "|    value_loss         | 0.000552      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 98200        |\n",
      "|    time_elapsed       | 1498         |\n",
      "|    total_timesteps    | 491000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.7        |\n",
      "|    explained_variance | 0.18         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98199        |\n",
      "|    policy_loss        | -0.706       |\n",
      "|    reward             | -0.015020457 |\n",
      "|    std                | 2.87e+08     |\n",
      "|    value_loss         | 0.00188      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 98300      |\n",
      "|    time_elapsed       | 1500       |\n",
      "|    total_timesteps    | 491500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | 0.376      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98299      |\n",
      "|    policy_loss        | 0.913      |\n",
      "|    reward             | 0.01750887 |\n",
      "|    std                | 2.93e+08   |\n",
      "|    value_loss         | 0.00127    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 98400       |\n",
      "|    time_elapsed       | 1501        |\n",
      "|    total_timesteps    | 492000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.8       |\n",
      "|    explained_variance | 0.383       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98399       |\n",
      "|    policy_loss        | -2.65       |\n",
      "|    reward             | 0.075162545 |\n",
      "|    std                | 2.98e+08    |\n",
      "|    value_loss         | 0.00726     |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: -74423.65\n",
      "total_reward: -84423.65\n",
      "total_cost: 97.64\n",
      "total_trades: 5792\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 98500       |\n",
      "|    time_elapsed       | 1503        |\n",
      "|    total_timesteps    | 492500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98499       |\n",
      "|    policy_loss        | 1.99        |\n",
      "|    reward             | 0.016951395 |\n",
      "|    std                | 2.99e+08    |\n",
      "|    value_loss         | 0.00329     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 98600       |\n",
      "|    time_elapsed       | 1505        |\n",
      "|    total_timesteps    | 493000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98599       |\n",
      "|    policy_loss        | 0.433       |\n",
      "|    reward             | 0.071403675 |\n",
      "|    std                | 3.04e+08    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 98700       |\n",
      "|    time_elapsed       | 1506        |\n",
      "|    total_timesteps    | 493500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98699       |\n",
      "|    policy_loss        | -2          |\n",
      "|    reward             | 0.091547035 |\n",
      "|    std                | 3.1e+08     |\n",
      "|    value_loss         | 0.00345     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 98800      |\n",
      "|    time_elapsed       | 1508       |\n",
      "|    total_timesteps    | 494000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | -8.02      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98799      |\n",
      "|    policy_loss        | 1.6        |\n",
      "|    reward             | -0.1498364 |\n",
      "|    std                | 3.09e+08   |\n",
      "|    value_loss         | 0.0169     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 327        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 1509       |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | 0.232      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98899      |\n",
      "|    policy_loss        | 26.9       |\n",
      "|    reward             | 0.16559587 |\n",
      "|    std                | 3.12e+08   |\n",
      "|    value_loss         | 0.509      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 99000        |\n",
      "|    time_elapsed       | 1511         |\n",
      "|    total_timesteps    | 495000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98999        |\n",
      "|    policy_loss        | 114          |\n",
      "|    reward             | -0.031402018 |\n",
      "|    std                | 3.12e+08     |\n",
      "|    value_loss         | 8            |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 99100        |\n",
      "|    time_elapsed       | 1512         |\n",
      "|    total_timesteps    | 495500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -41.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99099        |\n",
      "|    policy_loss        | -1.32        |\n",
      "|    reward             | -0.012498277 |\n",
      "|    std                | 3.11e+08     |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 99200       |\n",
      "|    time_elapsed       | 1514        |\n",
      "|    total_timesteps    | 496000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -41.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99199       |\n",
      "|    policy_loss        | 0.247       |\n",
      "|    reward             | 0.009729107 |\n",
      "|    std                | 3.15e+08    |\n",
      "|    value_loss         | 4.32e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 99300         |\n",
      "|    time_elapsed       | 1515          |\n",
      "|    total_timesteps    | 496500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99299         |\n",
      "|    policy_loss        | 0.186         |\n",
      "|    reward             | -0.0017236468 |\n",
      "|    std                | 3.19e+08      |\n",
      "|    value_loss         | 3.12e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 99400         |\n",
      "|    time_elapsed       | 1517          |\n",
      "|    total_timesteps    | 497000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99399         |\n",
      "|    policy_loss        | 0.305         |\n",
      "|    reward             | -0.0027529749 |\n",
      "|    std                | 3.25e+08      |\n",
      "|    value_loss         | 0.000105      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 99500       |\n",
      "|    time_elapsed       | 1519        |\n",
      "|    total_timesteps    | 497500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42         |\n",
      "|    explained_variance | 0.629       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99499       |\n",
      "|    policy_loss        | -0.134      |\n",
      "|    reward             | 0.002006278 |\n",
      "|    std                | 3.35e+08    |\n",
      "|    value_loss         | 3.92e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 99600        |\n",
      "|    time_elapsed       | 1520         |\n",
      "|    total_timesteps    | 498000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99599        |\n",
      "|    policy_loss        | 0.753        |\n",
      "|    reward             | 0.0005176514 |\n",
      "|    std                | 3.42e+08     |\n",
      "|    value_loss         | 0.000326     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 99700        |\n",
      "|    time_elapsed       | 1522         |\n",
      "|    total_timesteps    | 498500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99699        |\n",
      "|    policy_loss        | -0.0539      |\n",
      "|    reward             | -0.016747462 |\n",
      "|    std                | 3.47e+08     |\n",
      "|    value_loss         | 0.000146     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 99800         |\n",
      "|    time_elapsed       | 1523          |\n",
      "|    total_timesteps    | 499000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99799         |\n",
      "|    policy_loss        | 0.066         |\n",
      "|    reward             | -0.0070799226 |\n",
      "|    std                | 3.56e+08      |\n",
      "|    value_loss         | 9.02e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 99900       |\n",
      "|    time_elapsed       | 1525        |\n",
      "|    total_timesteps    | 499500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99899       |\n",
      "|    policy_loss        | -0.547      |\n",
      "|    reward             | 0.019271394 |\n",
      "|    std                | 3.69e+08    |\n",
      "|    value_loss         | 0.000247    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 100000       |\n",
      "|    time_elapsed       | 1526         |\n",
      "|    total_timesteps    | 500000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99999        |\n",
      "|    policy_loss        | -0.0841      |\n",
      "|    reward             | -0.016412662 |\n",
      "|    std                | 3.83e+08     |\n",
      "|    value_loss         | 1.85e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======A2C Validation from:  2021-10-04 to  2022-01-03\n",
      "A2C Sharpe Ratio:  -0.40645046565625265\n",
      "======Best Model Retraining from:  2010-04-01 to  2022-01-03\n",
      "======Trading from:  2022-01-03 to  2022-04-04\n",
      "[[ 1.1509458e+04  1.5568901e+02  6.4265143e+02 -1.6000000e+01\n",
      "  -3.0000000e+00  9.6467656e-01  2.7117748e+01  1.6118150e+02\n",
      "   6.8079883e+02  1.4802783e+02  5.4665094e+02  4.9942398e+01\n",
      "   6.7751945e+01  3.0670872e+01  9.1113693e+01  4.2563453e+00\n",
      "   5.3900658e+01  1.5406818e+02  5.8775287e+02  1.5493849e+02\n",
      "   5.4942822e+02]]\n",
      "Ensemble Strategy took:  103.03052273591359  minutes\n"
     ]
    }
   ],
   "source": [
    "# df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "#                                                  PPO_model_kwargs,\n",
    "#                                                  DDPG_model_kwargs,\n",
    "#                                                  timesteps_dict)\n",
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 None,\n",
    "                                                 None,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "-0qd8acMtj1f",
    "outputId": "b5d9cb94-51a9-4569-a9a8-7e18f1139f4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.058675</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.29121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.209951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.40645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126  2021-01-04  2021-04-06        A2C  -0.058675          0           0\n",
       "1  189  2021-04-06  2021-07-06        A2C   -0.29121          0           0\n",
       "2  252  2021-07-06  2021-10-04        A2C  -0.209951          0           0\n",
       "3  315  2021-10-04  2022-01-03        A2C   -0.40645          0           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9mKF7GGtj1g",
    "outputId": "8b89807b-ff71-4902-dd45-1f9111788cbb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  -1.2529620258201952\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oyosyW7_tj1g",
    "outputId": "d2dc62c2-e2a0-48fc-8183-0399d1b27f53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9999.023978</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>2021-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9998.250580</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001.288105</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>2021-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9999.473356</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>2021-04-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   10000.000000  2021-04-06           NaN  2021-04-06\n",
       "1    9999.023978  2021-04-07     -0.000098  2021-04-07\n",
       "2    9998.250580  2021-04-08     -0.000077  2021-04-08\n",
       "3   10001.288105  2021-04-09      0.000304  2021-04-09\n",
       "4    9999.473356  2021-04-12     -0.000181  2021-04-12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "wLsRdw2Ctj1h",
    "outputId": "9a874df9-2c5f-423c-8fd2-8966aab63fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "b419a565-8c15-47d8-f66c-00f81c3c526d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return         -0.255350\n",
      "Cumulative returns    -0.255350\n",
      "Annual volatility      0.217373\n",
      "Sharpe ratio          -1.252962\n",
      "Calmar ratio          -0.741627\n",
      "Stability              0.784744\n",
      "Max drawdown          -0.344311\n",
      "Omega ratio            0.805421\n",
      "Sortino ratio         -1.739329\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.779021\n",
      "Daily value at risk   -0.028467\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiHhM1YkoCel",
    "outputId": "903ef035-f9f4-4678-d18a-1516254eaf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (251, 8)\n",
      "Annual return          0.112517\n",
      "Cumulative returns     0.112046\n",
      "Annual volatility      0.149492\n",
      "Sharpe ratio           0.790765\n",
      "Calmar ratio           0.862325\n",
      "Stability              0.388079\n",
      "Max drawdown          -0.130481\n",
      "Omega ratio            1.139645\n",
      "Sortino ratio          1.131726\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.856084\n",
      "Daily value at risk   -0.018365\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^GSPC\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HggausPRoCem",
    "outputId": "e61a64e0-58ed-4490-b19a-78bd4f76e666",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (251, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.43</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.38</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.56</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.05</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>-0.11%</td>\n",
       "      <td>-4.52%</td>\n",
       "      <td>5.24%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAA36CAYAAABTrs5sAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9d3xkaXnn/X/uilIp59gtde6Zno7TMz3Tk2GAwSbZgO21AYNN8q4DD8/LXh7sn40xxrvOu34eG3ZZL/YagzEm2IAHmGHy9KSe6emcW1mtnEuqeP/+KNXpUi6pSyqF7/v10qvrnDrn1F3SjFTXua77uo21FhEREREREVmdXNkegIiIiIiIiMxNQZuIiIiIiMgqpqBNRERERERkFVPQJiIiIiIisoopaBMREREREVnFFLSJiIiIiIisYgraRERkQzPGfNkY8+WbvManjTH/nqEhiYiITKGgTUREVoQxZp8x5uvGmOvGmFFjzFVjzN8bY27L9tgWwxjzpDHmM6n7rLWft9a+NUtDmpMxpskY88Fsj0NERG6OgjYREVl2xpgHgReBduAIUAAcBp4D3pm1ga1RxhjfCr6WyxjjXqnXExGRmRS0iYjISvgi8HVr7f9lrW22Cf3W2i9aa/8QZi9TnJ7VMsZYY8yvG2NeMsaMGWNeMMZsntzXYozpN8b8l5TjHzTG2GnX/KAxpmmugRpj/sAYc3kyG9g8ue2afO4LwH3Apyefvz65/zPGmCcnH/9HY8z5adcsmDz+DZPbxcaYv5m8fp8x5vvGmK3zjOmDk1mzTxhjWoCWyf27jTHfNcZ0GWPajTF/bYzJm3zu34HNwBcmX/ul2b6nk/ucjJwxpnHy+/zLxpjTQBC4ZfKY3zbG/LsxZsQYc8kY886Ua+w3xjxljBk0xgwYY44bY3bN9Z5ERCR9CtpERGRZGWN2ADuB/5OhS74PeDdQQSKgeAyoBLYDbwQ+aYx54CaufwF4kEQ28D3ArwC/DGCt/TjwDPB5a22+tbZ6lvP/EWgwxtyTsu9ngS7gCWOMAb4F5AMHgVrgJPBdY4x3nnHVk/g+3gJsNcaUT47lhySCs/3ADuAvJ8f6VhLB3ccnx3rn4r4N/CLwyOQ4L07u+wjwaaAI+B/A3xtj8ief+2vgcaCcxM/ml4HBRb6miIjMQkGbiIgst8rJf9szdL2/sNa2WmuDwDeAOuD3rLVha+1rwGkSpZdLYq39B2tt22Q28GXgK8DDizh/EPgXJgO9Sb8M/K211pII1O4GPjaZbQwBv00i8Doyz6XjwCettWOT7/0DwHlr7X+31oastb3A7wAfyFA54+9Pfh+i1trw5L7/Ya19zVobB/4GKASS2bTw5HtomDznhLW2KwPjEBHZ8BS0iYjIcuue/LcuQ9frTHkcBHqstbFp+wqWenFjzK8YY05MlvgNAh/jRuCZri8BP2OMyTfG3ArcAfzvyed2AD6gY7KUcBDoA9zApnmued1aO5GyvQM4krzG5HV+CFhgtgzgYl2bZV9H8oG1dnTyYfJ7/cHJ1/6xMabVGPMXyVJNERG5OZ5sD0BERNY3a+0lY8xF4BdIlDLOZYSZwUbtTb78CIAxJs9aO7bQNY0xR0mUF74JeN5aGzXG/DcSpYdJ8TRe9ykSweXPkihnfNRamwx4rgPjQLm1NrqI9zL9da8DT1pr37yIcyDxPXGCKWOMh9mD0nTep8Na20yifBJjzHbgO8Aw8HuLuY6IiMykTJuIiKyEjwE/a4z5k8nGIWayGccvG2M+PXnMK8AbjTE7jTFeY8wngC03+boXSQQpH5vsgngA+Og8xxcBMaAHiBlj7iMRbKa6TmJu2ZwmyyD/lsT7fj+JzFvSs8A54K+NMZUAxpgSY8y7jTGBdN8YiczdYWPMx40xgcnv6SZjzLumjXV6M5BXgHcZY2qMMbnAfwHmm0uXlslmKfWTc/aGgSiJ76WIiNwkBW0iIrLsrLVPkpjH1UAiaBgBXiPRifHbk4d9Bfhn4AWgFSgmsSTAzbzuCImGGv+JRCDxRyQaaMzlB8D/mnzdfuDXJ8eV6s+A2yZLEtvmudbfAYdIlAx+N2VMMRKZvAngRWPMCPA68FOTx6b73lqAo8BbgCskmn78ANibcthngfdMlno+P7nvL4ATJBquXAAuk5n5hg8BLwGjJN7PMeBPMnBdEZENzyRuBoqIiIiIiMhqpEybiIiIiIjIKqagTUREREREZBVT0CYiIiIiIrKKrfmgzRjzq8aY48aYsDHmy/Mc95PGmGcnJ45fN8b8rTGmeNoxnzPG9E4e8zfGmJvupiUiIiIiInIz1nwjEmPMT5NYS+YtQK619oNzHPfzJDqBPU1iUdN/AHqTxxtjPgx8CniYROerfwN+aK1Na30ZY4yfxOKpnajFsYiIiIiIzM4N1AAvW2tD6Zyw5oO2JGPM54D6uYK2WY5/B/Bn1todk9vPAV+x1v715PZbgf9hrd2U5vXuBZ5ZythFRERERGTDuc9a+2w6B3qWeySr2P3AmZTt20isK5N0Aqg3xhRZa4dST5wsqyyedj03wDPPPEN9fX2mxyoiIiIiIutAW1sb9913HyQq9NKyIYM2Y8wbgA8D96TszgdSg7PByX8Lpu0H+AQwa9lkfX09jY2NmRimiIiIiIisX2lPqdpwQZsx5gjwT8DPWGtTM22jQGHKdtHkvyOzXOYvgS9P21ePyiNFRERERCTDNlTQZow5SKLByEestT+c9vRpYD/w/OT2AaBtemkkgLV2kBuZuOS1MzxaERERERGR9dHy32OMySExp8xtjMmZrVW/MeY24FHg1621357lUl8G/i9jTIMxphz4/wF/u3wjFxERERERWdh6yLT9DlPnl70P+Dvgg8aYUeCt1tpngP8bqAC+ZIz5UvJga23+5MMvAY3AccALfBX43LKPXkRERERkkrWW/v5+QqG0OsHLKuV2uyksLCQ3Nzcj11s3Lf+zzRjTCFy7du2aGpGIiIiIyJIMDw8TjUYpKSnR9Js1ylpLJBKhv7+foqKiGYFbU1MTW7ZsAdhirW1K55prvjxSRERERGS9CAaDFBYWKmBbw4wx+Hw+SktLGR4ezsg1FbSJiIiIiKwS8Xgct9ud7WFIBni9XmKxtLv6z0tBm4iIiIjIKqIs2/qQyZ+jgjYREREREVmSz3zmM/zcz/3cgsd9/OMf5/d+L9E78Mknn6S6unq5h7aurIfukSIiIiIisop94QtfyOrrf+Yzn+H8+fN87Wtfy+o4lkqZNhERERERWdOi0eiavv5CFLSJiIiIiEhaTp48yZ133klBQQGPPPIIvb29znM/93M/R3V1NUVFRTz44IOcO3fOee6DH/wgn/rUp2Zc70//9E95xzveMWXfpz/9aX7xF39x3nF88IMf5KMf/Shvf/vbycvL47vf/S4dHR285z3vobKyksbGRv7sz/4MgEcffZTPf/7z/Mu//Av5+fns2rULgMbGRh599FHnml/+8pe56667nG1jDH/1V3/Fzp07qampcco6/+qv/oqamhoqKir4/Oc/v4jv3tIpaBMRERERkQVFIhHe+c538q53vYu+vj5+67d+iy9/+cvO84888giXLl2iq6uL2267jfe///0LXvN973sfjz32mBP8WWv5yle+wgc+8IEFz/3qV7/Kb/7mbzIyMsKb3vQm3v72t3PrrbfS2trKk08+yd/8zd/wne98h0ceeYRPf/rTvPvd72Z0dJQLFy6k/Z6/9a1v8fzzz9PS0gJAb28vra2tNDU18eijj/KZz3yGM2fOpH29pdKcNhERERGRVejf/u3fVuy13v72ty94zLFjxxgbG+NTn/oULpeLN7zhDbz97W/HWgsksl9Jn/nMZ6ioqGBsbIy8vLw5r1ldXc1DDz3E1772NX71V3+Vp556CmstDz30UFpjvv/++wE4ffo0nZ2d/P7v/z7GGBobG/nYxz7G1772Nd75zncueK25fOpTn6K8vNzZdrlcfO5zn8Pn83H77bezf/9+XnvtNfbs2bPk10iHMm0iIiIiIrKgjo4O6urqcLluhBANDQ0AxGIxfuu3foutW7dSWFjI9u3bAaaUT87lgx/8IH//938PwD/8wz/wC7/wC1NeYy6bNm1yHjc3N9Pd3U1JSQnFxcUUFxfz2c9+lq6urkW9x/leA6C0tBSfz+ds5+XlMTo6elOvkQ5l2kREREREVqF0sl8rqba2lvb2duLxuBNUJcsGv/KVr/Cd73yHxx9/nMbGRvr6+qioqHCycPN5xzvewcc//nFef/11vvGNb/D888+nNZ7UddA2bdrEpk2buHbt2oLHJuXn5xMMBp3tzs7OtM7LBmXaRERERERkQXfffTe5ubn88R//MZFIhCeffNIp4RwdHcXv91NWVkYwGOS3f/u3076u3+/n537u5/jABz7A9u3bufXWWxc9tjvvvJOSkhI+//nPMz4+TiwW4+zZs7z44osAVFVV0dTURDwed845ePAg//iP/0g4HOb8+fN86UtfWvTrrhQFbSIiIiIisiCv18t3vvMdvvGNb1BSUsIf/dEfOV0eP/CBD9DY2EhdXR179uzh6NGji7r2Bz/4QU6ePJlWA5LZuN1uvvvd73Lq1Cm2bNlCeXk5H/rQhxgYGADgve99Lx6Ph7KyMmf+2R/8wR/Q2dlJaWkpH/3oRxfsWJlNJp2UpSzMGNMIXLt27RqNjY1ZHo2IiIiIrEUdHR3U1tZmexgrrquri82bN9PW1kZFRUW2h5Mxs/08m5qa2LJlC8AWa21TOtfRnDYRERERmTJPaS6dnZ2cPXuW0tJS6uvrKS8vXzVzfmTtstby53/+57zrXe9aVwFbJiloExEREdlgotEoFy9epLCwkLq6Oi5dusSlS5fYvn27s/DwdIODg7z22mvEYjGCwSBtbW0cPHiQ+vr6FR69rCdjY2NUVVVRX1/P97///SnP5efnz3rO1772Nd72tretxPBWDQVtIiIiIhvMpUuXuHLlCgBnz54lFAo5+2traykoKJhy/MTEBC+//DKxWIz6+npisRidnZ0MDw+v+NhlfZmvZf5KtNJfK9SIRERERGQDCYVCTlt0v99PKBTC6/U67dlPnz49pU17LBbj5ZdfZmJigrKyMvbv309VVZVzLRFZfsq0iYiIiGwgly9fJhaLUV1dzcGDB+ns7KSsrAyPx8MTTzxBb28vnZ2d1NbWYq3lxIkTDA4OEggEOHz4MC6XC7/fDyhoE1kpyrSJiIiIbBDj4+M0NTUBsGvXLjweD5s2bSIQCODz+di9ezcAp0+fJhwOc+nSJTo6OvB4PNx55534fD4ABW0iK0yZNhEREZEN4tKlS8TjcWprayksLJzx/ObNm2lvb6evr49jx44xPDyMMYbbb799yjw3BW0iK0uZNhEREZENIBgM0tLSgjFmzg6RxhgOHDiAx+NxmozceuutVFZWTjkumXELh8NozV+R5aegTURERGQDuHjxItZa6uvr52ylDhAIBNizZw/GGBobG5OLAE/hcrnw+XxYawmHw8s5bNkAvvzlL3PXXXdlexirmoI2ERERkXVudHSUtrY2jDHs3LlzweM3b97MW97yFvbu3Tvn4tkqkdyYHnzwQXJycsjPz6ewsJA77riDZ599dtle78knn6S6ujoj13rwwQf5whe+kJFrrTQFbSIiIiLr3IULF7DWsnnzZgKBQFrneL3eeZ9X0LZx/eVf/iWjo6MMDg7yS7/0S/z0T/+0ymSXmYI2ERERkXVseHiYjo4OXC4XO3bsyNh1FbSJy+XiF37hF+jp6aGnp4dXXnmFu+++m+LiYmpqavj1X/91IpGIc/y5c+d4y1veQllZGZWVlfw//8//M+t1f+/3fo/bb7+d5uZm3vrWt9Ld3U1+fj75+flcvXqVeDzOf/2v/5Xt27dTVlbGu9/9bnp6eoDEQvDvf//7KSsro7i4mMOHD9PZ2clv//Zv88wzz/CJT3yC/Px8PvzhD6/I9yhTFLSJiIiIrGMXLlwAoLGxkdzc3IxdV0GbRKNR/u7v/o7t27dTXl6O2+3mz//8z+nt7eW5557j0Ucf5Ytf/CIAIyMjPPzww7zhDW+gra2NpqYm3vGOd0y5nrWWX/u1X+PJJ5/kiSeeoKGhgX//93+nsrKS0dFRRkdH2bp1K3/1V3/FN77xDX784x/T0dFBVVUVH/3oRwH4u7/7OwYHB2ltbaWvr4//+T//J4FAgD/8wz/kvvvuc7KEX/rSl1b8+3Uz1PJfREREZJ0aHBzk+vXruN1utm/fntFrK2hbfr/9w99e0df7wzf/YVrHffKTn+RTn/oU4+PjuFwu/vEf/xGXy8XBgwedY7Zu3cpHP/pRnnrqKX71V3+V733ve5SWlvKf//N/do65++67ncfRaJT3ve99DA4O8uijj857g+ELX/gCf/mXf8nmzZsB+P3f/32qqqqYmJjA6/XS19fHpUuX2L9//5QxrWUK2kRERETWqfPnzwOwZcsWJ8jKFAVtG9ef//mf8/GPf5x4PM7zzz/P2972NrZs2UJubi6f/OQnOX78OMFgkGg0ypEjRwBoaWlh27Ztc17z6tWrnD59mmeeeWbBjHBzczPvfe97cbluFA36fD7a29t5//vfT1tbGz//8z9Pf38/P//zP8/nP//5jP/3v9JUHikiIiKyDvX19dHT04PH45n3w/JSKWgTl8vFvffey44dO3jsscf4lV/5FXbt2sWlS5cYHh7ms5/9rNOgZNOmTVy9enXOa+3cuZN/+Id/4O1vfzunTp1y9s/WvXTTpk3827/9G4ODg87XxMQE27Ztw+v18ru/+7ucOXOGF198kR/+8IdOKeRcnVDXAmXaRERERNYZa60zl23btm3OYtiZlLzmUoK20dFR+vv72bRp05r+IL3c0i1XzKYXXniBs2fPsmfPHr7+9a9TWFhIfn4+586d44tf/CJ1dXUAvO1tb+OTn/wkf/Inf8Kv/dqvEY/Hef3116eUSL7nPe8hEonw5je/mccee4w9e/ZQVVXFwMAAAwMDlJSUAPDxj3+c3/md3+Hv//7v2bJlC729vTzzzDP81E/9FE888QTl5eXceuut5Ofn4/F4nIxcVVXVvIHjaqZMm4iIiMg6MzQ0RF9fHz6fb9bFsTNhqZm2aDTKsWPHeP311xkYGFiOockyS3ZgzM/P533vex+f+9zneOtb38qf/umf8tWvfpWCggI+9rGP8bM/+7POOQUFBfzoRz/iBz/4ATU1NWzZsoXvfve7M679H/7Df+BP/uRPeNOb3sS5c+fYvXs3v/ALv8D27dspLi7m2rVr/MZv/AY/9VM/xSOPPEJhYSF33nknzz//PADXr1/nPe95D0VFRdxyyy3cddddTqfI3/iN3+Db3/42JSUlfOxjH1uZb1aGGK2pkBnGmEbg2rVr12hsbMzyaERERGQju3DhAhcvXqSxsZG9e/cuy2vE43G+973vYYzhJ3/yJ9POmJ06dYqmpiYA9u/f7zSTkISOjg5qa2uzPQzJkNl+nk1NTcmbKVustU3pXEeZNhEREZEVFI/Hp6xdtRy6u7sBqKysXLbXcLlc+Hw+rLWEw+G0zunv76e5udnZDgaDyzU8kXVFQZuIiIjICnrllVd4/PHHGRsbm/e4trY2WltbF339UCjE4OAgLpeL8vLypQ4zLYstkbx06RLWWvLy8gAYHx9ftrGJrCcK2kRERGTN6+npWRNZm3g8Tk9PD5FIhNOnT8973Ouvv87rr7+edhYrqaenB8BZ7Hg5LaYZibWWwcFBAHbs2AEo0yaSLgVtIiIisuxisRhDQ0O0tbVx/vx5Xn75Zc6dO8dS5tZba2lqaqK/vx9IzBl54YUXeOqpp+js7Fzw/PHxcU6ePMnw8PCiX3spenp6uHjxItZaRkdHicfjQKKEsaura9ZzJiYmiMfjWGsZGhpa1Oslr7mcpZFJOTk5QGK8C5mYmCAcDuPz+SgrKwMUtImkSy3/RUREZNlcvnyZlpYWgsHgrAFaWVnZooOLzs5OTp06hcfj4f7773cWkI5Go7zyyis0NDSwe/fuWdvcx2IxXn75ZYaGhojFYhw8eHBpbyxNoVCIV155hWg0SklJiRPceDweotEoZ86coaKiYsoiwTA1CBocHKSioiKt17PWOpm2lQzaTp06xejoKLt27ZrxXpKSWbaioiJycnIwxhAKhYjH43OeIyIJ+j9ERERElsXo6Cjnz5935m4VFBRQU1PDzp07nY6BFy5cWFS2zVrLlStXgESQ9uyzzzI2NkZeXh579uzBGENzczNPPPEEzc3NU65treXUqVNO5mp0dDRTb3VO586dIxqNAonFrpPZvW3btlFQUMDY2Nis60alzvVKBjvpGBoaIhKJkJeX58wbW07btm2jpqaGWCzG5cuXnZ/NXGODRNDmcrnIycnBWqt5bbNQd/f1IZM/R2XaREREZFlcvnwZay2bNm1i3759U7IpsViMrq4uBgcH6erqorq6Oq1r9vX1MTg4OKMBxu7du6mtraWiooLTp0/T29vLyZMnaWlp4bbbbqO4uJgLFy7Q2tqK2+0mFosxOjqKtXbZFnceHByc0kikt7fX+R4UFxdTUlLCCy+8wKVLl6ivr3eyVjAz05auZFBYXFx8c4NPk9/v5/Dhw3R2dvLKK69w7do1tm3bNmvmLDVoAwgEAoyPjxMMBlckwFwrvF4vo6Oj5Ofna+HxNcpaSywWY3h42PlddbMUtImIiEjGBYNB2traMMawc+fOGR/i3W43O3bs4PTp01y8eHFG0DY0NDRrJiy5vteWLVsoLCzk5ZdfpqioiJqaGiCRzbvrrrvo7Ozk7NmzDA4O8uyzz1JcXMzg4CDGGA4cOMCpU6cIh8OEQqEpwVImXbx4EYDGxkaam5sZHBx0GoMUFhaSk5NDTU2NM9ZDhw4556ZmnyYmJpiYmEhrnCMjI0Di+7CSqqurKSwsZHh4mI6ODurr66c8nzo3LxlQBgIB+vr6lGmbprS0lP7+fudnKWuTy+UiEAhk7P9FBW0iIiKSccksW319PYFAYNZjNm/ezIULFxgaGmJ8fJzc3FwgkT179tlnnYYd03k8HhobG/F6vTzwwAPO/KgkYwy1tbVUVlY6JXvJgOn222+nqqqKa9euOR+MlytoS5aFNjY2Mjg4yODgINFoFL/f77zmrbfeSnd3N+3t7TQ0NDgNOpKZNmOME/CkM85kpq2wsHA53tKcjDFs3bqVEydOcOXKFerq6qb8TEKhEKFQCK/X6/yck/+qGclUbrc77TmMsnFoTpuIiIhkVDgcpq2tDYDt27fPeZzb7aakpASYWgLY19dHPB4nNzeXuro6amtrp3wdOHAAr9cLJDJKycfTeTwedu/ezYMPPsi2bdu4++67qaqqcs6D5Z3XlizdTO2WCDfKAyGRbdq2bRsAp0+fdubAJLNPs31/5mKtzVrQBlBXV4ff72d4eJgXXniBy5cvMzQ0NCXLVlRU5ARzyWBemTaRhSnTJiIiIhnV3NxMLBajqqpqwdKgkpISuru7GRgYcEoc+/r6AGhoaHDW87oZeXl53HrrrVP25efnA8sXtMXjcSKRCMYYfD4f5eXlTpOO6QHV9u3baW1tZXh4mObmZhobG51Apqamhv7+/rSCtnA4TDgcxuv1Llv2cD4ul4tbbrmF119/nd7eXnp7ezl37hw+n8/p5Dk9YAVl2kTSoUybiIiIZEw8Hp8y72whyflNAwMDzr5k0Jaancq05Q7akgti+3w+jDGUlpY6GabUwAUSGcc9e/YAiW6a0WiUcDiMMcbJDA4ODi7YiS6ZZSsoKMhaA4tNmzbxpje9idtvv53NmzcTCAQIh8PO9zm1QYrKI0XSp0ybiIiIZMz169eZmJigoKCA8vLyBY9Plv8NDQ052amRkRHcbveydkBc7qAtWRqZ7Bzn8XioqKigr6/Pec+pqqurKSgoYGRkhM7OTqy15OTkEAgE8Hq9aTVNyWZpZCq/3++UslprCQaD9Pb2EolEnGwqJIK25FptV65cIRKJsGvXLnVMFJmFgjYRERHJmNQsWzofvr1eL/n5+YyOjjI8POxkXUpLS5d1weXc3FzcbjcTExNEIpE558Ut1fSgDeD2228nGo3OGngZYygvL2dkZIT29nZnjMYYCgsL6evrW7BpymoJ2lIZY+ZcM84YQ25uLsFgkLNnzwKJsdfW1q70MEVWPZVHioiISEaEw2H6+/txuVzU1dWlfV4y8zQwMLAipZFwI5iAubNtvb29PPPMM0tqvT5b0ObxeOYNukpLS53XBZxjk/MCk0HZXLLV7v9mJN9zcn5bc3NzNocjsmopaBMREZGM6OnpwVpLaWkpHk/6xTzJoK2np4eenh5g+YM2mL9E0lrrrPPW2dm56Gundo5MV/I9J+euJed8JYOw+YJHa63z/GrKtC1k//79vPnNb+b+++/H7XbT29vrLJUgIjcoaBMREZGMSAZclZWVizovGbR1dXUxNjaGx+NZ1vlsSfO1/R8cHHTa1CfXTFuM2TJtC/H7/U4gCTeCtmQQNl+mbWxsjHg8TiAQWFTAnG0ulwu/34/X63Xmu7W2tmZ5VCKrj4I2ERERuWnWWrq7u4HFB20FBQUUFBTg8Xioqanh8OHDyzqfLWm+TFtybh7cCMAWI9k9cjFBG9woF4SZ5ZGjo6NzdpBMBpbJQG8t2rx5MwAtLS0LdsoU2WjWzq0YERERWbWGh4ed7oap2aJ0GGN44IEHnMcrZa6gLRQK0dHRMWV7sZaSaYNEiWRLSwtwIwDzer3k5uYyPj7O2NjYrN/fZNCWjfXZMqW0tNRpStPV1UV1dXW2hySyaijTJiIiIjcttTRyKYGXMWbFW73n5eVhjHFKC5NaW1uJx+NOhmulyiNh9kwbLDyvbT0EbcaYKdk2kcWamJhwyprXGwVtIiIictOuX78OLL40Mpvcbje5ublYa53mF9Zap4Phrl27gEQAtthyvaUGbYFAgMrKSkpLS6cEYAvNa1sPQRtAfX09LpeL7u5uxsfHsz0cWWNeffXVJXd8Xe0UtImIiMhN6evrY2BgAK/XS0VFRbaHsyjTSyS7uroIBoPk5eVRXV2Nx+NxFv1Ol7XWmdO2mO6RSUeOHOGee+6ZknncCJk2SAS51dXVWGvVkEQWxVrL4OAg1lrnJtJ6oqBNREREbsqFCxcA2Lp165rqXAgzg7ZkA5LGxkaMMU4QtJh5beFwGGstXq83Yw1VNkqmDW40JGltbVVDEknbxMQEsVgMwGmKtJ4oaBMREZEl6+vro6+vD6/Xy5YtW7I9nEVL7cw4OjpKT08PbrebTZs2ATfKGxcbtKWemwn5+fl4vV7GxsYYGBiY8fx6CtrKy8sJBAIEg0FnrqTIQlIbCg0MDCwqO74WKGgTERGRRYlGo7S3t/PKK6/w4osvAoksm9frzfLIFi8105acy1ZXV+e8l2TgtZhmJEudzzYfl8tFY2MjAJcuXZrynLXWGV8mXzNb1JBEliJ1UXZr7boL+NdWDYOIiIhkRSwWo7Ozk87OTrq7u6d0W6yoqGDr1q1ZHN3SpQZtyQ99yeAIWFJ55HIEbQBbtmzh6tWrdHV1MTw87JRMJssxfT4fbrc7o6+ZLZs2beLChQtcv36dUCi0LoJRWV7JTFtOTg4TExN0dXVRW1ub5VFljjJtIiIiMq9oNMrzzz/Pa6+9xvXr17HWUlpayp49e3j44Ye566671txctiSfz4fP5yMajRKJRCgpKaGoqMh5finlkcsVtPn9fhoaGoCp2bb1VBqZlJOTQ2VlJdZa2trasj0cWQOSN12SZdo9PT3rak6kgjYRERGZUywW46WXXmJwcJDc3Fz27t3Lww8/zD333MPWrVudBaDXstTFqlOzbLC6gjaAbdu24XK56OzsdDIL6zFoA5wAtaWlZV19+Jblkfz/obq6mtzcXEKh0JR5bmudgjYRERGZ0/nz5+nr6yMnJ4e7776bxsbGdRccJJuR+P3+GeVUyfe6lDltS2n3v5CcnBw2bdqEtZbLly9PGdt6+7lUVlaSk5PD6Ogo/f392R6OrGKxWIzx8XGMMQQCAfLy8gDW1Vp/CtpERERkTr29vQAcPHjQ+SC03pSWlgKJsqrpLfqXkmlb7qYg27dvxxhDW1sbwWBw3QZtxhini2c2GpIkF1oPBoMr/tqyOMFgEGstgUAAl8vlVAAoaBMREZF1Lx6PMzIygjGG4uLibA9n2dTV1fHAAw+wffv2Gc8ttntkMBikt7cXY8yUuXGZFAgEqKurw1rLlStX1m3QBok124wxdHR0OEsprJTr169z8uRJzp8/v6jzenp6+NGPfuTc8JDllyyDTJY6K2gTERGRDWNkZARrLXl5eWu20Ug6jDEUFhZijJnxnM/nwxhDJBKZ0jFzLleuXMFaS11d3bLO90tm21paWhgaGgLWZ9AWCAQoLy8nHo/T3t6+oq+dXA9vMaWxkAj2JiYm1uUCz6tVsglJshpAQZuIiIise8ngJBkMJFvLb0TGmBnZtrGxMS5cuEAsFptybCgUorW1FWDWrF0mFRQUUF1dTTweX9dBGzBlzbaVbEiS/L4uNsOXLKdcTEmt3Bxl2kRERGTDsNZy8uRJvv/979PX18fw8DDAspX5rRXT12q7ePEiFy9edAK0pKtXrxKLxaiurnaamyynHTt2zDrO9aa6uhqfz8fw8PCKfQi31t500LbYDJ0sTTQapa+vD1CmTURERNY5ay0nTpygubkZay1NTU3KtE2a3owkeVc/WT4HEIlEaGpqApY/y5ZUVFREZWUlkMgILke3ytXA5XI5cyqT/00ut/HxcSKRCHBj8fJ0WGsVtK0gay2vv/46wWCQgoICp6lQMmibmJhYN8tFKGgTERHZ4KLRKK+88gptbW14PB6MMVy/fl2ZtknT2/4nP5SnBm1NTU1Eo1HKy8spKSlZsbEls215eXmzzslbL5I3DlYqaEt9HWst0Wg0rfNCoZBTXqygbfldu3aNjo4OPB4Phw8fdrq/ut1u/H4/8Xh83ZSpKmgTERHZwCYmJjh27BjXr1/H6/Vy5MgRysrKiMfjRKNRcnJylq11/VoRCASAxFy2aDTqlMuNjY0RCoWIxWJcvXoVmFmyuNxKS0u58847OXTo0Iq+7kpL3jhI3khYbtODw2TWbSGpywNEo9G0gz1ZvL6+Ps6ePQvAgQMHnPlsSeutRFJBm4iIyAY1PDzMs88+y+DgIHl5edx7772UlpZSX1/vHLPRSyPhRnOD0dHRGWt2DQ4O0tLSQjgcpri4mLKyshUfX1VV1brPhibfXzYybZD+vLbp/32slyzPajMxMcHx48ex1rJt2zZqampmHKOgTURERNYcay2jo6PO/I6uri6ee+45xsfHKS0t5d5773WCk5qaGtxuN6DSSJgatCVbiyf19/dz5coVIJFlW88litkUCATweDxMTEwseyBkrWVwcBC48bNPN2ibHiCoRDLz4vE4r776KqFQiLKyMm655ZZZj1tvQdv6XXRFREREHJcvX+b8+fMUFhZSWVnprCdWX1/P/v37nbkgAB6Ph7q6OlpaWrKSOVptAoEAxhjGx8edJiS5ubmMj49z7do1YrEYBQUFVFVVZXmk61dyLb3+/n6Gh4epqKhYtteamJggHA7j8/koKipidHR0yZk2BW2Zd+7cOfr6+sjJyeH222+f80bJegvalGkTERFZ50ZHR7l48SKQKIm8fPky1lp27drFgQMHpgRsSbfddhv33Xffsn44XitcLhd5eXlYa50Fk2trawGctdqSi13L8lmpEslklq2oqMjpyLnYoC2ZoVN5ZGZ1dnZy9epVjDHcfvvt8863VdAmIiKyBMFgkLGxsXXTfnmtSK69Fo/Hqa+vZ/fu3RQWFnLo0CF27tw5Z6DhdrudNuty40N4smNkaWmp86EwEAhQV1eXtbFtFMn5lcvdjKSnpweAsrKyJQdtydbzyrRljrWW8+fPA3Drrbc63+O5rLegTeWRIiKy7AYHB3nuueeIx+O43W4qKyvZunXrgn905eZ1dHTQ19eHz+djz549+Hy+Fe9wuB4kg7bkTYdAIEB5eTmtra3Ksq2Qlci0WWudoK2iosIJ0tPpHmmtZXx8HGMMxcXFtLS0KGjLoKGhIUZHR/H7/TQ2Ni54vII2ERGReQwPD+N2u8nLywMSk8Zff/114vE4Ho+HaDRKZ2cnnZ2dlJaWsm3bNqqqqvShdxlYa7lw4QIAt9xyy7pdfHklTG8nHggEuPXWW6mtrVUJ6QopKCjAGOMsveDxZP5jbDAYJBgMOvPZko1n0sm0jY+PY60lJyfHWSZC5ZGZ09raCkBdXd2sJd3T+Xw+XC4X4XCYF198EYCDBw+u2d+DCtpERCQjrLVcvHiRS5cuYYzhlltuoaGhgUuXLjE8PEwgEOCBBx4gGo3S1NREU1MT/f399Pf3k5eXx7Zt26ivr3e6FsrNa2trY2xsjLy8PDZt2pTt4axpqUGb3+93AobKyspsDWnDcblc5OfnMzIywujo6LKU7yazbOXl5RhjFlUemSyNDAQCMxZkl5sTj8fp6OgAmLIkyXySzWsGBweduajJhc/XIgVtIiJy08LhMK+++io9PT0YY4jH45w5c4YzZ844x+zfvx+Px4PH42H37t1s376dlpYWrl27xtjYGCdPnuTChQs0NjayZcsWvF5vFt/R2hePx53mI/PNXZP0pAZtySyKrLyCggJGRkYYGRlZ1qAtmT1V0LY6dHV1EQ6HKSwsXNQyJEeOHHEaywBr+u+KgjYREbkpAwMDHD9+nPHxcXw+H4cOHSIWi3Hy5EnC4TB5eXk0NjZSXl4+5TyPx8PWrVvZsmULHR0dXLlyhaGhIS5cuEBzczMHDx6ccY6kr6Ojg2AwSEFBgZpkZIDX68Xv9xMKhRS0ZVFBQQEAIyMjGb92PB6nt7cXmBm0pTOnLbkcRF5eHh6PB7fbTTQaXbZSzo2ks7MTSD/LluTz+dZNNlz/BYmIyJJYa2lqauLMmTNYaykpKeH22293Jn9XVVVhrV1w7oExhrq6Ompra+nr6+P8+fMMDAxw7Ngx9u3bR0NDw0q8nXUnmTFoaGhQli1D8vPzFbRl2XIGbQMDA0SjUfLz853fY8nMTDqZtmTTkuLiYowx+P1+gsEgoVBIQdsixWIxRkdHnaxaMiDeyM2r1PJfRESW5NSpU5w+fRprLVu3buXo0aPOBx1IBGPpTBZPPb68vJx77rmHnTt3AnDhwoU1PQchW6y1TsZA2crMSZbjJVvPy8pbzqAtOe8pNTPjdrtxuVzEYjFnTb7ZxONxpwyvpKQEQCWSN+HChQs8/fTTzs8ktfR0o1LQJiIiixYOh2lubsblcnH48GH27NmzqABtPsYYdu7cSUFBAaFQiOvXr2fkuhvJ2NgYExMT+P3+GV0PZel27tzJ0aNHqampyfZQNqy8vDxcLhfj4+NEo9GMXjv5u6a6utrZl24zkqGhIeLxOAUFBU52TkHb0vX39wOJ7GUkEiESieDxeNZs58dMUNAmIiKLlryjXFxcvCwfYI0xzjo8zc3NGb/+etfX1wckFgdWaWTmeDwefU+zzBjj3IjIZLZtbGyM0dFRvF6vkylLSgYKY2NjvP7667S3tzvr9SUlSyNTz/X7/YDa/i+Wtdb52Y6OjjrLLgQCgQ39/56CNhERScvVq1e5cOEC1tpZP6BkWl1dHW63m97eXmc+g6RHpZGyni1HiWRXVxeQKI2cXjWQDNrOnTtHS0sLr776Ki+//PKUDNpsvxOVaVuaiYkJJ4s6Ojqq0shJaz5oM8b8qjHmuDEmbIz58jzH1Rhj/tUY02mMscaYxlmO+ZwxptcYM2iM+RtjzNrtCyoikkHXrl3jzJkzXLx4keHh4SmZtuXi9XqdroctLS3L9jrrjbV2SqZNZL1ZjqAtWRpZVVU147lkuWPy957b7aarq4snn3yS1tbWOW9kKWhbmtSf69jYmIK2SWs+aAM6gD8A/tcCx8WBR4Gfnu1JY8yHgZ8DDgPbgQPA72RslCIia1R3d/eU9dY6OztXJGiDG+2dk50QZWGjo6OEQiFycnLIy8vL9nBEMi7TQVskEqG/vx9jzKzt4VPnUQUCAR566CGqqqqIRCKcOHGCY8eOMT4+jtfrnbEIOyhoW6zUn2ssFnNuQiloW+Ostd+01n4b6FvguC5r7V8DL89xyIeAP7fWNllre4HPAr+U0cGKiKwxzc3NvPzyy1hrnQ8zzc3NhMNh/H7/lG6Ry6G4uBiXy8Xw8HBaLbeBDdtt0lpLW1sbx44dAxKlkRt5/oesX5kO2rq7u7HWUlZWNuviy6lBW11dHbm5udxxxx0cPHgQr9frBBUlJSVT/p9LZto0p21xpv9cFbQlrPmgLYNuA15P2T4B1BtjZiy7bowpNsY0pn4Bi1vtT0RkBYyNjXHq1CleeOGFRX9wOHPmDCdPniQej7N161buuOMOvF6vEzxN/4CyHNxut1NulOwmNp+Ojg6+//3vO2vHbRTDw8M8//zzvPbaa4RCIUpKSti9e3e2hyWyLAKBAC6Xa8rcp5sxX2kkTA3aktl/Ywz19fU89NBDTjOm6eerPHJpkkFbMmuZXGphowdtWunvhnxgKGV7cPLfgmn7AT4B/N7yD0lEZGkGBwe5cuUKnZ2dTvDS3t7O1q1b0zq/q6uLq1ev4nK52L9/v/NBpbq6mtbWVmD5SyOTSktL6evro6+vb0or7tkk3+/Vq1cZGRnh8OHD63pR20gkwoULF2hqasJai9/v55ZbbqG+vl5ZNlm3jDHk5ORkZOHqeDzulF/PFbQlyxxLSkpmLKHh9/s5fPgwoVDIOS7J4/HgdruJRqNEo9F5xxkOh2lqamJkZIR9+/bNmvHbCKy1TuOp6upqLl++7DynoE2SRoHU1TKTGbbZcu9/CXx52r564JmMj0pEJE3WWnp6erhy5YrTPdDlclFcXMzAwAA9PT1pBW2RSISTJ08COAFAUk1NjRO0LWfnyFRlZWVcunRp1kxbLBZjZGSEoqIijDFOMwCPx0NPTw9NTU1s3759Rca50sbHx3nmmWcIhUIYY9iyZQu7du3asB/2ZGNJBm0TExM3NXezv7+fSCRCQUHBnNeprq5m27ZtU34XTjc9YINEcOn3+xcMLtvb23n99dedjFJtbe2GXQswuf6e3++ntLTU2Z+Tk4Pb7c7iyLJPQdsNp4H9wPOT2weANmvt9Cwb1tpBbmTiAHRHU0SyKhaL8dprr9HZ2QkkgpaGhga2bt2KMYYf/vCH9PX1EY/HF1wE+/Tp00xMTFBaWsqWLVumPFdeXo7P5yMej69Ypi1Zhjk0NOTcrR4dHaW5uZm2tjbC4TA7d+5k8+bNTjOA2267jddee80J4taj9vZ2QqEQRUVFHDhwgMLCwoVPElknMtXkI9nqf64sGyTKtG+99dYlXT+d4LK1tZVYLIbb7SYWi23oOXDJLNv0IHqjZ9lgHQRtxhgPiffhBtzGmBwgZq2NzHJszuRxAP7J7ZBN1A59GfhNY8z3gTHg/wf87Qq8BRGRmxIKhXjppZcYHBzE6/Wyfft2GhoapmRcCgoKGBkZYWBgYN428NevX6etrQ23283+/ftn3JByu90cPXqUeDy+YmWHHo/HyRZeuHCBoaEhZ2J6Ultbm9OcoKSkxAkok10u16Pk92Dbtm0K2GTDyUSTD2vtgvPZblY689rGx8eBxBpxnZ2dGyJo6+7u5tVXX8XlcuHz+fD5fHi9Xue9FxQUOItpW2sVtLE+GpH8DjAOfAp43+Tj/wlgjBk1xtyXcuw4iTJIgPOT2w2T218C/hk4DlwBTgGfW+7Bi4jcrDNnzjA4OEggEOCee+5h+/btM0rkKioqgPlb54fDYacscvfu3TPmbiQVFBRQVDSjR9OySgaaV69epa+vz8kk3nfffU75UVNTE5AI2vLy8vB6vUxMTCzpTnw8Hnc+SK1G8XjcKRfVWmyyEWWiyUdy4Wafz7ds5d4LBZfWWmcdsuTNpo0QtHV2dhKJRAiFQoyMjNDX18f169ed6ojCwkJcLpeTbVPQtg4ybdbazwCfmeO5/Gnbc9YwTmbbfnvyS0RkTQgGg3R0dGCM4e67757zD1tFRQVXr1515rrN5syZM4RCoVnLIrOttraWa9eukZ+fT0NDA3V1dU6mr6amhqamphltt4uKiujt7WVwcHDBBiapRkZGOH78OCMjI1RWVrJz584Vm7+XrsHBQaLRKPn5+c6HQpGNJBPlkamlkcs1zWWhcYbDYeLxOD6fzwlQ0l3eZC1Ldog8fPgw+fn5hMNh5yvZmRMSNwlHR0e15iTrIGgTEdnIrl69irWW+vr6ee9ElpaW4nK5GBwcJBKJzMjEpZZFHjhwYNXN0y0qKuInfuInsNbOGFsyaIPE/OJkgFVSUrLooK2np4dXXnnFaSPe3d1Nd3c3FRUV7NixY9VktZIB6moZj8hKy0R55HKXRsLCGcFkli03N9dZWmC9Z9pSO0SWlpbO2sQlaefOneTn5y/qxtt6paBNRGSNCofDtLS0AIl5TfPxeDyUlJTQ19dHf3//lA8p08siV/MdzdmCybKyMvx+P6FQiIKCAicDlyzhXMy8tkuXLhGNRqmrq2P37t20tLRw7do1enp66OnpoaysjF27dmU9WEpmTMvLy7M6DpFsudnyyFAoxODgIC6XyykfXw4LjTNZhp2bm+sEL+s9aAuFQs7Nw9Q18GZTWFioObuT1sOcNhGRDWd8fJxXX32VWCxGZWVlWn/UkkHM8PDwlP3nzp0jFApRVla26soi02GMce7CppYxpjYjSXeh7WTJzq233kogEGD37t288Y1vZOfOnXi9Xvr6+jh27FhW57vF43Fn3ke2g0eRbLnZ8sju7m6stZSXly9rU6WFArHk75JAILBhgrZkli0/P3/VVXWsZsq0iYisMkNDQ1y6dAm3201BQQH5+flOJ614PE5zczMXL1507lTu3r07resmuysmAxNIlKkklwnYu3fvmv0DunPnTqy1U9Zky8nJcTJwwWBwwQxicj6Fx+OZUq7j8/nYtWsXW7du5fnnn2d4eJhgMEhubu6yvZ/5DA4OEovFKCgomLesSGQ983q9uFyutBaunk06rf4zYTHlkR6Px3lPySUA1qPUtv6SPgVtIiKrSHd3N8ePH3fmVKVyu924XC4ikcSKJlVVVezbty/tRhTJbFxqpm10dJRIJEJubu6c3SLXgpycHPbv3z9lnzGG4uJiurq6GBwcXDBoSwazc9399Xq95OXlMTw8fNNrQ92MsbExgBXv4CmymhhjnDXQ5lu4ejaxWMzppLvcQZvH48Htds8ZXKaWRyYX4x4fHycUCq3bjompv2slfSqPFBFZJQYGBnjppZecOVX79u1j69atVFRUkJOTQywWIxKJUFhYyJ133skdd9yxqM6BBQUFGGMYHR0lHo8DOG3jS0tL12yWbT7J8sHkXfX5pJbszCUTzQ9uVvJDnrpGyka31BLJkZERotEoBQUFy54xTwZiMPs4U8sjYeFyyvUgnd+1MpMybSIiSxSLxeju7nbKF5dy/qVLl6itraWwsJCWlhastWzevJl9+/bNCKKSa9rk5eUtKcByu90EAgHGxsYYHR2lsLBwStC2HtXU1HD27Fm6uroWLDdK54PEavhAlXpnXmQjW+pNlGRL/ZW68ZGaEZz++yW1PBLYEB0kVR65NMq0iYgsUjAY5OzZszz22GO88sorHDt2zMlcQaJRxNmzZ525YnNpb2/n0qVLvPbaa1hrnfbTW7ZsmbM872Ynbk8vkVzvQVsgEKC4uJhoNEp3d/e8x66VoC15t15Bm2x0S+0gmQzaFupcmCnJcU5vYBSJRJySyeQyLKvhd8xyikQiTExM4Ha79TtskZRpExFJg7WW7u5umpqa6OnpcboRulwuQqEQnZ2d1NXVAdDW1saVK1fw+XxUVVXhcs1+fywZMA0PD3PlyhXC4TB5eXnLevexoKCAzs5ORkZGGB8fJxgM4vV61/Udz9raWgYHB+ns7KSmpmbO49K5+7saPlCpPFIkYanlkcmgbaUa+SRvBJ06dYpoNEpDQwPGmBnz2VLHtF4X2FbnyKVTpk1EZAHWWp599lleeukluru7McZQX1/Pvffey549ewBobm52jr1y5QqQ+KObnOw+m2TQBnD+/HkAqqurl/UPWWqmLfn6JSUl6/qPZzJQS5ZIziYWizE+Po4xZt7J/6spaNNdatno5iqPDIfDXL16dc7s+kpn2rZt20ZtbS3RaJRTp07xwgsvEAwGZ5RGwur4HbOcNJ9t6ZRpExFZQDAYZHBwEI/Hw44dO9i8ebPzx76goIBz587R19fHyMgIwWDQ+aMEiRLI2bqTTUxMMDY2htvtJh6PO5m7+TJBmZAM2kZGRpwFmtdraWRSIBCgpKSEgYEBuru7Z/0ej46OYq0lPz9/zswo3PzaUDcrWU7ldrudciqRjWp6eWQoFOLKlSs0NzcTjUbxer285S1vmXFTKhkQrVTQ5vF4uP3226mpqeHUqVP09vby1FNPOetKbqSgTZ0jl06ZNhGRBQwNDQGJToTbt2+f8ofe4/E4ZZFnzpxxMmbJRaqvX78+a/v+5OLIpaWlVFRUAIkPIMkFoZdLIBDA7XYzPj5OS0sLAOXl5cv6mqtBbW0tAB0dHbM+n+7d39TSpXQX7J5PJBKZM/s3m9T5bOs5OyqSjuT/j2NjY5w6dYrHHnuMK1euEI1GMcY486emW+lMW1JtbS0PPvggNTU1RKNRpxIjNbu/3oM2NSFZOgVtIiILSDbtSGappmtoaACgp6eH4eFhZ8Hr0tJSYrHYrO3mUxuAbN++HWMMmzdvXvYP4sYY54+l2+1m7969zt3e9Sy1RHK2IDrdDxIulwufz4e19qbnnESjUX784x/z5JNPOmVSC9F8NpEbUht8NDU1EY/Hqamp4b777nMqCFIrH5KyFbRBIii7/fbbOXTo0JSKjdTnYf0Hbcq0LZ7KI0VEFpDMtM21mHFRURFHjhxhcHCQUChEVVWVk4Hr7+/n1KlT9PT0UF1dTUVFBW63e0rQVlZWxiOPPDJvO/pM2rVrF52dnezYsWPdLt46XW5u7pQSyWTmLWkxHyT8fj/hcJhQKHRTjQz6+/sJh8OEw2GOHTvG3XffveDPQ/PZRG7wer3k5OQQCoWoq6tj+/btTgCUn59PX18fo6OjTjVDUjaDNkjcPKurq6O8vJyhoaEp40uOaT02IonFYgSDQYwx5OXlZXs4a46CNhGRBSwUtAFUVlZSWVk5ZV9dXR3t7e309/fT2tpKa2srHo+HiooKhoaGMMY45ZAez8r9Op5trBtBbW0tAwMDdHR0zAjakj/jubKpqfx+PyMjIzd9JzwZuLtcLoLBIC+88AL33nvvvB8kFbSJ3GCM4f7778daOyP7nLwBs9oyban8fv+M38U+nw9jDOFwmHg8Pu8c25uVLPFeqVLrsbGxtOYOy+z0HRORdcNaS0dHBxcuXFjUPKH5TExMEAqF8Hg8i/6g7PV6ueeee3jwwQfZvXu3s15YZ2cn1lqKiopWNFjb6JIlkt3d3VNKJCORiNMUJp1M21IX9J0uGbTt37+foqIixsbGOH78+JQ1/6ZLzs9ReaRIgt/vn/X/h7mCNmstkUgEY0zWg7bZpI5rqdm2zs5OLl68OG/ZdTwe56mnnuKll17KyPzcdKg08ubo04KIrAsjIyOcOnWKvr4+IJG92LFjx01fNzmfraioaMl3IwsKCigoKGDHjh0Eg0GuX79Of38/mzdvvunxSfpyc3MpLS2lv7+frq4up4HM4OAgkMiypXP3NxMdJOPxuPO6lZWVlJWV8cwzz9Db28uZM2fYu3fvrOcp0yaSnrmCtmQToWRGazXy+/2EQiFCodCib9BYazlx4gTRaJSLFy9SWVnJli1bKC8vn/J+g8EgIyMjjIyMMDw8PG8lSaaoc+TNUaZNRNa0SCTCmTNneOqpp+jr63PaoF++fJlQKEQsFrupD9fplEYuRiAQYOvWrRw+fHhDlihmW7IssrOz09mX/Bmn27kzE40ChoaGiMViFBQU4PP5yM3N5Y477sDlctHU1ERTU9Os5yloE0lPbm4ubrebiYmJKZn11VIaOZ9koDY2Nrboc2OxmNM90xhDV1cXL7zwAk8++STXrl1zvhepfxfb2toyM/AFqHPkzVHQJiJrkrWW1tZWnnjiCa5evQpAY2Mjb3jDG6iqqiIajfLqq6/y+OOP8/jjjzst9hdrMXOdZPWrqalxPsgkP7wkM14rGbSlNqJJKikpYf/+/QCcPn16xsLs1topLf9FZG6pzS5Ss21rIWgrKysDmPE7IB3J30u5ubk8/PDD7N69m9zcXEZHRzl9+jTPPvssMDVoa29vn7csO1NUHnlzFLSJyJp05coVTpw4QSgUorS0lPvuu4+9e/fi8/m45ZZbMMbQ29tLKBQiHo9z+vTpRdftW2sznmmT7MrJyaG0tJR4PM7169eBG0Fbuj/j5QraAOrr69m+fTvWWo4fPz7lTntyTTev16u5kCJpmK1Eci0Ebcm1M3t7exf9dyv5e8nv9+P3+9mxYwdvfOMbOXz4MC6Xi5GRkRnr14VCoSUFiIthrVXQdpMUtInImpRc++zWW2/l6NGjUz5wFxQUsHPnTvLz89m3bx+5ubkMDg46i0mn68KFCwSDQTwej/7IrCOpJZKhUIjx8fFF/YxvNmiz1s4ZtAHs3r2b6upqIpEIL730EpFIBNAabSKLNV/QdjPLdSy3oqIifD4fwWAw7TUck1KDtiRjDDU1NU7mcXx8fEZTo+UukQwGg8TjcXJzc3XTaYkUtInImhCJRGhvb8dai7XWaRBSX18/62TynTt38tBDD9HQ0MCtt94KwPnz52ddWHk2V65c4dKlSxhjOHDggNoTryPJEsnu7m7n7vJiGs2kNiK5dOnSlCxuLBZzgqy59PT0EA6Hyc3NnbXM0RjDwYMHKSwsZHR0lOPHj2OtdcqANR9EJD2zBW3JoGY1Z9qMMU62bbEZsPkyicnfN8Fg0Anatm7dCiS66i5nF0ll2W6ePoWISNbF4/F5/1hYa3n11Vd59dVXaWlpcSaW+3y+tP7w1tTUUFxcTDgcTusPYDQa5fz58wAcPHjQaRUv64Pf73dKJE+cOAEsrvw12XUuEolw/vx5rl275nwgef7553nyySfnDdwuX74MwJYtW+YMFD0eD3fccQc+n4+enh5efPFF2tracLlc7N69O+2ximxkyQChv7/fKTVeC+WRwJKDttkybUmBQABIZNqSmfuSkhLy8vKIRqPOdIDloKDt5iloE5Gs6u7u5vvf/z6PP/44J06coK2tbUa3x+7ubrq7uwHo6+tz2gYXFhamlR0xxlBVVeWcv5DBwUHi8ThFRUVOW3hZX/bu3UtxcbFzs2C2MsW5GGNmfCAaGRkhHA4zODjIxMQEzc3Ns57b39/vdDltaGiY93UCgYDTUTL5wW3Xrl1OiZOIzK+goIDCwkJCoRBPP/003d3dayZoq6ioABY/r22+oG22TFtOTo7T+CSdv49LpTUmb56CNhHJqra2Nqy1jI+P09raymuvvcaPfvQjnnzySU6fPs3169c5c+aMc/zAwIBTGrmYMrHUid0LSc43Sv4hk/WnoKCA++67j/vuu49Dhw5RXV29qPO3bt1KVVUV9fX1QOIucvJmAsC1a9dm7caWzLI1NjamNa+jtLSUffv2AYlsYLKUSUQW5nK5OHr0KDU1NUSjUV577TUneFjtQVsgEHAyYO3t7Wmfl06mLRgMOsetVNC2FuYSrnaaCSgiWWOtdYKow4cPEwwG6e3tdbJpIyMjXLt2DUiUVExMTBAMBp2sw2KCtuLiYjweDyMjI4RCoXn/cMzXJELWl+Li4rRb/afatm0b27Zto7W1lba2NkZGRqZ8CJyYmKCjo8MJ6iDxoaWrqwuXy8WWLVvSfq1NmzZRUlJCbm6u5laKLJLX6+X222/nqaeeYmRkxPn9vtqDNkj8njl58iSnTp2iuLg4rdLC+TKJyaBtYGAAay1+vx+Xy+X8revv78dauyyLjs8XTEp69NtfRLJmdHSUUChETk4O1dXVbNu2jSNHjvDII49wzz33sGvXLsrKysjJyWHfvn2UlJQAN7Jli1k7LfUP03zZNmuts6abgjZZSPLGQWqmLfnf5dWrV6eUNSUzxEVFRYv+4JKfn4/b7c7EkEU2HGOMcwMl+f/kWgjaNm/eTG1tLdFolFdeeSWtRlrplEemZtkgEcwFAgEikciUioFMUtB28xS0iUjWJIOn8vLyKXf2kgHWzp07OXr0KG9605soKytzgrakxXbRS6cEZGhoiGg0Sl5env64yIJSu9Mlg7Jdu3bh9/sZGhqa8t+aFmoXyZ66uropf2fWQtBmjGH//v3k5+czMjLCqVOnFpzfNl9w5PP5ptz8SZ1flrxJuVwlkgrabp6CNtlQesd6+W/P/Te++OIXmYhMLHyCLKvUoC0dqZmvQCCw6LVe0pnXptJIWQyPx0Nubi7xeNzJ0BYXF9PY2AjgtOmHqZk2EVlZubm5zo07t9u9ZtYK83g8HD58GLfbTVtb27zrjcbjcSKRCMYYvF7vjOeNMU6JJEwN2pZzXpu1ds00gFnNFLTJhvLvF/+d7rFuWoZaePTSo9kezoZmrXX+OKTb8KO4uNi5U7qUtaqKiorwer2MjY3NuWCpmpDIYiX/W7TW4vV68fv9NDQ04Ha76erqcsqNkkGbMm0i2ZHsBrzWAoeCggKnIdHp06fnbM2fms2aa15a6tqQs2Xakn8DMykSiTi/HzUvd+n0nZMN5XzPeefxiY4T2RuIMDQ0RCQSIS8vb8qdv/l4vV7nA/JSgjZjDJWVlQBzduNSpk0WK7U5QEFBgbMkQHIOTbKT5MjICMYYLY4tkiW1tbWUlZWxadOmbA9l0err62loaCAej/PKK6/MuhZkOguHz5Vpy8vLw+v1EgqFZiy7c7NUGpkZCtpkw4rE5178VpZfV1cXkH5pZFJyvbXFnpeU/CDd2to6Y25AJBIhFArhdrvTDiRFpgdtScn2/G1tbfT19WGtJS8vb82UZYmsNx6Ph6NHj7Jr165sD2VJ9uzZQ1FREcFgkBMnTsz4G5ZOW/25Mm3GGKd0O9OLbCtoywwFbbKh5HpzFz5Ilp21ltbWViBx53Mxdu7cyYMPPugsPLpYFRUV5OTkMDY2xuDg4JTnkiWTgUBgWVoey/qUGqilPs7Pz6eqqopYLMbp06cBlUaKyNK53W4OHz6M1+vl+vXrU+bMQnrB0VyZNkBB2yqnoE02lBzP1F9QsXgsSyPZ2Pr6+hgfHycQCCx67pjL5bqp8jJjjDOvIRk4JqUGbSLpmivTBjeybaOjo4CCNhG5OYFAgAMHDgBw7ty5KY1DMhW0Tb+hebMUtGWGgjbZUOI2PmV7cGIwOwPZ4JLBUn19fVYyWsn5DB0dHcRiNwJ3BW2yFD6fz1lHbXpQVlZWNqVbpDpHisjNqq6uZvv27VhrefXVV52/Y+nMaUuWR7rd7hkdJpcr06bOkZmhoE02lPHI+JTt/mDmuyTJ/KLRKJ2dncCN+WUrraCggKKiIiKRCN3d3c5+BW2yVEeOHOHee++d8aHEGONk20CZNhHJjN27dxMIBJiYmHAy+enMafP7/dx6663cdtttM26aJufcTkxMOAFgJijTlhkK2mTDiNs44Vh4yr7+cQVtKykYDPLyyy8Ti8UoKysjLy8va2NJbUiSpKBNlioQCMwZkNXW1lJSUkJFRYU+tIhIRhhjnNLsZLfHdIOjbdu2sXnz5lmvuRzZNgVtmaEWVrJhzLaY9kKZtvHIOMfbj1NdUM32su3LNbR1y1pLT08P7e3tjI6OMjIyQiwWw+fzccstt2R1bHV1dZw9e5bu7m5CoRB+v19BmywLl8vFvffem+1hiMg6k5yTttigbT5FRUX09fUxODjoLJFzsxS0ZYaCNtkwxqPjM/YtlGn70eUf8WLri7iMi0/c8wnKAlpwOR3BYJDW1lZaW1sZH5/6fa+pqWHv3r1Z/+Xt9/uprKykq6uL9vZ2tmzZoqBNRETWjLmCtpuZO7YcmbZ0yjZlYQraZMNYSqataaAJSJRWtg61KmhbQFdXF01NTfT09Djrx+Tl5bFp0yanHHI1/dLetGkTXV1dtLW1UVtbSzwex+fzaR0tERFZ9VKDtlgsRigUwhgzoyvkYhQXFwOZC9qstRkJJkVBm2wgc2XarLWzdjC01tIXvNFKV01L5tfR0cHx48eBRDlYbW0tmzdvpqysbNWueVZZWYnX62VoaMhZ7FtZNhERWQuSnSDHx8czts5oshnJ+Pi4M3UgVTwe5/z581RVVaW1ZE8sFiMWi+F2u3VD9CapEYlsGBPRmZm2cCzMaHh01uMHJwaJxqPOtoK2uUWjUc6ePQskJji/6U1v4tChQ5SXl6/agA0SLY+Ti3tfunQJUNAmIiJrQ2qmLVPl/cYYp6nSbNm23t5erly5wmuvvUY8Hp/x/HSaz5Y5Ctpkw5itPBKYkk2bb3/f+OzHCVy+fJnx8XGKi4u55ZZb1lQJRHLNtuTcu2x2tBQREUnXcgRtMH+JZDIIGx8fp6OjY8FrKWjLHAVtsmHMVh4Jczcj6R3rnbI9MD6Q8TGtB8FgkCtXrgDMuu7LaldcXDwlUEuWm4iIiKxmXq8Xl8tFJBJhZGQEyMyNx/makSSbikDihm1y/vpcFLRljoI22TBmK48EGBwfnHX/9EzbSGhkxjpvAu3t7cTjcWctqrXGGDNlkW9l2kREZC1IbTrS15f4zJKJTFu6QdvIyAg9PT3zXkudIzNHQZtsGOORG5m2irwK5/HgxOCsx/cGe2fsWw/Ztng8Tl9fX8Y6QyXLI1IDn7Umdeya0yYiImtFsjpkdDQxPz8Tf8Py8/Nxu90Eg8EpQRrcCMKSC3u3tLTMe63kcgRradrEaqU2LrJhpGbaqguq6RlL3B0ampg9eJltrlt/sJ+q/KrlGeAyikQidHd309XVRXd3N5FIBGMMt99+OzU1NUu+7sjICMPDw3i9XioqKhY+YZUKBALs3LmTUCik8kgREVkzprf3z0TQZoyhqKiI/v5+hoaGpvx9TwZttbW1XLx40SnLnEuyPPJmliGQBAVtsmGkZtqq86s5xSlg9vLIWDw2a1ZtocW4V5vr16/T1NREb2/vlLrz3NxcxsfHOX78+JICt2Sglsyy1dTU4HKt7cT9rl27sj0EERGRRUkNhnw+H16vNyPXXShoKykpwRjD2NgY8Xh8zs8AmtOWOQraZMNIzbTVFNwIUoYmhmas1TYwPkDczmxlu5aCtubmZk6dOuW8t7KyMqqrq6mqqiIQCHD+/HkuX77Ma6+9Rnl5edq/6IeHh3n66acxxuB2uwGctvkiIiKyclKDtkyW9yfntQ0ODk7ZnwzacnNzyc3NJRgMEgwGnXLJ6RS0ZY6CNtkwUlv+F+UUkePJYSI6QSQeYSwyRr7vxi+c1PlsxhgnS7VW1mpraWnh5MmTAOzcuZMtW7bMqCffvXs3AwMD9PX10dHRQUNDQ1rXbm5uxlqLtZZ4PI7f76e8vDzj70FERETmt9xB2/T578mgzefzkZeXRzAYZHR0dMGgTeWRN29t1zOJpEgGEXNJzbTlenMpzi12tqeXSKbOZ9tUuMl5vBaCtkgkwpkzZwDYs2cPu3btmnUCsDHGWaOsra0trWvHYjHa29sBOHToEJs3b2bv3r1rrs2/iIjIepAaDGWy+3FBQYHTjCQSiQCJz1nJOfE+n88J1MbGxma9hrVWjUgySEGbrBvHjh3jiSeemNHpKCl1TluOJ4finGJne3oHyWSTEoAd5TumHDdb2eRyGx8fp6mpic7OToaHh4lGo3Me29raSjQapby8nK1bt8573ZqaGtxuN/39/XP+0k3V2dlJJBKhuLiYuro69u/ff1ONTERERGTplivTZoyhsLAQuJFtC4fDWGvxer0YY5ygLdm5crpoNEo8Hsfj8eDxqLjvZuk7KOvC2NiYs0bJxYsXue2226Y8H41HicQTd4pcxoXP7aMop8h5PrWDZOdIJ691vOZs1xfVk+fLYyw8RjQeZXhieEqWbiWcPn2a69evT9nn8/kIBAL4fD7C4TA+n4+9e/fS1NQEwJYtWxa8rsfjoaamhra2Ntra2hZsxpFs7bt58+alvRERERHJmOUK2iBRIjkwMMDQ0BDl5eVTSiOBBYO2ZJZN89kyQ5k2WRd6e2/MQWtqaprRgja1NDLHk4MxZmqmbbI8MhQN8fWTXycaT2SyqvOr2Va6jbLcMufYgYmVXavNWusEpJWVlU7JQjgcZnBwkO7ubuffp556irGxMQKBAFVV6S1NkFyj7MqVK7z44otOR8jpRkdH6evrw+PxUFdXl5k3JyIiIkvmcrmcpWoyWR4JM5uRTA/akq83V6WO5rNlljJtsi709CTKGXNycpiYmODs2bMcOXLEeT61CUmON/HLY8qctsnyyO9d+B7dY90AeN1efnbfz+J2ucn335hgOxZeuIwwk0ZHR4lEIuTm5jrvyVpLKBRyas29Xi/nz593grvGxsa055mVl5dTWlpKf38/3d3d9PX1UVNTM+P8a9euAVBXV6cyBxERkVXiwIEDjI+PZ3yd0eLiYmBqeSTcCNpycnLweDyEQiGn4ieVOkdmljJtsmpYa+edqzXfeclM2x133IHH46G7u5vu7m7nmClNSDyJX2rT57Sd7DzJ8fbjzr637347lfmVAOT5bty9Wumgrb8/0fykpKTE2WeMIScnh9LSUqqqqigtLeXIkSPU19dTVFS0qPJFYwxHjx7l4Ycfxu/3E4vFGB8fn3JMJBKhtbUVSK/sUkRERFZGeXm501gsk/Lz83G5XIyNjRGJRGYEbcaYebNtCtoyS0GbrBpnzpzhBz/4AcPDw4s6b3BwkEgkQl5eHsXFxezcudO5XrKb5PQmJDA1aOsd6+Xb577tbO+v2c+h2kPO9koHbeFw2FkQe2AgUY5ZWlo67zlut5uDBw9y//33L3pxTWMMubm5c9ant7S0EIvFqKiooKCgYFHXFhERkbXH5XI5zUiGh4dnBG0w/7w2zWnLLNU4yaoQj8dpa2sjHo/T0dHh/JJIR7I0sqKiAkhkgpqbmxkdHaW5uZktW7YwHk0J2ibLIwv8BbiNm5iNEY7d6DhZFijjnbe8c0p5YMB7Y3LvaHj2CbfpGBsbo6enB5fLhdfrxev14vF4pjzu7e3lxIkThEIhbrvttlkzbcslPz+fvr4+RkdHqaxMZBmttYtqbiIiIiLrQ1FREYODgwwODs4atCUzbbMFbZrTllkK2mRVGBgYcNYB6enpYffu3WmfOz1oc7lc7Nmzh5deeokLFy5QV1c3ZU5bsjzSGENhTiED4zcai7iNm5/d+7P4PVPvChX4bmSXlpJp6+3t5eLFi86cs3RduHCBSCSC2+1eVCC7VLOtuXL9+nWCwSB5eXlOICciIiLrX3FxMc3NzQwNDTk3s1ODtuRnk46ODrZt2zblOZVHZpaCNlkVUtvZDw0NzTqhFRJZnyevPcnA+ABv2v4mct25DAwMYIyhrOxGh8fKykoqKiro6enh/Pnz9OfcWBQ713tjom5xTvGUoO0tO99CXdHMzogB341M23xBWzAY5Ny5c2zatInKykpCoRCnTp2is7MTSJQwVlVV4Xa7iUQiRCIRotHolMcul4sdO3bQ09PjBHnFxcW4XMtfzTxbmUOyAcmWLVu0iLaIiMgGkmxG0t/f70yPSP18VlVVRXFxMYODgxw/fpwjR444n1cUtGWWgjZZFZJNQ/x+P6FQiJ6enilt5YPBIE1NTTQPNfPM8DMYY/C6vdxVdhfWWoqLi6fM4zLGsGfPHv79x//Ol179EjkVOc7zqVm08rxyrg0kgpLdFbs5uvnorONLndMWjARnPcZay4kTJ+jr6+P69evs3buXK1euMDo6itvtZvv27WzdunXezovWWmf8FRUVPPPMM8DC89kyZXqZw9DQkNPmfzkmOYuIiMjqVVBQgN/vZ3x8nFgsBkwN2lwuF3fccQdPP/00vb29nD171lkrV+WRmaWgTdJirc1IliUUCtHd3c3w8DA+n4+8vDzy8vIYHR3F6/WydetWzp075wRtQ0NDXLlyhY6ODqy1XBy7yETuBLm5uVwfuU4fiUxUapYtqaCggKG8Ifq7+8kdyKWyshKvy8uu8hsLSN+9+W5ah1op8Bfw7j3vnvM95vtutPyfa05be3s7fX19GGOIx+O8/vrrQKJ04M4770yrFW/q6xcXF9PQ0EBLS0vaa67drEAggMvlYmJigmg06mTZNm/erDb/IiIiG0zyJnJbW9usc9ogEZTdcccdPP/881y7do3CwkLq6+sJhUIYY2atnJLF06cwWVBfXx8vvfQS1dXV7Nu3D7fbnfa51lqGh4fp6uqiq6uLoaEhJ5uUlAxUKisrqays5Ny5c3R1dXHs2DGnlb8xhvz8fMZHxgkGg+Tm5jI0MURfeO6gDSAcCOMyLsbHx9lTsYc373wz5XnlzvNV+VX82t2/tuD7SG1EEowEids4LnOjXDESiXD27FkA9u/fz8DAAM3NzZSWlnLnnXcuuptj0t69e9m1a9eKlRYk2/eOjIzQ399Pe3s7xhgaGxtX5PVFRERkdUkGbUmzBWElJSXs3buX119/nVOnTjmfe3w+n6ZWZIiCNpmXtZbTp08TjUZpa2tjfHycw4cPp3XXpK+vj1dffdVp+QqJNHpFRQWlpaVEIhH6+/udlvY1NTUUFBQ4C2T39vbi8XjYvHkzW7duJRKJ8Ni/PsZ4ONEJciA4QH+kH2PMrOWDoWiI62PX8fl9TExMcFf5XVMCtsVwu9zkenMZj4xjrSUYCU7Jvp07d45QKERZWRn19fXU19fT0NBAQUHBTc1FM8aseC14fn4+IyMjnD17lng8TnV1tVM2KSIiIhtLstEbJD6XzFV5s3nzZoaHh7l27RqvvvoqoPlsmaSgTebV2trK8PAwubm5WGvp6+vjueee48iRIwQCgSnHWmsZHR0lPz8fYwwtLS1MTEyQk5NDVVUVVVVVlJWVzfiffWhoiGAwSHV1NcYYduzYQUtLC3V1dWzevNm5W5OTk0PUFSUWixEOh4nH4wTjQWpKa2bNZLUOtRK3cfx+P/6on4mRiRnHAM66cAt1Z8zz5jnrvQXDN4K2gYEBWlpaMMawd+9e545SUVHRQt/eVSkZoI2MjABq8y8iIrKR+f1+ioqKGBoaWjBzduuttzI8POw0UtN8tsxR0CZzikajnD9/HoBbbrmF0tJSXnrpJYaHh3n22We58847na5CkAjwXn/9dfbt20dDQ4MTDB0+fHjeNcaKioqmBDiNjY2zluMZY3DluGAMxoPjWCxBd3DO0simgSYg8cumMFLorHeWKhQK8eyzzxKLxSgpKaGxsZHa2tpZs2N5vjx6g4lyzWQHSWstp06dwlrL9u3b18XC08kOkpCYFzjX91dEREQ2hoqKCidom4/L5eLw4cM888wzBINBZdoyaPl7iMuadf36dUKhEMXFxdTW1pKbm8vRo0cpLy8nFArx/PPP09XV5RyffNzV1UU8HmdkZARjTEYDGetLzIcbHRtlbGyMYGzuoC3ZFdLv91Ppq2RoaMjpfJQ0Ojrq7BsYGOC1117jRz/6EefOnSMYnNolcrZmJNeuXWNoaIhAIMCOHTsy8yazLDVo27p1q2rRRURENrjq6mpg6meEufh8Pu68806qqqrYvHnzcg9tw1DQJnNKZsqqqqqcD+5er5cjR45QX19PLBbj5ZdfpqurC2utMzdtYGCAkZERrLXk5eVlrOtgKBrC5XXhcrmIRqOJ9c3ckVmDtkgsQttQYtKsy+Via9lW4vE4g4ODU45LLiJdU1PDvn37KCwsJBwOc/nyZX784x9z9epV59jUtv9j4TEmJia4cOECALfddtu66a6Yn5+Px+PB7/dPWXZBRERENqaSkhLuu+8+9u7dm9bxBQUF3HnnnSu2ZNFGsD4+ZcqymGuul8vl4sCBA/h8Pq5evUpTUxMFBQXOehzhcNhZTHqheWKLGk9oGGMMJSUljI+PE8gN0LCzYdb5bG3DbUTjUQDKA+XUFdXRNNZEf3//lCAvGbQVFhbS0NDA5s2bGRgYoKmpifb2di5duuQsKh3wBYjFYvT09PBa7DVsuyUajVJdXb1iLflXgtfr5d5778Xtdi+qU6iIiIisX6lTYmTlKdMms0q26ofZA69kwxBjDL29vU5r/qSWlpY5z12q4YnEePLz86moqCAvP4/RyOxrpjX1NzmPt5Ruce70TJ/XliyBTDZVSXaiPHjwIDk5OYTDYWeh6TxfHuPj44RCIbr6u+jt7cXtdjuLSK4nBQUFMxrNiIiIiEh2KGiTWYVCIUKhEF6vd85FoX0+HyUlJcTjcS5duuTsS54Pme2gOBwanrFvcGJw1mObBpucx40ljU4jlLnKI6e3tE9dRiAZ6OV7852FJb0BL2VlZezbty+tRbNFRERERJZKQZvMKjXLNl8jisrKSuBGxqqhoWHK85nMtI2ERmbsGxwf5PXO13mu+TkisQgAsXiM5sFm55gtJVvIzc3F5XIRDoeJRhNlk9baGZm2VNODtjxfnhO05ZXkcfToUerr6zP2/kREREREZqOgTRyhUIiXXnqJtra2tNcuS53LZYyhsbHRCfL8fn9GW70OhYZm7JuITvD1U1/n+xe+z7GWYwC0D7c7AVxJbglFOUUYY5y1QpKBVyQSIRKJ4PF4Zm1hOz1oC3gDRMKJ68Zd8Yy9LxERERGR+ShoE8fp06fp6uri1KlTzqKICwVtqXOf8vPzycnJcVr8L5SlW6zZMm2pkkFbcn02SJRGJiUDyImJxCLbqaWRs42zsLAQj8dDMBhkfHwcIhC3cTweD8ORYU50nqB7tPtm3pKIiIiIyIIUtAkA3d3ddHR0AIlFtbu7E8HIQkGbMcYpkUzOG0v+m8nSSICRiRtBm9c1s2NkOJbIoCXXZ4NEaWRSMmhLzrebrzQSZs5rC48lru/z+YjEIvzzqX/mCy99gaGJmRlAEREREZFMUcv/DSQej3P8+HGCwSAulwu32+38m2zQUVNT47TrT3dh7O3btxOLxdi+fbuzba1l69atGR1/aiOSuqK6KRk1gFAsRDgWnjKfbbZMWzJom6sJSarS0lK6u7vp7+9PfK+Me0opZSga4ljLMR7Z+ciS35eIiIiIyHyUadtAenp6uH79OsPDwwwODtLX1+fsm5iYoLCwkEOHDlFeXg4kyh3TWacrNzeXAwcOOMFPIBBg//79zhyyTLDWTimPLAvMXFDbWsvZ7rOEoomgrNBfSGnujUUdk+OZXh45X2v75Peira2Nnp4efMY3Y/7bS20vOa8pIiIiIpJpyrRtIMm11BoaGti0aRPxeJxYLEYsFsNaS1lZGS6Xi927d3Ps2LG0F4w+1nKMp649xZFNR3ho60PLMvaxyBgxGwMg15vLttJtHG8/PuO4l9tedh43ljROmas2V3nkfJm24uJiJ/s4MjJCpb+SmC8xDr/HTygaIhQN8Ur7K9zTcM9NvksRERERkZkUtG0gPT09ANTV1TnzzmZTUlLCm9/85rSybNF4lB9c/AGReITHrzzOXZvuIteb+XXLkgtrAxT4Cri18lZ2V+xmNDxKrjeXS72JdeJSSyZT57PB0sojjTHs3buX/v5+QqEQd5TdQf6OfDYVbWJoYojvnPsOkAhc7958Ny6j5LWIiIiIZJY+YW4QExMTjIyM4Ha75w3YAE52nuSPnv4jvvr6V7HWznvs9ZHrROKJNvjWWq6PXs/YmJOstRzvuJFVK8wpxOv28v6D7+dXjvwKu8t3z3pe6nw2uFEeGQqFiEajhEIhXC7XgmWcfr+fAwcOYIyhobqBh7c/zK6KXRysPUieNxHwDYwPcLrr9E28SxERERGR2Slo2yCSpZHJEsj5PHblMSaiE5zpPkPLUMu8x7YNtU3Zvj6S2aDNWsu/nf83Xmh5wdm3rXTblGMq8ipmnJfny5uxP7Xl/+joaOK4Odr9T1dZWckb3/hG9u3b5+zzur0c2XzE2X626dkFg1wRERERkcVS0LZBJIO2ioqZAU6qkdAIfcE+Z7t9uH3e49uGly9os9bynXPf4cXWF519eyr3cLTh6JTjyvPKZ5w7fT4bTC2PHBlJNDVJpztmUm5u7oyS0SObjuBxJaqM24fbaRpsSvt6IiIiIiLpUNC2AVhrnflsyW6Ic2kZnJpZ6xzunPf49qGpQV2myiPjNs43z3xzSmORvdV7+dl9P+sESUmF/kJ87qkdHafPZwNwuVz4fD6stc7i4YsJ2maT78vnYO1BZ/u5pudu6noiIiIiItMpaNsABgYGmJiYwO/3LxikpK5xBtAx0jHnsaFoiJ5gz5R9XSNdxG186YMlEbD9y+l/4dWOV519B2oO8DN7fwa3a2ZzFGPMjCUAps9nS0pm25KZx5sN2oApXSPP9Zyjd6z3pq8pIiIiIpKkoG0DuHQp0Vlx8+bNC87fmh60dY92E4lFZj22fbh9xhyuSDwypbxyKb55+puc6DzhbB+qPcS7b3v3vJ0ZU+ev5Xpzqc6vnvW4ZNA2Pj4OZCZoq8irYHfFjWYozzUr2yYiIiIimbPmgzZjzK8aY44bY8LGmC8vcOx7jTFXjTFjxpgfGmPqUp7zGWO+aIwZNMb0GGM+u+yDXwGDg4N0d3fj8XjYunXrvMeGoiE6hqdm1uI2Tvdo96zHT29CktQ5Mn9J5Xzahtp4rfM1Z/uO+jv46T0/vWAr/dSgrbF45ny2pGTQBolyyfna/S/GvQ33Oo9f63iN0fBoRq4rIiIiIpL1oM0Ys8MYUzH5OGCM+T1jzO8YY/wLnTupA/gD4H8t8Dq3AH8LfBQoBy4A/5hyyO8C+4DtwB3AzxtjPrSoN7PKWGu5ePEiAI2Njfh8vnmPbxtqm7W0ca4SydQmJPm+fOfxzTQjuTZwzXm8u2I377zlnWl1d7y18lbnuNvrbp/zuNT2/gUFBWldOx2NJY3UFtYCiWzj109+na+d/BrPNT83Z6ZSRERERCQdq2Fx7X8EfhnoAT4HvBmIAjXAf1roZGvtNwGMMYeB+nkOfR/w79baxyaP/x2g2xizzVp7BfgQ8BFrbS/Qa4z5M+CXgP+91DeWLee6z3G17yrtLe0MDwzjc/uoClTxTNMz9Af7icajeFyexJc78a/buKd0PvS4PETjUYAZ2TeAWDxG88CNUspDtYd4uulp4OaCttbBVufx7ordaQdV1QXV/N/3/t+EY2Gq8qvmPC4105aJ0sgkYwz3NdzHP536JwCu9F8B4NT1Uzzb9CzvuOUd3FJ5S8ZeT0REREQ2EGttVr+AfsA1+bgZ2ApUAu2LvM7ngC/P8/x3gN+etu8C8E6gBLBAXcpzdwMDc1yrGGic9nXv5DVm/friF79ok774xS/OeVziR3LDoUOH5jzuIx/5iHPcK6+8Mu81P/T/fsh++geftp/+waftgbcemPO46u3V9tM/+LT955P/bD/9g0/Pe823/sZb7ad/8Gn7h0/8of3j//bHGXlPd7ztDmecjz716LzXfOWVV5xrfuQjH5nzuEOHDjnHtba2znvN5fg5HXjrAfuZxz5jI7HIgj+npbwnm/iPctX+t6f3pPek96T3pPek96T3pPek93Tj61//9V+TjxttmrFO1ssjAQNYY8xWEt+Yq9babqAww6+TDwxN2zcIFEw+x7Tnk8/N5hPAtWlfz2RmmNmX48nh/i33p3380c1HKfBnJmuVLCX0uX2UBkozcs1UqeWRKykcCzMeGc/Ka4uIiIjI2mbstO5/Kz4AY54EHgM2A1hrPzrZIOQla23dfOdOu87ngHpr7QfneP47wIvW2s+n7DsP/GfgaRIZvzprbcfkc3eRKKcsmeVaxSSybanqgWeuXbtGY2NjusNeFhd7L3K1+youj4tIPEIkHiEcC5PjyaEsUIbf4ycaixKzMSKxCDEbIxqL4nP7CPgC7CzfSUluCX/89B8zNJGIY3/96K87ZYcnO086ZYC53lx+877fxO/x8/S1p/nBpR844/jFQ7/IzvKdaY/71PVTfO3k1wDYVrqNXzr8S5n6ljhGRkZ48sknAXjjG99IIBDI+Guk+otn/4LeYGIJgN84+htU5lcu6+uJiIiIyOrW1NTEli1bALZYa5vSOWc1zGn7deCvgTDwi5P7HgZ+lOHXOQ3sT24YYwqBLcBpa+2AMaZj8vnkBK4Dk+fMYK0dJJGJc2SqoUUm7CzfuahgaS61BbVO0NY21EZVfhXWWp689qRzzN2b78bvScwTu6/xPq70X+Fy32UAvnv+u3zy3k+m/XqtQzfms9UXzTc9celycnIwxuDxeMjNzV2W10iV673xGhPRiWV/PRERERFZf7JeHmmtPWmtvdda+wZrbevkvr+bK2M2nTHGY4zJAdyA2xiTY4zxznLoPwBvNca8wRiTS6Lj5As20YQE4MvA7xhjyo0xDcAnSXSb3LDqim4kOpPt/c92n6VrtAtIlDDevelu5xhjDO/d+17cJrEAdl+wj3AsnPbrpTYh2Vy8+abGPhev18uhQ4c4fPjwigTaOd4b5ZgqjxQRERGRpVgNmTaMMQFgF9PmkFlrn07j9N8Bfi9l+33A3wEfNMaMAm+11j5jrT1njPll4EtANfAs8PMp5/0+iaUArgAR4G+stf97iW9pXagvvJHtSi6knZplu2vTXQR8U8sL8335FPgLGJwYBGAkNEJZoGze13ml7RVe63xtyhICy5VpA6itrV22a0+X47kRtCnTJiIiIiJLkfWgzRjzDuDvmdl4xJLIns3LWvsZ4DNzPJc/bfufgX+e49gw8LHJLwHqCm9k2q6PXOdczzmn/b/X5eWexntmPW8xQdvg+CDfPvdtUudWluSWTFn3bS3L9dwoj1SmTURERESWIuvlkcCfkGjXX2CtdaV8LRiwyfIK+AJOwBWzMb5z9jvOc3fU3zFnYJXaSXIkNDLva3SPdU8J2Iwx3Ntw780Me1VRpk1EREREblbWM21AjbX2T7M9CJldXWEdfcE+AEbDo0Bi4e37Gu+b85wpQVt4/qAt2egEYE/lHt5+y9sztnzAapA6p01Bm4iIiIgsxWrItD1rjNmX7UHI7GabW3ao9hCFOXMvo1fgSz/TliyjBKgqqFpXARtMLY9U0CYiIiIiS7EaMm3PAt82xnwR6Ex9wlr799kZkiSlzmsDcBnXggtv5/tvlE0uFLQNjd/ItBXlFC1hhKtbanmk5rSJiIiIyFKshqDtI5P/fnzafkuiQYlkUU1BDcYYZ97ZgZoDlOTOWG98isXMaUvNtBXnFC95nKuVyiNFRERE5GZlNWgzxriAtwEXrbWRbI5FZuf3+NlUtImWwRZcxsUDWx5Y8JzU8sjR0Oi8x677oE2NSERERETkJmU702aBl4H10d99nXr3nnfzYuuLbC/bTnle+YLHp5tpi9s4wxPDzvZ88+TWqlyvWv6LiIiIyM3JatBmrbXGmCtAFdPms8nqUZ5Xzk/u/sm0j8/35zsllWORMaLxKB7XzP/URkOjxGwMgDxvHj63L2NjXi2UaRMRERGRm7Uaukf+BfBVY8yDxphGY8zm5Fe2ByZL4zIu8rx5zvZYeGzW41JLI4ty118TEpgWtEUmpqxJJyIiIiKSjmyXRwJ8afLfH5MolwQwk4+1wPYaVeAvcNZ1GwmNzNoZckrQ5l+fQZvX7cXj8hCNR4nZGJF4ZF1mFEVERERk+ayGoG1LtgcgmVfgL6BzJFHxOte8ttSFtddrpg0S2bZkADsRmVDQJiIiIiKLkvWgzVrbnO0xSOal04wkNWhbj50jk3K9uTeCtugEhay/hisiIiIisnyyHrQZYz4w13NaXHvtmhK0hdPItK3DhbWTcj0pHSSj6iApIiIiIouT9aAN+P1p25UkxtWOFtdes1LXapsr07be12hL8nv9zuOJiDpIioiIiMjiZD1os9ZOmdNmjPEAfwRcys6IJBPSKo8c3yDlkSmZNrX9FxEREZHFWg0t/6ew1kaB3wU+ne2xyNItFLSFY2HGIomlAFzGRb5//a6vntr2f7ELbFtrCUVDmR6SiIiIiKwhWc+0zaEIKMn2IGTpUoO2wYlB4jaOy9y4RzAwPuA8LsopmvLcepPjTQnaFjGnLW7j/O0rf0vTYBM/sesnOLr56HIMT0RERERWuawHbcaY3522Kw94F/Doyo9GMqXAX4Df4ycUDTEWHuPJq0/yhm1vcJ5vHWp1HlfnV2djiCsmtTxyMVmzs91nuTZwDYDvnf+egjYRERGRDWo1pDcemvZ1C/AV4MPZHJTcHI/Lw/2N9zvbT1x9gtbBG4Fa21Cb83hT8aYVHdtKW2p55OW+y1O24zaesTGJiIiIyNqR9UybtfahbI9Blsf9W+7nYu9Fmgebids4/3z6n/lPd/0n/B7/lABuc9HmLI5y+S21PPJa/7Up2yOhkXW9NIKIiIiIzC7rmTZjzAtz7H92pccimeUyLt5z23vwexIt7/uCfTx68VFC0RBdY10AGGOoLazN5jCXXWqmLd3yyN6xXnqDvVP29Y/3Z3RcIiIiIrI2ZD1oA/bMsf+WFR2FLIvSQClv2/02Z/ultpd4/MrjWGsBqMqvcoK69WrK4tpplkde7Ls4Y9/g+GCmhiQiIiIia0jWyiONMR+YfOg2xrwfMClP7wL6Vn5UshwO1hzkfM95znSdAeC55uec59Z7aSRArjf9ddquDVzjYs9FLvRemPFcasdNEREREdk4sjmn7fcn//UDn03ZHweuA7+24iOSZWGM4V23vIuWwZYZa7bVF9VnaVQrJzWTOBGZO2g703WGr5382pwNR6YHbaFoiK+d/Bpdo12897b3sqV0y6zniYiIiMjalrXySGvtFmvtFuAHyceTX9ustfdYa3+QrbFJ5gV8AX56z0/P2L+5eP1n2qZ0j4yOO6WhqRYK2CCx3l2q7134Hhd7LzI0McT3LnwvY+MVERERkdUl63ParLU/AWASarI9Hlk+O8t3ctfmu5ztXG8u5YHyLI5oZXjdXqdEMm7jdI91T3l+esBWHijnrs13cdfmu3jfgfc5x6Vm2s51n+N4+3Fnu3OkU3PeRERERNaprAdtxphcY8z/AMaBy5P73mmM+e3sjkyWwyM7HmFb6TYA7m+8H2PMAmesD8n3DHCh58Z8tbPdZ2cEbB++48O8fffbefvut7O9bLtz7NDEEHEbZzQ8yrfOfmvGa5zrObeM70BEREREsiXrQRvwp0AD8AAQmdz3KvAfsjYiWTZet5cP3f4hfvcNv8v9W+5f+IR1YnfFbudxMrg6132Or77+VSdgKwuU8cuHf5kCf4FzrNftJd+XDySydEMTQ3zn7HcYC4/NeI3zPeeX8y2IiIiISJashqDtHcB/sNa+SKIJCdbaVqAuq6OSZWOMWfdt/qfbWb7TySq2DrVyvP34jIDtw4c/TGFO4YxzS3NLncc/vvJjznafdbZ/as9POY+v9l9Ne0kBEREREVk7VkPQ5gWGU3cYY3JJlEuKrAt5vjw2FW0CwFrLN898k5iNAfMHbADFucXO41c7XnUeH9l0hMN1h6krTNzfiNs4F3tnru8mIiIiImvbagjaXgY+Nm3fB4AXsjAWkWWzq3zXjH2lgVJ++fAvzxmwwdSgLaksUMZbdrwFgFsqb6xDr3ltIiIiIuvPagjafhP4PWPMU0CeMeZR4A+BT2V3WCKZlRpcAZTklvDhwx+mKKdo3vNKckqmbBtjeM9t73FKTFODweaB5lmXFBARERGRtSvrQZu19jxwC/Bt4H8BzwMHrbWq85J1pTKv0lmXriS3hI/c8ZEFA7bksake2PLAlPXtqguqnQBuODQ8YxFuEREREVnbPNl8cWOMF2gGtlpr/yKbYxFZbsYYPnjog7QOtdJQ3IDX7U3rvJrCGjwuD9F4lNrCWh7a+tCU513GxaaiTVzuuwxA82AzpYHS2S4lIiIiImtQVoM2a23EGBMBNsZiXbLh+T3+KWuvpSPfl88Hb/8gLYMt3FF3Bx7XzP9tG4sbnaCtZbCFg7UHMzJeEREREcm+rJdHAn8O/Mlk1k1EZrGlZAsPbHmAgC8w6/MNJQ3O4+bB5pUaloiIiIisgKxm2iZ9AqgHPmyMuc7kWm0A1tqt2RqUyFpSV1iHy7iI2zhdo10Ew8E5AzwRERERWVtWQ9D2mWwPQGSt83v81BbW0jbUBkDLUAu7K3ZneVQiIiIikglZD9qstX+X7TGIrAcNxQ1O0NY80KygTURERGSdWA1z2kQkAzYVbXIed412ZXEkIiIiIpJJCtpE1onUNd9GwiNZHImIiIiIZJKCNpF1otBf6DweCSloExEREVkvFLSJrBP5/nzn8Wh4lLiNz3O0iIiIiKwVqyJoM8a4jTFHjTE/O7mdY4zxZ3tcImuJx+Uhz5sHgLWWsfBYlkckIiIiIpmQ9aDNGLMFOAn8APjbyd0/AfzPrA1KZI0q8Bc4j1UiKSIiIrI+ZD1oA/4K+A5QDIQn9z0B3J+tAYmsVaklksOh4SyOREREREQyJevrtAFHgJ+y1saMMRbAWjtgjCnJ8rhE1hw1IxERERFZf1ZDpm0MCKTuMMZUAH3ZGY7I2qXySBEREZH1ZzUEbf8O/DdjTA6AMcYFfA74t6yOSmQNUtAmIiIisv6shvLITwHfBvoBPzAEnAPelMUxiaxJCtpERERE1p+sB23W2iHgIWPMIWA7cB141lotMiWyWKlBmxqRiIiIiKwPWQ/ajDEPWmuftNa+Crya7fGIrGVqRCIiIiKy/qyGOW3/Zoy5ZIz5lDGmOtuDEVnL8n03Wv6Phkex1mZxNCIiIiKSCashaKsB/ivwDqDFGPOvxph3TDYkEZFF8Lq9BLyJZqxxG2c0PJrlEYmIiIjIzcp6YGStHbXWfslaexQ4AFwA/gfQmtWBiaxRakYiIiIisr5kPWibpolE58hmoDK7QxFZmxS0iYiIiKwvqyJoM8bcbYz5EonOkf8Z+BawObujElmbCnwpQVtYQZuIiIjIWrcaukeeIxGgfRN4u7X2qSwPSWRNU6ZNREREZH3JetAG/HfgHyfXaxORm5Tvv9FBcmhC/1uJiIiIrHVZL4+01v6NAjaRzCkPlDuPT3edZiIyMe/x1lqOtx/nROcJLREgIiIisgplJdNmjPmetfYnJx8/Acz6SdFa+4YVHZjIOrCjfAelgVL6g/2MR8Y51nqMh7Y+NOfxxzuO860z3wLA6/Kyp2rPSg1VRERERNKQrUzbsymPn5rnS0QWyWVcU4K055qfIxQNzXl8MmADeOqa/rcTERERWW2ykmmz1v5RyuPPZGMMIuvZgZoDPHH1CSfb9uTVJ3nLzrfMOG56OaTbuFdqiCIiIiKSpqzPaTPGdMyxv2WlxyKyXriMiwe3POhsP9P8DJf7Ls84rmu0a8q23+tf5pGJiIiIyGJlPWgDCha5X0TScKj2ENvLtgOJjNo/n/rnGUsANA82T9keC4+t2PhEREREJD1Za/lvjPndyYfelMdJO4FmRGTJjDG857b38FfH/oqx8Bij4VH+5cy/8IsHfxFjDABNA01TzhkNjWZhpCIiIiIyn2xm2h6a/PKkPH4IeAAwwC9lb2gi60OBv4D33vZeZ/tS7yWeaXoGSGTfZsu0xW2cE50nuNBzYUXHKiIiIiKzy1qmzVr7EIAx5m+stb+SrXGIrHc7yndw/5b7efra0wD86PKPaCxppMBfMGPx7ZiN8fS1p/nR5R8B8N697+VAzYGVHrKIiIiIpMj6nDYFbCLL7+FtD7O5aDMAcRvn66e+zsttL8967Omu087jRy8+Ou9yASIiIiKy/LIetAEYY37ZGPNVY8zjxpgfJ7+yPS6R9cLtcvMz+36GXG8uAAPjA3OuyZbaUXIkNKK120RERESyLOtBmzHms8B/AbqAu4GTwF7g9WyOS2S9Kckt4V23vmvG/rrCOqfLJCQycamea36O/mD/cg9PREREROaQ9aANeD/wiLX2E8DE5L8/DdRmc1Ai69FtVbdxZNMRZ3tT0SY+dPuHKMktmfOcaDzKo5ceXYnhiYiIiMgsstaIJEW5tfZ4csMYY6y1zxhjvp3FMYmsWz+x6yco8BcQiUV4YMsD+D1+8n35M47zuX2EY2EAznSd4Vr/NbaUblnp4YqIiIhseKsh03bdGFMz+bgZOGqM2ZXNAYmsZx6Xh4e2PsSbd7wZv8cPMGvQtrl485TOkd+98N0ZpZMiIiIisvxWQ9D2VRLrswH8D+Bx4DjwD1kbkcgGk+fLm7GvJLeEN+94M163F4DrI9d5pe2VlR6aiIiIyIaX9aDNWvu71tp/nHz8N8AbgPcAn8jmuEQ2knz/zExbSW4JRTlFPND4gLPvscuPMR4ZX8mhiYiIiGx4WQ/aprPWPm+tfdRaa7M9FpGNosBXMGNfsjnJvY33UpxTDMBYZIwnrj6xkkMTERER2fCy0ojEGPO36Rxnrf2l5R6LiMxeHlmaWwqA1+3lLTvfwj+d/CcAjrUcI9eby70N9zqlkyIiIiKyfLKVaTNpfonICsjx5OBxTb2HU5xb7DzeW7WXhuIGILGO22OXH+OLL32RUDS0ksMUERER2ZCykmmz1n4oG68rIrMzxpDny2NoYghItPvP8+ZNef69e9/LV058hc6RTgA6Rzp5ue1l7m28F4DR8Cgvtr5IfWE9uyrUAFZEREQkU1bdnDYRyY7Utv8luSUYMzXZXZJbwn+86z/y4NYHnX0vt72MtZbxyDhfevlL/PjKj/k/J/4P1waurdSwRURERNa9rAdtxphrxpirs31le2wiG0nqvLZkE5LpXMbF/Y33O+u79QZ7udx3ma++/lV6xnoAsNbyvfPf05puIiIiIhmSlfLIaT4zbbsO+AjwxZUfisjGlZppSzYhmY3f4+dAzQFebH0RgC+/+uUZx3SOdHK8/Th31N+R8XGKiIiIbDRZz7RZa/9u2tfngZ8C7sv22EQ2koq8CudxdUH1vMfeWX/nrPtTz/vRpR9pTTcRERGRDMh60DaH11HQJrKi7qy/kyObjnBPwz0cqDkw77HVBdVsLtrsbHtcHh7e9jAfu/NjTmnlWGSMH1/58XIOWURERGRDWHVBmzEmF/gNoHsR5xQbY75ujBkxxrQbY/7jHMd5jTH/1RjTZowZMsb8H2NMfsrzPmPMF40xg8aYHmPMZ2/+HYmsDTneHN5xyzv4iV0/gdvlXvD4t9/ydjYXb+ZAzQF+/eiv89C2h/C5fTyy8xHnmBdaX6B7NO3/lUVERERkFlmf02aMiQN22u4R4BcXcZn/l8R7qQW2AT8yxpyz1j4x7bjfAh4ADgETwD8B/x1ILuL9u8A+YDuQDzxmjLlmrf3fixiLyIZQW1jLx+782Iz9eyr3sKVkC9cGrhG3cb534Xt88NAHZ3SjPN11mqevPc2B2gMc3Xx0pYYtIiIisuashkzbQ8AbUr7uAOqttd9J52RjTB7wXuB3rLUj1toTwN9yIxBL9S7gv1tru621w8B/Af7DZHYP4EPAH1hre621TcCfzXEdEZmDMYaf3P2TTpB2ue8y53vOTzkmFA3xzTPfpH24ne+d/x59wb5sDHXKeL53/nt84/Q3NA9PREREVp2sB23W2qemfb1qrR1dxCV2AsZaezZl3wngtlmONZNfqds5wE5jTAmJTN3rC11nshyzMfULqF/EmEXWtZqCminNSr5/8ftE41Fn+2z3WULRkLN9vP34io4vVSwe46snv8rzLc/zWsdrPH3t6ayNRURERGQ2WS+PBDDG3AccBgpS91tr05lTlg8MT9s3OP1ak74H/IYx5sckyiM/Nbk/MHkdgKE0rvMJ4PfSGJvIhvXwtoc5ef0k45Fx+oP9PNf8HA9seQCYGaQdbz/Ow9sfxmVW9j6StZbvnPsOl3ovOfuaBppWdAwiIiIiC8l6ps0Y80fAY8D7gDelfD2c5iVGgcJp+4pIzIub7o+A54EXSWTUvj+5v23yOky71lzX+Utgy7QvdbsUSRHwBXjjtjc6209efZKJyAT9wX6uDVybcuxoeJQLPRdWeog8efXJGQFkx0jHlKygiIiISLathkzbR4Ajk3PRluIiYI0xt1hrz03uOwCcnn6gtXaCRJbsEwDGmEdIBGzt1tq4MaYD2A90LHCdQRJZOMf0JgsiAkc2HeGFlhfoDfYSjoW51HeJrtEu53mXcRG3cQCeaXqGTcWbpizyvZxe7XiVx648NmN/NB6la6SLuqK6FRmHiIiIyEKynmkDxpglMEqXtXYM+AbwB8aYAmPMPhLNQ/52+rHGmFpjTL1J2Af8OfB71k5+aoQvA79jjCk3xjQAn5ztOiKSHpdxsbd6r7N9oecCr3a86my/afubnMfNg8382TN/xg8v/ZBgODjnNWPxGL1jvVg7vels+i73XeZbZ77lbG8v286eqj3OdutQ65KvLSIiIpJpqyFo+1Pgd83Npar+E4llAzqBR4HPWGufMMZsNsaMGmOSqwBvAZ4hESh+G/hra21qUPb7JALIK8Bx4J/U7l/k5uws3+k8fv366wxNJKaN5nnzONpwlLs23+U8H46FeeraU/zps3/K41cen9HJMRgO8v+98P/xF8/9Bd+/8H2WonOkk398/R+dDF91QTU/v//naShucI5pG2pb0rVFRERElsNqKI/8Nok5bf+XMaYn9Qlr7dZ0LjBZrvjeWfa3cKPBCNba50gEbnNdJwx8bPJLRDKgvqiegDdAMBJ0AiWA/TX78bg8vG3X29hWuo3HLz/O9dHrQKIF/4+v/JhjLce4p+Eejm4+itft5Suvf8Upr3yl/RXeuuuti2peMhoe5e9f/Xunc2Whv5APHPwAfo+f+qIbDWDbhhW0iYiIyOqxGoK2fyIxr+wvgblrokRkTXIZF9vLtnPy+skp+w/VHQIS80FvrbyVWypu4XTXaX585cd0j3UDMB4Z57HLj/Fc83PkefPoDfY654djYXrHeqnMr0x7LI9ffpzhUKLZrN/j5xcP/SJFOUUA1BbUOnPsesZ6mIhMkOPNuan3LiIiIpIJqyFo2weUTzYJEZF1aGf5zilBW21hLTUFNVOOMcawt3ove6r2cPL6SX585cfOotvjkfFZF73uGOlIO2jrHOnk5faXne333vZeqguqnW2v20tVfhWdI50AtA+3s61sW/pvUkRERGSZrIY5bWeA0mwPQkSWz/ay7VO2D9UemvNYl3FxoOYAn7jnE/z0np+mJLdkzmPbh9oXfO1YPEbTQBP/eu5fneYlO8p3sLti94xjNxVtch43DzYveG0RERGRlbAaMm3/AHzTGPPnwPXUJ6y1T2dnSCKSSQX+AraXbedy32UC3gD7q/cveI7LuLi97nYO1h6kd6yXSCyCy+ViYHyAr5z4CpDItM1nPDLOF178wpSySpdx8dadb511mY7GkkZeansJgFPXT/HQ1oe0nIeIiIhk3WoI2v7b5L9fm7bfAu4VHouILJP37n0vp6+fZkvpFgK+QNrnuYxrSglknjfPedwx3IG1ds7A6tnmZ6cEbAB3bbqLqvyqWY/fXbEbn9tHOBame6yb9uH2KQ1KRERERLIh6+WR1lrXHF8K2ETWkXxfPndtnjtgSleBv8BZgDscC88IypLGI+McaznmbO+p2sPP7P0ZHtn5yJzX9nv83FZ1m7OduqaciIiISLZkPWgTEVkMYwy1hbXOdvvw7PPaXmh9wWntXx4o5+f2/Rz7a/bjds1/PyjZ1RLg5PWTRGKRDIxaREREZOmyXh5pjPnduZ6z1n52JcciImtDXWEdF3svAomFsA/UHJjy/Gh4lOebn3e2H9j6QNrruTUWN1KSW8LA+ADjkXHOdZ9jX82+jI1dREREZLGyHrQBD03briWxAPazgII2EZmhrrDOeXys5Rjne87TUNxAY0kjdYV1fOvstwhGEss+luSWpNX4JMkYw6HaQzx+5XEAnrz2JLdV3zZv0Nc71ss3z3yTopwi3n3bu/G4VsOvVhEREVkvsv7Jwlo7PWjDGPMJoHDlRyMia8Gm4k14XB6i8SgAA+MDDIwPcKLzxJTjjDG8bffbFiyJnO7OTXfyTNMzhGNhuka7OHn95IxsXqpHLz7qLBGwvWw7t9fdvqjXExEREZnPap3T9v8CH8/2IERkdcr35fNz/3/2/ju8zey88//fBwTYexMpUiwSqTLqdUaa6vGMxy12Etux144dx4ntJM46+WY3my357aZuSTabsk7WLc7YcY8de+LYnt6L6qh3UixiETtIsBPE+f0B4BFAgk0iCZD6vK6Ll/BUHBRSz/3c59xnx4eoKajBk+SZcb+f3fKzMedjm8/5762811l+tu5ZJgOTMfcdHh/mcvdlZ7mup27BzyciIiIym7hn2mZQDaTEuxEikri2FG9hS/EWJgOTtPvaaehroLGvkSZvE2P+Md6+8e3sK993y+e/r/I+Dl8/zMjECH0jfZy5cYbda3dP2+9cxzkCNuAs1/fWzzoNgYiIiMhCxT1oM8Z8ZcqqDOCtwHfj0BwRWWGSXEmU55RTnlPO/VX3Y60lYAML7hI5VaonlYMVB3m+/nkAmr3NMYO2qV0yh8aH6BjsoCSr5LaeX0RERCQsEbpHmik/HcDvAL8Zz0aJyMpkjLntgC1sXc4653HHYMe07X0jfc5Ytkj1vfWL8vwiIiIikACZNmvtL8e7DSIisUROBN451Dmt2+OxlmPO48jCKPU99VFj4kRERERuR9wybcaYrcaY/zTDtv9ojFl49QARkUWUnZJNijs4vHZkYoTB8UFnW9tAG680vuIsP7T+IedxQ1/DjIVLRERERBYqnt0jfxfonmFbJ/AflrEtIiLTGGNYk3Ez2xbuIjkxOcH3zn3PKUBSkVvBg9UPkpeWB8D45DjX+68vf4NFRERkVYpn0HYf8E8zbPs+8OAytkVEJKaizCLncThoe67+OeexJ8nD+7a+D5dxsT5/vbNvY1/jsrZTREREVq94Bm3F1lpvrA3W2n6gKNY2EZHlFDmurWuoi8a+Rl5tetVZ9/bat1OYUQhAVV6Vsz5WgRIRERGRWxHPQiRDxph11tppfYiMMeuAkTi0SUQkSlHGzftHLf0tzjxsADUFNdy97m5ne2VupfO4ydtEwAZwmUQo0isiIiIrWTyvJl4GfmuGbb8JvLh8TRERiS0y09bua6d3uBeAVHcqP7/156OqSean5ZOVkgXAmH8s5jQBIiIiIgsVz0zbnwKHjTH5wNeBVqAM+AjwQeBgHNsmIgLcrCA55h+LWv/uze8mJzUnap0xhsrcSs51nAOgqa+J0qzSZWuriIiIrE5xy7RZa88A7wQOAc8CF0L/3gu8y1p7Nl5tExEJm1pBEmBr8VZ2le6KuX9l3s0uko3exiVsmYiIiNwp4jq5trX2RWCzMaYGKAY6rbV18WyTiMhUxZnFNPc3A5CRnMF77npPVLfISFW5Vc7jpr6maRNyi4iIiCxUQoyQt9bWWWtfV8AmIolo65qtALiMi5/f+vNkJmfOuG9JVokzIffA2AC9I73L0kYRERFZveKaaRMRWQk2Fm7ktw79Fi7jcsr7z8RlXFTkVnC1+yoAT115in+z899My7apsqSIiIjMl4I2EZF5KM4snve+hyoOOUHb+c7zPHX1KZKTkukd7qVnpIfe4V6GJoaoLajlI7s+gtulP8UiIiIyM10piIgsso2FG7l73d0cuX4EgFcaX4m535XuK5y5cYY9a/csZ/NERERkhVHfHBGRJfD2jW+nMH32rpQArza+6kzWLSIiIhKLMm0iIksgOSmZj+7+KE/XPQ1AQVoB+en55Kflk5GcwReOfoHxyXE6Bju40n2FTUWb4txiERERSVQK2kRElkhhRiEf3vnhmNv2le3j9ebXgWD3yY2FGzU1gIiIiMSk7pEiInFwqPKQUz2yoa+B5689H+cWiYiISKJS0CYiEgd5aXnsK9vnLD9f//yMBUtERETkzqagTUQkTt61+V3UFtY6y09eeZKG3oY4tkhEREQSkYI2EZE4cbvcfHjnh6nKq3LWff/89xnzj8WvUSIiIpJwFLSJiMRRclIyH9z+QdI8aQD0jfTxo4s/ImADcW6ZiIiIJAoFbSIicZadms3PbP4ZZ/lk+0m+dOxL9Az3xLFVIiIikigUtImIJIAdJTvYWbrTWW72NvNXr/0V3z37XdoG2qL2DdgAXUNdTAYml7uZIiIiEgeap01EJAEYY3j/tvdTlFHE8/XPE7ABAjbA6fbTnG4/TU1BDQ9UPUBeWh7fPP1N2n3tZKVkcaD8AAcrDjrdK0VERGT1MdbaeLdhVTDGVAENDQ0NVFVVxbk1IrKStfS38PTVp6nvrZ+2zWVc08a7VeRU8Om7P71czRMREZHb0NjYSHV1NUC1tbZxPseoe6SISIIpzynnE/s+wW/c/RtsL9mOMcbZFqtASXN/M91D3cvZRBEREVlGCtpERBJUWU4ZH9rxIX7n3t/h7nV343F5AMhOyeaT+z8ZNcfbuY5z8WqmiIiILDGNaRMRSXD56fm8Z8t7eOuGt9LS30JVXhUp7hR2je7iavdVAC50XuCh9Q/Ft6EiIiKyJJRpExFZITKSM9hUtIkUdwoAmwo34TLBP+OtA614R7xxbJ2IiIgsFQVtIiIrVJonjQ0FG5zl853n49gaERERWSoK2kREVrCtxVudxxc6L8SxJSIiIrJUFLSJiKxgW4q3ONUlG/sa6Rvpi3OLREREZLEpaBMRWcEykzOpKahxlk+1n4pfY0RERGRJKGgTEVnhdpfudh6fbDuJtTaOrREREZHFpqBNRGSF21K8xako2TPcw/X+63FukYiIiCwmBW0iIitcclIy29Zsc5ZPtp2MY2tERERksSloExFZBXavvdlF8lT7KXxjvmn7HG89zvfOfo92X/tyNk1ERERuk4I2EZFVoCq3ipLMEgDGJ8d5qeGlqO3dQ9388MIPOdl+ki8d+xJN3qZ4NFNERERugYI2EZFVwBjDo7WPOsvHWo5Flf9v9DY6BUrG/GM8fuJxWvtbl72dIiIisnAK2kREVolNhZuoyKkAwB/w83z98862toG2qH3HJ8d5/trziIiISOJT0CYiskoYY3hb7duc5ZPtJ+kc7ASgfWD6OLauoa5la5uIiIjcOgVtIiKrSHV+tTPZtrWWZ+ufJWADMYuP+MZ8mtNNRERkBVDQJiKyyryt5ma27XzHeU62nWQiMAFAdko2HpcHCHaRHJ8cj0sbRUREZP4UtImIrDJlOWVsXbPVWf7XS/96c1t2GVmpWc7ywNjAsrZNREREFk5Bm4jIKvRozaMYYwCismlrs9eSnZLtLA+MKmgTERFJdAraRERWoaKMIvas3TNt/drstWSlKNMmIiKykihoExFZpR5e/zBulztq3dqs6Eybb8y33M0SERGRBVLQJiKySuWm5XKg/ICznJGcQVZKVnT3SGXaREREEp6CNhGRVezB9Q863SG3rdmGMUZBm4iIyArjnnsXERFZqTKTM/nMPZ+he6ibyrxKgKgxbeoeKSIikvgUtImIrHJZKVlRgZqCNhERkZVF3SNFRO4wUdUjRwew1saxNXeGwfFBBscH490MERFZoZRpExG5w6S4U0hxpzDmH2PSTjI8MUxGcka8m7VqNfQ28A8n/gFjDJ8+8GnWZq9d0PEBG+Ba7zXy0/LJT89folaKiEgiU6ZNROQOpGIky8Nay0+u/IRJO4k/4OdE24kFn+OZumf4hxP/wOcOf47uoe4laKWIiCQ6BW0iIncgzdW2PK50X6FtoM1ZbuxrXPA5zrSfAWDMP8Zz9c8tVtNERGQFUdAmInIHUqZt6VlrefHai1HrOgY7GJkYmfc5+kb68I56neUzN87Q7mtfpBaKiMhKoaBNROQOFFVBclSZtqVQ31tPc39z1DprLU3epnmfI1Zm7tm6Z2+3aSIissIoaBMRuQNlpUZUkFSmbUm8cO0F57HH5XEeN/XNP2hr6GuYtu5S1yWNbRMRucMoaBMRuQNFdo9s87Wp7P8ia+hrcLJkLuPibRvf5mxbyLi2yKAtMznTedwy0HLbbRQRkZVDQZuIyB1obdZajDEAtPS38Hrz63Fu0eoSOZZt99rd7CzZ6Sy3DLQwPjk+5zkGRgfoHe4Fgpm63Wt3O9s6fB2L11gREUl4CtpERO5A+en53F95v7P81JWnoqocyq1r9jZT11MHgDGGB6oeICM5gzWZa4DgvGvXvdfnPE9kRm5d7rqo+d1uDN5Y3EaLiEhCU9AmInKHemvNWynLLgNg0k7yo4s/UjfJRRA5lm1nyU4KMwoBqMqrcta/3PjyrO91fU99VHn/6rxqJ+gD6BzsXMQWi4hIolPQJiJyh3K73PzC9l/A7XID0NzfzJXuK3Fu1crW2t/qvIfGGB5a/5CzbV/ZPqdLal1PHWdunJl2fPdQN18/+XW+cuIrdA/fLDayoWADhemFJJkkALyjXkYnRpfwlYiISCJR0CYicgcrzChkX/k+Z/mZumeUbbsNLza86DzetmYbRRlFzvLa7LUcXHfQWf7x5R8zPD4MwMjECD+5/BP+5vW/4WLXRWcfT5KHt298OxU5FSS5kqLO1zGkcW0iIncKBW0iIne4h6ofckrSt/vaudB5Ib4NWoGstRy9fjTqvXuo+qFp+z1S84hTuXNofIijLUdp97Xzl6/9Ja81vcaknXT23b12N79z7+9wf9X9ToZuTZa6SIqI3Inc8W6AiIjEV1ZKFvdU3MMrja8A8Fz9c2wp3oLL6L7efPgDfr725teo76131t1VfBclWSXT9k1xp/Bo7aN8/9z3ATjZdpIr3VcYGh9y9qnIreDdm95NWU7ZtOOLM4qdxypGIiJy59D/yCIiwv1V95OclAxAx2AHZ2+cjXOLVo7jLcejArb89HzeuemdM+6/bc02UtwpAHQPd9PkDU627TIuPrjjg3xq/6diBmxAVCCosv8iIncOBW0iIkJGcgaHKg85y8/VP0fABuLYopXjas9V5/Hesr189uBnyUvLm3H/5KRktq/ZPm39zpKd7CjZ4XSFjCWygmTHYIfGH4oIbQNtXO2+qr8Hq5yCNhERAeC+yvtI86QB0DPcw8m2k3FuUeKbDExyrfeas/xA1QN4kjxzHrenbM+0dfdW3TvncbmpuU5GdHhimMHxwQW0VkRWmxu+G/zt4b/l8Tcf50TbiXg3R5aQgjYREQEgzZPGvZU3A4cXrr2AP+CPY4sSX3N/M+OT4wDkpeVRkF4wr+Mqciqi9q0pqKE0q3TO44wxUV0kL3ddXmCLRWQ1ieyaXd9TP8uestKtiqDNGJNrjPmuMcZnjGk1xvzGLPv+oTGmxRjTb4w5bIy5J2JbsjHmC8YYrzGmyxjzR8vzCkREEsOhikNkeDIA6Bvp40Sr7tzOJvIiqaagZtaujZGMMTxQ9QAQnC/vLevfMu/n3LZmm/P4zbY3532ciKw+wxPDzmPfmC+OLZGltiqCNuBzBCthrgXeBfyhMWba/4DGmF8APgW8BcgDvg38wNz8X/a/AjuAGmA/8GFjzC8vffNFRBJDijuFB6ofcJZfvPYiE5MTcWxRYosM2jbkb1jQsfvK9/Gr+3+VX7v716jKq5r3cTtKdjiVPZu8TXQPdc9xhIisVuG5HkFB22q34oM2Y0wG8AHg9621PmvtKeArwCdi7F4NvGKtvWqtDQD/AJQAhaHtvwz8sbW221rbCPzFDOcREVm1Dqw7QFZKFgADYwN8+8y3dTEQQ+9wL9cHrgPBzNlCgzaA6rzqeXWLjJSVksXGwo3O8qn2Uwt+XhFZHSKnC9EY19VtxQdtwEbAWGsjZ4M9BWyLse+3gRpjzGZjjBv4JHDcWttljMkjmKk7Pdd5Qt0xqyJ/gPJFeTUiInGWnJQcNTH0pa5L/PXrf01rf2vc2pRIxifH+eqbX+UvXv0Lp1rb2qy1pCenL1sbdq/d7Tx+s+1Nuoa6lu25RSRxDE3cDNpG/aPqGbGKrYagLRMYmLLOC2TF2PcG8ApwARgFfpebmbTM0L/98zjPbwMNU35eWWjDRUQS1YF1B7h73d3O8sjECIevH45jixLH5a7LXOm+ErVu65qty9qGzUWbnUqf/aP9/M3rf8MTF55QRlTkDhPZPRKUbVvNVkPQNghkT1mXA8T6n+u/AfcAlUAq8O+BJ40x2aHzMOVcM53nrwh2tYz8uf/Wmi8iknhcxsV7tryHX9j+C866toG2OLYocfSN9DmPizOK+dm7fpb7q5b3vwC3y807Nr7DWQ7YAEdbjvIXr/4Fz9U/x5h/bFnbIyLxEZlpA41rW81WQ9B2BbDGmC0R63YB52LsuwP4rrX2urXWb639RyAF2GGt7QPagJ1zncda67XWNkb+AC2L8mpERBLI5qLNzuPOoU51vSH6omhP2R72l+93CoMsp71le/nMPZ+JGks3MTnB8/XP8xev/gWXui4te5tEZPlYa6OqR4KCttVsxQdt1toh4HvAHxtjsowxOwh2efxKjN2PAO83xpQYY1zGmA8DGQQDP4DHgd83xhQaYyqB35nhPCIid4QUd4ozn1jABugY7Ihzi+Kvf+xmL/rslKkdPZbX2uy1/PLeX+aX9vxS1PxtQ+NDfPu0CsiIrGYjEyPOuNowdY9cvVZ80BbyGcAC7cCTwB9Ya18wxlQYYwaNMRWh/f4MOA68SXC82n8AfsFa2xna/ocEM2v1wAngO9baf1i+lyEiknjWZq91HquLZPSd7HgHbRCsXLmxcCOfueczvH/b+8lMDg7RnghMcLbjbJxbJyJLZWrXSFDQtpq5492AxWCt9RIs+z91fTM3C4xgrR0D/m3oJ9Z5xoFPh35ERIRgZcSzN4IX/20+BW2RQVt4aoRE4DIudq/dzcTkBE9cfAKAs+1nOVRxKM4tE5GlEFnuP0zZ9dVrtWTaRERkiSjTdpO1loHRmwWLEyloC9u2Zpszxq65v5ne4d44t0hElkIiB23WWobGh6Z135Rbp6BNRERmFTn5c8dgB5OByTi2Jr6GJ4aZtMHXn+pOJcWdEucWTZeenE5NQY2zfObGmTi2RkSWytQiJJA43SN/euWn/PcX/ztfP/X1eDdl1VDQJiIis8pIziA3NRcAf8BP51Dn7AesYgNjN7NsiTCebSY7S28WQj5z44zudousQomaaese6ub15tcBuNR1Kap3gtw6BW0iIjIndZEMirz4yE5N3KBtS9EWPC4PEMyOqvz/4vCN+bjYeVHz4ElCiBW0DY4Nxv0mzcuNL0e1IVGyfyudgjYREZnT2qybQduxlmMEbCCOrYkf33hEEZLkxBvPFpbiTmFv+V5n+ckrT97R3VoXw8TkBF84+gW+furrfOfMd+LdHJGY3SMn7SQjEyNxaE3QwOgAp9pORa1LhOzfaqCgTURE5rStZBtJJgmA6/3XefHai/FtUJxEFSFJTdygDeDh9Q87Y+66h7s51nIszi1a2S52XqRvpA+Ay92X6Ry8c7sJS2KIVfIfom8uLbfXm193xv2GKdO2OBS0iYjInIoyinh4w8PO8gvXXrgju0km2hxts8lIzuCh6oec5afrnqahtyFu7VnpTrafjFp+s+3NOLVEJGh4/GamLdwdGoJdJONhZGKEI9ePTFsfqxunLJyCNhERmZcHqh+gMrcSgIAN3JGZm5VSiCTsYMVB8tLyABjzj/H4m49rfNst8I35uNpzNWrdm21vqsupxFVkMFScWew8XuxM28TkxLzGyR25foTxyfFp65VpWxwK2kREZF5cxsVbN7zVWW7sa4xfY+JkpQVtniQPH939UWc+OX/Az7fPfJvuoe44t2xliVWBc2h8iB9f/jGvNL6iTILERWT3yDWZa5zHc2Xa+kf75x1IXei8wJ++8Kd87o3PzTrn48TkhFMxEmB9/vqb7dTvx6JQ0CYiIvO2LnedM7atc6jzjruDulKqR0Zak7mGT+3/lJNxm5ic4HvnvnfHFpOJZWRihDM3zsz4fT7ZdrNrZEF6gfP4yPUjPHnlSb587MuqKCnLanxynInJCQDcLnfU93K2v8v1PfX82ct/xp+99GfzGpf5SsMrTAQmuDF4g7878nfOuM6pTraddIKznNQcDlUcmld7ZP4UtImIyLwlJyVTllPmLDf1NcWxNctrMjDp3Nk2xpCZnBnnFs1ffno+H975YVwm+N/+9f7rPFv37Kxdnl649gL/78j/40r3leVqZlxMBib58vEv850z3+HzRz4/LfgaGB2g3dcOBC+OP7TjQ877GNY51Mn3z38/7qXW5c4Rmb1K96Q72XSYvVpjeGzmpJ3kfOf5WZ/DH/DT3N/sLI9MjPD4icendQsO2AAvN77sLN9beS85qTnOsoK2xaGgTUREFqQqr8p5fCd1kRwcvzn/UYYngyRXUpxbtDBrs9dGFZN5qeElvn3m24xOjE7bt3e4l2frnqWlv4Vvnv7mqr7oOtpylBu+GwD0jfRNq4waDtgg+B6uzV7Lh3Z8iB0lO9hest3Zdr7jPK80vrIsbRaJLEKSnjz/oC2ya3T/aP+sz9Hh65h+/HA3Td7om3XnOs45Gbg0Txr7yvZF3dSKV2GU1UZBm4iILEh1XrXzuKHvzqlGGHkhFHmBtJI8WP1g1FiTcx3n+NsjfzutEmjLQIvzeGJygufqnlu2Ni6nkYkRnq9/Pmrdq02v0jXU5SxHBm2lWaUAbF2zlQ/u+CAf2vEh7l53t7P96bqnqeupW+JWy61qG2jjr177Kx5/83H8AX+8m3NbIsezZSZnRgdJM9xksdbSOXSzS6R31Dvrc0T+HYgU+bfQWsvLDTezbAcrDpLiTiE9OT2qrcpC3z4FbSIisiCVuZUYYwC4MXgjZqZmNYoMbCK7/qwkLuPiY7s/FhVo9A738oWjX+Bw82HnwiqceQo71npsVU7x8FLDS9MmKA7YAP966V+d92Jqpm2qd256JxW5FUDwAvY7Z74z47gfia9vnfkWXUNdXO2+yoWOC/Fuzoyudl/lhWsvRGXTIvWN9PHTyz91ljOSM+aVafON+aK6/0aO0Y2lpT920BYZFNb11Dm/Ix6Xh3vW3QMEuxKnedKA4O/FTHPKyfwpaBMRkQVJcaewNit48WqtndZVZiWo66njXy7+C8/UPcObbW/OWUQiYAO82vSqsxyZrVppPEke3rPlPXxwxwedybf9AT8/uvQjvnP2O4z5x6YFbdZafnL5J6vqbnnvcC9vNL/hLD9Y/aBzM6Kup84Z7xOVacssnXYet8vNh3d+2LloHp4Y5hunvuEUiZD4GfOP8Vz9cxxuPszIxEhU9cO63sTMiA6MDvC1k1/j2bpn+eGFH07b3trfyuePfD4qY7Zn7R4ykjOc7+/wxHDMTGJkBhnmkWmLCNpqC2udx5FBW+Tv0N7yvWQkZzjLkdk/VZC8fQraRERkwSLHta20SYa7hrr46ptf5cj1I7x47UW+f+77PHHxiVmPOddxjp7hHuDmmI2VbkfJDn7j7t9wuvwBnL1xlu+d+x43Bm9M27+hryGq658/4OdS1yW+d/Z7fPPUN1dcdunpuqedC9uKnAoerXk0KgP5k8s/wTfmcz53l3FFzYUVKSsliw/v/LBTWbXd184TF55YVUHuSvRq06s8X/88P7r0I7595ttR2xI1qG7ztTmVXc93no8KkC51XeJLx7/krHO73Hxw+wepKajBZVxkeG4GTLGCpMhAD4JB7Uw9Jcb8Y3QNB4M8l3FRW3AzaIs8d5vvZgY+nGULiwzgNK7t9iloExGRBdtZstN5fK7j3IzdaJbaxc6LfOnYlzjeenzexzxT98y0cvcXOi7MOMbFWstLDS85y3evu9vJUK10hRmFfPrAp6OClQudF5wCBW6Xm/3l+51tz9Q9Q0NvAz+88EP+10v/i388+Y+cbD/J+c7zfPfMd5e9/beq2dvM2RtnneW3b3o7xhge2fCIc6HZP9rPP539J2efoowiPEmeGc9ZkVvBuze/21k+2X6SE20nlqD1Ml9Hmo84j6eONQwH44lm6t+hczfOAXC4+TBfP/V1J9hM86Tx8b0fZ0fpDmffubpITs20wczZttaBVuemQ3FmsTNlCNwM2iYmJ5zncRlX1LQDoEzbYlPQJiIiC1aWU8bWNVud5aevPr3sWYXB8UG+c+Y7NPY18oPzP6C+p37OY1r7WznfcbPMdao7FYCJwATX+6/HPOZK9xWnu6DH5eFgxcFFaH3iCHeX3JC/Ydq2NZlreHj9w3hcwWCldaCVLx//Msdajk0bC9bc30yzt3naORLNyMQIT1y4mVndtmYblbmVQPBC+G21b3O21ffe/E5FZiRnsr98P3vL9jrLJ1oVtMWLtZZhf+wxYRCsgpiImdBRf3Tm63T7aZ688iQ/uvQjp715aXl8+sCno4pCAWSmzF6MJLJyZNhMFSQjb8Sty1kXs9BJ5LE5qTnTpsKIbI9vfOaKljI/CtpEROSWvK3mbc5/0vW99TGr5rX0t/B3h/+Or5/8+qJ3R3qt8TUmAjfP+YMLP5hzbNrTdU87j7eu2cq2Nduc5Ybe2JUwI+cf2l++f0XNz7YQdxXfNW1dSVYJ2anZMwaquam5lGSVOMuR4/4S0Zh/jK+d/JrT/dPtcvNY7WNR++xdu5d1OeumHRurCMlUxhgerH7QWZ6rpLosnZ7hnlmDsjH/WEIWx5j6N6y5vzlqKonynHI+feDTFGUUTTs2K3n2TNvU7pEwv6CtPLs8qqtjOGsW2SU6NzV32jkyPXNXtJT5U9AmIiK3pDCjMCqr8NTVp6IuksJjx1oHWrnYdXFRsw5D40Mcvn44al3fSB9PXX1qxmPqe24GlsYYHq15NKqgSKzpCxr7Gp256JJMEvdV3bcIrU9MMwVtAPdX3e90fcrwZHD3urv55P5P8u/v//e8f9v7nf0vdF6IKvaQaH5y+SdR2cD33vVe8tPzo/YxxvAzm3/GKeoQVpJZwnxkp2Q7j31jvmldcWV5zKfaaazMU7xNzbRF2lK0hU/s/cSMU45EZbamBG2jE6MxA7mZukdGlvsvyymbNu+atTbq2Ny03Fnbo+6Rt09Bm4iI3LLIrnPtvnZnnJBvzMdX3/xqVBe6S92XFu15X29+nfHJcQCnrDTAsZZjMbNt1tqoLNuetXsoyiiK6l7U7G2elg2MHMu2s3Tnii31Px/ZqdnTMkzhLoHpyen8xt2/wWcPfZbfe/D3eM+W91CVV4UxhtKsUmoKaoDg+/zExSeczyaRWGs513HOWX7npneyZ+2emPuW5ZSxv2x/1Lr5dI+EYHfTdE9wjqqADehidQlZa7nYeZHzHeenBceRBTKKMopIMklkJmc60zNAYo5rm6m3wMGKg3x414dnHU8bGcxNzWzFyrJB7EzbwOiAs96T5GFN5hqSk5Kdv/UTgQnGJ8ejMm2RY97CNMH24lLQJiIityw7NZtDlYec5XBFvufqn5tWTbCht2FRLuZHJkaiyky/Z8t7nIxQwAZiTkFwseui093H7XLz8PqHnfYXphcCwQIAkV2C2gbauNJ9BZje7W21mppti8wupXpSWZO5hiRX0rTj7q+633lc11PH4ycep8nblFBZppGJESeL4UnycKji0Kz7P1rzqNMlrCy7LGqy4Llkp97Mts01F5bcuvOd5/n6qa/zzdPf5EtHv0Tn4M3AJDLT9kjNI/yHB/8Dv3Pf70SN3eweXp5M22Rgku6h7nlN6D0105bmSeNdm9/Fuze/e9qYsalmC5Iii5CEbypA7KCtdaDVeVyWXYbLuDDGTBszF5Vpi9E9Mqp6pLpH3jZ3vBsgIiIr2/1V93O05SgjEyP0jfTxauOrnG4/PW0/f8BPQ28Dm4o23dbzvd78unM3ujijmG1rttHkbXKKhTR5m9hYuNHZP2ADPHP1GWf57nV3R3Xlqc6vdi7ervVdozo/mH2LHMt2V/FdFGYU3la7V4K7iu9yupgWphdGZTFnU1NQw1s3vJXn6p8Dgp/BF49+kYzkDB6sfpAD5Qdmrby4HHpHbnbbLEgrmNb9car05HQ+feDTXOm+wtbirbPuO1V2SrbzfRwYG6CMsoU3WOZ05sYZ53FzfzN/e/hveXjDw9xXeV9Upq0s+2b3vsgKh8uVafvaya9R11OH2+VmXc46qvKqqMqrYl3OummZs8ig7YM7Psj2Ndvn/K6GzVQ90h/wc+T6zUqaGwo2OL0iYnWPjCzKFJl9z0jOcG7GDY0PLSjTpozz7VOmTUREbkuaJy0qC/VM3TNORm1N5pqoLMzl7su39VyjE6O83vS6s/zQ+odwGRdVuVXOuqa+6EzbqfZTTtegFHcKD1Q/ELV9fd76qH3H/GN0D3VHdaV7qPqh22r3SlGYUci7N7+b6rxq3rPlPQs69uEND/POTe+MWjc0PsRPLv+Ev379r2OWG19OkWPtpo5jm0lBegEHKw5GZc7mI3Jcm4qRLI2ADXCt91rUOn/Az9NXn+ZvD/8tIxMjQPDvU2QWKCpoG1r6oG14fNgZS+sP+Gnoa+CFay/wDyf+gT954U/44tEvRmX4I7tHprpT5x2wwZRCJBHVGp+re87Jnrldbu6vvPk3eWB0YFrBlsj2lGXfvOEwdR4474jXWZ5Ppi0Rq3WuJAraRETktt2z7p6Y470OlB9gU+HNzNqV7isL+o/bH/BzpfuK08XsjetvOHeiC9ML2V6yHYie7Lulv4Ux/xjN3maGx4d5ru45Z9t9lfdNq/5YU1BDclIyELyw/9657/HCtRecdtYU1MyrcuBqcbDiIL+6/1fZUDB9CoC53Ft5L7+6/1fZV7Yv6n3uG+nj++e+H9eLtp6Rmxfo+WnzC9puVVT3yDF1j1wK7QPtTmCW4cmICi46Bjucx2uz1kYFPuHu0DB3hcnFMFthkXB37h9f+nHM/cNTksxX1Ji2ULGQup66qF4Db6t9G2U5ZU4XyUk7GdV10VobVYSkPKfceRzZPdI76nW+28aYmH//U9wpzt9Wf8A/63shc1P3SBERuW2eJA9v3fBW/vn8P0et21W6C0+ShxR3CmP+MfpG+ugc6mRN5pp5nfcH53/AqfZTZKVk8cn9n4zKsj24/kFnjEdWShb56fn0DvcyEZjgj57/IyA44Wt4XFWGJ4N7K++d9hzpyen83F0/x3fOfgcIVkCMdKdk2RZLdV411XnV+AN+jrUc48krT+IP+Lnef53TN06zq3RXXNp1K5m2W5WTcvMCVmPalkbkHHq1hbW8b9v7eKXxFZ6vfz5q7NjUGy7pyemke9IZnhhmIjDBwNjAkhYYigxUCtILeKTmEacqbTi4jOy6Ozpxc//Zio7EEi4WMhGYYCIwQe9I8CZUWG1hrTOWMzs12ykU1T/a7wR83cPdTrYvIzkjKoMWmTlr7b857i0nJSfmWFcI/m0Od0P1jfnm3eVaplOmTUREFsXutbspzih2lneW7CTVk0qSK8mpLgjEnM8tls7BTk61nwKC/9l/+diXnYuMvLQ8dpbsjNo/sotkWGQhjAfXPzjjRdCO0h0xC1NU5FZEZfFk/twuNwcrDkYVqnnqylNzzqW3VCIvjJc60xaZ8VCmbWlEBm3r89fjMi4erH6Qz9zzmahxWFuKt0w7NjLbdrj58JJm28Ymb37fM5Mz2VGyg/dseQ+fPvDpm/tE/E5E7r/QTNvUYiHfOv0tZ2xbRnIG79v6PifrGBmMRd7QmDqpdmSWMjJ7HlmsJFa5/7DIgFhdhW+PgjYREVkULuPiZ7f+LKnuVDKTM6PGudXk3wzaZprEGoJdczoGOxjzj/Fa02tR2yIvfh9a/9C0O7uVeZUznjcvLY8D5Qdmbf/bN76dvWV7yUvLoyy7jF2lu/jAtg8saEyJTPdQ9UPOxd7A2EDMCbgHxwf5x5P/yDdOfWPJ5nlbzkxbZPdIXaguvonJiaixq5E3hYozi/nUgU/xsd0f45P7P0ll7vS/C+sLbo5jfbnxZb5//vvzqux4KyIDssibRslJyU5PgYnAhPP8t9M9EqJvGLT72p3H79v6vqhtkWP7nq57muHx4A2xyCIk5dk3u0ZCdKYtcgqBvNTpRUjCosZ3jul34Xaoe6SIiCyaytxK/tND/4kkkxQV7IQrMgI0ehsJ2MC08tUdgx08ceEJmrxNpLpTZ7yIykvLi9nFbmqmbXvJdnaX7qZjsIOdpTvnrF6Y5Eri57f+/ByvUBYqxZ3Co7WP8oPzPwDglYZX2Fe2L+oO/I8u/ohLXcF5/K71XuP9294fM0NyqyYmJ5yg32VcMYsmLKao7pHKtC26Zm8zE4HgnIqF6YXTuje6jGvWKrUPVD1A60ArV7uvAnCy7SS+MR8f3jn7PGi3YqagzRhDijvFGZc36h8lzZ3mzBVpjHHGgy1EZDGSsEMVh6a9HwfKD3C89bjTbf07Z7/DL+35pehy/znRVU+njgcOmy3TFnkDwzc6fXJvmT9l2kREZFG5Xe5p2anC9ELnP/yRiRGnHDrA+OQ4T119is+98TlnjrVR/6gTtE0tJf1A1QO4XdPvORakFziD5vPT83nvlveyqWgTD1Q/sKonxV4J9qzd40xOPRGYcKYVgOD0AJGVOkf9o3zj9Ddo9jbHPJdvzLfgrEhk18ic1JnH3yyWNE+aMxHx+OR43LqErlaRXaxvpWBOijuFj+76KHvL9kad84vHvrjoYxCnVoOMFLk8OjEaHeAlpdxSlj+yeyRASVYJb6t927T9CjMK+cC2DzjLdT11nLlxhvaBm9m52TJtkWYN2pRpWzQK2kREZMkZY1iff7NLUrhU95XuK/zN63/Dyw0vzzgR89tq3uZMG1CRU8Gesj0zPsdHd3+Uf7Pz3/Cb9/ymBrwnEJdx8a7N73KWT7efptnbjLWWn1z+ibM+fJFqreV46/Goc1hrea7+Of7s5T/jz1/+8wVN1hvZNTKyW9hSMcaQlXoz46EukosrPOk9EDUn40IkuZL4ubt+jkc2POKsu+G7weePfj6q+uTtiuzumJIUncWLDNrG/GO33TUSojNtHpeHD27/4Iy9DLYUb4kay/tKwytM2kkg+HsydUL5mTJts3WPjLxhpqI8t0dBm4iILIvIoO1C5wW+febbfPXNr0ZN0FqRW8Gv3/3r3F91PynuFLYWb2VbyTYeq32M33vg9/iV/b8SM8sWlpmcybY12xa9i5Pcvuq8arauuTlJ9Y8v/5gTbSecwgdul5tf2PYLzvbLXZedAhEBG+CJi0/wfP3zBGyAwfHBqImV57KcRUjCIjMM6iK5ePpH+7kxGMzUu11uqvOq5zhiZsYY3rLhLfz81p93umv3j/bz5WNfXtBNgdlEFhaZ+ncpKtPmH12UoK22sBaXcWGM4d1b3k1xZvGs+28r2eY8Dr+vEF3qPywjOWNa9s/j8jhZ9FiUaVs8GtMmIiLLIvLiKtwNMizNkxYsBLJ2L8YYynPKeaz2sagLhIVOcCyJ5+21b+dy12X8AT8t/S1R42cOVRxiW8k2/vXyvzI0PsTg+CAt/S2UZJXwT2f/ifOd56PO1djXGLPiZyzhkuOw9EVIwmJVzesb6cM35ptWlU/mLzLLVpVXtSg3aPaW7SU7JZtvnfkWY/4xhieGOdZyjLesf8ttn3umMW0wPWhzuW7mUpLdCx/PBsFg67cO/RaTdnJeU6uUZ5eTnJTM+OR41PrIee/CXMY1rdLmQ+sfmpaRi6RM2+JRpk1ERJZFQXpB1F3XsN2lu/nte3+bfWX7oi5kdVG7+uSn50dNARC+ACxIL+Ch9Q8FC0hETMZ+6sYpvnbya9MCNggGbfMt1Z4Imbbe4V7+7xv/ly8c/QKHrx9eljasRpe7LjuPb7VrZCy1hbW8Z8t7nOWj148yGZi87fMuJGibbfzbQhRmFM57LswkV1LMaU0ip02IFFlAymVc3Fd136znz0jOcI4Znhh2Cq3IwiloExGRZWGMYXPRZme5ML2QT+z9BO/f/v4Zx0rI6hM5BQAEL/w+uP2DzgVt5HfkcPNhZ/wjBLNx6Z7gXf2h8SG6hrrmfL7B8UGue2+WMV+OMW0wZa620QF+eOGHzkX58/XPL0sbVht/wB81P1tkgL8Ytq3ZFjU9RaybBQs1tbhIpBTPzeXF6h55KyK7rkPwd3KmLo/h+TGNMfzq/l+dtbt6+Fyat3BxqHukiIgsm0dqHiHVnUpWahb7y/bPWYZfVp8Udwrv2PQO/unsPwHwttq3RZUWrymowe1yT6sQ+VjtY9xfdT/eUS8XOi8AwWzbXGN2nr76tHMxXJBeMOf+iyWyW1j3cHdU8BmeJF4W5mr3VacbX0F6AYUZhXMcsTBul5sD6w44QfUbzW+wo2THbZ1zIWPakkxSzG1LbUN+dAXOkqySGf82v2vzu1iTtYby7PKYc+DFkpOS43QRHhgbWLYbJ6uNgjYREVk2GckZPLbxsXg3Q+JsV+kuclJzCAQC00q2p7hTqM6vdubQMsbws3f9LPvK9gHBcUzhoK2hr4ED62aeNL3Z28yJ1hPO8rs2vWva/IBLJTJTERmwwfRpLGRufSN9zlx/sPhZtrAD5Qd48dqLBGyAZm8znYOdtxXoz5Y9m1ryP15BW2lWKemedOdmwtRS/5HSPGlONd/5ykrNglANEo1ru3XqHikiIiLLrjqvesY5tu6rvM+ZXPjDOz/sBGzh48JmG9cWsAF+dOlHzvKWoi2zTri82ArSC9havDXmNo3rWZjxyXG+furrDE0MAcGbPwsNHOYrKyUrqovu1Z6rt3W+cf/NAh9TM21p7pvTkkwd07acFXCnTslSkVuxqOePnGx+odNfdAx2cPT6UYbHlZ1W0CYiIiIJpaaghv/04H/i9x74Pe4qvitqW0lWiXNBOzA2wPfPfz/mvFrHW47TNtAGBMuSv3PTO5e+4VO8ZUPs6oOj/tF5F1EReKH+BW74guXok0wSH9n1kSWtJltbUOs8ru+pn2XPuc2WaYsMzKbO07bc05a8dcNbKc0qZUvRFraXbF/Uc0d+VgsZ0zbmH+NLx77EExef4IcXf7iobVqJFLSJiIhIwslIziDVM72LmMu4orJtJ9tO8vkjn3cu6iFYpOTpuqed5QeqH1i2Uv+RSrNKY2bb/AH/tBLrElvnYCevNr3qLL9r87vmPZbqVkVmgBv6Gmjtb+XbZ77NybaTCz5X1Ji2WSbXHvWPRu27nN0jAYozi/nNg7/JL+7+xTmLiyxUZKZtId0j233tjEyMAFDXU3fH3+hQ0CYiIiIryiM1j1CccXOc0fjkOE9dfcpZfqbuGediLy8tb8m60s3HwxseJjlp+pxbkVkVic1ay79c/BcCNgAExzMeKJ95DONiyU/Ld8Ydjk+O86VjX+LsjbP88/l/xjfmm/d5rLVRXR6nzr02bXLtifhUj1xqt5pp6xvpcx6P+ccW9N6vRgraREREZEUpzSrls4c+y8f3fNyZz+9K9xUaehto6W/heOtxZ993b353XKuUlmSV8Ot3/zq/tOeXKMooctaHg0qZ2ZkbZ2joawCCGdaf2fwzyzJ/ozGGmoIaZ3kiEByDGLCBmF1xZxKZTU1OSp5WBCfNEz2mLV4l/5da5JyFCxnTFhm0AXQOdS5am1YiBW0iIiKy4hhjqC2sZVfpLmfdjy//mH+5+C9ON6rNRZujikrES3FmMRsLN0ZdpI/4FbTNZnRilJ9c/omzfLDiICVZJcv2/FPL4If1DPfM+xxzjVGLXDe1e+Ryj2lbSlMzbS9ce2FeXR2nBm3zmZdxNVPQJiIiIivWIxseccbgtPvaaR1oBYJzbr1r07vi2bRpwhODgzJtc3m2/lkGxweBYKbmrRveuqzPvyF/Q8ys3kKCttkm1obpJf8j919NmTa3y826nHXO8rN1z0ZVdp3JYgRtARuIel9XMgVtIiIismLlpuXGvKCPV/GR2USWeFfQNrO2gTYOXz/sLL9j0zuWPfOUnpwes+BJ73DvvM8RFYTFKKrjdrmdudkm7SSDY4M3919FQRvAR3Z9JKqA0JHrR+Ys4+8d9UYtdw4urHvkwOgAf/7yn/M/XvwfHG4+PPcBCU5Bm4iIiKxoD1Q/wCf2foKtxVtJTkqmtrCWB6oeiHezpom8cFchktistfzo4o+c7nM1BTVsX7O4Jejn631b38c9Fffw0PqHnHW9IwsI2mapHAnBLr6R34nw2DlYXd0jITj/3Sf2fSJq0vnr/ddn3D9gA9PGvy10TNsb199gYGyAicAEP7r0I56rf25FV6Bc3JqeIiIiInGwoWDDjJN1J4rI7pHDE7GzDNZazt44y3hgnN2lu0lyJS1X8xLCidYTNPc3A8FM1HIVH4klPz2fn9n8M4xMjPDitReBYKbNWjuvNs2nsEiqO5Wh8aGodR6XZ1V+7i7jYn3+etp97QA0eZtmnPDeO+J1qoaGDY0PMTw+THpyesxjIllrOd1+Omrd8/XPMzQ+xLs3v3taUZiVYOW1WERERGQFisyqzNQ98lLXJb5z9jv84PwPONm+8HnBVrKh8aGoqRvuq7qPwozCOLYoKM2T5gTcE4GJaaXnrbX0jfRNy+JElfuPMe0DxA7mVluWLVJFboXzuNnbPG17/2g/5zvOz1ils2t4fuPaGvsaY1aqbBtowx/wz7O1iUWZNhEREZFlMJ8xbVe6rziPr3uvs69s35K3K1E8ffVpJwOZl5bHg9UPxrlFNxWkFzDcH2xbz3CPUxFxdGKUb57+JvW99dxVfBcf2fUR55io6pGe2IFYrKBttY1nixQ5TrClv4XJwCRJriQCNsAbzW/wzNVnorqJTtU12DWvydUjb3jsL9/P+OQ47QPtfGz3x2YMoBOdgjYRERGRZTCfkv9tvjbn8cDYAP6An8PNhzHGcKjiUNy6Ci61Zm/ztPn1EuniOj893xmD1TPSQzXVDI0P8dU3v+pULL3QeSGq+964/+Y8bbHGtEHsAG0+3f9WqqyULPLS8ugb6WMiMEG7r51UdyrfP//9mJk3CHYXDQdyP7jwA9p8bWQlZ5Gdmk1Oag7ZKcF/wxnKickJznWcc47fs3YP63LWMTIxsqLfWwVtIiIiIssgajLliemFSCYDk9zw3XCWB8YGONV+ip9e+SkQ7GK3v3z/0jd0mfWN9PHExSec5USZXy9SQXqB87h3uBffmI+vHP/KtOIYvnGfExhEFiKZKXsWqytkeXb5YjQ5YVXmVjrl/J+++jTN3uZZs2tV+VVc7b7qLB+5fiTmfjmpOfzC9l9gaHzI6ZpakF7Aupx1GGNWdMAGGtMmIiIisizm6h7ZOdQZNd7GN+bj5YaXneUfXvjhkrZvuVlrefLKk/yfV/+PE6x6XJ6Em18PID/t5vQRDX0NfPHYF2NWMxwYHXAeR83TNsM4tVjBXGXe3N3/VrLIOdvqe+udgM1lXGwp2jJt/63FW+d13v7Rfp6pe4ZrfdduHrtm66rJTivTJiIiIrIMorpHxgja2gbaopaHxoeiAj0IZuhizfm1EjV5m3il8ZWodY9tfCzh5teD6ExbZDc+l3GRm5brzN/mG79ZpCRqTNtMQVuMz3I+Y7ZWslhBaUlWCe/b+j6KM4v5ny/9z6jfjw35G3j35ndT11NHflo+uWm5DI4NMjA2QP9oP/1j/c773+xtjipAsiE/sSvKLoSCNhEREZFlMHVM29TS8ZHj2cIGxgailq/2XGV7SXzmLVts4bFgAGsy1/Azm3+G6vzqWY6In1iBpNvl5kM7PhQVfM6YaZvnmLa8tDyyUrIWo8kJa03mGmdcm8u4eGj9QzxY/SBuVzAsuav4Lk60nnD2z0nN4WDFQQ5WHJzxnJ9743O0+9oJ2IDT9TLJJEVl9VY6BW0iIiIiy8DtcjtFFQI2wPjkeFQGZmqmDWB8cjxq+XLX5YQO2o63HudU2ynSk9MpTC+kMKMw+G964bQxRZFl3feV70vYgA0gw5NBijvFCcQ8SR4+uuujbCjYEDXhdmSmbT5j2qauX+1ZNghmJz++5+Nc6LzApqJNrMlcE7V999rdTtCWl5Y3rznragtrnfnfwspyylbV9AkK2kRERESWSZonjYmx4BiekYkR56IyYANRRUhmcqX7CgEbSMjJgX1jPp648MS0SZHDslKyePfmd7NtzTaAqNdbklmyLG28VcYYthRt4VT7KVLdqXxsz8ecACsyM+YbXWD3yDswaAMozCjkgeoHYm6ryq3i3sp7udB5gbfVvm1e59tYsDFq/CfA+vz1t93ORKKgTURERGSZpHnSnC6PI/4RcskFgnN/Tc2qxTI0McT/ff3/kpOWQ25qLtkp2WSnZrM+b33cx4I1e5tnDNggGNR9/9z3Kc0qJS8tj87Bm4U8pmZbEtHP3vWz7CjZwbqcdVFZw6igLWLi7VuZXDty8uk7lTGGd256J+/c9M55H7Mudx3JSclRv0Pr8xS0iYiIiMgtiFWMxFrL4euH532OzqHOaZULXcbFZw99lqKMosVp6C1oGWhxHm8q3ERpdik9wz10DXXRM9TDRGCC8clxvnfue/zcXT/nVA3MSskiIzkjXs2eN0+Sh01Fm6atz07Jdh5Hdo+MnKdtpuIxLld0xnQlBK+JyO1ysyF/Axe7LjrLqy0AVtAmIiIiskymlv0P2ABPXHgiamLpkswSbgxGd5WsKaihZ7jHKbIwVcAGON9xnofWP7Qk7Z6Plv6bQduesj1ON0iA1v5WPn/08wRsgGZvM/98/p+dbSs9UInMtA2MDjgFZiLHtM1UiGRdzjpyUnPoH+3nYMXBVVOePh5qC2udoK08pxxPkifOLVpcCtpERERElklkxsU35uPbZ77N+Y7zzrrNRZvZW7aXb5z6RtRxG/I38PE9H2doYoj+kX6n3Pm1vmvO8bEKmSyXgA1EVYOcWrWvLKeMh9c/zLP1zwJwvf+6s600q3R5GrlEkpOSSXWnMuofZdJOMjwxTIo7xZlzz2VcTmXEqdwuN589+Fk6hjpW/aTaS21X6S4ONx/GO+rlgarY4+VWMgVtIiIiIsskMtP21NWnosbg7C7dzc9t/bmYkzbnpuZijCEzOZPM5EzKKAOCc16Fg7bIoGm5dQ91O2O4MpMzo7oMhj24/kFOtJ2Yli1c6Zk2CHaRDBceGRgbIIub2bdUd+qsGbRUT+odU4BkKaW4U/jsoc/iD/hXXZYNIPFKD4mIiIisUpFj2iIDtkMVh3jftveR5EqKOU9XblpuzPMVZxQ7WRzvqJfB8cHFbfA8RWbO1uWsixmkuIwr5lxbqyFom1qMZHRi7sqRsviMMasyYAMFbSIiIiLLJjJoC3u05lHeuemdTqCT4ckgyUTPTZWbmhvzfEmupKjuha398cm2RWb5ynLKZtxvX9m+adMVxLN4ymKJKkYy5osq9x/rMxdZKAVtIiIiIsskMiNjjOG9W97LQ+sfispMGWPITr0ZBLhd7pjZt7C12Wudx22+5R/X1jvcS2Nfo7M8dTxbpBR3CjtKdjjLLuNaFZmRqGIkYwNRQdtME2uLLITGtImIiIgsk02Fm6jKq6JvpI93bnpnVIXFSFnJWc7Yr+zU7FnHRJVl38xsLXem7fvnvs+bbW/O2J5YHqt9jKvdVxmaGOLB6geXsnnLJjMl03k8NdOmoE0Wg4I2ERERkWXiSfLwyf2fdMrCzyQrNQv6g4/zUvNmPWdU0LaMxUh8Y75pAVtFTsWc3QGzU7P5t4f+Lb0jvVTkrI65tGbrHqkxbbIYFLSJiIiILLO55uOK7G6Xk5oz677FmcV4XB4mAhMMjA3gG/PN2p1ysbT72p3HmcmZ7Cvfx93ld8/r2KyUrGVp43KJ7M46MDbgVNKE6IqhIrdKY9pEREREEkxJZsnNx1kls+wZHBcWVYxkmbJtHYMdzuO7iu/i0ZpHo4KXO0lW8pTqkZHdIz3qHim3T5k2ERERkQSzq3QXXUNdBGyAfWX75ty/PKec5v5mAJq9zWwu2rzUTaTDdzNoWw1l+2/H1JL/wxPDzrLGtMliUNAmIiIikmA8SR7euemd896/Mq+S15tfB6DJ27RUzYrSPnize+SarDs7aPMkeUhxpzDmHyNgA3hHvM42jWmTxaDukSIiIiIrXGVupfO4tb8Vf8C/pM83GZike6jbWY7sznmnykjOcB73Dvc6j5Vpk8WgoE1ERERkhctKySI/PR+AicAEbQNLO19b93C3ExjmpOZoAmkg03Oz7H/viII2WVwK2kRERERWgchs21J3kdR4tunSk9Odx5GZTgVtshgUtImIiIisAlW5Vc7jpr6lDdpuDN5wHs9V3fJOEdk9MpKCNlkMCtpEREREVoHKvOhMm7V2yZ7rhu9m0FaaWTrLnneODE/soE2FSGQxKGgTERERWQUK0wtJ9wS76A1PDNM11LVkzxU5R9udXjkyLDMlM+Z6ZdpkMShoExEREVkFjDFU5VU5y5e7Ly/J83QMduAd9QLgdrkpTC9ckudZacIBcyS3y40nyROH1shqo6BNREREZJWInFT7zI0zS/IcbzS/4TzeVLSJJFfSkjzPShNrTJu6RspiUdAmIiIiskpsLd6K2+UGoG2gLWoutcUwPD7MqbZTzvLBioOLev6VLNaYNnWNlMWioE1ERERklUj1pLKxcKOzvNjZtuOtx5kITABQmlUaVbHyThcr06b562SxKGgTERERWUW2l2x3Hp+5cWbRqkg2eZt4ufFlZ/lgxUGMMYty7tUgVtCmTJssFgVtIiIiIqvI5qLNJCclA9A11MW3Tn+LnuGe2zrnmfYzfOX4VxiZGAEgKyWLHSU7brutq4knyeO872Ea0yaLRUGbiIiIyCqSnJTMztKdzvL5zvP8zet/w5NXnmR0YnRB57LW8sK1F/jO2e/gD/iBYEbpF3f9oqoixjA126ZMmywWd7wbICIiIiKL6x0b38HE5ASn2k8B4A/4eaXxFd5sfZO31ryV/eX7cZnZ7937A35+eOGHnGw76awrzijmo7s/Sn56/lI2f8XKSM6gb6TPWVbQJotFmTYRERGRVSbFncIHtn+AX7/716nIqXDWD00M8S8X/4XPvfE5rnZfxVrrZNAiDY8P8/iJx6MCtg35G/jUgU8pYJvF1LnaFLTJYlGmTURERGSVKs8p51MHPsXZjrM8deUpZ1LsjsEOHn/zcYwxWGvZUrSFD+/6MC7jonuom388+Y90D9+cLmBv2V7eu+W9mpNtDlO7R2pMmyyWVZFpM8bkGmO+a4zxGWNajTG/McN+nzfGDEb8jBljfAs9j4iIiMhKYYxhR8kOfvve3+bRmkejimWEK0te7LrIm61v0uxt5gtHvxAVsD1W+xg/d9fPKWCbh8zkzKhlZdpksayWTNvnCL6WtcAG4BljzEVr7QuRO1lrfw34tfCyMeZxILDQ84iIiIisNJ4kDw+tf4i9ZXt5pu4ZTrefjuoa+UzdM/gDfkb9wWIlHpeH9217X9QUAjK7qd0jNU+bLJYVH7QZYzKADwC7rbU+4JQx5ivAJ4AZg63Qce8D3n075xERERFZSbJSsvj5rT/Pe7e8l4nJCf7q9b/CN+ZjcHzQ2SdcIbIit2KWM8lUqh4pS2U1dI/cCBhr7YWIdaeAbXMc9z6gCwjPEjnv84S6UVZF/gDlt9Z8ERERkeWX5Eoi1ZPKWze8NWp9clIyH9/zcQVst0BBmyyV1RC0ZQIDU9Z5gaw5jvsl4Gs23Jl7Yef5baBhys8r822wiIiISKLYW7aX4oxiAFzGxYd2fIi12Wvj3KqVKcOjQiSyNFZ890hgEMiesi4H8MXYFwBjTAXwEPDJWzzPXwGPT1lXjgI3ERERWWFcxsXH936coy1HqSmooTqvOt5NWrGmZtrS3BrTJotjNQRtVwBrjNlirb0YWrcLODfLMR8FXrPWXruV81hrvQSzcA5jzK20XURERCTuclJzeLTm0Xg3Y8VTyX9ZKiu+e6S1dgj4HvDHxpgsY8wOgsVDvjLLYR9jSqbsFs8jIiIiIgIExwNW5lYCsD5/vaZJkEWzGjJtAJ8BvgS0ExyX9gfW2hdC3SAvAHdZa5sBjDEHCXZl/Kf5nmcZ2i8iIiIiK5wxhl/a80s0eZuoyquKd3NkFVkVQVuou+IHYqxvJlhgJHLdG0DG1H1nO4+IiIiIyHykuFPYWLgx3s2QVWbFd48UERERERFZzRS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIgnMHe8GrCJJAC0tLfFuh4iIiIiIJKiIeCFpvscYa+3StOYOY4y5D3gl3u0QEREREZEV4X5r7avz2VFB2yIxxqQA+4F2YDLOzVktygkGwvcD4VsSDUB13FokkRbjs4j1GcvCrITfiTvlc14Jn8VSSMTP9079LJbKrX7G+hwSR+RnkYi/s3eSBqAGKAWOWWvH5nOQukcuktAbPq9IWebHGBN+2GKtbQyvCz+W+FqMzyLWZywLsxJ+J+6Uz3klfBZLIRE/3zv1s1gqt/oZ63NIHJGfRSL+zt5JQp9FPVC/kONUiERERERERCSBKWiTleYP490AceizSAz6HBKHPovEoc8iMehzSBz6LBLHLX0WGtMmCcsYU0WoD7bS96uTPuM7gz7n1U2f7+qnz3h10ee5MinTJonMS/BuhDe+zZAl5EWf8Z3Aiz7n1cyLPt/Vzos+49XEiz7PFUeZNhERERERkQSmTJuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIiIiIiKSwBS0iYiIiIiIJDAFbSIiIiIiIglMQZuIiIiIiEgCU9AmIrIIjDGPG2Mev81z/GdjzE8XqUkyB2PMQ8YYe5vnqDDGDBpjKkLLHzfGNEZs/7wx5vO32dSEZIxpNMZ8fJHPGfX+LRVjzIvGmD9Y6ueZ5fmrjDHWGFMVrzYkYltEZGYK2kRkRTHG7DDGfNcYcyN0sXzNGPM1Y8y2eLdtIWJdNFpr/7u19h1xatKMluLifCWKFVBYa5uttZnW2uZYx1hrf81a+2sR50jI99IY8wfGmBfj3Y65LFdQJyKSaBS0iciKYYx5CDgCtAJ3A1nAPuA14L1xa9gKZYxJXsbnchljkpbr+URkbsv5N0BEbo+CNhFZSb4AfNda+/9Za5tsUK+19gvW2j+F2N0Up2a1Ql2BPmuMOWqMGTLGHA51c/usMabZGNNrjPmfEftP60Y31x1/Y8wfG2PqQtnAptCyK7Tt88D9wH8Obb8RWu9kO4wxv2GMuTTlnFmh/R8OLecaY/5f6Pw9xpifGGPWz9Kmj4cyPb9tjGkGmkPrNxtj/tUY02GMaTXG/J0xJiO07adABfD50HMfjfWehtY5WaSILle/Yow5BwwDW0L7/BdjzE+NMT5jzFVjzHsjzrHTGPOSMcZrjOkzxpwwxmyK8VqSjDFtxph/M2X9HxpjXo5Y/qQx5qIxZsAYc9IY8zOzvD8PGWPeCH3+PcaYHxljqkPb7gc+D4S7Qw4aY352rq5lkd/HWO+lMebtodeaHnGMa7aMXOh78pIx5r8bYzpD7f3d0Hf42dD7+qYxZmvEMR8IresPfc7fMMYUhrZ9BPjPwP0Rr213aNu9xpgXQu9HrzHm6SnNKZvpswwd/05jzJHQZ3nVGPPZKdsfM8acDT3n80DlLJ9PzM8gtO0+Y8zrofeyzhjzH83cNwnyjTE/jGj7R6Y8392h73mPufk77I7Ybk3w9/T1UFvOGGMOTTnHLxtjTofe93ZjzJ9MacN9oeN8ofNsjjj2cWPMN40xXwq9rnZjzC+aYG+DI6FjXjLGlEUc8xljzPnQtlZjzN9O+W49boz5Vuic3cA3YrzPa40xx40xX4h8vSISZ9Za/ehHP/pJ+B+gFrDAI3Ps9zjw+JR1LwJ/ELFsgaPAOiAdeB64AvwJkAzsBsaBB0P7PxT8cxl1zo8DjTM9L/CLQDlggP1AN/DJmdoUWvcHwIuhx7nACHBvxPZfBepD5zTAC8A/AvlACvA/gQuAZ4b35uOAH/g7ICP02guBLuCzoXMUAs8AX4o4rhH4+Gzv6dT9gKrQ+/xy6H1wh97bxtDPboI3Dn8X6AcyQ8e9BvzX0P5uYBewZobX8z+AZyKWXUAT8LHQ8i8AfQQDZDfwc8AYsC/W5wrcC9wDeELv6Q+B12b6zKe8zqp5fi+i3svQ51g/Zd07Qu1Om+F1/wEwAfxa6HW9AwgAzwF3hdr/LeCFiGPeDmwHkkKfxxvAN2J99yLWbQNGgU8DaaHP79Epr2W2z/ItodfxcGj7NuA68JHQ9urQ5/EroddxD9A59T2e7fcutK6S4E2BXwu99h0Eb0j8zizneTF0zLtCz/2uUFvuDm3fBPiAD4S2VwKngP8y5e/Im8CG0D7/F6iP2P5poCP0+pOAHOC+Kd+bp4A1QCrwz8BzU747o8B7Qsf/GjAE/Iibf7teAv4h4pifB2oIfq82A1eBP51yzgngY6E2p0e0pSr0WTYD/36hf6P1ox/9LO2PMm0islIUh/5tXaTz/aW19rq1dhj4HlAG/Ddr7bi19iRwjmDXy1tirf26tbbFBh0jeEf7kQUc7wW+T/CCNuxXgK9Yay3Bi6uDwKdtMNs4BvwXgpmcu2c5dYDgxexQ6LV/DLhkrf0ba+2YtbYb+H3gY/PIVMzHH4beB7+1djy07ovW2pPW2gDw/4BsghfJEAyWK4DK0DGnrLUdM5z7K8DDEVmuRwleGH8vtPwrBIPPV0Ln+gHBC95fjXUya+1r1trD1toJa20v8IfAwchMxWILfZZfAD4VsfpTwNestSOzHHrNWvv50Ov6KcGbAs9aay9YaycIBm3O99da+6S19qy1dtJa2wL8GXN/H38deNIGM9kjod+NZ6bsM9tn+f8Bn7PWPm+tDVhrzwGfA345tP3DwClr7d+HXsdh4B/maFMsHwbOhd6PCWvtmdDr+9Qcx/3IWvvj0HP/mGCQ/onQts8AP7TW/lNoexPBmwS/POUc/9taW2+t9RP8HNcbYwpC2z4L/I/Q65+01vZba1+dcvwfWms7rLWjBL/PB6Zsf8la+y/W2kngawSDrG9G/O36PtGf8z9ba+tCf3cuEbxBM/VzPmyt/VrodQ1HrH8v8CTwWWvt/57jvRORZaagTURWis7Qv2Wz7jV/7RGPh4Gu0IVR5LqsWz25MebXjTGnQt3CvATvuhfPcdhUXwZ+wRiTaYy5i2DGLnxRW0sw89EW6jrlBXoI3pFfN8s5b4QuEMNqgbvD5wid52mCd95LFtjeWBpirGsLP7DWDoYeht/rj4ee+3ljzHVjzF+aUFfNqay1V4FXuHkh/SvAtyIuRNcB16YcVkcwKJzGGLPLBLuYthljBghmMQxQNMvrWwxfAfYYY7YaY0qAdxMMAGbTPmV5mOnf6czwgjHmLaGufh2h1/aPzP19rAIuz7HPbJ9lLfDvpny3fh8oDW0vZ/r3I9b3ZS4L+pxnea4Gbv7u1AIfmNL2LzH9d6It4vHU11/FAt6/0PGZU7Y7n2nE93rq5+z8nTLGvN8Eu3t3G2P6gT9l+uc803v8Hwn+Pj0xR5tFJA4UtInIihC6QL8CfGSOXX0Eu/5FWnubT+8DmBI8zHjO0LiWvyJ4p73IWptL8CLcROwWmMfzvkTwAu2DBDMAT1prwxd5Nwh2nyy01uZG/KRZa781yzmnPu8Ngt3iIs+RY61Ntda2znAMTHmfQ2NfYgUB83mdDhscq/hJa20lwe51bwP+wyyH/D3wcWNMEcFMwd9HbLtOsAtepA2ExvLF8F2C3UvvstZmAw+G1oc/twW9lhlMO0cou/k9gpmhTxDMhFxYhOcCnGITPyKYSVofem0fnatdBLs+bryNp74B/MmU71aWtTY81q6FYGATaeryVLHaudDPeabnqgq1CYJt/9qUtmdba6cGVbNp5PbevwUxxpQD3wH+N1Bmrc0hmH03U3ad6Xv8HoLv49eNMZ4la6iI3BIFbSKyknwa+KAx5s9NsOiCMcFiHL9ijPnPoX2OA281xmw0xniMMb/N9Au6hbpCMEj5tAkWidjF7F2vcoBJgmPFJkMFFKYGmzeY44Iu1HXuKwRf90cJZt7CXgUuAn9njCkGMMbkGWPet8DufP8A7DPG/JoxJj30nq4zoQIPEW2dWgzkOPCzxphSY0wawfF0t32hZ4LFUsqNMQYYIDgGb3KWQ75H8P3+B+CitfZ4xLavAJ80wWIaSSZYJOM9ofWx5ISec8AYswb4oynbbwBFxpi8Bb+w6HNMK6xCsGvhR4FPMneWbaGSCY6Z8lprh0ywWM1/jNGuSmNMypQ2vcMEi7mkGmOSjTHz7uIL/DXwW8aYh40x7tDPNmPMA6Ht3wJ2m2CxDrcx5gDBTOtsYn0G3wK2G2M+Ffqd30Yw0P9yzDPc9DPGmHeEvhvvIDjmMZzJ/juCWe73hV53kjGmxhjz9vm/fP4a+E/GmAdDx+cYY+5bwPELlUXwuq7bWjtmjNlBsJvnfHURvFFSBvww9HstIglCQZuIrBjW2hcJjuOqJBg0+ICTBAtN/DC02zeAfwIOE7wDn0uwuMXtPK8P+CWCF0ADBMe2fHGWQ54imPF5DeglmHGbWqXtL4Btoa5XLczsq8Aegl0G/zWiTZMEx3CNAkeMMT7gNMELz3lPGG2D84sdAh4jWBDDG2r/9ojd/gh4f6ir5+uhdX9JsDDD5dBPHYsz3vAtBIvEDBJ8PW8Afz5L+0eAbxIsJPH3U7Z9h2BVxL8nWBDjD4EPWmuPznC6XyFYQMYHPEuwMESk54EfA3Whz+09C3plQbHeS6y1rxHM8mRzc0zeogh1W/w08EfGmEGC38Wp38fvEPwM20OvbVdoDNqjBIPJ9tDP7y7geX9I8Pfmjwl2b+4kGEgVhrZfI/h9/XcEv3f/k2CgOJtpn4G1tpFgoZVfJji27wmCv59/Oce5/p7g++IlWETkk9baN0JtO0bwd+LTBL/XPQQ/lxmrW05lrf0iwe6gnws9x6XQOZeEtfZi6Pm+E+oC+78JjoNbyDkGCL6Xk8BTxpicRW+oiNwSE7yRKyIiIvFkjHmCYPXB34l3W0REJLFo/g0REZE4M8bsJ5jh2BLvtoiISOJR0CYiIhJHxpg3CM6v9nuhLoMiIiJR1D1SREREREQkgSnTtkhCFbf2ExyoPVulMxERERERuXMlEZyz8pi1dmw+ByhoWzz7CU5KKSIiIiIiMpf7CU7hMycFbYunHeCVV16hvLw83m0REREREZEE1NLSwv333w+h+GE+FLQtnkmA8vJyqqqq4twUERERERFJcPMeUqXJtUVERERERBKYgjYREREREZEEpqBNREREREQkgSloExERERERSWAK2kRERERERBKYgjYRERERmRe/309HRwder5fJyXkXvhOR26SS/yIiIiJ3mOHhYS5evEhqaip5eXl0d3fT0dFBeXk5mzdvxhgTtb+1lra2Ni5cuMDo6CgALpeLAwcOUFRUFI+XIHJHUdAmIiIicgcZHBzk8OHDjIyMTNtWV1fHwMAAe/bswePxANDf38+5c+fo7e0FICsri8nJSYaHh7lx44aCNpFloKBNRERE5A4xMDDA4cOHGRsbIz8/n4KCAvr6+sjOziY3N5dz587R2dnJyy+/zPbt27lx4wbNzc1Ya0lJSWHz5s2sW7eO7u5uDh8+zMDAQLxfksgdQUGbiIiIyB2gr6+PI0eOMDExQVFREfv27cPtjr4UzMvL4/jx4/T393PkyBEAjDGsX7+ejRs3Otm37OxsIBgEWmundacUkcWloE1ERERklevu7ubYsWP4/X5KS0vZs2cPLtf0enTp6encd999XLx4kYaGBgoLC9m6dStZWVlR+6WkpJCamsro6CjDw8NkZGQs10sRuSMpaBMRERFZxTo6Ojh+/DiBQIDy8nJ27do1a2bM5XKxdetWNm/eTFJS0oz7ZWdnMzo6ysDAgII2kSWmkv8iIiIiq1RrayvHjh0jEAhQVVU1Z8AWabaADSAnJwcIFioRkaWloE1ERERkFWpqauLkyZNYa6mtrWXbtm2LOvYsclzbQo2NjdHT07NobRFZ7dQ9UkRERGSV6enp4cyZMwBs2bKFmpqaRX+OWw3aOjo6OHnyJBMTE9x3333k5eUtettEVpsVn2kzxvymMeaEMWbcGPP4LPuVGmP+xRjTboyxxpiqKdv/wBgzYYwZjPjZuNTtFxERkTtLW1sb58+fZ2JiYtb9ent7bykbFQgEOHv2LAC1tbVLErABZGRk4Ha7GRkZYXx8fF7HNDU1cfToUee1d3Z2LknbRFabFR+0AW3AHwN/P8d+AeBJ4Odn2ef71trMiJ8ri9VIERGRO5G1luHhYbxeL52dnbS0tHDt2jUuXbpEW1sb1tpbOmd7e7szlsrn8/Hqq69y/PhxOjs75zzn6OgoDQ0N8w40bld/fz/t7e1Ya5mYmODUqVNcu3aNV155hcHBwZjHTE5OcuTIEd54442Yk2DPprGxEZ/PR3p6OrW1tYvxEmIyxjhVJefzvgcCAS5dugTAmjVrgGBVSxGZ24rvHmmt/WcAY8w+oHyW/TqAvzPGrPjXLCIishKMj49z5MgRvF7vjPvU1NSwefPmeY+1stZy8eJF6uvrMcZQVVVFS0uLk7lpb2/H4/FQVFREcXExxcXFpKSkAMGgobm5mUuXLjExMYHX62X37t23/Tpn09zczNmzZwkEAuzdu5eJiQkmJycBGBoa4tVXX2Xv3r0UFRVFHdff34/f7weC2anNmzfP6/nGx8e5fPkyANu2bZuzmMjtysnJoa+vj5MnT3LhwgX27NlDYWFhzH3b29sZHx8nOzub3bt389RTT9HX14ff7582X5yIRNNvSLR3GGN6gXbg/1lrPxdrJ2NMLpA7ZfWMAaOIiMidZnx8nMOHD9Pf34/H4yE9PZ3k5GTnxxhDQ0MDdXV1BAIBtm7dGnV8T08PPp9v2nkHBgZoampygryGhgYgmLnJy8ujpaWFwcFB2traaGtrAyA3N5fc3Fw6OjqislY3btwgEAjEnK9sMVy7do3z5887y1euXHGCqB07dtDV1UV7eztHjhxh69atVFVVOa+rt7fXOa65uZmNGzfOq51tbW34/X4KCgooLi5e5Fc0XU1NDYFAgK6uLkZGRjh27BgHDx4kNzd32r5NTU0AVFVV4fF4yMnJwev10tvbuyxtFVnJFLTd9F3gi0AHcDfwfWNMv7X2H2Ps+9vAf1vGtomIiKwYfr+fI0eO0N/fT2ZmJgcPHiQ1NXXafoWFhRw/fpxr166xbt26qMIWb7zxxozd7Ywx7N27F4/Hw/nz5ykoKGDr1q0YY6itrWVoaIjOzk46Ozvp6enB6/U62b7MzEw2b97M1atX6e/vp6ury+mqt9gaGxsB2Lp1Kw0NDU4Q6vF4KC8vp6KigitXrnDlyhXOnTuHz+dj27ZtuFwu+vr6nNc6NjZGW1sb5eVz3x9uaWkBoLKyclErRc4kLS2NnTt3Yq3l5MmTtLa2cuTIEUpKSkhPTyctLY309HSstfT09OB2uykrKwOCn7/X66Wnp0dBm8gcFLSFWGsvRCy+boz5a+D9QKyg7a+Ax6esKwdeWZLGiYiIrBCBQIATJ07g9XpJT0+fMWCDYHassrKShoYGrl27xq5du4BgRspaS35+vjNmKlJpaanTnfDBBx+ctj0jI4Pq6mqqq6uZnJykp6eHvr4+cnNzKS4uxhjD4OCgM9ZsKYI2v9/P8PCw04XT4/Fw6tQpAMrKypyM26ZNm8jMzOT06dM0NTUxNDTEPffc42TaampquHr1Ko2NjXMGbYODg/T19eF2uykpKVn01zQbYwy7du1iYmKCzs5OmpubY+5XVlbmdIUsLCykrq6O7u5uJicnsdaqm6TIDPSbMbMZR9Naa72AN3LdctzNEhERSXTnzp2js7OTlJQU7rnnnhkDtrD169fT2NhIa2srmzdvZnR0lPb2dpKSkti7d++cx88lKSnJGdsWqaSkhEuXLs3aRdJai8/nIysra8H/z/t8Pqy1ZGdn43K5KC8vp66ujqGhISorK6P2LSsrIyMjg6NHj9Ld3c2VK1cYHx8nJSWFmpoaGhoa6Ovrc9oyk3CWrbS0dMnHssXicrk4cOAA3d3dDA8PT/uB4OcdlpeXh8vlwuv18uSTT2KM4eDBg5oCQCSGFR+0hQqLuIEkIMkYkwpMWmun1dENbQv/FUsJLY9Za60x5r3AywSDsf3AZ4H/sgwvQUREZFXo6+ujqanJuXjPyMiY85j09HRKSkpob2/n3Llzzpizqqqq2w7YZpOVlUVWVhY+n4+enp5phUCstbz55pu0tbWxe/fueXVNjBSeuyzc5dMYw6FDhxgdHXXWRcrNzWXz5s2cPn2aq1evApCfn4/b7Wbt2rU0Nzc7gW0s1lpaW1sBFtzWxWSMmfZehllro4Jft9tNYWEhnZ2dBAIBAI4fP87999+/pJ+9yEq0Gkr+/z4wAvxH4BdDj78EEJpr7f6IfUeAcG3dS6Hl8O2uDwF1gA/4GvC/rLWPL3XjRUREVgNrLefOnQNgw4YNMQtRzGTDhg1AsLqg1+vF7XYv2dxikcJdCNvb26dtC09JALdWln5q0AaQkpJCTk7OjMeUl5c7478gGLSF1wO0trbOOM5vYGCA4eFhUlNTKSgoWHB7l0OsbOWePXu49957eeyxxygoKGB0dJTjx487QZyIBK34oM1a+wfWWjPl5+OhbZnW2lci9p26n7HWNoa2/RtrbUHomM3W2r+JzysSERFZeVpaWvB6vaSmpi444MrLy2Pz5s2Ul5ezadMm7r//fpKTk5eopTeVlpYCwSqSkcFQc3MzdXV1znJ4PriFiBW0zcXlckW9d+Fugvn5+aSlpTE8PBxVVTJSuNBKQUHBihqy4fF4yM/PJzk5mb1795KWlkZfXx9nz569pTn85M7W29tLY2PjqvzurPigTUREROKru7ubs2fPArBly5ZbKiZRW1vL7t272bhxI5mZmYvdxJiys7NJT09nbGzMCYa6u7s5c+YMgFOR0ufzOXOrzYe19paCNsCpopmenu5k5YwxUdm2WMLVJlfyeLCUlBT2799PUlISzc3NTvVNkfkId2k+e/Ys169fj3dzFp2CNhEREVkQay0jIyN0dXVRV1fH0aNHmZycZN26dU4595XAGONk29rb2/H5fBw/fhxrLRs2bGD9+vVkZmY6BUnma2RkBL/fT0pKijOx93y5XC7uv/9+3vKWt0QVRwm/ry0tLfT09Ew7LpxpW0i31ESUk5PDzp07ATh//nzM1yoSS39/vzMm9uLFi0xMTCtvsaKt+EIkIiIisrSstXR2dtLW1sbg4CCDg4P4/f6ofSoqKtixY8eK6poHwS6S9fX1tLe309HRwcTEBKWlpWzZsgUIBhE+n4/+/v55B0S3mmULi1XJMisri8rKSpqamjh69Ch33323M+bN7/czODiIy+W65edMJGVlZfT391NfX+8UJklPT493syTBdXR0OI/Hx8e5fPky27Zti2OLFpcybSIiIjIjn8/Hq6++ytGjR51xa+EsUkFBAZWVlezevXtFBmwQzEylpaUxOjrK8PAwubm57N6923kt4S6KCxnXdrtB20y2b99OeXm5M3l5uEun1+t1pheIR6n/pbBlyxaKi4sZHx/n+PHjC+qeKnemGzduAHDXXXdhjKGxsdHJvK0GyrSJiIjIjE6fPo3X6yUlJYX169eTn59PZmbmshQKWQ7GGEpKSmhoaCAtLY0DBw5EBT4LDdqstXR1dQGLH7SFJ7AOl/c/cuQI99xzz6rpGhnJGMOePXt45ZVX6O/v59SpU+zZs2dZbwyMj49z/vx51q1bR2Fh4byP8/v9tLS0UF5ersnCl8nw8DADAwO43W6qq6vp6emho6ODnp6euE6BsZiUaRMRERGHtdbJavh8Pvr6+nC73bzlLW+hpqbGqfS3mtTW1rJ+/XoOHjw4bQxaOGgbGBhwytD7/X66u7unVaiz1nLy5El6e3udOcgWmzGG3bt3U1ZWht/v5/Dhw05xkpVchCQWj8fD/v37cbvdtLW1UV9fv6zP39DQQEtLS1Ql0fm4evUqZ8+e5dq1a0vUMpkqnGUrLi7G5XI5017MVG11JVLQJiIiIlhraW9v59VXX+WnP/0p7e3tNDc3A8ExRh6PJ84tXDopKSls3bo15mTgbrebzMxMAoGAU4zkwoULvPHGG877A8H37/Tp07S2tuJ2u7nnnnuWbILocOC2du1a/H6/0x1zNWXawrKysti9ezcQnDtveHh4WZ43EAg4n+/g4OAce0fr7OwEblb0lKV148YNJ6APz70YHu+5mgrZKGcrIiJyBxsfH+f69es0NjZGXRCfOnXKKYhRUVERr+YlhJycHAYHB/F6vWRnZzsFD+rr65335syZM1y/fp2kpCQOHDiw5FmvcOAWDrY9Hk/MoHM1KCkpoaysjNbWVq5fv86mTZuW/Dk7OjoYHR0FblYDnU9Xx7GxMSeIDo81XIljPVeCkZERzp8/T3t7OxDMNIeDtpycHJKSkhgcHGRsbGzBVVwTkYI2ERGRO4C1lqGhIVJTU3G73Xi9XhobG2lra3O6Q6anp7N+/Xp6enqcC6Hs7Gyni+CdqqCggNbWVjo6OsjPz3cu5oeGhujo6KCrq4vm5mYnYAt3zVpqLpeLPXv2cPXqVbKzs1d1cFBRUeEEbRs3blzy19rU1BS1PDQ0NK/fg+7ubufx+Pg4IyMjqny5yKy1NDY2cunSJSeY3rx5M1VVVc73wuVykZeXR3d3N729vc7UHiuZgjYREZFVbnx8nDfffJOuri5cLhdpaWkMDQ0524uLi6mqqqK4uNiZyLm/v5/h4WHWrVu3qoOB+SgpKeHs2bN0dXU5F+5utxu/38/Jkyfx+/24XC7279+/JOPYZuNyuZYl8xRvBQUFZGRkMDQ0RFdXF8XFxUv2XOHnSEpKci78BwcHFxy0QTDbpqBt8fh8Pk6dOuUU3yktLWXr1q2kpaVN27egoEBB22IyxtQCXmttlzEmHfhdYBL4c2vtWHxbJyIii2FkZIQLFy443VQyMzPJy8sjLy9vVY+VSgQDAwMcO3aM4eFh3G43k5OTDA0NkZyczLp166isrJzWrc7j8XDw4EE6OjqorKyMU8sTR0pKCvn5+fT09DhjZ7Zs2cLFixejAraioqI4t3T1Msawbt06Ll26RHNz85IGbZcuXQKCYzlTUlKcoG0u1lonaFuzZg0dHR14vV7Wrl27ZG29k4yPj3PkyBFGRkZIS0tj27ZtTnfIWMLj2rq7u515JZOSklbsTai4B23AN4FfAbqAPwHeBviBUuAzcWyXiIgswMTEBG1tbbS2tpKUlMTatWvJyMhgcHCQixcvMj4+HvO4rKwsJ4DLy8sjMzNzxf6nmmi8Xi+HDx9mYmKC3Nxc9u3b54zzCI/5mEl6ejrV1dXL2NrEVlJSQk9Pj9OVtLS0FL/fT11dHbt27VrSIEKC1q1bx+XLl7lx4wbj4+NLUsW0r6+PtrY2kpKS2Lhxo1PIYj5B2/DwMMPDwyQnJ1NRUeEEbXL7wpVZR0ZGyMvL45577plzjGFeXh4ul4uBgQF++tOfAvDoo48uWYGgpZYIQdsG4Fzo8fuAtwCDwEkUtImIJLTwnFTXr1/nxo0bTkl0uFlBLay4uJjq6mrGx8fp7++nr6+P/v5+fD4fPp/PqdTm8XgoKipi7dq1lJSUKIC7RQMDA7zxxhv4/X7WrFnD3r17nSAtfAda5q+0tJTz588DwXF+KSkp1NTUsGHDBn1Hl0lqaipFRUV0dnbS3t6+6Flga63zGa9fv560tDQyMzOB+QVt4fn5CgoKnEI0/f39KkayCBoaGujs7CQ5OZm9e/fOqyhMUlISlZWVXL9+3Vm3kj+HRAjaDGCNMesBa629BmCMWdwZKUVEZFE1NTVx5coVpyiDMYbCwkLWrVtHIBCgra0Nv99PcnIyxcXFVFZWOv9hhic7DQQCTgAX/hkZGaGtrY22tjaKi4s5cODAiv6PNl4uXLiA3++ntLSUPXv2OJUg5dakpaWRm5uL1+uN6gap7+byKisro7Ozk9bW1kUP2lpbW+nr63MCcsDpOjw0NDRr8BUujgHBrGxKSgppaWmMjIwwNDTkBH8yP+3t7Vy9epW9e/eSkZHh3NTbsWNHzPFrM9m2bRvbtm1bqmYuq0QI2k4D/wWoAJ4GMMaUAQPzOdgY85vALwPbgW9aaz8+w36lwBeA/UAJUG2tbZyyz58Av0bwffkW8Flr7cSCX5GIyCoUCAQIBAK43W4GBwc5c+YMELyoWbduHeXl5VH/mc6nTHy4wldkefTh4WHa29upq6ujs7OT8+fPr5r/dJdLd3c3XV1duN1uduzYoYBtkdTW1nL58uU7fgqEeCopKcHlctHb28vo6OiidXWbmJjgwoULQHC8YjiT4/F4SElJYWxsjP7+flpaWsjIyKC0tDTquTs7O/H5fKSlpTlj2HJzcxkZGcHr9SpoW6DLly/j8/loampi/fr1+Hw+3G43a9asiXfT4iYRgrbPAn8HjAO/FFr3CPDMPI9vA/4YeAyYLfQOAE8C/wN4fepGY8yvAh8C9hHsnvkj4PeB/zbPdoiIrErWWpqamrh8+TLGGB544AEaGhqA4BiTnTt3Lmq2IT09nQ0bNpCXl8cbb7xBQ0MDOTk5rFu3btGeYzWz1jqFFGpqapZk3M+dqqSkZNbCB7L0whfu7e3ttLW1sX79+kU578WLFxkbG6OgoMDpCRCWmZnJ2NgYx44dc3oWnDt3zpkXrLS01ClQs379eucmSU5ODu3t7Xi93mnnlJmFu8xDcOLsrKwsINjt9E6+ARX3oM1aewa4b8q6rwJfnefx/wxgjNkHzPgbYa3tAP7OGDPTa/5l4P+Es2/GmD8CvoiCNhFZway1zsSw2dkL63U+NjZGc3Mzzc3NUZMunzx5kr6+PoAlHc+Tn5/P9u3bOX36NBcvXmTt2rWzFs6AYDaws7OTvLy8VTGZ6nxZaxkYGKCzs5OOjg6ni5cKichqVFZWRnt7O62trYsStPX29tLU1ITL5WL79u3T/qZlZmbS09PD6OioU0m0s7PT6dJ98eJFIJiVi8zC5ubmAqgYyQK1trY6j4eGhpybhMs9nUaiiXvQBhAq9b8JyIpcb619eRmbsY1gV82wU0C5MSbHWtsfuaMxJhfInXK8bqGISNyFx4j19vY6FxThO8P79u2b91w17e3tnD59momJYA/x9PR0amtruXDhglPSuri42LkDulTWrVtHU1MTXq/X6SYzVeQ4k0uXLlFfX48xhtLSUrZv376qM03hggydnZ3O5wzBbqdbt26d12B9kZWmuLiYpKQkvF6vM43IrQoEAk5X7w0bNsT8mxbu2miMYffu3RQVFeH3++nq6uLGjRvcuHEDv99PdXV11O9cOGgbGBggEAjMmCXy+/3cuHGD3t5eJicn2b59+x37u2utpa2tDQi+74ODg/T3By/D7/QpNeL+jTDGvAf4GjD1FrAFZr+lurgygcjgzBv6N2vKeoDfRhk4EUkQ1lp6e3tpbGycVsERghW0JicnuXDhAmvWrJm1e0l4v/CA+qKiItavX09RURHGGIwxnDp1CmBZsjjGGDZu3MjRo0epq6tj7dq1zn/i4Z/h4WG2bdvG2rVraWpqco5ta2vD4/GwY8eOJW9nPLS2tvLmm286y6mpqaxZs4bi4mIKCwvv2Is+Wf2SkpLIzc2lp6eH/v7+25pu4dq1a/h8PjIyMqitrY25z5o1a7h27RrV1dVO4OB2uyktLaW0tJRAIMDg4OC0gM/j8TgTgg8ODs7Y2+HcuXNRFQ6LiopWfXfKyclJbty4gbWWpKQk52d0dJShoSFSUlLYsmULx44dA4J/3+70cYGJ8Bf9zwnOz/b/rLVDcWzHINGBY3jae1+Mff8KeHzKunLglUVvlYjILKy1nD17NipYCc97lp+fT15eHunp6bz00ksMDg7S1NQ0Y7Dl8/k4ceIEPp8Pl8vFli1bqK6ujuoqVF5ezsDAAJOTk8t217O4uNip2vfMM7GHO58/f56+vj78fj9FRUXcddddvPTSS7S0tLBly5YFTeAd7mI5NDRETk4OeXl5c3bLXG6BQMAZt1ZdXU1FRQVZWVmqZCh3jJycHHp6evB6vbcctA0PD3PlyhUAtm/fPuPveUZGBo888siM53G5XDMGZLm5uQwNDeH1emPuY611pkfJy8ujr6+PgYF51eJb0a5evcrVq1dn3L527VqKiopwu93O3/U7/e9bIgRtpdba/x3vRhCcK24nN4uU7AJapnaNBLDWermZiQNU8ldElp+1losXL9LU1ERSUhIbNmygoqIiZjnk8B3LK1euUF5eHhXEWGtpbm7m/PnzTE5OkpmZyZ49e8jJyZl2HmMMW7duXdLXFes5N2/ezJEjR5yLo5ycHOfn2rVrtLS0OHeqN2zYQHZ2NkVFRXR1ddHc3MyGDRvm9VwdHR2cPn2asbExZ53L5SInJ4f8/Hzy8/MpKChYUBC4FMLjDLOysti6dav+D5I7TrjrYbjr3EJZazl37hyTk5OUlZUt2U2o3NxcWltb8Xq9MauODg0NOV08a2pqOHbs2KoP2qy1zri1NWvWYIxhcnKSQCDA5OQkLpeL6upqkpKSWLNmDa2trXd01ciwRAjaXjXG7AgVJFmwUGERN8GulEnGmFRgMlap/tC28G2UlNDymLXWEsyc/a4x5ifAEPD/A75yK20SEbkd4bESLpeL5ORkkpOTSUlJce4CDw4OOmOZ+vr6MMawb9++We82r1mzhvz8fHp7e2ltbaWqqsrZduHCBa5duwYEx5Bt27Yt4brWFRUV8dhjj+F2u6cFKNu2baO7u5vR0VFycnKcwerV1dV0dXXR2NjI+vXr5wxswhdxY2NjZGVlkZ+fj9frZWBgwBkfWF9fj8fj4eGHH47bWLnJyUnnDvWmTZsUsMkd6XaLfNy4cYOOjg48Hs+S3ogK3/yaqZ09PT1AsDJiOBO32oO2gYEBhoeHSUlJYf/+/bP+Ddu+fTvr1q2744uQQIIEbcAPjTFfANojN1hrvzaP46eW5f9FgpUnP26MGQTeYa0Nd1scidjvUujfaqAR+DJQBZwAPATnafuThbwQEZHbMTk5yaVLl2hubsbv90/b7nK5cLlcUdvcbjc7d+6cs3uQMYaqqip6e3tpaWlxgrZwZa7wAPuysrJFfU2LaabslsfjYc+ePZw7d4677rrLuQAoLi4mPT2d4eFhbty4MWcRlsgLiQcffNA5j9/vp7e3l97eXq5fv87o6Ci9vb1xK/3e0dHhBKgqPy93qvT0dDweD6Ojowuer21ycpJz584BwV4IS1lpNicnB2OM0618ahfMcNBWWFhIWloabrebsbGx2y6wksjChUZKS0vnvOnk8Xju+AIkYYkQtH0y9O+vTVlvCRYomZW19g+AP5hhW+aU5Rm/GaFs238J/YiIzCg8yWr4Jy8vb1r3u97eXjIyMmb9T3dkZIRTp045E1OfP3/eGZuWl5eHx+NhfHzc+fH7/QQCAVJTUyksLKSkpMTp8z8fJSUluN1u+vr6GBwcJDMzk/r6eqy1rFu3LqEDtrkUFBTw4IMPRq0zxrBhwwbOnj3L2bNnKSgomDU71t4evG9YUlISdSHhdrspLi6muLiYQCBAfX09AwMDcQuYent7Y7ZT5E5ijCEnJ4fu7m68Xu+Cfh+9Xi+jo6NkZWUt+UTpbrebzMxMfD4f/f395OfnO9ustU413vz8fIwxZGdn09vby8DAwKoMVqy1zt/a8CTkMj9xDdqMMS7g3cCVWN0ZRUQSRWtrqzNJ6sjISNS29vZ23G43lZWVANTX13PhwgXS0tJ44IEHZgwUrly5Qnd3Nz09PU6REJfLxT333ENBQcG0/ScnJ/H7/SQnJ9/SxXpSUhKlpaVcv36d1tZWKioquH79OsYYampqFny+laCyspK2tjZ6eno4c+YMe/funfG9C19IzJaRC3d1utVxNIshHLRFXvyJ3Ilyc3Pp7u6mv78/KmibmJjA6/WSkZFBenr6tOPCEzfn5eUty42P3NxcfD4fb7zxBoWFhaxdu5Y1a9YwPj7uZNTClRFXe9Dm8/mc6pD6G7Yw8c60WeAYwXL7IiIJaXh4mJMnTxJMyAfvnIaLYLhcLurq6jh79izWWiYmJpyqfiMjIzMGCiMjI7S0tADBO4/hMUq1tbUxAzbAKYl8O8rKyrh+/TrNzc10d3cTCAQoKytbtaWUjTHs2rWLl156yZmMN1YpbZ/Px+DgIMnJyTO+/4Az5mSxgraJiQlcLte8P1e/38/AwADGGGdMj8idKvw70NPTQ2trq9ON2efzYa0lNTWVRx55ZNrf33DQttTzTIZt2LCB4eFhent76ezspLOzE2MMGRkZQLCnQLiNq31cW7hrpHoKLFxcgzZrrTXG1ANrmDKeTUQkUTQ3N2OtZc2aNWzZsoXMzMyo/2ystdTX13P27FlnXW1tLY2NjbS3t3Pq1Cny8vLIzMwkMzOT1G2VFgABAABJREFUlJQU6uvrCQQCTveQtrY2srOzlzzjVVhYSGpqqjMOxO12zzg30WqRnp7O1q1bOX36NOfOnaOgoGBahc1wlm2ueewyMzNJSkpiZGSE8fHx2ypGMjY2xosvvoi1lqqqKtavXz/n+fr6+rDWkpubm3DFYkSWWzjz3dPT44wNg5vjf0dHR+np6ZlWxCIctC3XzaqsrCwOHTrE2NgYN27coL29ne7ubgYHBwGi2pcI2fylEtk1cq4xxjJdIvzF/0vgW8aYPyBYEMSZFdZa2xynNonICjQ5OUlvby9jY2OUlZUtyl08a21UKflYd2a3bNlCcnIy/f39TE5OUlpayrp168jOzubEiRO0tLQ4WTUIZurCE2DX1taSkZHBmjVrKCoqmjVgWAzGGLZt20Zra6szLm4hA/hXqnXr1jnV4k6dOsU999zjfD+stc7nM9cYi/CYk/BcSrdT0ezatWuMj48DwTmLGhsb2bRpE1VVVTN+d9U1UuSmtLQ0CgsLnbHF4Wk5cnNzuXLlCnV1dbS3t0/7PQ0HS8uVaQtLSUmhsrKSyspKxsfH6ejoYHh4mHXr1jn7hG8KDg4OEggEbun/BK/Xi8/nIycnZ9b5G+vr60lOTo56/qU0ODjo9GhQNciFS4Sg7cuhf58n2F0SwIQeJ9ZspiKScEZGRpzuJl1dXUxOTgLBzMmePXucAh63+p9zZ2cno6OjZGRkzHihPNOYsLVr15KWlkZvb6/zn5XP52NiIjiEt7S01OkKE6vL3lIpLS294+5yGmPYuXMnL774It3d3TQ2NjqTjHd1dTE0NER6evq8xpDk5OTQ19dHf3//LV94jI+P09jYCMCOHTtoa2uju7ubc+fO0dzczLZt22J20+zr6wMUtIlA8Pf64MGDWGunBSalpaXU1dVx48YNtm3b5mwPjyNzu91xvWE1U7DkdrvJyMhgcHCQgYGBBXeDttZy5MgR54ZQUlISOTk55ObmkpOTQ1FRESkpKQwNDXHhwgWnLcsxD5q6Rt6eRAjaquPdABFZebxeL6dPn57W7z8nJ8cp8f7ss886/3HV1tYueE4ra61zYV1RUXFL/8nk5eWRl5cXdc7x8XFGRkaW/S7vnS4lJYUdO3Zw/PhxLl68SGFhIVlZWc5nXFlZOa/PeDHGtTU2NuL3+ykqKqKyspKKigo6Ojo4f/48AwMDvP7666xdu5a77rrL6cpprVXQJhJDrN/bnJwc0tLSGBkZwev1On+HI7tGJmrgUFBQwODgIPX19ezdu3dBxw4PDzM+Pk5SUhIpKSnOWLpwlj4tLY23vvWtzt8SgJMnT/LAAw/ELNqymNQ18vbEPWiz1jbFuw0ikvjGxsbo6+tjzZo1GGM4e/YsAwMDuN1uioqKnJLsqamp+Hw+jhw5wsjICG6325mMeHBwcNbqgZHCF9BDQ0O4XK5F6z5ijCElJWXVzr+T6MJdV69fv86pU6fYtGkTnZ2dC/qMIyfLbWxsJCkpyTl2ZGSEQCDgFBiIZWhoyJnMPDye0BjjTOFw7do1rl69SltbGx0dHdTU1LBhwwaamprw+/1zTiUhIsHfqdLSUq5du0Z7e7sTtMWra+RC1NbW0tLSQltbG+vXr4+68TeX8I3MgoIC7r77bsbHx/F6vfT393Pt2jVGRkYYGBhwgja3283ExASnTp3i4MGDSxbI+nw+fD4fHo9HXSNvUdyDNmPMx2baNs/JtUVkBRscHOTcuXO43W7S09OjftLS0khKSqK/v59jx44xMjLC5s2bKS0txev14na7efTRR6cVZMjKyuKBBx5gcHCQ3Nxcenp6OHHiBO3t7TQ3Nzul+WcyMjLC8ePHnYvvrVu36iJ5Fdm6daszt9ORI0eAYFXN+X7G4TEiQ0NDTvGZrKwssrOzee211xgbG+PAgQMxu1oODw/zxhtvMDExQXFx8bSMWVJSErW1tZSXl3PhwgXa2tq4fPky165dc7rVzvX9FZGgkpISrl27xrVr1/D5fNTW1i575chbkZaWxvr167l69SoXLlzg0KFD8w6mwq8v3CMgOTnZuak5NDTE9evX6enpwev1ArBr1y7OnDlDT08PXV1dFBcXL8lr6uzsBIKfyVKP3V6t4h60AX84ZbmYYLtamcfk2iKycllrOXv2rDO5aCwpKSn4/X5nrFpDQ0PUmLCZKuglJyc7F8RFRUXs2LGDEydOcOXKFcrLy2ctsV5XV0cgEKC0tHTemTlZOTweD3fffTdXr17F6/UyMTGxoKqdSUlJFBUV0dnZSUpKCmNjY7S3tzvdXgGOHz/OPffcE3WHPBAIcPjwYUZGRsjPz5/1u5WWlsbevXupqqri3LlzTlZ5x44dK3oSdJHllJ+fT3V1NU1NTXR2dtLT0+N0N070aU5qampobm6mt7eX119/nR07dswr0Axn2mLtW1hYyPXr1+no6KC/vx9jDEVFRdTU1HDhwgWuXLlCUVHRkvyfF+5Orq7dty7uQZu1NmpMmzHGDfwP4Gp8WiQiy6W7u5vu7m48Hg/btm1jZGSE4eFhhoeHncdjY2NAsFCHz+dzungAC7p4LS0tJScnh/7+fhobG9mwYUPM/UZHR2luDhauXegYOFk5srKy2LNnzy0fv2/fPiYnJ/H5fLz++uu0tbUxOjoK4EypcPToUQ4dOuRcPHV0dDA0NERGRgZ33333vEr2FxQU8MADD3Djxg1ycnKWfMyJyGoSrpa7ceNGzp49S1tb24roHgnBbot79uzhzTffpLe3l5dffpna2lpqampmzVSFg7Zwpi1SuLhR+EZpVlYWbrebyspK6urq6OvrW7Js22ztkvmJe9A2lbXWb4z5r8BF4Ivxbo+ILA1rLRcvXgSCdxRjVU+01jI6OkogECA9PZ329nZOnDjhTJq6kH7xxhg2b97MkSNHqKuro7y8PGZ3uGvXrjlZtkT/T13iJzzReX5+vjPYP5xlO3jwIBcuXKCjo4MjR45w7733kpaW5kwdUVVVtaA51sJjc0Tk1iQnJ7Nz504GBgYYHBwkKSlp2lyNiaiwsJC3vOUtXLhwgebmZi5fvkxbWxs7duyImbHy+/3OOOxYmcS0tDQyMjIYGhoCcHoCuN1uJ9t29erVRQ/aJicnGRwcxBij/1dvQ6J2Ks0B5j/qUkRWnOvXr9Pf309qaqpTen0qY4zzn0z4wjVc4GHt2rULzoIVFRVRWFjI+Pg4p06dwlobtT0QCNDUFKyNtNSTXMvqYIxx5nYLT3qdmZnJ3r17yc/PZ2RkhMOHDzMwMOAUPFH3RpHlF85cud1uCgsLV0wvCo/Hw86dOzl06BCZmZn4fD5ee+01zp496wwVCIusjDlTNi7yZmfkdAKVlZV4PB56e3sXfWLvwcFBrLVkZGTMOjRBZhf3oM0Y81+n/Pwv4CXgyXi3TUSWRn9/P+fOnQOCE1PP94+4MYbt27dTXFzM+vXrF/y8xhh27dpFcnIynZ2d1NXVRW3v6+tz5nRb6Nw4cueKzIKFA7KkpCQOHDhAdnY2g4ODvPrqq1hrWbNmjYraiMRJTk4OjzzyCPv37493UxYs3FW6trYWYwyNjY28+OKLdHR0OPvMpwtiZNAWOebW7XY7PV7CNy8Xi7pGLo64B23AW6b8bAG+AfzqfA42xvymMeaEMWbcGPP4HPt+wBhzzRgzZIx52hhTFrHt8dA5BiN+9D+ryCKy1tLb28uJEyeYnJykoqJiwZNKFxUVcffdd99y15a0tDR2794NwOXLl6OKoIQfqxyxLER+fj7p6ekkJSU5WTe4WfAkPT3dKaRTUVERr2aKCMHfy5WSZZsqKSmJzZs388ADD5CXl8fo6CjHjx93umbPJzgqKCjA5XKRnJw8ratiuDJta2srfr9/0dqtoG1xxH1Mm7X2Lbd5ijbgj4HHgBmv4owxW4CvAD8HvAb8GfBN4MGI3f6PtfY/3mZ7RO541loGBwfp7++nv78fn8/H2NiY8wPBO57btm2LS/uKi4upra3l6tWrvPnmmzz44IOkpKTQ1dUFELNUu8hMjDHce++9TE5OkpqaGrUtNTWVe+65h9dffx2Px6PvlojctuzsbO69914OHz5Md3c3vb29lJWVzSs4SklJ4Z577iEpKWla8JqVlUVBQQE9PT20trYu2vQiCtoWR9yDNmPMYWvtPTHWv2qtvW+u4621/xzafx8w2y37XwR+aq19NrT/7wOdxpgN1tr6W2u9iIRNTExw5coVent78fl8TmZhqrS0NEpLS6mpqYlr3/ZNmzbR29vrzOG2b98+vF4vxhinwpbIfE0N1iJlZGTw8MMPY4xZsXf4RSSxGGMoLCx05pwsLS2dd3A02/9xlZWV9PT00NjYSEVFRcy/Wf39/WRkZMyroJK1VkHbIol70AZsnWH9lkV+nm3A0fCCtbbfGNMYWh8O2j5ljPkU0Aj8T2vtd2OdyBiTC+ROWb2wPl4iq8jg4CDHjh1zSikDpKenk5OTQ3Z2NtnZ2aSlpeHxeEhLS0uIC1djDHv27OHll1+mp6eHY8eOYa0lPz9/QZX9ROZDg+9FZLGFx1739fVFjcm+nXGzpaWlJCcnMzAwgNfrjRr3BuD1ennllVfIysri0KFDJCcnz3q+sbExxsfH8Xg8s97ckrnF7crEGPOx0MMkY8xHgciruE1AzyI/ZSYwtRyOFwh36P0b4N+F9nkb8F1jzA1r7csxzvXbwH9b5PaJrEjhIgsTExNkZWWxdetWcnNz8Xg88W7anFJTU9mzZw+HDx+mt7cXUNdIERFZGXJzczHG0N/f7xQkud3/w1wuFxUVFdTV1dHU1BQzaINgpcojR45wzz33zPr/fWSWLRFu2K5k8byd/Iehf1OAP4pYHwBuAP92kZ9vEJial80BfADW2jcj1v/EGPN14H1ArKDtr4DHp6wrB15ZjIbK0gnYAOdunCPFncKmok3xbs6y8fv9DA4OMjQ0xNDQEIODg6SkpFBdXX1bk/UGAgFOnjzJxMQExcXF7N27d8VlqQoLC9m4cSOXL192lkVERBKdx+NxpgEIV3xcjBuP4cm229rauOuuu6KyaeFpBYwxeL1ezp8/z65du2Y8l7pGLp64XV1Za6sBjDE/sda+cxme8hywM7xgjMkGqkPrY7EzrMda6yWYpXPo7sHKcLzlOE9cfAKAj+z6CHcV3xXnFi2dgYEB6uvr6erqcop/TNXQ0EB1dTV33XXXvL/Dk5OTXLhwAWMMfr8fr9dLenq6M//NSlRbW8vw8DATExPT7iqKiIgkqry8PHw+H36/H5fLtShjstPT0ykuLqazs5OWlpaoKXbCwyC2bNnChQsXaG9vZ8eOHTPOCxee8y0nJ+e223Wni3vJ/3DAZoJK59p/KmOM2xiTCiQR7GqZaoyJlaf9OvAOY8zDxpg0ghUnD4eLkBhj3m+MyTTGuIwxbyNYuOSJW31dsvwCgQCBQGDWfV5tetV5/I1T31jqJsWFtZYzZ87w0ksv0dLSwtjYGC6Xi6ysLKcAyM6dO51S+9euXaOhoWHe5z59+jSNjY00NDRw/fp1Z+6zldAdcibh17B//37dgBERkRUjck7R/Pz8RRs/G64c2dTUhLU38xjhTFtpaSnZ2dn4/f6oqXOmUtC2eOJ+WzwUQP018DFgEsgwxrwX2Gat/dN5nOL3iR5f9ovAV4GPG2MGgXdYa1+x1l40xvwK8GWgBHgV+HDEcb8F/D3BsXUNwCettc/f3quT5RIIBHjttdcYHh5m7969M3Zx6x+NHtb4/2fvPsPjOs6D7/9nd4FF7713AixgJ8UmqtuSY8m2LMvdcpEdx0ns5Gl5nTyJ0/OkOY4dFymxFcdVtixHsnoXKfYOECBAEL0t+mIXZbFl3g+7OMSikAAJEAvw/l0XLmLPmTM7Zwt47jMz93QOd5IVlzVrWfAHKRd6L5AclUxaTNqitnkhOjo6uHTpEmazmbCwsKAfs9mM1+s1Fsa8dOkSLS0tmM1m8vLyKCgoIDo6ekYwkpeXR0ZGBidOnKCmpob4+HiSkpKuGLQ0NTXR0dGBxWKhoKAAu91Oenq6ZFsUQgghlsHU0SGLOSc7PT2diIgInE4n/f39pKSk4Ha7cblcmM1mIiMjycjIYHh4mO7ubtLSZl4jud1uRkZGMJlMxMTELFrbblbLHrQB/wjk418v7aXAtlPAXwd+rkhr/TXga3Psi5n2+BfAL+You2++DRahp7m52Zgce+TIESorK2csYjs6MYrHF7xY5NG2o7x/3fvnrPf5uuc51HoIq8XK7+z8HVKib/x8J6/XS3V1NRMTE1cte+HCBXw+H0optm/fftU/4JmZmRQVFdHY2MihQ4cwmUxkZWUZi09PZbPZqKmpAWDTpk1kZi64Y1wIIYQQiyg2NhaLxYLH41nUoE0pRV5eHvX19bS0tJCSkmL0ssXExKCUIiMjg/r6erq7u9mwYcOMm75T57PNNXxSzF8oBG33Axu11gNKKR+A1rpNKZW9zO0SN5jNZqOrq4t169YtaKjdxMQE9fX1gP/OkM1m4+zZszidTioqKow/Il2OrhnHnu06y7vL3k1k2Mx12R0uB8fa/atEuDwuDrcd5r3l772WU1uw0dFRnE4nqamptLa2MjExQUJCAmvXrsXtdgf9eL1ezGZzUPaoTZs2zfuPd0VFBRMTE9hsNtxuN+3t7axZsyYoQcng4CAnT55Ea01ZWZkEbEIIIUQImBzePzY2tujJPvLy8rh48SJdXV24XC5jPltsrD/xelxcHFFRUYyOjs66PIAMjVxcoRC0hQHDUzcEhkyOLU9zxHJwuVxGFkKLxcL69evnfezFixdxu92kpKSwfft22traOHfuHJcuXWJkZITNmzdjsVjodHTOONbtc3Om6wy78nbN2He07WhQz9zpztPcU3IPVsuV1z+ZDKKmPu7v76evr4/h4WGcTidKKUwmEyaTCbPZHPS7y+VicHAQ8PeETf7RKykpueowxJGREdxud9AY96sxmUxGz9qpU6fo6Oigu7vbmHg8MjLCsWPH8Hq95ObmUlZWNu+6hRBCCLG0lupGamRkJOnp6XR3dxs3kAFjqONkb1tjYyMXL15k06ZNQZkmJ69fJHPk4giFoO048AXg36Zs+yRwZHmaI24ErXVQN3pNTQ1utxvwD3XMz8837uR4PB7sdjuDg4MopSgqKjKOHRsbo7m5GaWUkQExLy+PqKgoTpw4QXd3N4cOHWLHjh1BPW3pMenYnP5eqdmCNrfXzbG2Y0HbXB4XVd1VbMvZNuc5Xbx4kfr6ehITEykqKqK3t5f29na8Xu+CXh+z2YxSiq4uf5tjYmLIyMi46nHR0dELep7pMjIygoI2l8vFkSNHmJiYIC0tjcrKSknUIYQQQtwk8vPz6e7upqmpybjGmDo/LTc3l+bmZmw2G2+88QYVFRXk5uYa68eB9LQtllAI2v4X8LZS6kP4k5C8CGwDdi9vs8Qkh8NBbW0t8fHx5Ofnz3tFe601DocjaH2wyZ/JjIbh4eHExsbS29uL2WwmNTWV7u5uzp49S3x8PIODgwwPDwdlLjKbzRQUFAD+Xjafz0d2dnbQH4WUlBT27t3LsWPHsNvtHDp0iM7wyz1t95Tew0/O/ASv9tJub6dvpM+YrzY0NsRrl15jxD0y45yOtB1ha/bWGYGL2+3m9OnTxvDEgYEBY7Fm8Gd3Sk1NJSEhgdjYWJRSeL1eI+Olz+czHiulSE5OZmxsjKNHjzI2NkZJSckNCZbS0tIwmUwMDAwwOjrKyZMnGR0dJSEhga1bt8qYdCGEEOImkpqaSmJiIoODg8byQZM31cHfi3brrbdSXV1NX18fZ8+epbW1lbVr1xoji6SnbXEse9Cmtb6glKrA37t2Hv/C2o9qrduWt2UCoK+vj+PHj+PxeLDZbDQ0NJCZmUlhYeGMscs+nw+bzUZ6ejomk4nGxkYjccVsfD4f4+PjjI+PA/61svLz8+nv72dwcNAYIqiUIj4+nujoaDo7O6mtrSUzMxOv10traytKqVmH7MXExLB3717eeecdhhxDNHuaiY7xZ1EsTCykLKWM2t5axsfHea36Nbbkb+Gk7STne87j05eXDthfuJ9DLYdw+9x0ObrocnQFZZx0OBwcP36ckZERwsLC2LhxIw6Hg66uLqPH7VqyJsXGxnLrrbficDhuWHZGi8VCSkoKPT09HDx4EJfLRXR0NDt27Fixa7AJIYQQ4toopVi/fj0HDhwwHk+d8w7+65VbbrmFzs5OampqGBwc5J133jH2LdYyBDe7Zb0KC6yn1gIUaa2/vpxtETPZ7XaOHDmC1pqMjAyUUnR3d9PR0UFHRwcJCQkUFhaSnZ2NUoq6ujoaGhooKipi7dq1NDc3A/7em9jYWKKjo42fiIgII2iz2+243W7y8vJQSrF582Y6OjqIi4sjMTGR+Ph4LBYLWmu8Xi/d3d0cPX4UpRVaa3JycuYMisLDwykrK+OVI69gd9iJjokmOTIZq8XKpqxNVHVV0dPTw3M9z/HsuWeN3j+r1Up4eDgVWRXsL9zPwNgAVd1VADQONBpBW2dnJ2fPnsXj8RAXF8f27duJiooiMzNzUeZ+hYeH3/B0+hkZGfT09OByubBarezcuROr9crz+IQQQgixOiUkJJCTk0N7ezsxMTGzjrpRSpGdnU16ejr19fU0NjaitZahkYtoWYM2rbVbKeXGvzaaCDHNzc1GULRp0yaUUoyOjtLS0kJraytDQ0OcPn2aoaEh1qxZYwRpra2tJCUlMTo6SlRUFDt27Jh1aJ/ZbDaCuKnS09NJT0+fUV4pRfGaYn5Y80OcPU72JuwlOzr7isHR8PgwL3W9xGHnYdxuN6Ojo2Rl+AOuNSlr8E340FpjtpgxaRMer4fx8XHifHGsMa1hnXsd4eZwipOKqequwufz8eaZN4kaiMJkMtHW5u8Qzs7OZuPGjavibtJkT6lSih07dlz3PDkhhBBCrGwVFRWMjY2RlTX32rbgH7Gzdu1acnNzaW1tNRbpFtcvFMY7/TPwD0qpP9Bau5e7McLP4/HQ2emfA1ZaWmoEXVFRUVRUVFBWVkZ7eztVVVU0NzfjdrvxeDzGsWfOnAEwJqMultrBWsITw4l2RdMf189H9350Rjf9JJ/28fOqn9M82ExUbBRj/WPY7XZy4nMACDOHkWnOpIsu/1yzmFjKk8tZn7CeCHcEzc3NDAwM0NvbS2FiIQBOp5PuoW7aTG2YlMlIgFJYWLhqEnRERESwZ88ezGZz0Lh1IYQQQtycIiIi2L17/ukmYmNjWbdu3RK26OYTCkHbV4Ac4HNKqW7AmEyktS5arkbdjJxOJxcuXDB6uTweD0lJSbMOPTSbzeTn5zMyMsKlS5dob28HoKCggObmZjweD0opcnJyFrWNtb21REZGEhkZyTDDjDFGFLMHbW80vkHzYDPgz6roHHKSakqlMrUS8KfiL1SFOKIcbC/fzu6C3SREJgSdY21tLRcvXmTXrl3EWePocHTg0R7is+PJiM4gPT19xty+1WAhSwYIIYQQQoilFQpB29eWuwE3k6GhIcbGxozhb5PrhY2OjlJdXY3H46Grq8uYw5Sbm3vF+srKyujs7GRsbIyYmBjWr19Pf38/DoeDlJSUOXvBrsXIxAgtQy1B2851neO2otsAgnq6mgaaeKPxDePxXSV3ERYVxtDQEOMj48RGxdLf349FW7g993Zurbh1xvMVFBRw6dIlIxNkalgqVZ4qLBYLKklRXli+aOcmhBBCCCHEXJY9aNNa/+dyt+FmMZnNZ2r6/OmmpnU1m83zGrtcWVnJ2bNnqaioMIYLnjt3jtLS0kVt/4XeCzPa/uqlVznVdYpx9zif3PxJchNyGZ0Y5cmqJ42yhYmF3FZ0G+dHzzM0NITdbic1NZXe3l7AnyhlrnMrLCykrq7OP9wzMHg3JiaGQy2HUChyE3KNoZNCCCGEEEIshWUP2sSNobWmtrYWrTUJCQlYrVa01vh8PiO4yczMpKCggLa2Ns6dO0dubu680rynpaVx5113YlIm4/Fdd9216OdwoffCrNsHRv3roT1f9zyf3/F5njr/FMOuYQCiwqL40IYPYVImI4PR5GKPPT09gH8NkrkUFRVhs9kYGhoi0hOJUoqYmBicE05euvgSAHvy93BP6T1YTPJ1EkIIIYQQi0+uMm8SNpuN/v5+wsPDueWWWwgLC5uzbFZOFv2mfjITM+dV9/N1z/NOyztsydrCB9Z9YNETcmitabW3crH/orEtLyGP1qHWoHKt9laeqn4qKLh7cP2DxEX4F3WcGrSNjIzgdDqxWCxXnJNmsVjYs2cP9fX1XLx4kfSE9BkZIt9peYeWoRYe3vAwSVFJ132+QgghhBBCTDVzoYUVRin1u0qpk0qpCaXUE1cp+5BSqlEpNaKUelkplT1lX7hS6ntKqSGlVK9S6i+WvPE3iNfrpba2FvDPQbtSwKa15kdnfsQva37Jt49+m/7R/ivWfaH3Au+0+BdQPNV5irq+ukVps0/7aBpo4pnaZ/h/b/8/Hjv2GG6vf3xiSlQK95bdawSH4eZw47jTXaeN33fn7aY89fK8s9jYWEwmEyMjI7S0+OfGZWRkzLreyFQmk4ny8nLuvfde3r/t/cZzZsZeDmrb7e1868i3jLXchBBCCCGEWCyroaetE/hL4F1A5FyFlFIVwPeB9wPvAH8P/ATYHyjyp0AlUALEAK8qpZq01j9YuqYvPY/Hw/Hjx3E6nURHR191vYxDrYe42Ofv0XJ5XDx34Tk+ueWTs5Z1eVw8U/tM0LYX61+kLKXMGCq5UFprDrYc5EDzAUYmRmYtsyN3B3kJeXx+++dxuBwkRyXzzcPfDCqTGZvJu8reFbTNZDIRGxuL3W6nqakJ8K+vNl8Wi4U9BXuozKwkwhKBxWThUOshXqp/Ca/24vK4+Nm5n9E40MiWrC24vC4SIhJIikq65tdDCCGEEEKIkAjalFJmYCeQq7X+uVIqAtBaa9fVjtVa/ypQxzb8SwfM5ePAC1rrVwPl/wToUUoVa60vAZ8GHtVa9wF9Sql/Aj4DrLig7Vz3ORr7Gxm2D9Pb08vY6Bjh4eGU5JXwzIVn8Pq8QeUne6y01pzrPhe0r66vjgu9F4J6rADcXjfP1j6LfdwetL13pJejbUfZlbfrmtp+svMkL9a/OGN7dHg0a9PWUplRaST+yEvIM/ZXpFZQ2+vvTQw3h/Phyg/POscsPj4eu92Oz+fDarVecT7bXGKtl9cu25O/h/yEfH527mcMjg0CcKz9GMfajxllwsxh3FZ4m5HlUgghhBBCiAXRWi/rD1AInAccwEhg2weAHy6wnr8CnrjC/v8G/njatjrgASAR0ED2lH27gME56koACqb97A3UMevP9773PT3pe9/73pzl/G/JZVu2bJmz3KOPPmqUO3HixBXr/MS/fEJ/9aWv6q++9FW96d5Nc5bLKMnQX33pq/pPXv4T/dWXvnrFOu/98r1GnR/7o48tyjltfc9Wo84vffdLV6zzxIkTRp0fe2Tu59+yZYtRrqmp6Yp1Xuv7tHnz5jnLbbp3k/7jl/9Yj7hGrvo+TT2nRx99dF7npP0fypD97Mk5yTnJOck5yTnJOck5yTnJOV3+eeaZZyZ/L9DzjHVCYczWN/EHVAnARGDbG8DMhbOuTwxgn7ZtCIgN7GPa/sl9s/kK0DTt58DiNHNpzCcL5KRwczif3fZZosLmt8bahowN7M7ffa1NCzLZC5gUlcTHN3983sfNt62TyUgW29WSr2it6XZ2L8lzCyGEEEKI1U3pK6zZdUMaoFQvkKW1diulBrTWSYHtdq31vK+wlVJ/BeRorR+ZY/9/A0e11n8zZdsF4P8AbwMD+HvaOgP7bsE/nHJGakGlVAL+IHOqHOBAU1MTBQUF8232kmgaaKLD3oHJbEJrjdfnxad9WEwWws3hV028UZBQQEp0Csfbj/Prml8DYDFZyIrNotV+OWNjmCmMd5e9m525O1FKYR+38/LFlznXfQ6f9gHwhR1fCBrGOF23o3vGfDSAz237HIVJi7/+mdfr5Y033sBqtbJ3795Fz3Q53a/O/4qTHScBuG/NfezJ37OkzyeEEEIIIUJbc3MzhYWFAIVa6+b5HBMKc9pGgCim9HIppVKBK6ctXLhqYOOU54jDPzSzWms9qJTqDOzvDBTZFDhmBq31EP6eOMNSX/wvRGFS4aIEPNuyt3Gi4wTt9nY8Pk9QwJYTn8ND6x8iJTrF2BYfEc9DGx7CbDIbgUpdX90Vg7azXWdnbNtXsG9JAjYAs9nM7bffDtyY92xqhsmu4a4lfz4hhBBCCLH6hMLwyBeAbwSSj6CUMuGfn/bsfA5WSlkCx5oBs1IqQik1W077HwH3KqXuUEpF4s84eUT7k5AAPAH8iVIqRSmVD/wh/myTNy2lFPeX3x8U3JiUiTuL7+QLO74QFLBNtSZljfF7Xe/cSwBoramyXU6Rf9+a+/i9Xb/Hu0rfNecxi8FsNs9Ya22pZMRmGL93OSVoE0IIIYQQCxcKQdsfAfn4hyfG4+9x24w/Bf98/AkwFqjn44HfHwdQSjmVUvsAtNa1wGeBf8ffi1cBfHRKPX+Ov2ftEnAS+Lle4en+F0N2fDb7C/cDkBadxhd2fIE7iu+4Ygr7kuQSzMofFHU5uhgeH561XJu9zci4GBkWyc7cnWTEZoRUr+X1yoy53NPW4+zB4/MsY2uEEEIIIcRKtOzDI7XWduB2pdQW/GukdQMHtQ5Mirr68V8DvjbHvphpj38B/GKOshPAFwI/Yoq7S+5mT94eIsMi5xVQWS1WChILuDTg78Ss769nW/a2GeXOdl8eGrk2be2sKfpXuoiwCBIjExkcG8SnffQ4e8iKy5r38VprfNqH2XRjegaFEEIIIUToWfaeNqXUbQBa61Na6ye11m/PN2ATN05UeNSCesDKUsqM3093nmZ0YjRov9fnpbr78pTByozK629kiMqKvRykdTnmP0TS5XHxxKkn+PPX/pyjbUeXomlCCCGEEGIFWPagDXhWKXVRKfVHSqmMqxcXK8HUoK15sJl/OPAPvFj/Ig6XA4ADzQdwTjgBiAmPoSipaFnaeSMEJSOZZ9Dm0z5+du5nNPQ34NVeXr74Mm6ve6maKIQQQgghQlgojEfLBD4MfAb4C6XUi/jnnf1GetxWrtToVMpSyqjvqwdgwjvBgeYDHG49zMbMjUFZI/cW7L3iHLmVLjPu6kGb2+umvq+eals1HcMd+LTPmO8HMO4Zp7anlsrMyz2SIxMjHGs7xrBrmFsLbyUxcsbqFEIIIYQQYhVY9qBNa+3EH6T9u1JqLfBp4DHAC2QvZ9vEtVNK8YnNn6C6u5o3m97E5rQB4PF5jOUAALLjslf92mVTe9o6hzsZHBskMTIRj8/Dpf5LVHVXUdNbg8vjumI9p7pOUZlZicPl4J2WdzjadpQJr389+rq+Or6w4wvERyzN4uFCCCGEEGL5LHvQNk0zUAu0AFuWtyniepmUicrMSjZkbOBC7wXebHqTdnt70P73r3v/qu5lA4izxpEUlcTA6AAT3gl+eOqH5CbkUtNTw5h77IrHlqeWc6H3AgAN/Q08U/sMpzpO4fYFD5W0j9t54uQTPLr9UaLCo5bsXIQQQgghxI2ntNbL3QaUUrvwp+P/ENAF/AD4T631ilnYSilVADQ1NTVRUFCwzK0JTVprGvobONB8AJvTxt2ld8+aVXI1ahpo4olTT1wx5X9yVDIbMjZQkVpBmDkMhSI1OpX/OPEfNA02zXpMWnQa/aP9eLUXgNKUUj61+VOratkEIYQQQojVpLm5mcLCQoBCrXXzfI5Z9p42pVQtkAf8Cniv1vqtZW6SWCJKKUpTSilNKV3uptxwhUmFPLjuQX5e9fOg7YmRiWxI38CGjA1kxmbOGmxtyd4yI2jLisvi9qLbqUitoMpWxc/P+eu92HeR4+3H2ZG7Y+lORgghhBBC3FDLHrQB/wr8JLBemxCrVmVmJT58nGg/QWZsJpUZleTE51y1V2x9+nrebnqb3pFecuJzuKPoDspSyozjKjMqabe3807LOwA8X/88RUlFpESnLPk5CSGEEEKIpRcSwyNXAxkeKZaSx+dheHyYxMjEWYM8t9fNd45+x0j4silzEw9teOhGN1MIIYQQQlzFihkeqZR6Tmv9nsDvbwCzRo5a6ztuaMOECFEWk4WkqKQ594eZw3hg7QM8duwxwJ9N0qd9qz7JixBCCCHEzWC5hkcenPL7W8wRtAkh5i8vPo84axzDrmHG3GO02dvIT8hf7mYJIYQQQojrtCxBm9b6b6f8/rXlaIMQq41SirKUMk50nACgrrdOgjYhhBBCiFVg2cdOKaU659jeeqPbIsRKtyZ1jfF7XV/dMrZECCGEEEIslmUP2oDYBW6fQSmVoJR6UinlUEp1KKV+Z45yYUqp/6eUaldK2ZVS/6WUipmy/wml1IRSyjnlx7rA8xFi2RQnFWNWZgC6Hd3YxyUpqxBCCCHESrdsKf+VUn8a+DVsyu+TyoCWBVT3LfznkgUUA68opWq11m9MK/e/gf3AFmAc+Dn+JQc+M6XMP2ut/2gBzy1EyLBarBQmFdLQ3wDAqc5T3F50+1WP63H2YFImWSZACCGEECIELec6bZNXkpYpvwP4gG6CA6k5KaWigYeAzVprB3BGKfX9wPHTg7b3AV/XWvcEjv074EWl1Je01mPXeiJChJKylDIjaHu14VV6nD3cU3oPiZGJs5Y/3Xmap84/BcCj2x+VeXBCCCGEECFm2YI2rfXtAEqp72itv3gdVZXhX2+uZsq2M8A9s5RVgZ+pjyMCdZwNbPu8UurzQDPwd1rrJ2dUolQCkDBtc87Cmy7E4tuatZWjbUfpH+0H4Fz3Oapt1WzM2Mi+wn2kx6QbZftH+/ll9S+NxyfaT0jQJoQQQggRYpazpw2A6wzYAGKA4Wnbhph9TtxzwJeVUq/jHx45OQwyKvDvvwL/A7DjD/qeVEp1a63fnlbPV4A/u852C7EkIsIi+J2dv8Nv6n7D6c7TAPi0j9NdpznddZry1HL2FewjJTolKGADf/KSvpE+fnzmx4SZw7ir5C7KUsqW4zSEEEIIIUSA0nr5l0hTSn0WuAtIY0pP2HwW11ZKbQaOaq3Dp2z7MPB/tNabp5WNAP4O+EBg0z8C3wDytNZts9T9XcCltf7ytO0JzN7TdqCpqYmCgoKrNVuIG6Khv4E3G9+kabBpxj6lFLN9/3Pic2i3txuP16at5b419805vFIIIYQQQsxfc3MzhYWFAIVa6+b5HLPsPW1Kqb8Avgj8GHgAeAz4GPCjeVZRD2ilVIXWujawbRNQPb2g1nocfy/ZVwLP/W6gHeiYo+5ZI1qt9RD+3ryp5zHP5gpx45Qkl1CSXELbUBsHmg9Q01tjBGpz3bCZGrAB1PTUcLHvIrcW3sq+gn2EmcOWvN1CCCGEEOKyZe9pU0o1AR/UWp9USg1orZOUUvuA39VaPzzPOn4MWIFPA4XAq8DD07NHKqWy8C9z0AFsAH4G/KPW+vuB/R8EXgRG8ff8PQU8oLV+fR5tKACapKdNhLK+kT7ebn6bM51n8OEjPyGfbdnbcE44ebH+xaCyEZYIxj3jQdsSIxO5o/gO8hPySYpMkpsVQgghhBALdC09baEQtDm01rGB3weAZK21Vkr1a62T51lHAvA4cC/++W1/pbX+tlIqD6gB1mqtW5VSe/D34KXjz1D5z1rrb02p5wBQiX+IZhPwt1rrn82zDQVI0CZWCLfXjU/7sFr8yxB2Dnfyb0f+LajMe8vfS2ZcJs/WPkuXo2tGHZmxmXy48sPGMgE9zh5qemrIiM1gTcoaCeiEEEIIIWaxIodHAt1KqUytdRf+tdl2K6X6FlJBYLjiQ7Nsb8WfqGTy8Tv4e+LmqmffQp5XiJVq+hDHzNhMIsMiGXP7V76wmCxUZlQSFR7F79zyOxxvP84rDa8Y+wG6HF1879j32Jq9lZahFlqHWo19xUnF/Fb5b5EWk3ZjTkgIIYQQYhUzLXcDgJ9yeZ22x4DXgJPMf06bEOI6KaUoSiwyHq9JXUNUuD+pqkmZ2Jm7kz/Y8wfcWXwnJcklWEz++z2j7lEONB8ICtgALg1c4puHv8kLdS/g8rhmfU6tNQOjA3POrRNCCCGEEH7L3tOmtf7TKb9/Ryl1FogDXlq+Vglx89mavZXzPecxKRN78/fO2B8dHs0dxf6Eru32dn54+oeMTIwY+03KRF5CHi1DLWit8WkfB1sOcqbrDO8uezebMjcZQybH3eP89NxPaehvID0mnU9s/sSyZad0e92c7znP2S7/Uo3vW/s+4iPil6UtQgghhBCzWfY5bauFzGkTq0HfSB9mk3leAdTQ2BAHWg5gURay47IpTCok1hpLl6OL31z4Dc2DzUHlS1NK+fimjzPmHuOJU0/Q7eg29sWEx/DusneTFZdFSlQKZpN5sU9thm5HN8c7jnO262zQsM+CxAI+t+1zMidPCCGEEEtixSQiUUp9fz7ltNafWeq2LBYJ2oS4TGtNVXcVL9S/wLBr2Ni+Ln0dncOdDI4NznmsWZlJjUklIyaD9Jh00mPSSYtJw2Ky0OPs4XDrYfpG+7ir5C7Wp69fcLvOdp/lSOsR2uwzlmY0PLj+QbZkbVlQ3UIIIYQQ87GSEpHILWwhVjGlFJWZlaxJXcMrDa9wuPUwAOdt540yJmViX8E+jrUfC+rp8mov3Y7uoJ642fyy6pfkxudedSijx+ehx9mDfdzO201v02pvnVEmMTKR5KhkGvobAHix7kXKU8qNeX1CCCGEEMtpWYI2rfWnl+N5hRA3ltVi5T1r3oPL4+JU5ylje5gpjA9v/DDlqeVsz9nOiY4TdA13YXPaGBofmlfdbp+bF+tf5OHKuZdzrOut41fnf4Vzwjljn1mZWZu+lu3Z2ylKKmLCO8E3Dn0D+7idEfcI3z/5fR7Z+ggx4TGz1CyEEEIIcePInLZFIsMjhZibx+fhP078B61DrUSGRfKJzZ8gPyF/1rJj7jFsTpvx0+3oZmBsAJ/2YTFZyE/I51z3OaP83SV3kxSVREx4DNHh0USHR2Mfs3Ok7UhQoDjJrMzsLdjL7vzdMwKyC70X+K/T/2U8TolK4SMbP0JGbMYVz09rTeNAIzHWGNJj0hfy0gghhBDiJrNi5rQFNUCpJmDWRmiti2bbHookaBPiyjw+Dxf7LpITn0OsNfa66vrp2Z9Sbaued/nosGgy4zJJikxid/5uUqNT5yx7ouMEv675tbEUgVmZuaP4DvYX7p81OYlP+3iq+inOdJ3BpEx8YvMnKEspW/hJCSGEEOKmsJLmtE31tWmPs4FHge/d+KYIIZaKxWShIq1iUep6d9m7qe+rZ8I7cdWyFakVvH/d+4kOj55X3duytxFpieTJqifx+Dx4tZdXGl4hMiySnbk7g8q6vW6eOv8UVd1VgD+A+0XVL/jdXb8rywYIIYQQYtEse0/bbJRSm4C/1lq/Z7nbMl/S0ybEjdXl6KKmpwany8nIxAjOCf+/I27/2nHlKeVszd5KQWLBNaXv73H28NT5p2i3twMQHxHPH+79QywmCx6fhxPtJ3ir6a2g7JiT8uLz+Nz2z92QpQuEEEIIsbKsyOGRs1H+Kyy71jpuudsyXxK0CbH6uL1u/vHAPxqJTO6vuB+zMvNG4xszEqasS1tHbW8tPu0D4I7iO7iz+M4b3WQhhBBChLhrCdpMS9qia6CUigS+DPQsd1uEEDe3MHMYe/L3GI+fqX2Gp2ueDgrYYsJjeKDiAT6y8SPcXXK3sf3NxjfpHO68kc0VQgghxCq17HPalFI+ZiYicQCfWobmCCFEkJ25O3m7+e2gteTAn9zk1sJb2ZG7g3BzOAB7C/ZS21tL61ArPu3jyaoneWj9Q2THZwP+OW9urxuXx4XH5yExMvGahm4KIYQQ4uay7EEbcPu0xw6gXms9c2GlOSilEoDHgHuBYfzz4b49S7kw4K+AjwGxwDPAFyefSykVDnwTeBhwA9/RWv/pQk9ICLF6WC1W9uTv4dWGVwGIDItkb/5eduXtwmqxBpU1KRMPrnuQbx3+Fm6fm96RXr599NtEh0Uz4Z3A7XMHlU+JSuFDGz5kBHVCCCGEELNZ9qBNa/3WIlTzLfznkgUUA68opWq11m9MK/e/gf3AFmAc+Dnwr8BnAvv/FKgESoAY4FWlVJPW+geL0EYhxAq1v3C/0Zu2NWsrEWERc5ZNiU7h/rX386vzvzKWDZhMjjJd32gfjx1/jNuLbmdr9tbrXgpBCCGEEKtTSCQiUUrtA7bh7/0yaK3/Yh7HRgMDwGatdU1g2/8DsrTWn5hW9jjwda31TwKP9wMvAkla6zGlVAfwqNb6+cD+LwIf1Vrvm0c7CpBEJEKIAJvTxhuNb1Btq2bq39lwczjh5nBcHldQz5tSirVpa7mz+E5ZoFsIIYRYxVbkOm1Kqb8F/hCoBkan7NLAVYM2oAx/8FkzZdsZ4J7Zni7wM/VxBFCmlGrF31N3dlo9fzNLmxOAhGmbc+bRViHETSI9Jp0PV34Yl8fFhHfCCNYm57D1jfTx03M/pdvRDYDWmvO289T01FCUWERhUiFZsVmkxaSREJEgc9+EEEKIm9iyB234F9LeqbU+c43Hx+CfxzbVENN67QKeA76slHod//DIPwpsjwrUA2CfRz1fAf7smlorhLipWC3WGXPfwD+M8rd3/DZnu89ypvMMTYNNgD94uzRwiUsDl4yyYeYwUqNTSYtOIzo8mubBZmxOG7HWWNKi07i18FYKEgtu1CkJIYQQ4gYLhaBtBH8v27VyAtPXc4vHn9Bkur8N7DsaePyPwLuA9kA9BOqa/H2uev4FeGLathzgwPybLYS42YWZw9iWvY1t2dvoHO7klYZXqO+rn1HO7XXTOdw5YwmBwbFBBscGuTRwiU9t+RRFSUU3qulCCCGEuIFCIWj7R+BPlVJ/pq9tgl09oJVSFVrr2sC2TcwSCGqtx/H3kn0FQCn1bvwBW4fW2qeU6gQ2Ap1XqWcIfy+cQYYuCSGuR1ZcFp/a8ins43aaBptoGWyhZ6SHXmfvnIlMJnl8Hn505kd8btvnyIrLukEtFkIIIcSNsuyJSJRSucCr+OeT9U7dp7We121jpdSPASvwaaAwUN/D07NHKqWy8C8o3gFsAH4G/KPW+vuB/X8N3AY8AEQDrwB/O5/skZKIRAixVEYmRowAbtg1TEZsBgWJBdjH7PzozI8YdvlHiEeFRfHIlkdkCQEhhBAihF1LIpJQCNoOAWPALwlORILW+j/nWUcC8DiX12n7K631t5VSeUANsFZr3aqU2gP8CEgHuoF/1lp/a0o9k+u0fZjL67T933m2oQAJ2oQQN1i3o5t/P/HvxuLfVouVj238GMXJxTPKjrnHsI/bSY1OxWwy3+imCiGEEIKVG7Q5gZTA0MUVS4I2IcRy6bB38MSpJxh1++97KaXYlbuLu0vvNtaXc044+e7R7zI4NkhUWBTr09dzR/EdsjacEEIIcYNdS9BmWtIWzc95IGm5GyGEECtVdnw2n9v+OWLC/UlwtdYcaj3Etw5/i5ahFgBev/Q6g2ODAIy6RznWfoxnLzy7bG0WQgghxPyFQiKSHwG/Ukr9M/4hiwat9dvL0yQhhFhZ0mPS+dItX+LpmqeNDJT9o/08fvxxtmVv42THyRnH1PfW4/a6CTOH3ejmCiGEEGIBQiFo+0bg359N264BmXQhhBDzFBcRxyc3f5JTnad4ru45XB4XWmuOtx83yhQmFuJwOegb7cPtc9M02ERZStkytloIIYQQV7PswyO11qY5fiRgE0KIBVJKsTV7K1/e/WVKkktm7L+37F7WpK4xHs+2LpwQQgghQsuyB21CCCEWX3xEPI9seYT3r30/VosVgO0528mOzw7qWZOgbem1DLXwnaPf4bFjj2Efty/4+NGJUV5peIVTnafwad8StFAIIUSoW/bhkUqpP51rn9b6L25kW4QQYjVRSrEtZxtr09bSO9pLbnwuAAWJBYSbw5nwTtA/2k/fSB8p0SnL3NrVx6d9vN30Nq9des0Itp6qfopPb/00Sql51eH1eXni1BN0DHcAcLz9OA+ue1DeLyGEuMmEQk/b7dN+Pgb8Cf5FroUQQlynqPAo8hPyMSn/n3yLyUJx0uV13E53nWa5l39ZbRwuB0+cfIJXGl4J6h27NHCJo21H513Pm01vGgEbQOtQK48dfwyHy7Go7RVCCBHalr2nTWt9+/RtSqmvAHE3vjVCCHFzKEspo7a3FoA3G9+krreO+yvuJy8hb5lbtvLV9dbx1PmnGJkYMbZFh0cbj1+8+CKRYZFUZlTO6HHTWjMwNkDHcAft9nYOtx6eUf/IxAgHmw9y75p7l/ZEhBBChIxlX1x7NkopC9Cqtc5a7rbMlyyuLYRYSUYmRvjGO99gxH05sFBKsb9wP7cX3Y7FtOz39FYUl8dF82AzF3ovcKz9mLF98jW9teBWvnfse9icNmNfXkIeH934UcLN4RxqPUTzYDMdwx2Mucdm1F+QWMDO3J38/NzPAQgzh/E/9/1PY20+IcTNy+Fy4PK4ZNj0CnIti2uHatBWChzRWicvd1vmS4I2IcRK43A5ONB8gGNtx3D73Mb2zNhMPrThQ6TFpC1j61aOLkcXPzz1Q4Zdw0HbY62xfGjDhyhKKgKg29HND07+AOeE0yiTFJWECRN9o31z1p8QkcBnt32WxMhEvnXkW3Q7/Eua7i/czz2l9yzBGQkhVoq+kT6+efibeHwePlz5YTZkbFjuJol5WJFBm1Lq+9M2RQN3Ar/QWn9xGZp0TSRoE0KsVINjgzxV/RRNg03GNovJwj2l97A7b/e8k2bcjFweF/925N/oH+0P2l6WUsaD6x+c0RPm8rh4s/FNDrYcnDMTZFRYFFlxWWTHZZMdl01JcomRAbSqu4qfnfMvaxpuDufzOz5PZmzmEpyZEGIleP3S67x26TUAipOK+cy2zyxzi8R8XEvQFgrjX6ZfDdiAPwR+vAxtEUKIm05iZCKf3fZZDrUe4uWLL+PxefD4PDxf9zw1PTVsytxEUVIRyVErZvDDkrOP22kebOZM1xkjYAs3h7M1eyvFScWUp5bPGuxaLVbeVfYu8hLy+Nm5n+HxeQAIM4Xx7rJ3U5ZSRmJk4pyB8vr09aRFp9Ez0sOEd4Lvn/g+D214iMLEQsLMYUt3wkKIkNRqb738+1Arbq9b/hasUsve07ZaSE+bEGI1sDltPFn1pDEEb5JSioc3PCxDb/APR/rW4W8FDSkFeHjDw1RmVs67nob+Bp6tfZaosCjuX3v/vHvM2u3tfP/k93F5XMY2kzKRFp1GZlwmWXFZZMVmkZeQZ2QMFUKsPlpr/vrNvw6aB/uZrZ+hOLn4CkeJUHAtPW3L9tdcKbVOKfX/zbHvj5RS5Te6TUIIcbNLj0nnizu/yP7C/UG9PVprXqh/AbfXfYWjbw5nu8/OCNi252xfUMAGUJJcwh/s/QO+sPMLCxrimBOfw2e3fpbIsEhjm0/76HZ2c7rzNM9deI7Hjz/O9459LyiDpRBidekb7ZuRuOjSwKVlak2wut46fnL2J5zrPrfcTVk1lvMW3P8C5pp53QP87/lWpJRKUEo9qZRyKKU6lFK/c4Wyf66UaldK2ZVSR5RSt0zZ94RSakIp5ZzyY533GQkhxCowOZ/t93f9PveW3Ut0eDTgHxI4Wwr6m019X73x+4aMDbx/7fu5v+L+G9qG7PhsfnvHb7M5azMpUSmzDqdst7fzg5M/mDUbpRBi5Wsdap2xrXGgcRlacplP+3ip/iV+ePqHnLed56nqp+Tm0SJZzjlte4GvzLHvKeCPF1DXt/CfSxZQDLyilKrVWr8xtZBS6kPA54FbgUvA7wNPK6Wy9OVxov+stf6jBTy3EEKsSmkxaaTFpBFmDuOZ2mcAeKvpLTZnbSbWGrvMrVsezgmnsdi1UooHKh4I6vG6kVKiU/jg+g8C/gQnnY5OOof9P2e7z6K1psvRxePHH+fBdQ+SHZ+9LO1cTRoHGqnvq2dz1mbSY9KXuzniJtdmb5uxrX24nXH3OBFhEYv2PG6vG7PJfNXh1g6XgyerngwKHD0+D82DzaxLX7do7blZLWfQlqa1Hppth9barpRKnU8lSqlo4CFgs9baAZwJZKT8DPDGtOKFwAGt9cXAsT8Avg6kAL3XdBZCCLHKbcvexjst79A/2s+4Z5x/PvjP7CvYx21Ft910c6Ya+huYvMeXG5+7bAHbdFaLlcLEQgoTCwEoTCrk6fNPA/55it899l0qMyrZkLGB0uRSzCbzcjZ3RTrRcYJf1/warTVH247ysU0foyS5ZLmbJW5iU3vawkxhuH1utNY0DTZRkVYx6zEuj4sX618kzBzGu0rfddW/BWe6zvBU9VOEm8PZkLGBXXm7Zr1h0TrUyk/P/nTG0icATYNNErQtguX833ZEKZU7247A9vmO5yjDn1ClZsq2M8D6Wcr+DChRSpUHFvB+FDihtZ4asH1eKTWglDoV6JmbrX0JSqmCqT9AzjzbK4QQK4rZZObesnuNxxPeCV679Bov1r+4jK1aHlOHRpallC1jS65sW/Y2PrDuA4SZ/FnkfNrHma4z/Nfp/+Lr73yd052n51xyYJLH56F/tJ+bIWHZ4Nggx9qO0Tcy+6yNEx0nePr808ZrMeGd4Ienfsg/H/xnvvHON3i14dWg9feEWGouj4uekR7A3+u/JXuLse9K89peuvgSx9qP8U7LOxxvP37F53C4HDxT+ww+7WPcM87x9uN8+8i3GR6/HJhprTnceph/P/7vRsCmlGJt2lqjTPNg87WcophmOXva3ga+DPzPWfb9LvDmPOuJAaaH9UPAbGN3uoEDQA3gA/qBu6bs/1fgfwB24B7gSaVUt9b67Wn1fAX4s3m2TwghVryKtAo+sfkTvFT/knGhcKj1EGvT1lKQWLC8jbtBfNrHxb6LxuM1KWuWsTVXtzV7KwWJBfy65tdBw5UGxwb5ZfUvefbCsxQnFVOSXEJxUjHJUcnG3Di31813j36Xbmc3eQl5vG/t+1blcECf9nG49TCvXHwFt8+NSZnYm7+X24puM9bGGxgd4JmaZ2Yc69VeY7mHnsYeDjYfZHPWZvbk7yElOuWGnoeY22SgrZSiy9HF83XPkxiZyAMVD4Rkj/Nk0qeWoRbuLL4z6OaQx+fhUv8lanpqqO2tNc4tPSad8tRyjrYdBeae1zbmHuNU5ynjcZWtilvybpm1LMCrDa8GZamdbEN9Xz3bcrYB/iHzrzS8YuyPCovioQ0PkZ+Qz1++8Zdorel2djPmHguZkQkr1XIGbX8NHFFKJQE/AjqAbOBjwMPArnnW4wTipm2LBxyzlP0z4BYgH+gCPgK8qJSq0FoPa61PTSn7vFLqR8CD+APMqf4FeGLathz8AaEQQqxK5anllKWU8cPTP+Ri30W01jx1/im+tPNLizp/4ka41H+Ji/0XUSiiwqPYmrWVqPCoOctrrXmj8Q1G3aMAxITHrIhFrZOjkvnM1s/QOdxJla2Kkx0njXNweVzU9NRQ0+MfqJIYmUhpcim3Ft5KTU8N3U7/sg+tQ6186/C3uK3oNm4rvM240HV5XAyMDTA0NgT4ex5D8SJ4LjanjafPPx00L8infbzd/DZnu89y35r7WJe2jtcbX8ervQBkxGbwwfUf5Ofnfk7vSPCsCrfPzbH2YxzvOE5FagV7C/aSn5B/Q89JBGu3t/OjMz8iKiyK/YX7ea7uOSMpRnZcNjtzdy5zC2fqGO7gnZZ3APjPU//JRzZ+BJ/2UdtTS11f3YwgCvyLaucn5GNWZrzai81pw+FyzJh7fKLjRFAG4JahFpwTTmLCY2bU2TncycnOk8bjkuQSGvobAH/P2bacbbi9bt5uvnyJnBWXxUc3fpTEyET/49gsOoY70FrTMtRCeaokhr8eyxa0aa3PKaXuA74LPAJo/Att1wPv0VpXzbOqekAHAq/awLZNQPUsZSuBJ7XWk3+h/0sp9fXA9oOzNXOOtg/h780zzLUQqhBCrCYmZeL9a9/Pvx76V8Y94wyMDvDNw9/kA+s+MOfaQM4JJ2GmMKPnYrH4tI+3mt7ibNdZChILuKPoDuIipt/DC+byuHiu7jlOdpwM2l7VXcUXdnxh1qBjdGKUX1T/Imho5Lr0dSvm775Siuz4bLLjs7mt8DbeaX2Hkx0nsY/bg8oNjg1yrP0YNT016Gn//fm0j9cvvU5VdxXh5nAGxwaN4G9SQWIBH9n4kVkvAENJu72dEx0nONVxygjGACIsEYx7xgF/ptSfnv0pRUlFNA02GWV+q/y3yIzN5Hd3/S59I31YTBY6HZ0cbD5oJKjRWhvB8H1r7mNP/p4be4IC8L8PT9c8jcPlMBJkTHWs/Rg7cnaE3Pd4+hqZPz370znLxoTHsD5jPbcX3Y7VYiU3IdcYitg40MjGzI1G2cle5am01lzovcC27G0ztj9X95zRk1eWUsYdRXdcDtqG/M/R0N9gBJGJkYl8fvvngxb2LkwsNL4XTQNNErRdp+XsaUNr/SZQrpQqAdKAHq11wwLrGFFK/RL4S6XUp/EnG/kM/t666Y4CH1RK/Rj/sgIfBqLxB34opT4IvAiM4h82+XHggWs4NSGEWLXiI+L5rfLf4pfVvwRgaHyI75/8Pjtzd/Ku0ndhtVjRWlNlq+Jo21GaB5uJDovmka2PkBWXtShtGB4f5smqJ40L6t6RXs50nuG+NfexI3fHrMc0DTTx1PmnGBwbnLGvY7iD1xtf5+6Su4O2t9vb+enZnzI0PmRsK0gsmFFupYgIi+DO4ju5o+gO+kf7udh/kYb+BhoHGpnwTgAEzc2Ks8aREJlgJDyY3rs0VfNgM98+8m32Fuxlbepa4iPiQ+6C+KX6l4J6BgDMysztRbezr3AfVd1VvFD/gtEbM3WYWWlKqZHoxWKykBGbAfizeG5I30DzYDMHmg9Q11dnHPNOyzvsztsdcq/DajHmHuPF+hcZmRghNyGXgsQCsuOysZgsnO0+OyMAmqrb0U2bvY28hLwlb2fTYBNnOs9gNpmJCY8hJjyG6PBoYqwxJEYkBt1sutJ3DPzB0bq0daxNX0tufG5QMqjipGIjaLs0cMkI2mxOG69cfGXGjRqAGlvNjKCt2lZt1GNSJt6z5j0kRiYSZg7D7XUzODaIfdxOle1y/8qGjA1BARv4EyIdbPH3iUwGeuLaLWvQNikQqC0oWJvmS8Dj+Ic8DgNf01q/oZTKwz9/ba3WuhX4e/zB4Sn8c+EagQ9prXsC9XwZ+A/8PX5NwKNa69evo11CCLEqbc7ajNlk5tnaZ40el6NtR7nYf5H3VbyPU52nONN1xig/4h7hx2d+zBdv+eJ198TU99Xzy6pfMuIOXvvH7XPzzIVnyIjNCLoQc3vdvNLwCodaDwUl1ViXvg6r2WrM8Xir6S2yYrOMCfRH247yfN3zQb0xtxbcyt2ld6/4rJlKKVKiU0iJTmFX3i48Pg91vXU8WfUkHp/HKHd70e1sy/FnD3214dWgfRaThYSIBGKtsTQPNaO1xj5u57kLz/HchecwKzMJkQlkxmaSl5DHtuxti97buhCjE6Mcaj0UtC0vPo/3rbs8X29z1mbKU8t5peEVjrUfC/q83FV8F3NRSlGYVEhhUiE2p43Hjj3GuGcc+7gdm9NmBHhi8Witear6KWp7/YOsJv8NM4WRE59jzDcEf4+Uc8KJSZlIi0kzgrnj7ceXPGhze9385MxPZvRMT1JK8a7Sd7GvYB8we9CWEZvBurR1VKRVkBGTMedNgOLkYl679Brgv+HQ4+zh9cbXqbZVB32WN2du5nTXacAf3E2db+b2unnp4ktG2VtybzHmaObF5xlJTi72X6S2p9YotyF9w4z25Cfko5RCa03ncKfMa7tOIRG0Xa/AcMWHZtneij84m3zsAn4v8DNbPfuWqIlCCLHqVGZUUphYyK9rfs2F3guAP2nD909+f9byQ+ND/Pzcz/n01k/PO+ip7anlcOthsuOzubXgVt5uejuop0Qpxa7cXVwauITNaUNrza/O/4oNGRtoHGgkOjyaXmevkTwFIDIskvvL76cysxKtNYNjgzQNNqG15idnf0JKVAomZQo6JsISwQfXf3DONNorncVkYV36Oh70PcjPq34O+O/ob8negkmZ2Fewj40ZG2kfbic6PJrEiERirbHGxWNdbx2/qP5F0ELek4k6+kf7qbZVc7j1MA9UPEBpSumsbZiaMGIpnOs+ZwSdKVEpvH/d+42LyqkiwyK5v+J+tmZt5dkLz9Jmb2Nn7k5y4ueXJDo9Jp2S5BKqbf5ZGnV9dRK0LYFj7ceMQG0qt88dNKQ1KiyKr+z5Cr0jvUSFRTHmHuO7x74L+D8TMdYY1qWtIzsue0k+e32jfXMGbOD/3B9qOXQ5aBu9HLT9zs7fISkqad6BTk5cDuHmcCa8EwyODfKvh/91RvbXjZkbed+699Hl7KLb0Y3H5+HrB7/OvsJ97M3fy8GWg8ZohKiwKO4ovsM4tiCxwAjaXr74stE7nxKVMusc38iwSGNem0/7uNh/kcqMynmdi5hpVQRtQgghlkesNZaPb/o4p7tO89yF54w5QZMmMxj+6vyv0FrTONDIW41vcXvx7UHlPD4PncOdtA610u3oJsYag0/7jAn5lwYucajlUFBPT6w1loc3PExhUqH/AuXQvzLhnaB3pJfXL80+SKI0pZQPrP2AMRxJKcWD6x/kO0e+Y/Tc9Y0Gp33PjM3kIxs/QnJU8vW9WCtAZWYl4ZZw6nrr2JW3C4vp8mVCXEQcayPWznrcmtQ1/OGeP6TaVk21rZpOR2dQAAf+OXNPnHqCTZmbuHfNvUaPq9aak50nefniy3h8HkqSSqjMrGRd2uzzBq81uJvsWQDYlbfrqllPs+Oz+e2dv43L41pwD2F5avnloK23jv2F+xd0vLiyLkcXL9S9YDxel7YOq8VK02DTjOHPtxXdRmRYpNGjprUmMzaTLkcXHp/HfyOo6W3iI+KNYYf5CfmL1ps+tcdvMsujc8LJyMQI9X31+LSPYdcw4+5xLGaL0X6lFGkxaTOGHF6J2WSmILHAmH87NWCrSK3gjuI7jCHqmzI38aLDv2zLiHuEF+tfxOFyBC0DcHfJ3UEB49TEOpNDiME/NHKu7+Oa1DXGvLb63noJ2q6DBG1CCCGui1KKLVlbKE4q5umap420+HeV3MVthbehlMI+ZufVS68C8Hrj62THZ+PxeWgdaqVlqIXO4c6ggGw2U/eXppTywfUfNC78EyMTeVfpu3j2wrOzHhtmDuO+svvYnrN9xsVFYmQiX9r1Jd5ufpuT7Sdx+9zGeW3L3sZ71rxnQRdOK115avk1JQyICo9iR+4OY06hy+Oif7SfpsEm3mh8wwjiznSdob6vnvvW3Ed6TDov1r8YtK7U+Z7znO85z90ld3Nb0W2Af2hjTU8NVbYqGgcaSY1O5dNbPz0jO95cbE4b7fZ2wN+ruJALx2sZ0lmaUmoMC2u1tzI6MUpUeBQ+7cPr895Un6fFNuYe4ydnf2J8TzNiM3how0PGazo8PkzzYDPtw+0kRCawKzc4GblSineXvZufnv1p0E0m+7idQ62HONR6iPSYdD626WOLcqNm6tp/xUnF3FN6j/H4m4e/aQzV7BnpMeYDAyREJFzT56QspWzGepJ3Ft85o6d4T/4eLCYLB5sPGnN2J2+SAWTEZBhp/SflJvjn0E1d49GkTEEJT6YrTyk3bqJNBqkrfXj5cpGgTQghxKKIj4jnU5s/Rau9lXBzeNBwmf1F+7nYf5GWoRZ82sd/nvrPedebF59H72gvY+4xTMrE3SV3s69g34zga2fuTpoGm6i2VZMSlcKthbdiUibcXjelKaVGGuq52v7e8vdyV/Fd9Iz0YFEW4iLi5h0UiJmsFitZcVlkxWWxMXMjz114jnPd5wAYdY8aiWzm8krDK0x4J+h0dHKp/1LQhaLNaePXNb/m45s+ftUeN5/2cbD5coLo8tTyKy7vsBhiwmPIicuhzd6G1pqL/RfJjsvmh6d/yPD4MB/Z+BHWpIb2On+haNw9zpNVTzIwOgBAuDmchzc8HBTcxEXEUZlZSWXm3IF5SXIJf7T/j2job+B8z3ku9F4I6hm2OW187+j3+Njmj133sg1Te9qmB4Fp0WlBQVuE5fLSKde61t+27G30OHuY8E6wM3fnnHP2TMrErrxdbM/ZzuPHHzduaky6b819M4KrcHM4eQl5RpKSCEsE7614L6nRqXO2Jysuy5hTOOIeod3evqB5hF2OLloGW6jMqFzy722ok6BNCCHEolFKzXqRY1ImPrj+g3zz8DeNeRDTJUclkxefR3Z8NvZxO12OLvIT8rmt6DZGJka40HuBvIS8ORd5Vkrx4coPM+IeITos+prmp0SGRcraWksgJjyGhysfZlPmJp698OyMIWxKKXbn7WZz1mZ+c+E3xkXhW01vzVnnhd4LnOo8xdbsrXOWaR1q5b9r/zsoi+CWrC3XdzLztCZ1jbEG3CsNr+B0OY3eoUOthyRoW4Ax9xhvNb3F0bajQX8/Hlz/IGkxaddUZ5g5jIq0CirSKvD6vDQNNlHTU8OpjlO4fW5G3CP84MQP+OItX7yuheWnDreeHohNDXZ6nb1B612mRs0dCF1JmDmMB9bOP/G5xWThofUP8W9H/s14bdemrZ1zCZf3rHkPLze8TGpUKvuL9l81sZRSijWpa4xlVur66uYdtDknnDx+/HFcHhe1vbV8euun531eq5EEbUIIIW6IpKgkPrDuA0YPS3ZcNvkJ+eQl5JGbkHvF//xjrbFsz9l+1edQSoX8OmE3szWpayhILOC1S68Z2TzXpa3jjuI7jGQdH934Ub5z9DszAru8+DzWZ6zH5rQZF4C/Ov8rXqh/gdLkUu4tu9eYqzg6McrLDS9zouNE0Lye4qTiOROhLLYN6Rt449IbeLV3xrm0DLagtZalAK5Ca83Z7rO8UPdC0FIUALcW3sr69PWL8jxmk5mS5BJKkkvYlLmJH535ESMTI7h9bn5+7udUpFVwquMU5anl3F9x/4Letyv2tE0JOHtGeogKu9yTdKXeq8WWEu1PzPNU9VNEh0dz35r75iybFZfFI1seWVD9a1IuB23H247j9XnZk7/nqiMZqrurjXXgGvob6LB3kB2fvaDndnlcTHgnVsWoCQnahBBC3DAbMjYYGRinJrkQNw+rxcp9a+5jb/5evNo7Y9hqdHg0j2x5hF/X/BqNZm3aWtalrSMhMgHwX4Q1DjQagdCYe4xz3ee42H+Rvfl7CTOH8VbTW0GJEsJMYdxWdBt7C/besPk0KdEpPLThIZ6uedq48Jzk9rlxTjhXxYXkUrE5bTxb+2xQJkjwDyncW7B3yXpM8xLy+Oy2z/KdI9/B7XNjc9qwOW2AP2NlZUYlhUmF86pr3D1ufA4nl8iYKi36ctA2md1y0o0M2sCfDXhNyhrMJvOi/20uSS7BYrLg8XkYcY9woPkAVd1V/P7u37/inNHJ4dSTDrUe4qENM5LFz6llqIUfnf4Ro+5RMmMz2ZCxgQ3pG0iKSrrmc1lO8j+mEEKIG0qCNQEELSg8XUp0Cp/b/rlZ91ktVj668aP8d+1/Y3PYjCGHY+4xXml4ZUb58tRy3rPmPctyobYhYwNZcVn85sJvGBgdCBoq1+XomjNoc3vd+LRvWde1Wy4uj4s3Gt/gnZZ3guYxxlnjuHfNvWxInztT4WJJj0nnPeXv4dc1v56x72TnyXkHbdN72aa3OykqyUjsMTg2aCQEgWuf03Y9lurzZrVYuaf0HiNDLPiXgHm54WXeW/5eABwuB02DTTQPNmMft7M2bS0tQy1B9ZzrPsf+wv2EmcP8P6Ywws3hs34eWoda+c9T/2ncMOlydNHl6OJUxyn+YO8fLMl5LjX5n1MIIYQQK0pWXBZf3PlFYxmJp2uenjEEMT4int8q/y0qUiuWdRhiclQyn9ryKQCeqX2Go21HAeh2dFOWUjajfLejm8ePP47X5+Uz2z5DXkLeTZF1UmvN+Z7zPF/3PPZxu7HdpEzsyd/D7UW339Agdlv2NlqHWjnVeSpoe7WtmveWv9fI9Ng81ExVdxVt9ja2Z283sqdC8Hy22TJRWkwWkqOSjQW1J4fyRoZFrrph3nvy97AtexsnOk7wfN3zABxtO4rL7aLN3jZjqZXJtT+n8mkf3zj0jRnbw0z+IC7OGsf9a+8nOiw6KGCbakPGzEXAVwoJ2oQQQgixIimlKE4u5vd2/R5nu87S7ezGPm4nJy6H3fm7Q66nKiPm8iLbXY6uWcs8X/e8kYr+SNsRrBYrjx17DLPJzEc3fvSq68utNA39DVTbqmm3t894TQoSC7i/4v7rSgRyrZRSfGDdB9idv5ukyCS+d+x72Jw23F43bzW9hU/7ONd9LijAfNbxLOvT1xtZDq80n21SWnSaEbRNSo9JX5XzHa0WK7vzdlPfV09DfwNa66D1E+dSnlo+axA3ye1z4/a5GXWP8uMzPyYhIsH4DkWHRfPxzR+nf7Sfalu1BG1CCCGEEMvFarEG9XCEqslkK0BQRstJDf0NQWvWNfQ1ABgXoE+cfIKv7PmKMb8vFA2NDXFp4BJmk5kISwRWsxWrxf8TEx4TFEh32Dt44tQTQcliwD+v8d6ye9mUuWlZgxellLF0ydbsrUYP0VxZTX3ax6WBS0ZgEJQ5Mmr24Y6pManQE7zt1oJbr7fpIUspxf0V9/PNQ980hjaDv9cxJz6HgsQCznadNXrOLSYLD657kGcvPEtNTw3h5nDCzGF4vB4mfBO4ve6g+kcmRox5hCZl4lNbPkV2fDZ5CXlsztp84050CUjQJoQQQghxA0z2oGit6Rvtw+11G0Me3V43L198Oaj8iHuEs11njcdun5vvn/w+efF5l+f1mP3zevLi8+Y912qpjE6M8p2j35mR6XGSUor16eu5q/guUqJTeKPxjaCAzaRM7MjdwV3FdxEZFnmjmj0vGzM38mL9i0Hz7ACiwqKIi4gzgvCG/gYjaJtPT1t6dHAv4rr0dat+OYjkqGQ+sfkTnO48TVJUEoWJheTE5xjfhR05O3ji5BP0jPSwM3cnUeFRPFz58Kx1aa1x+9w0DTTxX2f+K+jzdEfxHQvONhnKJGgTQgghhLgBrBYrSZFJ9I/249M+uhxdjLnHqOquoqa3ZtY5ONP1j/YHBQNTPbLlkRu2pMFsXmt8bc6ADfwX2FXdVZy3nWdH7g5qe2uNfR+u/DDFScUhu4ByTHgM+wr28VbTW4Sbw1mbtpbKjEqKk4tpt7fz+PHHAYxhfxActM2VWCQ9Njho+601v7VEZxBaipOL51wLLj4int/b/XsMjQ3NyC47nVKKcHM4a1LXcGfRnbx66VUAcuJz2F+4f9HbvZwkaBNCCCGEuEEyYjOMi/nHjz8+o+cG/D1yk2nmJ4Wbw+dcmH7SC/UvUJxcfMOWNZiqx9nDsbZjxuPy1HJ82ofL48LldeHyuIwhbz7t40jrEaPs2rS1K2Ku0d0ld7MrbxdWi5Vwc7ixPTc+F6vFisvjYmh8iP7RfiLCIhhzjwH+926uxCLpMenGPK9719x7xayqNxOTMi044+ttRbdhMVvoH+3nzuI7l+V7sJRWRdCmlEoAHgPuBYaBv9Zaf3uOsn8OfBaIBWqBr2itjwT2hQPfBB4G3MB3tNZ/uuQnIIQQQoibQmZsJudt5wFmBGzJUclsy97G5qzN/N1bfxe079NbP43F5L8gdfvcuL1uJrz+OT0Hmg8w4Z3A5rRxuvM0W7O33rDzOdlxksOthxkaHzLOpzipmI9v+viM+WitQ628UPcCrfbWoO23Fd52g1p7fZRSsy7TYDaZKUosMnoOL/ZfDEo6kxqdesW5ee8pfw/v4T2L3+CbjFKKfQX7lrsZS2ZVBG3At/CfSxZQDLyilKrVWr8xtZBS6kPA54FbgUvA7wNPK6WytL8v+0+BSqAEiAFeVUo1aa1/cONORQghhBCrVWFi8LyzxMhENqRvYEPGBjJjM42L+8zYTCObYpw1jtz4XJRSZMVlzVrva5deA+DVhlfZkLEhqCdoqfSN9PF0zdNB84iUUty75t5Zg5S8hDw+u/2z/ObCbzjefhyAspSyVTHvqCS5xAjaGvobMCuzse9GL5QtVqcVH7QppaKBh4DNWmsHcEYp9X3gM8Ab04oXAge01hcDx/4A+DqQAvQCnwYe1Vr3AX1KqX8K1CNBmxBCCCGuW35CPh9c/0EGxgYoTS41grHpylLKjKBtbfraK/bU7Mnfw9G2ozgnnAy7hnmz8U3uKb1nyc5h0tvNb89IJHJH0R1GxsXZWEwWHqh4gNLkUrocXezO273k7bwRSpJLjN8bBxqJj4g3HkvQJhbDig/agDJAaa1rpmw7A8z21+pnwMNKqXKgAXgUOKG17lVKJeLvqTs7pfwZ4G+mVxIYjpkwbXPOtTVfCCGEEDcLpdS8Uo/vyd9Dy1ALPu276vBBq8XK3aV38/T5pwE40HyAyozKoCUGFpt93M6ZzjPG409s/gRFSUXz6uFTSrEufR3r0tctWftutOSoZOIj4rGP25nwThhDYEGCNrE4VkPQFoN/HttUQ/jnrE3XDRwAagAf0A/cNaUeAPuU8nPV8xXgz66lsUIIIYQQVxMdHs2j2x+dd/mtWVs53Xma5sFmfNrHf9f8N4/ueHTJkjEcaD6AV3sBf+9heWr5kjzPSqGUIi8hj6ruKoCgLJoStInFsBrSqjiB6al24gHHLGX/DLgFyAcigP8JvKiUigvUw7S65qrnX/APtZz6s3pnPgohhBAipCmleKDiAWMuVau9lWdqn5mxcPX10lrzdtPbHG49bGxbbanVr1VufO6MbdeSBVGI2ayGnrZ6QCulKrTWkwt+bAKqZylbCTyptW4LPP4vpdTXgUqt9UGlVCewEei8Uj1a6yH8vXCGK401F0IIIYRYamkxadxedLuxVtXx9uP4tI+NGRvJic/BarFec90Ol4PanlrOdZ+jabDJ2J6XkEdZStl1t301mC1oS4pMwmJaDZfbYrmt+E+R1npEKfVL4C+VUp/G3+v1Gfxp+6c7CnxQKfVjoAf4MBCNP/ADeAL4E6XU8cD2PwT+dmnPQAghhBBicdxWdBv9o/2c7joN+FPyn+w4iVKK1KhUsuOzyYnLITc+l/TY9CsGFAOjA9T21lJtq6bN3jaj164gsYCPbfyY3LgOyIrLwmKy4PF5jG1pMWnL2CKxmqz4oC3gS8DjQBf++W1f01q/oZTKwz9/ba3WuhX4eyANOIV/Dlsj8CGtdU+gnj/Hn0nyEpfXaZPMkUIIIYRYEZRSfGD9Bxj3jBsp6ME/rLFnpIeekR5Od/oDOovJQpg5DIDS5FLuW3MfPu3jVOcpztvOG9krZ7M1eyv3V9wvvUhTWEwWsmKzgtahS4lOWcYWidVELfZY55uVUqoAaGpqaqKgoGCZWyOEEEKIm5lP+6jurqZxsJF2ezs2p23GYt7TWS1W3F73rOWUUhQmFrI2bS1r09YGpbQXlz1f9zzvtLxjPP7g+g/OK1uouLk0NzdTWFgIUKi1bp7PMXJ7RAghhBBilTEpE5WZlVRmVgIw4Z2gy9FFu72dNnsb7fZ2BscGg45xeVxBjy0mC8VJxaxNX0t5ajkx4TGIK5s+r00yR4rFIkGbEEIIIcQqF24OJz8hn/yEfGOby+PC6/PSPtzO0+efZtjlX0GpOKmYrdlbWZOyhoiwiOVq8oqUl5AX9FiCNrFYJGgTQgghhLgJTWaTLEsp48u7v0x9fz3pMemkx6Qvc8tWrviIeEpTSrnYd5GK1IrrytgpxFQStAkhhBBC3OQiwiKozKhc7masCp/c/El6nD2SOVIsKgnahBBCCCGEWCQmZSIjNmO5myFWGdNyN0AIIYQQQgghxNwkaBNCCCGEEEKIECZBmxBCCCGEEEKEMAnahBBCCCGEECKESdAmhBBCCCGEECFMskcuHjNAe3v7crdDCCGEEEIIEaKmxAvm+R6jtNZL05qbjFJqL3BgudshhBBCCCGEWBH2aa0PzqegBG2LRCllBbYDXYB3mZuzWuTgD4T3AZO3JJqAwmVrkZhqMd6L2d5jsTAr4Ttxs7zPK+G9WAqh+P7erO/FUrnW91jeh9Ax9b0Ixe/szaQJKAEygeNaa9d8DpLhkYsk8ILPK1IW86OUmvy1XWvdPLlt8nexvBbjvZjtPRYLsxK+EzfL+7wS3oulEIrv7836XiyVa32P5X0IHVPfi1D8zt5MAu/FJeDSQo6TRCRCCCGEEEIIEcIkaBMrzZ8vdwOEQd6L0CDvQ+iQ9yJ0yHsRGuR9CB3yXoSOa3ovZE6bCFlKqQICY7Cl+351kvf45iDv8+om7+/qJ+/x6iLv58okPW0ilA3hvxsxtLzNEEtoCHmPbwZDyPu8mg0h7+9qN4S8x6vJEPJ+rjjS0yaEEEIIIYQQIUx62oQQQgghhBAihEnQJoQQQgghhBAhTII2IYQQQgghhAhhErQJIYQQQgghRAiToE0IIYQQQgghQpgEbUIIIYQQQggRwiRoE0IIIYQQQogQJkGbEEIIIYQQQoQwCdqEEEIIIYQQIoRJ0CaEEEIIIYQQIUyCNiGEEEIIIYQIYRK0CSGEEEIIIUQIk6BNCCGEEEIIIUKYBG1CCCGEEEIIEcIkaBNCCCGEEEKIECZBmxBCCCGEEEKEMAnahBBCCCGEECKESdAmhBBCCCGEECFMgjYhhBBCCCGECGEStAkhhBBCCCFECJOgTQghhBBCCCFCmARtQgghhBBCCBHCJGgTQgghhBBCiBAmQZsQQgghhBBChDAJ2oQQQgghhBAihEnQJoQQQgghhBAhTII2IYQQQgghhAhhErQJIYQQQgghRAiToE0IIYQQQgghQpgEbUIIIYQQQggRwiRoE0IIIYQQQogQJkGbEEIIIYQQQoQwCdqEEEIIIYQQIoRJ0CaEEEIIIYQQIUyCNiGEEEIIIYQIYRK0CSGEEEIIIUQIk6BNCCGEEEIIIUKYBG1CCCGEEEIIEcIkaBNCCCGEEEKIECZBmxBCCCGEEEKEMAnahBBCCCGEECKESdAmhBBCCCGEECFMgjYhhBBCCCGECGEStAkhhBBCCCFECJOgTQghhBBCCCFCmARtQgghhBBCCBHCJGgTQgghhBBCiBAmQZsQQgghhBBChDAJ2oQQQgghhBAihEnQJoQQQgghhBAhTII2IYQQQgghhAhhErQJIYQQQgghRAiToE0IIYQQQgghQpgEbUIIIYQQQggRwiRoE0IIIYQQQogQJkGbEEIIIYQQQoQwCdqEEEIIIYQQIoRJ0CaEEEIIIYQQIUyCNiGEEEIIIYQIYRK0CSGEEEIIIUQIk6BNCCGEEEIIIUKYBG1CCCGEEEIIEcIkaBNCCCGEEEKIECZBmxBCCCGEEEKEMAnahBBCCCGEECKESdAmhBBCCCGEECFMgjYhhBBCCCGECGEStAkhhBBCCCFECJOgTQghhBBCCCFCmARtQgghhBBCCBHCJGgTQgghhBBCiBAmQZsQQgghhBBChDAJ2oQQQgghhBAihEnQJoQQQgghhBAhTII2IYQQQgghhAhhErQJIYQQQgghRAiToE0IIYQQQgghQpgEbUIIcZNQSj2hlHriOuv4qlLqhUVqkrgGSqlHlFLNIdCOjymlzl+lzJK0VSnlVErtW+x6r4dS6jallF7udgghVicJ2oQQYpEppSqVUk8qpboDF5eNSqkfKqXWL3fbFkIp9aZS6mtTt2mt/0Zrfe8yNWlOSqlmpdQjy92Om4nW+sda63WTjxfjpsACnjtGa33gRjyXEEKEAgnahBBiESmlbgOOAh3ATiAW2Aa8AzywbA1boZRS4TfwuUxKKfONer6VTCkVttxtEEKIm4kEbUIIsbi+Bzyptf4DrXWL9hvQWn9Pa/3XMHuPxPReLaWUVkr9vlLqmFJqRCl1RCmVF9jWqpQaUEr93ZTyM4ZmXW1omlLqL5VSDYHewJbAY1Ng33eBfcBXA/u7A9u/ppR6M/D77yilLkyrMzZQ/o7A4wSl1HcC9fcrpZ5XShVdoU2PBHrNvqKUagVaA9vLlVK/UUrZlFIdSqlvK6WiA/teAPKA7wae+9hsr2lgm9Ejp5QqCLzOn1VKVQOjQEWgzB8rpV5QSjmUUheVUg9MqWOjUuotpdSQUmpQKXVSKbXmCuf0gFLqtFLKrpSqUUp9dsq+yTZ8XCl1LvB8h5RS5XPVN0v9kUqpf5ryGr+slFo7ZX+YUuofAj2/vUqpvw+0/2tTyjwe+Fw5A+f7u7O8bn+mlHpFKeUAvjD186WU+irwMeBjgTqcSqnkKcf/dqB9dqXUz5VSsdPq/lOl1GuBz3q1UmqzUurhQFvsSqkfqCmBYuA1u23K4z1KqTcC5z+glHr5Cq/Xh5RS55VSw0qpPqXUq1P2RSml/lb5vxeT7/2DgX3rlVKvB44ZCny+Nl3lvfmkUups4BzOK6U+fKXyQggxFwnahBBikSilSoEy4L8WqcqPAw8CqfgDileBNKAEuBP4Q6XU/uuovw64DX9v4AeBLwKfBdBa/zZwAPibwFC0jFmO/wmQr5TaM2Xbw4ANeEMppYCngRhgM5AFnAN+o67cU5OD/3WsAIqUUimBtryMPzjbCJQC/xJo6734g7vfDrR1x8JeBj4FvDvQzvrAtkeBrwLxwGPAD5VSMYF93wZeA1LwvzefBYZmq1gpdQvwJPDnQBLw28A/K6U+MK3oJ4C7A/V1A/+2gPb/E3A7cCuQDZwCXpkSGP1v4APA/sB+B7B7Wh1HgK1AHPB7wD8ppe6eVuYLwJ8Eynx/6g6t9d8APwZ+HHgPYrTW/YHd2fg/s+X439NtwFem1f2pwPMmAGeAp/C/HpuASuC9wEdnO3nlH3b8GvAz/J+dDOAf5igbBfwI+D2tdVyg/N9MKfIf+F/L+7TWscAdwMUp+/86cEw2cAF4eq7PcuDmwF8AnwES8b9+31NK7Z2tvBBCXIkEbUIIsXjSAv92LFJ9X9dat2mtR4Ff4r9Q/DOt9YTW+jRQjf8C+JporX+ktW4P9AYex3/RfdcCjh/Cf3H92SmbPwt8X2ut8Qdqu4AvBHobXcAf4w+8dl6hah/wh1rrkcC5fxK4oLX+V621S2vdhz94+KRanOGMfx54HTxa64nAtse01qe11j7gO/gDlcnetInAOeQHjjmjtbbNUfengf/WWv9aa+3VWr8NPA58fpY22LTW4/gDonkFnsrfM/pp4E8CPbvj+F9jM/CeQLFHgL/XWtcFzu+vgZ6p9Wit/0Nr3au19mmtXwReZOZn4T+01kcDn5fR+bQvwA38kdZ6TGvdiT+Qn35+/661rtFau/HfDCgE/m/gM9ACvM3cn/UvAi8GerPHAt+PV67SngqlVIrWelxr/TqAUioV+DD+4L8eIPD9Oxf4vVpr/VrgmBHg/wMK8Aeks/lD4C+11icDr+vBwLk9coW2CSHErCRoE0KIxTN5IZy9SPV1Tfl9FOjVWnunbYvlGimlvqiUOhMY4jeEvycg7SqHTffvwIeUUjGBIXnbgR8E9pUC4UBnYDjZENCPP6DIvUKd3YHgY1IpsHOyjkA9LwMaf6/K9WqaZVvn5C9aa2fg18nX+pHAc7+ulGpTSn1dBYZqziIXaJy2rQF/0Dfr8wFO/L1+85ECREx9jsBnpHnKc+QEHk/u9wFtk4+V3/9VStUGhvENAfcy87Mw2+s0Hz1aa8+Ux05mfm6nf9bRWk/fNtdnvQB/r/FVBYLNd+MPSOuUf0jq5FDQgsC/s9al/ENZfxF4z4e5/HrM9Z0pBb4x7XP7Cfw9zkIIsSCW5W6AEEKsFlrri0qpevxze169QlEHM4ON672QcwAopaIDvQBXrFMptRv/8MK7gUNaa49S6hv4hx5O8s3jed/Cf8H9MP6hby8GelPAP8xvDEiZdtF+NdOftxt4U2t9zwKOAf9rYgRTSikLs19gz+c8DYGen0cDdZYA/w0MA382S/E2/L1GUxUTmKu3CPqA8cBzXAi0yQzkT3mOdi4HJJO9c1OD5o8AvwvcA1RprX1Kqf8G1LTnutrr5GN5bgY34x9OOy+BrJMHAsN39wMvKv/SBdWBImXA2VkOfQz/671Fa92rlEoEBpj5Ok3qBv5Ya/2T+bZNCCHmIj1tQgixuL4APKz8iR/yAr0YCcqf7OKrgTIngDuVUmXKnyTiK8y8sF+oevxByheUPwviJmYOwZsqHvACvYBX+de8+ti0Mt1c5WI4MAzy+/jP+xP4e94mHQRqgW8rpdIAlFKJSqkHA3OL5usHwDblT2YRFXhNc5VS75vW1unJQE4A71NKZSqlIoG/A64766HyJ+DICVz0DwMe/K/lbJ4ItOG9SilzYD7TowS/Ttcs0Gv2BPCXgc9bBP55VBp4LlDsP4H/Gfi8heMf1jc1eI0PnEOf//TU+/EH8wvVDZQs0pDVhfgOcK9S6lGlVIRSKlwpNeswX6VUhlLqIaVUQuCzO4T/tfJqrXuBn+L/vJYGyucopSoDh8cDI8CQUioe+PurtOtfgD9TSm0LfCetSqntSqmt13vCQoibjwRtQgixiLTWb+Kfx5WPP2hwAKfxZ2L8daDYj4Ff4E/+0IY/+cI71/m8DvzJHL6EP5D4W/w9A3N5CX/ShXfw9xb8fqBdU/0TsD4wtKv9CnX9J7AF/8Xvb6a0yYv/4n8cOKr8WQfPAu8PlJ3vubXiT5zxLuAS/gvtl4ANU4r9BfDBwFDPQ4FtX8ef1KIu8NPA4sw3vB04hn+Y31ngMHMkvtBaH8bfk/WXwCD+YO1/a61/uQjtmPQ/8CdqOYh/mOVO4J7AZwLg/wHPBMp04A8+juN/X8Af9L0N1OAPvO7F33u4UI/hH/o6mV0x6VpOZqG01tX4P2efwN/r2wX8rzmKK/zJYBqVUk78c0W/GphrCP6A+h3gpcD+N7g8Z+3L+If/DuH/bl+pNx2t9Tfwfy6/h/871oH/czLXUFohhJiT8t9oEkIIIcTNINAT1gH8gdb6p8vdHiGEEFcnPW1CCCHEKqaUildKvScwFDeGy8NEX1jmpgkhhJgnCdqEEEKI1c0EfA1/5s52/MMn7w0s2SCEEGIFkOGRQgghhBBCCBHCpKdNCCGEEEIIIUKYrNO2SJRSVvxZpbqYO/WzEEIIIYQQ4uZmBjKB41pr13wOkKBt8WzHn05ZCCGEEEIIIa5mH/7lWq5KgrbF0wVw4MABcnJylrstQgghhBBCiBDU3t7Ovn37IBA/zIcEbYvHC5CTk0NBQcEyN0UIIYQQQggR4uY9pUoSkQghhBBCCCFECJOgTQghhBBCCCFCmARtQgghhBBCCBHCJGgTQgghhBBCiBAmQZsQQgghhJgXrTUOh4Px8XG01svdHCFuGpI9UgghhBDiJtPb28ulS5cwm81ER0fjdDoZHh4mJSWFsrIyoqKigso7nU7a2tpob29nfHwcAIvFwvbt20lJSVmOUxDipiJBmxBCCCHETWJ8fJzz58/T2dk56/62tjY6OjrIzc0lPz+foaEh2traGBwcNMpERETg9Xpxu920trZK0CbEDSBBmxBCCCHEKqe1pqmpibq6OjweD2azmdLSUqKionA6nURHRxMTE0NTUxMdHR20tLTQ0tJiHG+xWMjKyiI3N5fExERGR0d5/fXX6enpQWuNUmoZz06I1U+CNiGEEEKIVWxgYICqqiqGh4cByMjIYN26dTOGQAJs3ryZ0tJSLl26RHd3N3FxceTm5pKRkYHFcvmyMTo6mujoaEZGRhgcHCQpKemGnY8QNyMJ2oQQQgghViGXy0VtbS1tbW0AREVFsX79etLT0694XExMDBs3bmTjxo1XLJeWlkZTUxM9PT0StAmxxCRoE0IIIYRYZYaHhzl8+DATExOYTCZKSkooKSnBbDYv2nNMDdrKy8vndYzWGpvNxsWLFxkbG2Pv3r2z9vgJIYJJ0CaEEEKIJae1xuv14vF4cLvdeL1eIiMjsVqt11Sfy+XCYrFgNpvx+Xx0d3djNptJSkoiLCzsqm0ZHR0lKirqhszFmjxvq9WK1pozZ84wMDBAcXExeXl5mEyzr8B0/vx5vF4vGzZsWFA7R0dHOXLkCBMTEyQnJ7Nx40aio6MX63QMycnJmM1m7HY74+PjREREXPWYqqqqoLlyzc3NrF27dtHbJsRqI0GbEEIIIZbE6Ogo58+fp6+vD4/HM2O/yWSitLSU4uLiefcA+Xw+GhoaqK+vJywsjNzcXGw2G06nEwClFDExMcTHxxMXF0dcXBzx8fGEh4czMjJCd3c3LS0tjIyMUFJSQkVFxaKe8/S2trW1UVdXh9vtZufOnXg8Htrb2wF/ANPY2EhFRQUZGRlBgZnD4aCxsRGA2NhYCgsL5/WcHo+HI0eO4HK5SElJYefOnXMGhdfLbDaTkpKCzWbjtddeIy4ujvLyclJTU2ct39fXR0tLC2azmfz8fBobG2lra6O8vHzJ2ijEaiFBmxBCCCEWldaa1tZWampqgoI1i8Vi/JhMJoaHh6mrq6O7u5s9e/YYgZvX66WqqoqhoaEZdbvdbmOdsImJCS5dugT4E2NYrVaGhoZwOBw4HI6g48LDw5mYmAja1tTURFFR0TX39l1NVVUVra2txuOTJ08a55iXl0d/fz8jIyOcOHGCxMREKioqSE5OBqCjo8M47sKFC6Snp89rGGFDQwMjIyPExcWxffv2JQ+GioqKcDgcjI6OMjQ0xJEjRygsLCQlJQWr1Up4eDhWqxWlFOfOnQOgtLSUkpIS+vr6GB4epru7m6ysrCVtpxArnQRtQgghhFg0brebc+fOGeuAZWZmsm7dOiIiImYM8evv7+fMmTPY7XYuXLjAunXr0FpTVVVlJM+YTVRUFJs2bQKgpaWF+Ph4CgsLMZlMeL1eHA4Hdrud4eFh49+JiQnCwsJITU0lOzubtrY2uru7uXTp0pIMz/P5fEbgtWXLFtra2ujt7QUgLi6OyspKI7itr69ncHCQQ4cOkZmZyZYtW4zXLyYmBqfTSVVVFTt27LjiMMmxsTGjd66ysjIo2+NSSUlJ4c4778Tj8RhLCjQ1NdHU1BRUTimF1prY2FiKi4tRSpGXl0d1dTXNzc1YrVbMZjMJCQlL3mYhViIJ2oQQQgixKNxuN4cOHWJ4eBiLxUJlZSXZ2dlzlk9OTmbr1q0cPHiQxsZGEhISGB0dpa2tDbPZzPbt22edJxUdHW30IE32TE2avPCfevGvtWZ8fByr1WocFxkZSXd3N83NzRQXF8/a22az2WhtbWXt2rULnhM2MDCA1+slNjaW7OxsUlNTOXDgAGNjY6xfvx6lFEopCgoKyMnJobGxkUuXLtHV1cXx48cZGRkhIiKCXbt28eabb9LT00Nvby9paWlzPueFCxfwer1kZWWRmJi4oPZeL4vFQmlpKampqbS2tjI+Ps7ExAQul4uJiQk8Hg8mk4nKykrjPcjJyaG2tpb+/n4OHToEQGFhIevWrZN134SYRoI2IYQQQlw3n8/HiRMnGB4eJiYmhh07dswr0ElISKC0tJT6+npOnTplbK+srJxzbtRCKaWIjIwM2hYfH096ejo2m82YVzZJa82FCxdoaGgAICIigg0bNizoOSd71SaDrPDwcPbu3YvL5SIuLi6orMVioaysjJSUFA4dOkRPTw8AWVlZREREUFpaSk1NDbW1taSmps4a0IyMjNDe3o7JZFrSeXpXMz1gnjQ5THZq719YWBglJSW0tLQQGRmJ3W6nqakJp9PJli1bCA8Pv1HNFiLkyaxPIYQQQlwXl8vFiRMn6Ovrw2q1snPnzgX1TJWWlpKVlUVsbCypqalUVlaSk5OzhC32KysrA/wZDCfnu7lcLg4fPmwEbAA9PT1orRdU92TQNjXwtFqtMwK2qZKSkoICrsl5XgUFBURGRjI8PGwkMZmuq6vLOCYUU+hPzmWcrqysjLvvvpu9e/eya9curFYrvb29HDx4cMa8RCGupqqqitdff91ITLSaSE+bEEIIIebF4/EwPj4e9DM2NkZHRwdutxuLxcKOHTsWHDSYTCa2bt26RK2eW0JCAmlpafT09NDY2EhaWhonT540hlJu2bKFU6dOMTo6itPpJDY2dl71ulwu7Ha7sQTBQhQVFTE+Po7P5zN6rMxmM+Xl5Zw+fZrz589jNptnJO7o7u4GICMjY0HPF0qSkpLYt28fx48fx263c/DgQbZs2XLVxcCFAH/G1ebmZgCOHj3Knj175rUMxUohQZsQQggh5uTxeGhpaaGzs3PWbI6T0tLS2LBhQ0j28lxJWVmZEbQ1NDSgtSYpKYmtW7cSERFBWloabW1t2Gy2eQdtk71sSUlJC17MWinFunXrZmzPzs6mq6uL7u5uTp48SVdXFxs2bCA8PJyxsTEGBwcxm81XnPO2EkRGRrJ7927Onj1LZ2cnx48fp7y83EheIsRcJjPJmkwmRkdHOXbsGHv37l01y0lI0CaEEEKIWWmtOXHihBGEmEwmIiIign4iIyOJjY0lJSVlRV5UJyYmkpqaapxjcXFx0Lph6enptLW10dPTQ0lJyVXrm5iYMBaPXswASinFtm3bjKUUOjs76e/vp7KykrGxMeP5FhokhiKLxcKWLVuIi4vjwoUL1NbW4nA4qKysvKHnNz4+TnV1NXl5eQt6L8fHx5d8OQkRbLLHXynF7t27OXXqFHa7HZvNRmZm5nI3b1FI0CaEEEIItNY4HA5sNhujo6OUlpYyPDxMb28vYWFhbNy4cdUEBdOtW7eOCxcukJOTM+MCbzIYHRgYYGJigvDwcGOpgI0bNxITE2OUtdlsnD17FpfLhcViWfSLRaUU+fn5pKamcubMGfr7+zl+/LgxV2wlD42cTilFaWkpMTExnDlzhvb2dkZGRti9e/cN6zmprq6mq6uL8fHxBQVttbW1tLe34/V6Wb9+/RK2UACMjo5SU1ODz+czMqcWFBRQU1NDR0eHBG1CCCGEWNk8Hg99fX3YbDZ6enqMRavBH4BMXhyXl5evmguf2cTGxrJ9+/ZZ94WFhZGcnExfXx89PT1kZ2dTU1PDyMgIp0+fZs+ePfh8PmpqaowetuTkZDZt2jQjY+ViiYqKYteuXTQ1NXHhwgUjnf5qnPuVmZlJdHQ0x44dY3BwkKamJoqLi5f8eXt7e43kLna7Ha/XO68bFm6321hjz2azyfIFS0RrTV9fH83NzdhsNrTWmEwmozc8Ozub2tpabDYbbrebsLCwZW7x9ZOgTQghhFjltNZ0dHTQ0dFhDGns7+9nYGAAn89nlJucwzUyMkJ/fz/gD2jy8/OXq+khISsri76+Pi5dukRERAQjIyMADA0Nce7cOfr7+xkdHcVkMlFeXk5RUdGSX6grpSgqKiItLY26ujoSEhJWxYXpbCYXIz969Cj19fXk5OQs6bBDn89HdXU14H+dfT4fdrt9Xkll2tvbje/U6OgoDofjihlDxcJ4PB5aW1tpbm42vocmk4ns7GwKCwuJj48H/H/LJm+2dHV1kZeXt5zNXhQStAkhhFhUExMTKKWCLiAHBgZobGxkYmICi8VCZGQk0dHRxMTEEBMTQ2RkpNyNXiL9/f1UVVXNmj5dKUVSUhJpaWmkpaURFxdnXKSePXsWm83Ghg0bbvr3Jicnh/r6eoaHhzl79iyAMQ+ura0N8K/7tnnz5nknK1ksMTExy5J580ZLS0sz1tWrra1l06ZNS/I8WmuqqqpwOp3ExMSQlJREa2srAwMDVw3atNa0trYC/oQqY2Nj2Gw2CdoWydjYGEePHjX+lkVGRpKfn09eXt6sQXxOTg59fX20tLQYWSSTk5NX7BBvCdqEEEJcl4mJCfr7++nr66O/vx+Hw4FSitjYWKxWKy6Xi+Hh4SvWYTKZjCAuOjqahIQEEhMTV1W65hvN6/Vy/vx5Y8heVFQUxcXF+Hw+xsbGSEhIIDU1ddYFjE0mE5s3b0ZrfdMHbOBPuV9UVERNTQ2jo6Mopdi4cSNNTU3GcL2ysrJVk6UuVK1bt84IlIuKipYkGGpqaqK1tRWz2czmzZtxOp20trYyODh41WPtdjvDw8OEh4ezdu1aTp48ic1mo7S0dNHbebNxOBwcOXKE8fFxYmJiKC8vJyMj44p/nzIzM6mqqmJoaIijR48CcPfdd0vQJoQQ4ubS3NxMS0vLjIDMbDajtQ7abrFYKCoqIjk5GbfbzdjYGE6nk5GREZxOJ+Pj4zgcjhm9QTk5OTc8Y9xqoLXmzJkzdHZ2YjKZKC0tpaSkZMFBhQRsl+Xn53Px4kXcbjdpaWlERkaydu3aoEyTYmlFR0eTn59PU1MT9fX1bNu2bVHr7+7upqamBoBNmzYFDTkdHBy84k0MrbVxbE5ODmlpaZhMJoaGhnC5XJJFcoFsNhuNjY1s3LiRqKgoqqqqGB8fJzk5me3bt89rKLDFYmH9+vXG3ERgRX9XJWgTQghxVWNjY7S3t6OUori4mN7eXqqqqgD/f4JJSUkkJyeTkpJCQkICWmuGhobwer1YLBZiY2Ov+J+sx+MxAjin08ng4CADAwO0t7fjcDjYvn37kiV1WI2am5vp7OzEYrGwe/duY56HuHYWi4U1a9ZQW1sblPp/JV8ErkQlJSW0trbS1dWF3W5ftM/2wMAAp06dQmtNWVmZsXh5VFSUMWLg0qVLNDY2EhERYYwGSExMJDo6mqamJvr7+7FarZSWlmKxWEhJSaGnpwebzbYq5lTdKF6vl3PnzjE+Pk59fT3FxcX09/djsVjYsWOHkS11PvLy8lbNay9BmxBCrFJaayYmJnA6nfh8vgWvo+V0Ounq6qK3t5eBgQG01gCMjIwYa1qVlZVRUlIya09YcnLyvJ/LYrEQHx8fdAHmcDg4duwYdrud48ePz2uRVI/HQ1dXF7GxscTHx980PUUulwu73c7Q0BB2u52enh4ANm7cKAHbIiosLKSwsHC5m3FTi4iIID8/n8bGRurq6tixY8d11zn5t8br9ZKfn09ZWZmxb3LeZ1dXF7W1tcDl79vk0OOwsDC8Xi8AlZWVxpDjjIwMCdquQWtrq5HJtqOjw3hts7OzFxSwrTY375kLIcQqorU2eqcme6ucTidut9soU15ePq+5FQ6Hg4sXL9LZ2WkEapPpxHt7e42J9vHx8ZSVlS1ZYBQbG8u+ffs4ePAgdrudmpoa1q9fj9Yal8vFyMgIo6OjeDwesrKysFqtnD171ki3HRERwdatW+eV8W0lcrlcnD9/nv7+/qBU/ZNKSkqM3gIhVpOSkhJaWlqw2WyMjY1dVy/86OgoR44cwe12k5GRMWvincTERGOI3Zo1a0hOTmZoaIjBwUEGBweN719ubm7QWnmTa7v19vZeccmAgYEBLl68aAwP3717N1FRUdd8TivFZDBmMpmM19zr9dLQ0AD4ezlHR0eNv+k3e+ArQZsQQqxgWmtjfsfUAG1SWFgY0dHR2O126urqiI+Pn3OR2OnBmslkIicnh/T0dJKTkwkPD6enp4fjx4+jtWbjxo1L3pMVHh7Oli1bOHjwIE1NTfT29jI2Nmb8Zz+pqamJwsJCOjs7MZvNhIeHMzY2xpkzZ9i/f/+C5sS53W76+/sZGxszsltGRESEVK+d1prTp08bPZ5Teyrj4+NJSEgIWvRZiNXEarWSmppKd3c3PT0917wkxcTEBEePHjXmSm3ZsmXW73l2dja9vb1kZ2eTm5sLXB5JoLVmfHwcp9M5Y3RBZGQk8fHx2O12+vv75/zbW11djd1uNx53dnYGDcFdjdrb2zlz5oxxY1ApZQRvHo+H+Ph4KisrOXDgAMCMkRg3IwnahBBiBZqYmMBut9PY2GgMhYuOjiY1NZW4uDgj2AgPD0cpxcWLF7lw4QKnTp1i//79QXemR0dHuXDhQlCwlp+fT0lJyYw72Glpaezfvx+fz3fD0lgnJCRQUVFBTU0NTqcT8AdzUVFRREdHMzw8jMPhMNZVWrduHbm5ubz99ts4HA4aGhpYs2bNvJ6rsbGRmpoa40Ji0uS8vJiYGJKTk40Lt+VSX19Pb28vVquVW265hdjY2JAKKoVYaunp6XR3d2Oz2a4paPN4PBw7dgyn00lcXBzbt2+f8+ZOREQEt9xyy6z7lFJERkbO2duXnp6O3W6nu7t71qDN4XBgt9sJCwujtLSUmpoa+vr6VnXQ5vP5uHDhgvH/jdYarbVxM04pRXl5OQkJCSQnJ9Pf309+fv5N/zdOgjYhhAgRWmva2tro7u5mYGAApRQWiyXox2QyMTw8zOjoqHFceHg4GzduDBqWM11JSQmDg4PYbDbq6uqMNY7cbjeHDx82FgaeK1ibajl6cIqKikhKSjKWBpg6r2FiYoLDhw8zPDxMamoqeXl5KKWorKzknXfeoaGhgaysrKuun+VyuYwLiaSkJGJiYhgZGcHhcDAxMWEMhWprayM2NpaEhIQlPuvZ2e12Ll68iFKKzZs3yxpQ4qY0GQD19fVdcejhbLTWnDx5ksHBQaKioti5c+eSLUyenp5OfX09Nptt1uyT7e3tgH8B95ycHGpqahgYGFjwOa0knZ2dxkiG2267DaUUWmt8Ph8+n8/4vw9gy5Yt9PX1kZ2dvcytXn4StAkhxDxMDoEZHR1lZGTE+BkbGyMxMZGKigrjP1iPx0NTU9MVhyKC/w7r6dOnSUtLo6ysjDNnztDR0RFUZmJiYtZjzWYzcXFxJCYmUlRUdNU5HUop1q1bR09PD+3t7ZSUlBATE0N1dTWjo6PEx8eHdIZGpRSJiYmz7gsPD2fXrl10dXWRlZVlXBQlJSWRl5dHa2srR44cYdeuXVcMOJubm/F6vaSnp89IbuByuXA6nTQ0NNDT00Nvb++yBW3t7e1orcnPzyc1NXVZ2iDEcpvM4Dg0NHTFoYezGRwcpKenh/DwcHbu3Lmk60HGx8cTERHB+Pg4zc3NpKenExkZaQQqk3/zs7OzsVqtxMXFMTw8zODgICkpKUvWruWitTbmrJWUlBh/r5VSmM3mGYFqREQEOTk5N7ydoUiCNiGEuAqv18vhw4fnXFx1aGiIoaEh1q9fb6QqdjqdxgK8sw2l8/l8nDp1iuHhYex2O+3t7YyNjWGxWFi7di1paWmYzWY8Hg8ejwe3243H48Hn8xlDHxc6VCQ6Opq8vDxaWlo4f/48iYmJtLe3Yzab2bJlS8gGbPMRHh4+6xCp9evXMzo6Sl9fH4cPH2b37t1ER0fPKDcZaAOzDkuyWq1YrVYmJiaMoG0xFsydOp9jvuUnEyIs9xBNIZZbWloaQ0NDdHV1ERERYaz1OJmIKTk5mQ0bNsw4rr+/H/D3bi31yAGlFBkZGTQ3N1NdXU11dTUREREkJiYSGRnJ2NgYUVFRRsKklJQUhoeH6evrW5VBW3d3Nw6Hg8jISOk9W6B5BW1KqVJgSGvdq5SKAv4X4AX+QWvtWsoGCiHEcmtsbGRwcBCLxUJcXJwxl2pymF51dTWDg4PGhGnAuLN65swZbDYb0dHRREREEBERQWRkJB0dHQwPDxMVFYXH42FsbAyz2cyOHTuCJrNPpo5eLKWlpbS1tdHT02PMhVu7du2qTVphNpvZvn07x44do7+/n0OHDs0auLW0tOB2u0lKSrpitsnJZRMGBgbweDzXlX56fHycgwcP4vP5yMjIICcnh8TExCsGcENDQ0a2vOXq6RMiVEwOPWxtbTWy2k7lcDjIzc2d8V0ZGBgAuGGZZcvLy4mMjGRgYMDINjl1wefs7Gzje5+amkpjYyN9fX1L3q6F3jRajOeb7GUrLi6WNQ4XaL7/2/wE+CzQC/wVcA/gATKBLy1N04QQ4uq01oyNjRnrUw0NDeHz+SgtLSUtLe26/1NyuVzGfzLbtm2bdThaQkIC58+fx+Fw4PP5SE1NpaKiwujRmvqf81RKKbZs2YLVaqWhoYHs7OwFrW12LSIjI1m7di2tra3ExcWRlpa26tPCTy7IOhm4HT58mF27dhmB28TEBBcvXgRm72WbKiwsjMTERAYGBujr67viPMIr0Vpz9uxZxsbGAH/Q2NLSQlxcHAUFBXOuRzSZ+jozM/Omn5QvxGSmVLvdTnR0tJEsKDY2lr6+PlpbW2loaGDbtm3GMZPLo8CNC9rCwsKMvy1aa0ZGRowlWiYmJoLW/ktKSkIpxdDQEG63+5rm2p0/f56+vj7j5uLUH6vVilIKr9fLwYMHCQsLY9u2bYt+g3A2/f39DA0NYbVab/r0/ddivkFbMVAd+P1B4HbACZxGgjYhxDIYHh6mtraWoaGhWed9HT16lISEBEZHR9FaU1JSQlFR0YLu7Lndbs6fP4/H4yE9PX3O+UNWq5UtW7bM2F5UVERKSgp2u53x8XHGx8cZGxtjfHwcl8tFUVGRMU+rsrJy3u26XjfjAsGTgdvRo0cZGBgwhkpGRUVRW1uL2+0mNTV1XvNiUlNTGRgYoLe395qDtsnezrCwMLZu3Upvby/t7e0MDw9z7tw5ampqyMnJoaCgwEigMnVo5GoPtIWYD6UUe/fuNbIQTpWcnEx7ezvd3d2MjIwYN2kcDgdut5uoqKhlGRKulDKGuM82xNlisZCUlER/fz/19fWsW7duQfW7XC4aGxsB//+T0yUnJ7Nr1y76+vqM/YcOHWLnzp1L/npM3hwrLCxctUlWltJ8gzYFaKVUEaC11o0ASilJWSWEuC5aawYGBoy1taxW64w/5lpr2tvb6enpoaKigsjISE6ePGmkf7darcYd1/j4eEZGRqirq2NoaMioo7a2lra2Nnbv3o3Var1qm2pqamhubjYyWVVUVFzT+cXFxUl2vxBhsVjYuXOnEbgdOnSItLQ02traMJlMrF+/fl69V6mpqdTV1dHV1cXIyAgWi4UtW7ZgMplob29nfHx8zosSrTWtra2cP38egA0bNpCamkpqairl5eV0dXXR3NzMwMAAzc3NNDc3k5ycTE5OTtBCwjI0Ugg/pdSs39vJBBatra1UV1dTWlpq9JLDjetluxYVFRUcOnSIxsZGEhISFjT3a3K+XmJiIoWFhUGJsybXixsaGsJmswH+ha0dDgdHjhxh37591zXk+0qGhobo6+vDYrFQUFCwJM+x2s33nTkL/DGQB7wMoJTKBmaG8EIIsQA1NTXGXcFJFovFSPxgtVqN4Y/gnweUn5+P0+kkKiqKXbt2GZm4psrOzsZutxMbG8vIyAjV1dU4nU5OnTrFLbfccsWL89bWVhobG1FKkZKSQnFx8VXTxYuVYTJwO3LkCIODg7S0tAD/P3v/HR9ndeb//68jzah3y+q2JfeCO7YxppfQTQiQEEIIZBdIIZtsPp/vbtovSzZlS7L5sJtKkiUhIQQIIdQAAWLABdx7LypWsySr9ynn98dItzVqHtmSNZLfz8djHp6573Pfc0Zjjea6z3WuE5hfEeq8vpSUFNxuNx0dHc7i1qWlpaSlpTmLxVZUVLB06VLi4uKc46y17NixwynxnZ+fHzRiFhERQW5uLrm5uTQ2NlJcXExpaSknT550vohFRkYyZ84cpUaKhGDatGlBc3iTk5OdNMBwDtpSU1OZN28eu3fvZufOnTQ0NFBQUBDSSFj3Z0VmZmafYG/fvn0cPXqU48ePO0HbihUr2LNnD01NTezbt2/Esj66q2ROmTJlxJZXGO9CDdr+Afgp0Al8qmvbNcCbI9EpkZHS2N7I8/ueJ8YVw21zbyPaNfiIi4ysiooKJzhKTk6mo6ODjo4Op2JiS0uL0zYmJsYZlWtoaABg5syZQV+Ke+ou+gE4wd17771HTU0Nhw8fZubMmf0e19LSwr59+wBYvHixqluNQy6Xi4svvpjq6mqam5vx+/1MnTo15OO7q4JWV1cTGRnJsWPHOHLkCCkpKc46TPX19bz33nssWbLESbmsrKyktLQUl8vF/PnzBy1jnZSUxPz585kzZw5lZWVUVFSQkJDA9OnTR7Q8uch4kpCQwKpVq5zfoe6/HRDeQRsEgpumpiaKioo4evQox44dIycnh2nTppGcnDzgcd0FTPqrPJmXl+cEbX6/n9jYWCZMmMCSJUtYu3YtxcXFZGRknHHa92C6L3BlZmYO+7nPFyEFbdbaXcAlvbY9ATwxEp0SGSnri9dzuCaQU50am8p1M64b5R6dv5qbm9m5cycQqF7Y/aXZWovX63UCuI6ODqe6Xk1NDZs3b8bn8xEfHz+ktVtiYmJYvHgxGzdu5NChQ8TExPQ7EXrnzp14vV5ycnIUsI1jERERZGZmnvEXiOzsbLKzs7HWOnNmWlpaMMZw6aWXcvDgQU6cOMHGjRuZMWMGM2bMYP/+/UAg9SnU/7sul4spU6b0u5yBiJxeamoqqampzJgxgw8++IDGxkbcbnfYV8w1xjB//nwmTZrEsWPHKC8vp6ysjLKyMtLT05k6dSoZGRlBo+7t7e00Nzfjcrn6Dey60/W757JlZmZijCEpKYk5c+awd+9edu3aRXp6+rCmSXZ0dNDU1ERkZOSA623K6YU8I98YE2eMWWyMuaznbSQ7JzLc1hWvc+6/V/gefusfxd6cvxoaGtiwYQMej4esrKygohjGGOcP6oQJE8jJySEvLw+Xy+WURQeYNWvWkFPEuucNdVfu652W2djYyMmTJ3G73f2u7SPSmzEmqOLkpEmTnIXKZ8+ejTGGw4cP88477zjFEFQ1TeTci46OZuXKleTl5Y2pFOOUlBSWLFnCVVddxdSpU3G5XNTU1LBp0ybefffdoOrE3aNsaWlpAxbd6nnBqOeIWkFBAampqUEVk4dLKP2S0wt1nbbVwG+B3rPpLaDyLzImWGtxR7rx+DzOtsM1h5k1cdaAx7R2tvL+8ffJTsxmbsbcc9HNccXn89Ha2kpbWxsej4fOzk7q6+uprKzE6/WSkZHB4sWLh/THc9GiRcyYMeOMr5JOnz6dyMhI9uzZ41SGnDFjBsYYjh8/DgTmw52L8scyPuTl5XH48GE6OzudBbeNMU7hg23bttHa2goERtn0pUVkdERFRbF48eLR7sYZiYuLY968ecycOdOZd93U1MTWrVu5/PLLSUxMdOazDbYod25uLgcOHMDlcgUtMWOMYd68eaxbt46jR48yefLkAacfDNVgKZsSulDHPr9PYH22n1lrW07XWCQcNXY0BgVsAFvLtg4atL2w/wX2ntiLMYbPLP8Mecmhp+Odb7xeLyUlJTQ1NdHS0kJrayvt7e3OOmm95ebmsmjRoiF/ge0ul3w2CgoKcLlc7Ny5k4MHD+L1epk9e7YzUbq/MswiA4mMjOSSSy7B6/X2+ZKTnp7OZZddxp49e3C73SMyV0REzh9ut5tp06ZRUFDAtm3bqKio4MSJEyQkJDjB0WDrfcbExLBq1SoiIyP7/P1NTU0lNzeXsrIy9u/fz9KlS/s9R1NTE7GxsSGnUCpoGx6hBm3Z1tofjGhPREZYZVNln237q/fT1NFEYnTfyoB1bXXsqwoUpLDWsql0k4K2AZSXl7N3717a29uDthtjiI+PJy4ujqioKFwuF0lJSaSlpZGYmDiq6SmTJk3C5XKxbds2jh49Sm1tLR0dHSQmJg46yVukP4MVB4mJiQla3FdE5Gx1V5utqKigsrKS1NRUWltbiYmJOe3fsMGWDJkzZw6VlZWUl5cHrSXarb6+nrVr1xIXF8fSpUtPu/xIa2srra2tuN1u/W09S6EGbeuMMQu6CpKIjEmVzX2DNr/1s7NiJ5fkX9Jn36bSTUGjRLsrd3PTrJvGbMVJn88XtLiz2+1m4sSJZ52qdfjwYQ4cOAAE/hBMmjSJ+Ph44uPj+y3FH06ys7NZtmwZW7Zsoa6uDggEc+HcZxEREcD5G15fX+/MQzvbv2GxsbFMnTqVw4cPs3fvXlatWhV0vu4qkK2traxfv54lS5aQnZ094Pl6jv7pb+vZCTloA14wxjwGVPTcYa397bD3SmQE9Bxpm5Q8ieMNgflLu0/s7hO0eXwetpZuDdrW6etkz4k9LM3tP10gnFhrqa6upry8nPr6etrb2/F4PH3aud1u8vPzh1TUw+v1cvjwYbxeLwBFRUVOLnx+fv6Y+1DOyMhgxYoVbNoUCNJVMVJERMYCl8tFenq6sw4dDE96//Tp0ykpKaGuro7y8vKgv4vdFzhTUlKor69nz549ZGZmDngBWKmRwyfUoO2Brn8/02u7JVCgRGTUVVVV0d7eTl5eXr8fHieaTzj3r5x6Jb/f8Xt81kdpQyl1bXWkxgZSADw+D2uOraHF03f65payLaMStHk8Hk6ePElERAQul4vIyEhcLhcul4uIiAj8fj8RERG43W5aW1vZvHmzU9K3W0REhLN2WUxMDM3NzTQ2NnL48GFaW1tDml/W0dHBxo0bg9a66V6zaizPA5swYQJXXHEFPp9Pa2CJiMiYkZWV5QRsaWlpxMfHn/U5XS4Xs2fPZufOnezfv5+srCwiIyOx1jpB25IlS9i0aRPNzc1UVlaSk5PT5zzWWgVtw+i0QZsxJgK4GThkre17qV4kDHSXv7XWcuzYMebPnx80Edfr91LdUu08zk/NZ9qEaRyqOQTAnhN7WJ63nI3HN7K+eD3Nnc1O24snX8wHxz/Ab/2U1JdQ01JDevy5+/Cx1rJp0yZqa2sHbWeMIS0tjaamJjo7O4mLi2PSpElkZGQQGxtLVFRUn1Gw7nXPysrKaGhoIC4ujqysrH7XhGpqamLTpk20trY6Zcubm5vJyMjo98N6rImNjR3tLoiIiAxJz7Umh3M5kUmTJlFUVERDQwPHjh1jxowZtLa20tnZSXR0NHFxcRQUFLB7925n4e/empub6ejoICYmJuzXxRsLQhlps8BmQD9tGVGlpaVUVlYyb968IX2Bbm9vZ9u2bYGS/m43TU1NbNiwgcmTJzNnzhyioqKoaq5y1mRLi0sj2hXNgqwFTtC2vng97xa+S5unLejcmQmZXDXtKk62nuRgzUEACusKzyhos9bi8Xhoa2vDGIMxhoiICOfW/djr9XLy5Ek6OjrIy8ujvLyc2tpaoqKiSE5Oxufz4fV68Xq9+Hw+Z5StezQOAil/S5Yswe12D9qn9PR0Vq5cycaNG2lubqa5uZnq6momTpwYVAXvxIkTbNu2Da/XS0pKCsuXLyc6emzO7RMRERkvYmJiyM3NpampadC5ZUPVPe1hw4YNHDlyhEmTJjmjbKmpqRhjyMvL48CBA9TV1VFfX9+nKEn3/Lf09PQxN3UiHJ02aLPWWmPMUSCTXvPZRIbLiRMn2LFjB9Za2tvbufjii4NS9ay1tLS04LM+Xj32KrWttdw5/04y4jPYtm0bHR0dpKens2zZMo4ePcqRI0coKSmhrKKMltQWqu2pUbbshMCH2pyJc3BFuPD6vTR1NAX1JzkmmUvyL+HC3AuJioyiIK3ACdqK64pZlres39fR3NxMWVkZCQkJZGVl0dDQwIkTJ6irq6OxsbHfeWWDOXLkCD6fD4AFCxYM+oHs8Xg4ceIEPp+PyZMnh/wBmZKSwtVXX01TUxNHjhyhsrKSoqIi5s6di7WWo0ePcuDAAay15OTksGjRIiIjtTyjiIhIOFiyZMmInHfChAlkZWVRWVnJvn37nBL/3RUlXS4XkydP5ujRo2zcuJH8/Hzy8/Odi7pKjRxeoc5p+3/AH4wxjwBFgL97h7W2ZPi7JeGkpaWF4uJiYmNjyczMDHmxRWstDQ0NTrXCnrfOzk5nDlZcXBxlZWVYa4mMjKSuro7t27eTkJBAU1MTzc3NtLS04Pf7KWwrpCi6iNjYWF4/9DqrklZx8uRJoqOjWbJkCS6Xi1mzZpGbm8vu3bv567G/cvj4YeJi45iYMRGArMTAOkkx7hhmTJjB/ur9Tp9TY1O5ouAKFuUswhVx6tdjSsqpdMHihuI+r9Xj8XD48GGOHTvmVJw0xvRZo8zlcjmjiNZa/H6/82/3fQh8IPp8PiclMjs7+7RX0NxuN3l5Z7YkgcvlIjU1lRkzZlBZWUlJSQnTp09nz549ztpls2fPZvr06bpaJiIicp6YO3cu1dXVlJWVORdsey4DMG3aNGpra6mrq+PQoUMcOXKEnJwcCgoKQlrsW0IXatD2q65//0YgXRLAdN3XJfdxqnuU5eDBg/j9gTh9z549JCcnk5WVRVZWVtBaW21tbRw9epSpU6cSFxfHoUOHOHToUMjPl5uby9SpU1m/fj3l5eV99kdHR1NeX05NUw1ZmVnsK99HUlkSLlwsWrQoKF0vISGBjJkZ1FXWEdkRSWtbK02NTeRl5LE4Z7HT7qppV3Gg5AARNoLluctZOmkpiQmJRBBckCMnKQd3hBuP30Nta62ztpu1luPHj3PgwAE6OjowxpCbm0tLSwv19fXOHLH09HSSk5OJjo4OOeix1lJaWsrJkyeZM2dOyD/Hs5GSkkJqaip1dXW88847dHR04HK5WLx4sRYFFhEROc/Ex8ezYMECtm/fjs/nwxgTlAYZHR3NqlWrqK2tpbCwkMrKSkpLSyktLXWO15zx4RFq0FYwor2QsFRSUsL+/YFRqNzcXPx+P9XV1TQ0NNDQ0MDBgwedX+YJEyawfft2Tp48SUNDAxdeeCFHjx4FApNkY2NjgyoXRkVF4ff78Xg8gbRHn4+CggIiIyNZunQpZWVlxMfHk5CQ4Nww8NIfX8Lf7qe8IhDUlSaXcsWcK8jIyAjqe4e3gz/v+zPx8fGBOWMNESx1L+XmJTeTGHtqIe2ozihWRKwAwFZatlRuAQKjZHFxcUyfPp3JkyfjinCRl5xHYV0hLS0tbD60mbkT53L48GHq6+uBQNWmefPmOR9mHo8Hl8t1xiNTxhgmTZp0zqsyFhQUUFdXR0dHB3FxcSxbtoykpKRz2gcREREJD3l5edTV1VFUVERycnKfKRLGGCZMmMCECRNobW2lsLCQkpISvF5vUKEUOTshBW3W2r75YDKu+Xw+Dh8+DMDChQudikQ+n4+amhoqKys5ceJEIIDZvDloGLy2tpb3338fn89HZmYmy5cvH9Jzd4/i9VZYW0hSahLtne20d7QTERFBQ1QDnSmdbCjZwIq8FURGBD5IXjv0GnVtgQmzaUlpXJ51OfVV9ezbu48VK1Y45ywpKXGeMzY21knFbGtro6WlhV27dpGUlERKSgpTUqew+/huTp48ybrWdbQkBZYEiImJYe7cueTk5AQFaKcrAhKusrOznTVXFixYQFRU1Gh3SUREREbRvHnziIuLC6rM3Z+4uDjmzZvHrFmzqK2tJS0t7Rz1cPwLKWgzxtw70D4trj0+WGspLi7myJEjTJgwgYSEBNra2khKSgoa6YmMjCQzM5PMzEystWzbto3y8nInwOuesNrUFCjsMXv27GHr46GaQxhjyMzKxPotJsLQRhvP738egJbOFq6dfi2Hag6xuXSzc9wts29hdtps3n77baqqqujo6CA6OhqPx0NlZWDB7e4Po24+n48DBw5w7NgxduzYwWWXXcakxEk01AfWJyvxl+Bp9zAjYwYfW/kxoqPGTyXFiIiIIQfaIiIiMn5FREQwbdq0kNu7XK4+WVBydkJNj/xWr8cZXceWocW1x4zOzk62b99OU1OTMyLUXXre6/XS3t4O4OQhA8yaNWvA9D5jDIsWLaKqoYq9VXuZlzWPCy+8kPfff5+TJ0+Sm5s7rGl13eX5AdwuN16/N2j/xuMbWZG3gj/v/bOzbV7GPBZkLXDWMKuurqampobc3FzKy8vx+Xykp6f3Ka4SGRnJ7NmzOXHiBE1NTezcuRPjNvh8PqKiosjMzMSPn4MdB/ndzt9x18K7SIjSqhgiIiIiMvwiTt8ErLUFPW9AMvA/wL+PaO9k2Fhr2bFjB1VVVbS1tdHa2kpraystLS00NzfT3t5OXFwcCxYsoDOmk3dq36GY4tNeJfFaLzvMDopdxWz1baXT18mSJUuYOXMm8+bNG5a+VzRV8Pqh16lsDoyKuSJcrJqyqk+7Nk8bv9j8Cxo7GgGIj4pn9dzVTtDZXb2ouwRtd2rkQItRRkZGsmjRIowxlJaWcrzwOCnulKCqSRBYt+3nG39OeWPf4ikiIiIiImcr1JG2INZarzHmm8B+4BfD26WhMcY8DNwPzAeestbeN0jbO4H/ILDm3HrgfmttWde+KOBHwMcAD/Aza+03R7b3505RUREnTpzA7XazcuVK3G431lrnBoEKP+3edg4eO4gvyUepq5T91fuZlzlw8LW2aC3NnmaSkpJo87WxoWQDV069klmzZp1Vf+vb6tlZuZOdFTs50XwiaF9+aj6XTLmEA9UHaOpoIi85zxmF657HBnDrnFuDRr96Bm319fXU19fjdrsHrYqYlpbGZZddxoEDBzhx4gRXTLmCQlchyTHJZCZksql0E9Za6trq+MWmX/CReR9hQfaCs3rtIiIiIiI9nVHQ1iUZSD1tq5FXDnwbuA4YsKaoMWYO8DhwG4GA7T+Bp4DLu5p8E1gATAcSgLeMMYXW2l+PXNdHnrWWwsJC9u3bBwSKiiQnJw/Y/rVDr9HiaSE+Ph6Avx7+K7MnznYKfPRU11bHuqJ1QdvWF69n5aSVxLhjzqi/Pr+PF/a9wLbybf3uj4+K56ppVxEXFccXVn4Bi6Xd085/vvefePynFq5elL2oT7CZnJyM2+2mtbWVPXv2ADBlypTTLhSdlJTE8uXLaWtrIzo6OmjR75npM3l297N0eDvw+D08s/sZKpoquHjKxXR4O0iKSSIqUoU8REREROTMhVqIpPeIUzzwYeD14e7QUFlrnwcwxlwIDLay8D3Aa9bat7rafwOoMsZMs9YeJTBa94C1tgaoMcb8F/BpYMwFbRuKN7CrbBetLa00NTXR2twaKMeaPoHK0kr8x/39H2ihpCF4rfSa1hq2lG1hxaQVQdvbPG38ee+fgwKl7u3vFr3Lh6Z/6IxK3b9f8n6fgM0d4WZOxhwWZi9k+oTpzqLXxhgMhrioOBZkL2Br2VYAkqKTuHn2zX3ObYwhPT2diooK6urqiIiIoKAg9NUs+ltnZPbE2Xx2xWd5cvuT1LQG0i7fK3qP94rec54zIz6DywsuZ2H2wpCfS0RERETE0TNFbqAbsKbX7SUCI1OJoRx/Lm7Ad4DfDLL/ReDrvbYdBG4lMGJogdwe+1YCdQOcKwXI73W7pOsc/d4ee+wx2+2xxx4bsF3gLTllyZIlA7Z74IEHnHZbtmwZ9Jx3/+Bu+7U3vma/9sbX7KIbFg3YLmt6lv3aG1+z313zXfu1N7426Dlv+OINzjk/+y+fHZbXtOTGJc45v/HENwY955YtW5xz3nv/vQOfc8kSp11hYeGg5zzT92nx4sUDtlt0wyL7L2/+i233tJ/2fer5mh544IGQXpMN/KcM2/97ek16TXpNek16TXpNek16TXpNp24vvfRS9/18G2KsE+o6bVeG0i7MJQANvbbVA4ld++i1v3tff74E/MvwdW3kRceEXpI+OSaZB5Y9wC83/zKk9ldOvZIjhUfOtGtB/DYwCpgRn8HKOSv5Dt8J6bhoV2ivr3te23A73aiix++huqV6RJ5bRERERMY3Y7uKUAzayJgPrLUX9bN9nbX2khHp2RAZY74D5NkBCpEYY14ENlprv9dj2wHgn4H3gFoCI23lXfsuIpBO2WfenjEmhcBoW095wNrCwkLy8/PP9uWcleqWahraG/D5fVgsPr8Pn/XhjnAT7Yp25qf1fO8tgfsGQ3ZiNtGuaLaWbeX5vYE10NyRbmamz2Tvib3OMdGuaD4y7yNckHkBAK2draw5toZNpZuccvyfv+jz5CTlDNjXurY6Hl3/aJ/y/Z9e+mmmTQh9PZBQWWs5evQobrebKVOmDPv5e3tq51POz+wj8z7C0tylI/6cIiIiIhK+ioqKuqfoFFhri0I5JtRCJAOVD5wT4vHhYA+wsPuBMSYJKAD2WGvrjDHlXfu767Yv6jqmD2ttPYGROMeZzN8aKRPjJzIxfuJZn2dxzmI2FG+gsrkSj88TFLBlJWbx8QUfJz3+1MhVXFQcN82+iRZPCzsrdgJwtPbooEHb3hN7+wRsi7MXj0jABoH3afr06SNy7v5kJmQ6PzeNtImIiIjImRg0aDPG3Nt1N9IY80mgZ2QyCzg5Uh0LlTHGReB1RBLoZwzgs9Z6ejV9EthojLkKeJ9AxckPbKAICcBvgG8YYzYTKLTyZeDfzsFLCFsRJoLrZl7HE9ueCNq+LG8ZN826CXeku9/jpqZNdYK2IyePcGn+pQM+x76qfc79iyZfxIwJM5gxYcYw9D48ZMSfWueu99IFIiIiIiKhON1I27e6/o0G/rXHdj9QCXxhJDo1RN8geH7ZPcATwH3GmGbgBmvtWmvtfmPM3wG/ArKAdcDdPY77FpAOHOXUOm2/PhcvIJzNmDCD2RNnc6D6AO5IN7fOuZXFOYsHPWZa2qlRsuK6Yrx+r1PxsaemjianWqUxhiunXhm0rtp4kJmQ6dyvaq4axZ6IiIiIyFg1aNBmrS0AMMb8xVp747np0tBYax8BHhlgX0Kvx38E/jhA207goa6bdDHG8LEFH+PIySPkJuWSHJN82mNSY1NJi0ujtrUWj9/D8frjFKT1La1/sPqgM69uSsqUcRewAUyIm0CkicRnfdS319Ph7Qi5aIqIiIiICEDE6ZtAd8BmArJHtksSbqIio5ibMTekgK3b9LRT88aO1h7tt83eqlNz5OZmzD3zDoaxyIjIoHl/Z5IiGUqxIBEREREZv0IK2owxscaYXwBtwJGubbcaY74+kp2TsWtq2lTn/o6KHZTUBy/a3dLZwrHaY87j8Rq0AWQknJrXVtUSeoqkx+fhqR1P8e013+6z4LiIiIiInD9CCtqAHwBTgMsJzPcC2AZ8fCQ6JWPf1LSpTkXNurY6Htv0GE/teIqalhoA3j76tlM1Mjsxm9TYPisrjBs9i5EMZV7bqwdfZW/VXjq8Hbx+8HVnDTsREREROb+EWvJ/NbDQWltrjPEDWGuPG2NyR65rMpbFR8Xzoekf4s0jbzrBxt6qveyv3s/8rPnsqtzltL162tWj1c1zomcxksHSIz0+D/ur9lPaWEq7t52tZVudfS2ewMjk9AnByxXUtNTQ1NFEfmp+WC07ISIiIiLDJ9SgzQ009txgjIklkC4p0q/LCi5jbsZc3jr6FrsrdwPgt35nOQCA6ROmM3vi7NHq4jnRO2iz1joBlrWW8sZytpZvZVflLto8A/9K7Tmxxwna6tvqeevIW+yo3IG1lsU5i7l93u0K3ERERETGoVCDts0Eqir+pMe2e4EPhr1HMq6kx6dz14K7uHTKpbxx+I2goiQRJoKbZt007gONtLg03JFuPD4PTR1NrDm2huWTlrOzYifbyrdR2VQ54LHxUfG0dLYAsO/EPj40/UOsLV7LhuINQYuSby/fTmZC5qBr4omIiIjI2GRCqUxnjJkNvAfsBy4C1gAXAhdbaw+NaA/HCGNMPlBYWFhIfn7+KPcmPFlrOXLyCG8dfYvKpkqun3k9KyevHO1unRNvHnmTd469AwSWUYggAp/19WmXGpvKgqwFREVGEWEiWJyzmJ988BOaOpqAQCXPTl9nv89hjOHexfcyM33miL0OERERETk7RUVFFBQUABRYa4tCOSakkTZr7QFjzBwCo2t7CSys/YC19vgZ9lXOQ8YYZqTPYEb6jKAUwfPB1dOu5nj9cY7WHsVai49TAZs7ws0FmRewNHdpv3PT5mXO44OSwKB2z4AtNymXD834EGuOraGorghrLS/se4EvXvxFrQUnIiIiMo6cNmgzxriBYmCqtfb/jXyX5HxwPgVsEEgF/eiCj/KzD35GfXs9AJOTJ7MkdwnzM+cT444Z8NgLMi9wgjYIjMZ9aPqHmJ81H2MMWYlZ/M+G/6Gls4WG9gbWHFvD9TOvH+mXJCIiIiLnyGmDNmutxxjjAc6vb9kiwywhKoHPXfQ5DtUcIjcpN2j9tsHkp+RzyZRLOFJ7hMXZi7lo8kW4Ik796iZEJXD9zOv5054/AbC+eD2LcxYHFUARERERkbEr1EIkPwS+b4z5R2ut57StRaRf8VHxLM5ZPKRjjDHcMOuGQdsszl7M1rKtFNUV4bd+3it8jzvn33k2XRURERGRMBHq4tpfIlA9sskYU2SMOdZ9G7muiUiojDFcN+M65/GRk0cIpciQiIiIiIS/UEfaHhnJTojI2ctLziPWHUubp43mzmaqW6pDTsEUERERkfAVavXIJ0a6IyJydiJMBAWpBeyr2gfAsdpjCtpERERExoFQ0yNFZAwoSCtw7h+rU/ayiIiIyHigoE1kHJmaOtW5X1RbpHltIiIiIuOAgjaRcSQzIZN4dzwALZ4WKpsrR7lHIiIiInK2FLSJjCPGmKAUyf1V+0M67mTrSera6kaqWyIiIiJyFkIO2owxkcaYi40xH+t6HGOMiR65ronImZiWNs25//bRt3nj0Bt4/d4B2++v2s+j6x/lv9b9F8X1xeeiiyIiIiIyBCEFbcaYAmAX8AbweNfmG4FfjlC/ROQMLcxeSHpcuvP4vaL3eHT9o+yq2NVnjluHt4MndzyJ3/qx1rKzYue57q6IiIiInEaoI20/Al4EUoDOrm1rgMtGoE8ichaiXdF8ZsVnmJk+09lW11bHM7uf4Wcbf8bRk0ed7WuOrQk69sjJI/itn50VO9lftV+FTERERETCgAnlS5kxphrIsdZ6jDG11tq0ru0N1trkke7kWGCMyQcKCwsLyc/PH+XeiIC1lg0lG1hzbA1tnragfdMnTCcnMYd1xevwW7+zPcJEcM30a/jr4b867W6fdztJMUnntO8iIiIi41VRUREFBQUABdbaolCOCTVoKwIWWmsbuoM2Y8xEYKO1duppDj8vKGiTcNXmaeO9ovd4v/h9PH7Padu7I914fKfaxbpjWT1nNQuyFoxkN0VERETOC2cStIWaHvka8N/GmBgAY0wE8B3g5TPop4icQ7HuWK6bcR1fvuTLXJh7IcaYoP1pcWkUpJ6qONkzYINA0PfMrmd4dvezfUbsRERERGTkuUJs9xXgBaAWiAYagP3AtSPTrdFnjEkDXgfmApdYa3eMbo9Ezk5STBK3zbuNVVNW8V7he3itl4VZC5mZPpPt5dsprCsMap+dmE27t91ZCmBnxU4Kawu5afZNzJgwg2iXiseKiIiInAshBW3W2gbgSmPMEmA6UAmss7bHZJjxp4lAhcwfjHZHRIZTRkIGd8y/I2jbpJRJfdqtnLySCzIv4JUDr7CtfBsAjR2N/GHnH4gwEcyZOIfb5t1GrDsWAK/fS0l9Celx6ZoDJyIiIjKMQgrajDFXWGvfsdZuA7aNcJ/CgrXWA9T0TiUTGY8y4jOIdkXT4e0AcIKyaFc0t19wO7MnzubFfS/S4mkBwG/97K3aS0NHAx+e+2GO1R5jffF6GtobcEe4+dDMD7Fy0so+qZgiIiIiMnShzml72Rhz2BjzFWNM1pk8kTFmhjHmr8aYemNMsTHm787kPP2c92FjzFZjTKcx5jf97E8xxjxrjGkyxpQZYz43HM8rMp4YY5iUfGq0bWraVOKi4pzH8zLn8YWLv8CqKavISjz1EVDaUMqP3/8xfzn4FxraGwDw+D28euBVfrPtNzS2N567FyEiIiIyToUatGUD/wGsBkqMMS8ZY1Z3FSQ5LWOMC3gJeAdIBz4C/Jcx5vIB2i/uZ9s8Y0x/k2jKgW8D/zvA0/+YwIhiDnAT8C1jzJVd58wyxrzTz21WKK9LZDzpua7bwuyFffYnRidy46wb+cLKL3DrnFv7PUdEj4+EIyeP8D/v/w+7K3f327aquYrXD71OcX3xWfZ8eHj9XmekUURERCSchFTyP+gAY+YC9wOfBHzW2twQjpkHbAHiu+fBGWN+DURYaz/Vq20esBX4e2vty13bFgNvALdZa9cP8BzfAfKstff12BZPoHjKYmvtvq5t/0FgzblPhvh6fwM8erpCJCr5L2Od1+9lXdE6olxRIaU2bi7dzKsHXiUyIpLJKZOZM3EO87Pm827hu6wrXhe0MPei7EXcMvsWYtwxAFQ0VfC/W/6XNk8bESaCTyz6BLMnzh7R1zeQ2tZa1hWvY1vZNowxfHLxJ5mappVMREREZGScScn/UKtHBj0PgcqRxcCSEI8xvf7tvt9n4SdrbakxZjXwqjHmHqCMQBXHLwwUsA1iJoHAdF+PbTuAD4XUaWPeIlA9crYx5nFr7S+G+PwiY4YrwsUVU68Iuf2yvGUszV2KwQQFeNfPvJ5Z6bN4bs9z1LfXA7CjYgdljWV8dsVnaepo4jdbf+MsH+C3fv6w8w9cN/M6ClILyEzIDBqxGynljeW8V/Qee07sCQowX9z3Il9c9cVz0gcRERGRUIQctBljVgJ/B3wUqAB+DXw4xMMPEgi+vm6M+XdgMXAbgSqUfVhrNxpjbgeeB7zAP1lrnwm1rz0kAL0n1dQDiaEcbK29ZrD9xphHgH85g36JjAsDBTYFaQV8YeUXeOXAK2yv2A5AdUs1f9r7J8oby2nubA5q7/V7efXAqwC4I9xkJ2UzKXkSeUl55CbnkhabhjGGmpYa3il8h7KGMq6cduUZLfhdWFfIO8fe4cjJI/3ur2mtYXv5dpbmLh3yuUVERERGQqjVI/cDkwkEUbdYa98dypNYaz3GmFuB/wH+gUAQ9xvggkEOKwXagTjg6FCer4dmoHft8WQC5fzPmrX2EeAROJUeORznFRkPYtwx3DH/DqakTuGFfS8AsPfEXme/O8LNbfNu443DbzhFTCBQyKSkvoSS+hJnW7QrmqjIKFo6W/B3rTTywr4XmDFhhrPkwOl4fB7eOPwG75e832ff9AnTSYxKdALMNcfWsDB7Ia6IM0lGEBERERleoX4j+R/gqa712s6ItXYvcHX3Y2PM08AH/bU1xkwB3ga+QyAQ+rMx5mZr7cYhPu0hwBpj5lhr93dtWwTsGeJ5ROQMLctbxrHaY+yq3OVsizARfHzhx5k1cRYzJsxgS9kWShtKKW0sDQrgunV4O/oUCenwdvDB8Q+4cuqVAz63x+fhb0f/xsGag9S31wedwxjDBZkXcFn+ZeQk5dDh7eBgzUFaPa3UtdWx5tgarp1+7TD8BERERETOTqiLa//sbJ/IGDMfOAJY4OMEArjP99Mug0DA9mj383YtD/CyMeYaa+2uXu1dBF5HJBBpjIkhUCDFY61tMcY8B3zbGHM/UAB8GvjY2b4eEQnd6jmrKa4vpqG9AWMMd15wJ7MmBoq0xkXFcVnBZU7bpo4mJ4ArbSilrLHMmf8GgTXlqlqqANhQvIGLJ19MtKtvYdmmjiae2vEUJQ0lffbNnjibG2fdyIS4Cc62aFc0lxdczmuHXgPgnWPvkBydzPJJy4fnhyAiIiJyhgasHmmMedVae1PX/TUEgq0+rLVXhfRExvwb8BAQRaCS5Jf6q8hojIkCVltrn+u1/Xpgs7X2ZK/tj9B3XtkT3VUkjTEpwC+BGwjMb/uOtfanofR5KFQ9UmRwNS01bDy+kRnpM4KWFzgday0tnhb8fj+uCBfRrmj+3/r/R11bHQB5yXlkxGeQFJNEYlQiidGJVLVU8X7J+7R0tgSdK94dz1XTrmLFpBX9Vsf0+X38bsfvOFxzGAiMxt0w8wYunnzxoNU02zxtbCjZQFJ0EhfmXqhFxUVERGRAZ1I9crCg7avW2n/ruv8IAwdt3zqTzo43CtpEzp3NpZudeXKn0x14LcxeSLw7/rQBVYe3g8e3Pk5pQ6mzbVH2Im6/4PZ+C694fB4e3/K4M6J365xbNTonIiIiAxrWkv/dAVvX/UfOtnMiIsNlcc5iNpVuoryxfNB2SdFJfHjuh51UzFBEu6K5d/G9/Hb7b53AbUfFDnKSclg1ZVVQW2stf9r7p6AUzNcPv87sibNJiuldA0lERETkzIS0uLYxptxam9PP9hJr7eQR6dkYo5E2kXPLb/1UNlXS2NFIU0cTTR1Nzn2A+VnzuSDzgjOuAOn1e3lx34tsK98GQFpcGl9e9WVnpK66pZqX9r/EsdpjfY6dlzGPuxfdfYavTERERMazkVxce6B1zUJa70xEZLhFmAhyknLIoc/1pGHhinCxes5q9lfvp83TRm1rLUdrjzIlZQrvFL7D2sK1+KzPaT8jfYYzF25v1V4OVh8c0gifiIiIyEAGDdqMMd/suuvucb/bTKB4RHolIhIG3JFuFmYv5IOSwOokbx15i+bOZqcICgSCx1VTVvGhGR/ihX0vsLVsKwCvH3qdGekzBlyAXERERCRUpxtp614AydXjPoAfqCRQPl9EZNxanrfcCdqONxwP2jc5eTKr564mOzEbgGunX8ueE3vo8HZQ1VLF5tLNrJi04pz3WURERMaXQYM2a+2VAMaYn1lrP3tuuiQiEj4yEzKZnDKZkvpTxUZi3bFcN+O6PuX9E6MTuSz/Mt488iYAbx95m4yEDApSC4BA4RKP30OHt4NOXyfJMclnPOdOREREzh+hLq6tgE1EzltXFFzBb7f/FghUrrx+5vUkRCX023bVlFVsLt1MfXs9LZ4WfrX5V6TGptLh7aDd247f+p226XHpfGrJp0iLSzsXL0NERETGqJCqRwIYY/4OuAbIAJxLy6Eurj3eqXqkyPhW1VxFhIkgPT79tG2PnjzKkzuepNPXedq2idGJfGrJp5wUSxERERnfzqR6ZEgz5I0x/wr8O3ACWAnsAuYDO8+opyIiY0xGQkZIARvAtAnT+NKqL3FB5gV99rkiXMRHxRNpIgFo6mjipx/8lKd3PX3adedERETk/BTqOm2FwB3W2q3GmFprbZox5lLgYWvtx0a8l2OARtpEpD9NHU10eDuIcccQ44px5rAV1hXyu+2/o8Pb4bQ1xnDx5Iu5etrVRLuiR6vLIiIiMoLOZKQt1KCtyVqb2HW/FphgrbXGmJPW2gln0edxQ0GbiAxVZVMlrx58tc8C3a4IF9PSplGQVkBOYg45STnEumOd/dZa2r3txLhiggqhiIiISPgbycW1K40x2dbaCgJrs11sjKk5s26KiAhAVmIWf3fh31HeWM4bh9/gyMkjAHj9Xg7WHORgzUGnbWpsKrlJuSRGJ3Kw5iC1rbVEu6LJTszmmunXOBUqRUREZPwJddXXP3BqnbZfAG8DW4EnR6JTIiLnk5ykHO5bch93XHAHmQmZ/bapa6tjz4k9vF/yPrWttQB0eDsoqiviia1PUNlUeS67LCIiIudQyNUjgw4y5mIgCXjDnskJxiGlR4rIcKltreXIySOUNZZR1lhGVXMVPusLahNhIoKWD5gYP5HPrvis5sKJiIiEuZFMjwxird1wJseJiMjppcWlsTxuufPY6/dyoukE5U3l1LfXk5uUy4wJM6huqeYXm3+Bx+ehuqWal/a/xB0X3KF5biIiIuPMgEGbMebxUE5grf308HVHRER6c0W4yE3OJTc5N2h7TlIOt8y+hef3Pg/AjoodTIyfyBVTrxiFXoqIiMhIGWxOmwnxJiIio2RJzhKW5i51Hr955E12VvS/hGa7p52alpqgtEoREREJfwOOtFlr7z+XHRERkaEzxrB6zmpqW2sprCsE4Nndz1LXVsflBZc7qZKtna08tukxalprSI1NZcWkFaycvNJZN05ERETCV6jVI0VEJEy5IlzcvfBuMuIznG1vHnmT5/Y8h8fnAWBT6SZqWgMrtdS11fH6odd59cCro9JfERERGZqQgjZjTKEx5lh/t5HuoIiInF5cVBwPLHsgaL22HRU7eHzL49S31fPB8Q/6HLO/ej8qACwiIhL+Qs2LeaTX41zgAeCxYe2NiIicsbioOO5beh+vHHiFzaWbAShpKOG/N/w3nb5OABKjE+n0ddLh7aCpo4m6tjrS4tJGs9siIiJyGiEFbdbaJ3pvM8b8Bfgu8O/D3SkRETkzrggXt865lYnxE3nt0GtYa52ADeCiSRdRWFfIkZNHgEBQp6BNREQkvJ3NnLadwKXD1RERERkexhhWTVnFvYvvDVps2x3hZnnecqakTHG2FdcVj0YXRUREZAjOKGgzxsQCXwSqhrc7IiIyXGamz+Qzyz9Delw6AFdOu5K4qLigoK2kvmS0unfesNZy9ORRp7rnmZ5D8w9FRM5fIaVHGmP8QO+/Fk3Ap4a9RyIiMmwyEjL40qov0eppJT4qHoC85DwiTAR+6+dEywnaPG3EumNHuafjk9/6eWn/S84cw48t+BgLshYM6Rx7T+zlT3v/RGZCJh+d/1FSY1NHoqsiIhLGQh1puxK4qsdtGZBnrX1xpDomIiLDwxjjBGwA0a5oshKzgMAIzvGG46PVtXHN6/fy9K6nnYAN4I1DbzjLMISi3dPOi/tepMPbQUl9CT/b+DNKG0pHorsiIhLGQgrarLXv9rpts9Y2j3TnRERkZExOmezcP1B9QKl3w6zD28Fvt/2WvSf2Bm2vb69nU+mmkM/zXtF7tHhanMctnS08vvVxmjqahq2vIiIS/kKe02aMudQY84/GmG/2vI1k50REZGT0nNe28fhGntj+BI3tjaPYo/GjpbOF/93yvxytPepsy03Kde6/c+wdmjsHv+5praW8sZwNxRucba6IwIyGDm8HW8u2DnOvRUQknIW6uPa/AW8B9wDX9rhdM3JdG13GmDRjzCZjTLMxZtFo90dEZDjNmTiHrIQs5/HhmsP8fNPPqWyqHMVejX31bfX8YtMvKGssc7ZdO/1aHlz+oDMXrdXTyo/f/7Gz7EK32tZatpRt4Y+7/8h/vPcf/OSDn+DxB1Ipc5JyuG3ebU7breVbNToqInIeCXVx7QeAFdbaHSPYl3DTBNwI/GC0OyIiMtzckW4eWPYAbx59k43HN2KtpaG9gV9s/gWfWPgJpk2YNtpdHFNK6kvYXr6dvVV7aekMpDMaY1g9ezXLJy0H4MZZN/L7Hb8HoKmjid9s+w0fX/BxkqKTeH7v81S1DFyQ+foZ1zM5ZTIvu16m3dtObWstRXVFFKQVjPyLExGRURdqemQLsGckOxJurLUea23NaPdDRGSkxLhjuGX2Ldy35D5nPbcObwdPbHuCHRU7RrdzY8jB6oP8cvMv2VS6yQnYIk0kH5v/MSdgA5ibMZd7F9/rFIWx1vLcnuf49bZf9xuwxbpjmZsxl48v/DjTJkzDHelmYfZCZ79SJEUEoLG9kapmrcI13oUatP0A+KYxxpzpExljJhtjXjHG1BpjqowxvzHGJJzp+Xqc92FjzFZjTKcx5jf97E8xxjxrjGkyxpQZYz53ts8pIjKeTJ8wnQeWPUBSdBIAPuvjj7v/yDvH3lEK3ml4fB5ePvAyfut3tiVEJXDvknuZnzW/T/tZE2fxhZVfIC0uDYBOXycd3g4gsPj5jPQZXD/zej634nN87Yqv8YlFn+CCzAuc45fmLHXu7zmxh4b2hpF6aSIyBtS01PCDtT/gvzf8N7sqd412d2QEhRq0vQB8DGg0xhzreRvCc/0cqANygdlAAfD/66+hMWZxP9vmGWOi+2leDnwb+N8BnvfHBNJAc4CbgG8ZY67sOmeWMeadfm6zhvC6RETGvOzEbD6z4jNkJmQ629488iYv7X/ptEUzzmdri9ZS11YHQJw7jr+/8O/5p8v+iekTpg94TGJ0Ip9c9ElndBMgPiqez170We5bch+X5l9KbnIuEabvn+icpBxnuQaP38Pvd/x+SEsIiMj4sufEHnzWB8CO8h2j2xkZUaHOaXsGKAUeBVrP8LkKgB9ba9uANmPM88CHejcyxuQBrxtj/t5a+3LXtsXAG8BtwPqe7a21z3e1uRDI63WueOBOYLG1tgnYYYx5HPg0sMZaWwlccYavR0RkXEmOSeaBZQ/w+x2/p7CuEIBNpZvYXLaZ/JR8br/gdi3sTGDB7FcPvsrB6oPUt9c726+dfm3Ic8wyEjL4+IKP88zuZ4h1x3LPonuCAuaBGGO4edbNPL71cfzWT1ljGU9se4JF2YvIT81nQtwEziIpRkTGmJ6p1aWNpVhr9RkwToUatC0A0q217WfxXI8Cdxtj3gXigDsIBINBrLWlxpjVwKvGmHuAMuB14AvW2vW925/GTMBYa/f12LaDfoLF/hhj3gLmArONMY9ba38xxOcXERlTYt2x3Lf0Pv60509Oqo21lsK6Qt44/AZ3LbhrlHs4+vZV7eODkg+CtmUnZnNh3oVDOs+M9Bl8/YqvAwzpS1ZBWgE3zbqJlw+8DEBhXaETZCdFJzE1bSoFaQXMz5wfNJonIuPPiaYTzv2Wzhbq2+t1cW2cCjU9ci+QdpbPtY5AWmQDUAXUAz/rr6G1diNwO/B7AksN/JO1tk+AF4IEoPfCQ/VAYigHW2uvsdbmWGsv6i9gM8Y8YoyxxhgLFJ5B/0REwo4rwsVH53+UD8/9MPmp+c72vSf2alFncAKkbhnxGdxxwR39pjOejjHmjK6Kr5i0gosnX9xne2NHIzsqdvDnvX/mxx/82CmMIiLjj8/vo7qlOmhbaUPpKPVGRlqof2GeBJ43xnzUGHNZz1soBxtjIgmMlr0MxAMTAA/w34McVgq0A1HA0UHaDaYZSOq1LZlAOf+zZq19xFprrLWGQPqniMi4YIxhWd4yHlj2gBO4+a2fzaWbR7djYeB4/XHn/r2L7+WLq77ozDM7V4wx3DT7Jh5e+TDXz7yeWemz+oyq1bbW8tye51RMRmScqmmtceazdeu5RuRoq2ur0+fPMAo1PbI7uHq613YLRIZwfCqB+WY/ttZ2AB1dc8se7a+xMWYK8DbwHQIjWH82xtzcNQI3FIcAa4yZY63d37VtEefZ8gUiImdjxaQVFNUVAbDx+EYuK7gMV0Sofz7Gl05fJxVNFc7jySmTR7E3gbTM7MRsLs2/FL/1U9FYwYGaA/zt6N8AOFRziHcK3+HKqVeOaj9FZPidaD7RZ9vxhuP9tDy3PD4PT+96mgPVByhILeDvLvw7zbMbBiGNtFlrIwa4hRKw0bXe2THgM8YYtzEmGbgP6FOb1BiTQSBge9Ra+zNr7evA3wEvG2MW9NPeZYyJIRA8RhpjYowx7q7nbQGeA75tjEnsOv7TwOOh9FtERALriyVGB7LKmzubefPwm3j93lHu1egoayxzyvtnxGcQ644d5R6dEmEiyE3O5eppV3Np/qXO9reOvMXrh14PWpZAhs5ay2sHX+MHa3/AlrIto90dkX6DtvLG8lH9Xff4PDy540kOVB8AAunkNa1a9ng4DD0B/8zdBlxNYD7bUcAAD/fTrh74irX20e4N1tqXgHsJFCXp7RtAG/AV4J6u+7/ssf/zBEYEKwikaD5irV1zdi9FROT84YpwsTzv1CLR64rX8bONPzsv57f1TI2clDJpFHsyuGunXxs0H3Ft0Voe2/QYuyp24fP7Bj5QBrS2aC3ritdR11bHC/teYH/V/tMfJDKCehYh6dbp6+wzz+1c6Q7Yjpw8ErS9orFigCNkKELKbzHGfHOgfdbafw3lHNbaXcBVIbTrJDA61nv76wO0fwR4ZJDz1RMo+y8iImdo1ZRVHKs95hThqGyq5C8H/8LHFnxslHt2bvVMPZqUHL5BW2REJPcuvpc/7v4j+6sDwUVpQynP7H6GzMJM7rjgDnKScka5l+GltbOVuKi4fvcdPXmUvx75q/PYWsuzu59lXsY8XJEuFucsZkrKlHPVVREATrScCtpSY1OdNSOPNxwfcAkRv/WzpXQLUa4oFmYtPG3aYmFtIX/e92eSY5K5ZMolzEyf2e8xAwVsABVNFSzI7pMsJ0MU6qSE3snwOQQKb6wDQgraRERk7Ip2RfPpCz/N+yXv85eDfwFg94ndXN50+TkvwjFarLWU1Jc4j0d7PtvpRLui+cSiT/DW0bdYW7jWKVhwovkEP9v4M5bkLHHWd+vvS9hbR97iQPUBVk5eydLcpee6++dMm6eNZ3c/y6GaQ0xJmcLHFnyM5JhkZ7/H5+HZ3c/2KajQ6etke8V2ADaXbmZx9mKum3mdk0osMpI6vB1OkBZhIlics9iZy1rWUMaFuf0vQdLzMzwqMoq5GXMHfA5rLS/tf4mTrSc52XqSY7XHKEgt4P6l9xMZcWqGVH8BW0FqgXORr7yp/OxerAChz2m7stdtFvBPwDsj2jsREQkbESaCVVNWMXvibCDwB/3to2+Pcq/OnZOtJ2nubAYCAVFGfMYo9+j0jDFcO/1a/r/L/j+umnYV7gg30HW1vWwLv9ryK76/9vu8fuh1yhvLncCkpL6ENcfWUNFUwfN7n+fFfS+Oy3mMNS01/HzjzzlUcwiA4vpifvLBTyisPbWsw54Te5z3PSEqgfuX3t/v+nfbK7bz/9b/P9YVrVMKapgqqiviv9b9F7/e+ms8Ps9od2dADe0NHD15dMDKix3eDjYe3+jsnxA3gcnJpy4iDRYkbS3b6tw/XYrv4ZOHgxbvhsActaO1p4q69xewXT3taj4898PO44qmClWRHAZnU/7rx0AJGmkTETmvXD3tameS+b6qfRyuOcyM9Bmj1h+/9Q9pjTSv38vbR95mT9UeDIbE6ESumX4NBakDr9zS2tnK07tOFVCelDxpTFVDS4xO5OppV7MwayF/2vunoBHDhvYG1hatZW3RWjLiM1g9dzXby7cHHb+pdBPVLdXcs+geYtwxWGtp7mymuqWaE80nsFiW5iwdU4t5F9YW8tTOp2j1tAZtb+ls4fGtj3P9zOu5ePLFQctcXDzlYqZPmM7nVnyOY7XHiIyI5GDNQfae2AsEvky/dug1tpZt5abZNzF9wvRz+pokWG1rLX/c80fi3HF8aMaH+MPOP9Dc2Uxtay1by7Zy0eSLRruLfbR52vifDf9Du7edhdkLufOCO53PmqrmKjaWbmR7+XY6vB3OMZkJmWQnZTuPK5sq8fl9QaNhEBhl71m8pPeak72tL17v3DfGOIFXZVMlM9NnAvCXg3/pE7BdNe0qrLVERUbR6eukpbOF5s5mjUKfpbMJ2gqAsfPpPMra2tpobGzE59PVt7EsOjqatLS0MfVlTWS45STlMD9rPrsrdwPw5I4nuX3e7QPOWfD6vVhrcUe6h7Uffuvn1YOvsrV0K9MnTGf1nNUkxfRemjNYh7eDp3Y+FfQl42TrSZ7d9Sz/eMk/EhUZ1eeY1s5WHt/6uFPq3xjT78LWY0F6fDoPLnuQkoYSdlbsZHfl7qCgpaqlit9t/12/V8UL6wr52cafER8VT3VLdZ9gZ3fFbu5bel/YB24d3g7eL3mfvx39m5My6o5wc3nB5bx//H1aOlvwW7/zZbS4vhgIjDQvyVkCBH6O6fHpACzNXcqRk0d45cArTgGIqpYqfr3119w0+6Yx+39lPPjLwb84FygO1hwM+n+9v3p/WAZtJfUltHvbAdhZsZNJyZNIiEpg4/GN/QZZUZFRXDTpIhKiEkiOSaahvQGv30t1S3Wf1PXuz+xudW11NLQ3BKUDdzvRfML5nDTGcOmUS3mv6D0A57PQb/3srNzpHNMdsHUfk5WY5fz8yxvLmTVx1hn9TCQg1EIkvUvkxxOoBPnssPdoHGpra6OhoYG0tDTcbre+8I9R1lrq6upoamoiKWnwL4Yi4911M66jqK6Ipo4mvH4vz+x+hoaOBi6ZconzGVfXVsfbR95mR+UOUmJSuG/Jfc4X3bPl8/t4bs9z7KoMrByzv3o/xfXFfHT+Rwcc9WvqaOK3239LeWPf1KHGjkY+KPmAywouC9reX8D24bkfHtNfPowxTEmZwpSUKdw06yaOnDzCzsqd7Kvah8fnCbqCnxGfwcLshbx55E0gsJjvQOW7SxpKeHLHk9yz6J6wDdwOVB/g+T3P0+JpcbYlRCXwycWfJC85jyW5S/jDzj84BWe60yYB5mTMGXCkYPqE6Ty88mE+KPmAvx37m/Mz3Hx8s4K2UVLfVs+BmgPO494XIgprC2n3tBPjjjnXXRtUQ3tD0ONXDrzSb7sJcRNYMWkFi7MXOwV0chJznOMrmiqCgjZrbZ+gDQIpowuzF/bZ3nOUbW7GXGZnzHaCtu7RutKGUuf/enJMcp/1ILMTs52graKpYkx/boaDUPNJTK/bCeDL9F+yX3ppbGwkLS2NqKgoBWxjmDGGpKQkWltbT99YZJxLjU3loeUPBc3rev3Q67x68FX81s/+qv08uv5RtldsD1zwaKvjpf0vDcu8Bq/fyzO7nnECtm6tnlae2vmUM/+op5qWGh7b9FhQwHb1tKu5bsZ1zuP3it6jzdN26nwDBGwDTfAfiyIjIpk1cRYfnf9RPr30033+Rl2YdyFXTL2C2y+4vU8KalRkFHnJecyZOMfZdqz2GP/x3n/w0v6X2FK2hZL6krCZC9ddVKFnwJadmM1nV3yWvOQ8IPDF8++X/T3L8pb1OX5Zbt9tPbkiXFySfwlfuvhLzs+qqqUq6P+UDK+6tjp+/P6P+cHaH/DCvhc4VHPI+f+2uWzzoJ83Puvj0MlDA+4fTq2drew9sZdDNYeoaq4KujDSW317/YD7IkwE8zLmcf/S+/nHVf/Iqimrgiqe9qwI2/viVHljeb8XXIrqivpsa+5sZmfFqRG0VVNWkZVwKgCsbqnG4/MEzW2bljatz+dHz/50f47KmQtppM1ae/9Id2Q88/l8uN3DmxYkoyMyMhK/XwvUikAgcHtg2QP8fufvnT/875e8T3VLNcV1xX2+rB+tPcruyt1DLv1srXW+DHh8Hv6w8w8crDno7F+QtYDCukKaOpro9HWyvnh9UDBW2lDKb7f/lpbOwJd1YwwfnvNhLsy7EJ/fx5ayLZxsPUmbp40/7fkTt869lUgTOe4Dtt4mp0wOSoGKNJEsyl4EwJKcJWQlBFKd0uLSyIjPIDkm2Xlf3i18l78eDpTE7y6S0M0d6WZ62nRumHUDE+ImnNsX1UNlc6UzChEVGcVNs25icc7iPvN+XBEuPjz3w+Qm5fLKgVfw+r1kxGeEPD8tKSaJrMQs50vz8YbjzvwfGV4v73/Z+R3dXLqZzaWbiXZFMyt9VlBAcVn+ZRyrO0ZSdBKpsanOKNL+qv0syBrZUvTW2qDPkm6x7liSY5KZGD+RK6de6ZTo7z3SBoE5qcvylrEsd9mgKeBBQVtXMRJrLVvLtzoVIyF4eYD+grZNxzc5n995yXlMTp6MMYa0uDRqW2vxWz/VLdUcqz3mHDNtwrQ+58lOODXPTkHb2Rs0aDPGzANWW2v/rZ99XwFesNYe6Huk9KYRtvFB76NIsLioOO5bch9/3PNHpxhDz/liqbGp5CTlOPtePfgqM9NnhpyStL54PWuOrWFKyhRWz1nN83ufDzr/qimruGHmDeyt2ssfdv4BgA9KPqC+rZ79VftJi0ujrq2OTl8nEJi7dNfCu5wKmJERkVwz/Rqe2fUMEEizPLz2MIDzpeV8CNi6XTXtKsoayzhae5TLp15OfFS8sy8nKWfAtd0uL7ic5Jhk1hxd0+dqvsfncdJX7154NwVpAxd8GUkHq08F+rMnzubCvMHfz2V5y5iSMoXDJw8zL2PekD7/J6dMVtA2wo6ePBp08aZbh7cjaBQ+KTqJa2dc64x+ljeWO0HboZpDg67PNxzq2+v7DVjaPG20edqobKqksb2RB5c/COAEUwAfm/8x0uLSyE7M7nNxoT85icEjbd0Lwff8zIwwEdw+73Z+vfXX+KyPqpYqmjubSYhKAAK/rx8c/8Bpv2ryKuf/fnZCNrWttUBg7l3PgkZTU6f26U9GQgYRJgK/9XOy9WRYpqOOJacbafv/gPUD7KsiUPb/08PaIwkLjzzyCAcOHODpp58etN1nPvMZMjMz+da3vsU777zDXXfdRWVl5TnqpYiEA3ekm48v+Dh/OfgXNpRscLbHumO5b8l9JEYnUlJfQlNHE82dzawtXsu106/tcx6f30dJfQnF9cUkxSTR3NHMG4ffAAJzkQ7VHMJvT410X15wOddOvxZjDPMy5pGZkMmJ5hN0+jqdL209K6XFueP45OJP9llfbX7mfI7mHmVL2RaAoBHC8ylgg8B7ed/S+/D4PEOel7YoexELsxZy+ORhjjccp6alhuMNx50voa2eVn699desnru6z8+ztrWW1w69ht/6uSDzAuZmzB32eXGHTx527ocaRGUkZJCRMPSlHSYnT+YDAl98e36xleFhreW1Q685j+dMnENaXBr7qvYFBT0QCL57pvZmJ2Y7I03t3nb+873/ZEH2Ai6adNGILDjfc+QsKjKKhOgEGtsbgz5nukviG2OC2uck5QxpHnBidCIJUQk0dzbT6evkv9f/Nx7/qaUNJsRN4CPzPkJ+aj65ybnO/82ndz7N6jmryUjIYGflTicrITkmmXmZ85zjsxKz2FsVuAC3qfTUaFxGfEa/I4DuSDeZCZlO0FraWKqKqmfhdEHbJcCXBtj3J+Drw9obGXN+/vOfj+rzhxpcisjIMsZw0+ybSIlN4fVDr+OKcHH3wrudLxzXzbiO5/Y8B8CG4g2snLyShKgE2jxtHK45HBjhOnl40Pk/PQO2a6Zdw5XTTk16N8Zw5dQrg8ry95QSk8J9S+9jYvzEfvt+27zbmJc5j78c/ItTATAhKoEbZt3gpAieLyJMxBkHTMYYZqbPDAqKiuuLeWpHYK6hz/r4894/U9NSw4dmfIgIE0FJfaCASfcXxQPVB0iKTuLTF366z/tV11bH/ur9pMelD2n0qs3TFhQ8jfQSFZOSJzn3jzccD0rxlbO3rXybEwi4I9zcMucWkmOSuWHmDVQ2V7K/aj9HTh4hNTaVS/MvDTrWGBO0ELXH72Fr2Va2lm1lcspkVk5aydzMubgizqbA+imN7Y3O/RkTZnD3orudJTN+uO6HdPo66fR10uZpI8YdQ2PHqfb9VXUcjDGGnKQcp4BOd8DWXfH2munXOBVyZ6bPdH4nCusK+enGn/LQ8ofYUHzqwtvKySuDRvh6FjbpeUFssNHzySmTnfeqpL5EQdtZON3/yAxrbX1/O6y1DcaYvn/9RIaR1+vF5RqeD87ROL/I+WbVlFUsyFpApIkMSjlamL2QtUVrnZGwP+7+Iz6/j+L64qBgrD9ZCVmcbD3pfAG5bsZ1fao8AlyQeQGTUyZTUl9Cckwyq+esJtoVTUN7A7PSZxHrjh30eWamz2TGhBm0edpwRbpwR6ja73CYkjKFz674LL/b8TsqmwKZGGuL1lLdUk1BagFvHnmzz/zHxo5Gnt/7PA8uexBjDCX1JawvXs/eqr1OcYn7ltwXcvB1tPao8/8sNynXSQUbKamxqc6IR4e3g6qWKjITMp0v6CP9/ONZm6fNGYEHWJW/yglujDFkJ2aTnZjtlJ7vz1VTryIlJoX3S94PSl3sTvnLLMzk/qX3D8u6Yj0Li/TsZ2J0IikxKc7i1fXt9cT54pz/pwlRCWe0TErPoA0gPS6dj1zwEaakTAlqd2n+pbR2tvLB8Q/wW39gkeztTzr9jYqM6jMi3rMYSU/T0vrOZ+s2OWWyM8e1pEGjzmfjdNUjW4wxk/rb0bVdJZHGiV27drF8+XISExO5/vrrqak5NSfhrrvuIisri+TkZK644gr279/v7Lvvvvv4yle+0ud8P/jBD1i9enXQtq997Wt86lOfGrQf9913Hw8++CC33HIL8fHxvPLKK5SXl3PHHXeQkZFBfn4+//Vf/wXA66+/zve+9z3+9Kc/kZCQwKxZgVKy+fn5vP766845f/Ob33DRRafWYjHG8KMf/YiZM2eSnZ3NO++8Q1ZWFj/60Y/Izs5m4sSJfO973xvCT09EekqMTuwzRyTCRASlRB45eYTCusI+AVtyTDJLcpY4E9/zU/P5+2V/z4PLH+SiyRdxz6J7+g3YIPC7ff/S+3lg2QN8adWXmD1xNgWpBSzKXnTagK3nOeKi4oiKVLXf4ZQSm8KDyx4MqjR5oPoArx16zQnY4t3xXDH1CiJN4Mp+SX0JL+1/iZ9v/DmPbXqMPSf2BFUDfPPImyFVI7XWsufEHufxuZhfZowJSsMtqS+htrWWR9c/yn+8+x99Kp9K6N46+lZQ+t5l+f1/HgzGGMPS3KV8/qLP89Dyh1iYvdD5fweBUaTfbf/doFUeQ9XQcSrdsffIWUpsinO/rq2Ouva6fvcNxaLsRbgjAxecVk1ZxcMrH+4TsEGg4M5Ns2/ioeUPOemjPQPMJblL+nxupsam4o5w99k22OhZz1Hn0obSYakgfL463RDDe8AXgf/bz76HgXeGu0Ny7nk8Hm699VYeeOAB1q1bx7p161i9ejU333wzANdffz2//OUvcbvd/N//+3/55Cc/yZYtWwY95z333MM3v/lNampqSE9Px1rL73//ex5/vPeSf3394Q9/4NVXX+XFF1+kra2Nyy67jJtuuonf//73VFRUcM011zB9+nRuvfVWvva1r51ReuSf//xnNmzYQHx8PBs3bqSmpobjx49TVFTEnj17WLlyJbfeeivz5s07/clEJCSzJ85mcvLkPldb85LzmD1xNrPSZ5GdmO0ES37rx2AwxhDrjg1pvklUZBT5qfkj0X05S9GuaO5edDd/PfxX1hatDdqXlZjF3QvvdqpLvnPsHSAwb6Y3YwzWWsoayzhYc9ApKtMfj8/Di/tfDFqf6lwVBZmUPIl9VfsA2HNiD387+jcn9W1b+bYRr1o43nj9Xt4veT+oMumNs248q7mP3cH15JTJ3DDzBjaVbmLNsTXO/69ndz/LPYvuOasLOA1tp4K23vO+UmNTnfv17fVB88+GmhrZbWL8RP75sn/GWhtSgZW85DyW5i5lc+lmZ1t3OmVvxhjy0/I5XBOYHzo5eTJ3Lbxr0PcgLTaN+Kh4WjpbaPO0Ud1SfUbzROX0Qdt3gQ+MMWnAk0AZkAt8AvgYsHJkuzc+vfzyy+fkeW655ZaQ2r3//vu0tLTwla98hYiICK666ipuueWWUyko993ntH3kkUeYOHEiLS0txMfHD3BGyMrK4sorr+Tpp5/m4Ycf5t1338Vay5VXXjngMT37fdllgStne/bsoaKigm9961uBD4v8fB566CGefvppbr311pBeX3++8pWvkJ5+anJvREQE3/nOd4iKimLp0qUsXLiQ7du3K2gTGUbGGD664KO8euBVIkwEMyfOZFb6rAFTkHqvCyZjX4SJ4PqZ1zMxfiIv738Zn/VxWcFlXDn1SmcO0RUFV7CrcpdTpQ4CowILshZw8ZSL2Va2zSl488ahN2jpbGFm+sw+/48a2xv5/c7fU9pQ6mybkT4j6Mr/SOqZMtazel9/j2VwVc1V/GHnH5xUQggsaD4vY/j+RidGJ3L1tKtJjErkxf0vAoHR4F2Vu/pdfDpUPUfaUmJSgvb1fFzfVo/H5xmw7VCEmlnQ7aqpV7GjfIcTNM6ZOGfA5TlunHkjb0e+TXZiNpfkX3LauX/GGCYnT2Z/dSBLq6ShZEhB2/ri9RyoPsBV066iIHV0Ks+Gi0F/0tbaXcaYG4GfA/cBlsDi2oeAm6y1fZdWlzGnvLyc3NxcIiJOfUGaMmUKRUVF+Hw+vvrVr/Lcc89RU1PjtKmpqRk0aINAsPf973+fhx9+mCeffJJPfOITQc8xkEmTTv1BLS4upqqqitTUU1ejfD4fy5YNvsjpUJ4DcBY/7xYfH09zc98FekXk7KTGpnLP4ntGuxsyypbmLmVexjwsts8XTHekm49e8FGe3PEkESaCC/MuZHnecicou6zgMjaXbsbj91DVUsXze58nKjKKuxbcxayJgTT54/XH+f3O39PU0RT0nKvnrD5naa+5yblcPPnioIqq3QwGv/XrwkQI9lft59ndzzrLdgBkJmRy29zbRuS9XD5pOVUtVbxf8j4QSMNt7Gjkg5IPmJ0xm5tn3Tyk5+1ZDbJPemTPoK29Pmhu55mmR56JpJgkLp96OW8deQtXhIvLCy4fsG1GQgYfX/jxIZ1/UsqkU0FbfUnI1XhrWmqc9eXq2+v58qovn9dp66etwGCtfQeYbYyZDmQAVdZaXSI6C6GOgJ0rOTk5lJWV4ff7naCqpCSQvvT73/+eF198kbfffpv8/HxOnjzJxIkTQ8pJXr16NZ/5zGfYuXMnzz33HBs29P3D1Z+ev5CTJk1i0qRJFBYWnrZtt4SEBFpbW53HFRV910c5n3/pRUTCwWDrNU1KmcRXr/hqv/sSoxO5JP8S1hxb42zr9HXy5I4nuXb6tbgj3bx+6HXnC3CEieDGWTdy0aSLzvln/42zbsQY46wL1s1v/dS31ZMWl3ZO+zOWWGtZc2wNbx9929nmjnRz7fRruWjSRSGtW3amrpl2DbsqdtHiaaGurY7XDwXmyX9Q8gFLspeQm5wb0nk8Po8z/y7CRPQZDe49p61neuTZjLSdiSsKrmBS8iTio+LJTsw+bfuhmJx8an7n4ZrDHKw+yMz0maf9fey5TEdtay0VTRUjsizDWBHyJR5r7RFr7QYFbOPPypUriY2N5T//8z/xeDy88847Tgpnc3Mz0dHRTJgwgdbWVr7+9dBXeYiOjuauu+7i3nvvZfr06cydO3fIfVu+fDmpqal873vfo62tDZ/Px759+9i4MZDTnpmZSVFREX7/qWIGixcv5qmnnqKzs5MDBw7wq1/9asjPKyIi4evqaVfzqSWf4uppVzvzgvzWzxuH3+CVA684AVucO7D4+8rJK0flYp0xhhtm3sAdF9zBFVOvICP+VFpYbVvtIEee3zq8HTy186mggC01NpWHlj/EqimrRjRgg8AFhZ5LivTUszLj6fQcZUuMTuwzstp7TlvP+W/nOmgzxjB9wvRhD9ggUNGy+7U3djTy2+2/5bk9z512AOBY7bGgxz0LCoXC5/ex5tgaXtj3AoW1hWO+CIrG5QW3282LL77Ic889R2pqKv/2b//mVHm89957yc/PJzc3l3nz5nHxxX0npg7mvvvuY9euXdx7771n1LfIyEheeeUVdu/eTUFBAenp6dx///3U1QUqLN155524XC4mTJjgzD/79re/TUVFBWlpaTz44IOnrVgpIiJjS/d6cFdNu4oHlz3YbynyzIRMPrvis0ybMHA58nOhe12wa6dfS27SqRGa3otA93T05FEOVh8c818yz0RNSw0/3/hzp4gLBOYHfm7F50YkoBjIsrxl/c7rOnTyzIK2/gqLJEQlOHPC2jxtQXP2znXQNpKiXdGsmrIqaNuOih0U1RUNeIzf+imsC86y6l1B9nTeOvIWbx15i82lm/nVll/x040/ZWfFzjH7e2XGasfDjTEmHygsLCwkPz8/aF95eTk5OefncO6JEyeYPHkypaWlTJw4Ppb1O5/fTxGRcNTh7WBL2RaK64upbq4mLzmPm2fffFaVBUfC347+zRk9uiz/Mq6beV2fNgeqD/C77b8D4M75d55Xi7sfqjnEs7ufpc1zakWpVVNWcf3M60dl/l91SzXvHnuXiQkTnSUmjDF87fKvOZUZO7wdbDy+kWN1x1iSsySoKui28m38ac+fAJifNZ+7FtzV5zl+uO6HnGw9GbQtKjKKb171zXE3laOquYrXDr3mjFbOTJ/Jp5YELqx3eDs4WHOQvSf2UttWy/QJ03mv8L0+53h45cMhBe+Hag7xxLYn+mzPSszi4YseHvWfbVFREQUFBQAF1tqiUI7RqsIyYqy1/PCHP+TDH/7wuAnYREQk/HRfye99NT/c9JzDdrLtZL9t1hWtc+7vr9rPtLRpPLHtCSJMBHctuGvczYPzWz/ljeXsrdrL2qK1ziiIK8LFh+d+mMU5i0etbxPjJ3LH/DuAwHtxvOE41lqO1B6hILXAWYKg3dsOQFFtEbPSZzkXC3qOtA00cpYSk9InaEuJSRn1oGIkZCRkcNOsmzh88jDWWg7VHGJ98XqK64o5VHMoaE5feWN5v+f4+caf47d+ol3RREVGEeOKIToymmh3NCkxKVw97WqMMTy35znnmAlxE2hsb8Tj93DJlEvG7M9WQZuMiJaWFjIzM8nLy+Mvf/lL0L6EhIR+j3n66aedteFERETGm7TYUwFXzyUNutW01ASlhJU1lrG2aC0VTYGCWs/sfobPLP/MmP3S2VuHt4NfbP4FlU2VQduTopP4xKJPkJecN0o962tG+gyONxwH4K+H/0pzR3NQkAHg8XuoaKpw1orsGbT1XqOtW39VIgvSxm9p+/T4dOZmzGXvib0ATnXIwcxKn8XBmoMAznzVNk8bbZ42GmgIalvTUkN2YrZTACYxOpEHlz8IwLaybczPmj9sr+VcU9AmI2KwkvkqpS8iIuejnqNktW21Trpdt61lW4Pa17XVsaVsi/O4tKGU3Sd2h/XC3IV1hew5sQd3hJtYdyxx7rjALSqOlJiUoOIbOyt29gnYJqdM5u6Fdw+4fuNomTlhJn87+jeg73zECBOB3wYKopU1lvUbtCVH979YdmpMatBjY0zYjxifrcvyL3OCtp4yEzKZkzGHDcUbgpZ4uHHWjTR2NDoXLwZTWFdIUX2R83j1nNUkRAUGCy4ruOzsOz+KFLSJiIiInAPx7niiIqPo9HXS4e2gxdPifKH0+X1sK9/W55gOb0fQ41cOvMLhmsNEu6KJdkU76WGTUyaTldi3IMu51NjeyBNbn+gzAtXTBZkX8OG5HybWHcvOyp3O9ukTprMoexHzs+afdsHm0ZCbnEu8O54WT8upbUm5XF5wOfXt9c6IUUXjqcAipPTIXiNtF2ReMODC1uNFXnIeF0++mI3HNzIxYSIXZF7ABZkXMDE+MJUmMyGTZ3Y9A0BGfAbp8el87qLPUddWF/h/HxmNx+ehw9dBu7c9MKe1dAvbK7YDOCm2uUm5zJk4Z3Re5AgIv98KERERkXHIGENaXJozulTbWkt0ZDQ7KnawrmgdzZ2nz0Rp6WzpN7iLMBE8tPyhUU0p3Fy2edCADQIVAI83HOemWTc51QONMdxxwR1hN7rWU4SJ4LqZ1/HG4TfITszmsvzLmJo2FWMMxfXFTruyxjLnfkjpkb2Cucvyx/ZoUKhumn0TN82+qd99C7IW4PV7OVB9wPl5RJiIoGDWHekmjjjn8cT4ieyv3u/MLwSc+W3jhYI2ERERkXNkQuwEJ2h7r/A9jjcc7xOsZSZkcqL5RNC2hKiEQYM6v/WzoWQDH53/0eHvdAi8fi+bjm9yHl+YeyExrhhaPa20elpp7mymtKEUCAQzT+18ymk7LW1aWAds3ZbmLmVp7tI+27MTszHGYK2lurXaGR3tDiBcES5nRLW3nKQcYlwxtHvbmTNxznm9eHRPS3KWsCRnScjt46PiuWLqFc5C6JOSJzEzfeZIdW9UKGgTEREROUd6zmvbX70/aF+MK4aLp1zM3Iy5/Pj9Hwftu2XOLUyMn0h1S7WTEtbh7aC5s5mNxzcCsPfEXlpmtRAfFT/yL6SXfVX7nKAyKTqJ1XNW91kEe++Jvfx535+DSvoDY35Zg6jIKDLiMzjRfAJrLeVN5cS7T70HSTFJA474RLui+eyKz3K84ThzM+aeqy6PSxdPvpjG9kZqWmu4efbN42qUDRS0iYiIiJwzPStIdkuKTmLVlFUsy1tGtCsav/XjjnTj8Z1KNZySMoXE6EQyEzL7HF/WWEZpQylev5cdFTvOaSGLvSf28sHxD4KKRCzLW9YnYAOYlzmP5JhkfrXlV85rc0e4x0WwkpOU44yOljeWO/OzYOAiJN3S49NJj08f0f6dDyIjIgdMuRwPzv1KhXJe+M1vfsNFF1002t0QEREJKzPSZ+COcAOBIgsfmfcR/s+l/4dL8i9x1veKMBHkJJ5Kk0uPSx80fXBZ3jLn/qbjm5xCDCOtpbOFZ3c/y7HaY87oWaSJDOpPb3nJeXx8wcedxbIX5ywOu0XQz0RuUq5zv7yxnMb2RufxQEVIRIZCQZtwxRVXEBMTQ0JCAklJSSxbtox169ad/sAz9M4775CVNTwVrq644gp+/vOfD8u5RERERlpqbCr/eMk/8rkVn+MfLv4HluYu7bdaYs+CIt0l5AcyP3O+E/jUtNZwrPbYsPZ5IHtP7HXWzYJAsHnl1CtPOz9t1sRZfP6iz3Pn/Du5cdaNI93Nc6Jn0FbWWEZDx+mLkIgMhYI2AeDRRx+lubmZ+vp6Pv3pT/ORj3zknF2pExEROZ8kxySTm5w76JybpblLcUe6cUW4WDFpxaDni3ZFB80LW1c8chdee+pZsv+a6dfwjSu/wZXTrgzp2KzELBZlL8Id6R6p7p1TWYlZzvtZ01pDdUu1s08jbTIcFLRJkIiICD7xiU9QXV1NdXU1W7ZsYeXKlaSkpJCdnc0//MM/4PGcyrHfv38/1113HRMmTCAjI4OvfvWr/Z73X/7lX1i6dCnFxcXccMMNVFVVkZCQQEJCAseOHcPv9/Mf//EfTJ8+nQkTJnD77bdTXR34wGtvb+eTn/wkEyZMICUlhQsvvJCKigq+/vWvs3btWr70pS+RkJDA3//935+Tn5GIiMhIy0zI5KuXf5WvXfG1kCoKXjz5YidoOFRzqM+i1cOtob0hqGT/hbkXjos0xzMVFRnlzFe01gaNdibHDD6nTSQUCtokiNfr5YknnmD69Omkp6cTGRnJD3/4Q2pqali/fj2vv/46jz32GABNTU1cc801XHXVVZSWllJUVMTq1auDzmet5Qtf+ALvvPMOa9asYcqUKbz22mtkZGTQ3NxMc3MzU6dO5Uc/+hHPPfccf/vb3ygvLyczM5MHH3wQgCeeeIL6+nqOHz/OyZMn+eUvf0lcXBzf/e53ufTSS51Rwl/96lfn/OclIiIyUroX0A5Fenw6cyeeKuixrmhkR9t2Ve5y7o+Vkv0jLSM+w7nf0nlqEW6lR8pwUPXIUfD1v379nD3Xdz/03ZDaffnLX+YrX/kKbW1tRERE8NRTTxEREcHixYudNlOnTuXBBx/k3Xff5eGHH+bVV18lLS2Nf/7nf3barFy50rnv9Xq55557qK+v5/XXXyc2NnbA5//5z3/Oo48+yuTJkwH41re+RWZmJu3t7bjdbk6ePMnhw4dZuHBhUJ9EREQk4JL8S9hbtRcIpC5eNe2qoCUGhovf+tlRvsN5vCBrwbA/x1jUvcBzb0qPlOGgoE0A+OEPf8hnPvMZ/H4/GzZs4Oabb6agoIDY2Fi+/OUvs3XrVlpbW/F6vaxYEcitLykpYdq0aQOe89ixY+zZs4e1a9cOGrABFBcXc+eddxIRcWrwNyoqirKyMj75yU9SWlrK3XffTW1tLXfffTff+973iI4+f9MwREREepucMpn81HyK6orwWz8v7HuB+5feP+zrVb168FUqmwPpl64IF/My5g3r+ceq/sr2R0VGEeOKGYXeyHij9MgBGGPSjDGbjDHNxphFo92fcyUiIoJLLrmEGTNm8NZbb/HZz36WWbNmcfjwYRobG/nXf/1Xp0DJpEmTOHZs4ApVM2fO5Mknn+SWW25h9+7dzvb+/nhMmjSJl19+mfr6eufW3t7OtGnTcLvdfPOb32Tv3r1s3LiRv/71r04q5HhbOFFERORsXDfjOudv49Hao2wu3Txs5+7wdvDmkTf5oOQDZ9vlBZcT41ZQAsHpkd2SY5L1XUWGhUbaBtYE3Aj8YLhPHGrK4mj54IMP2LdvH/PmzePZZ58lKSmJhIQE9u/fz2OPPUZubqCs7c0338yXv/xlvv/97/OFL3wBv9/Pzp07g1Ik77jjDjweDx/60Id46623mDdvHpmZmdTV1VFXV0dqaioAn/nMZ/jGN77Bb3/7WwoKCqipqWHt2rXcdtttrFmzhvT0dObOnUtCQgIul8sZkcvMzBw0cBQRETmfTE6ZzKVTLuW9ovcAeOnAS2wr38asibOYlT6L7MTsIQcRdW11vF/yPlvKttDh7XC2z8ucx5VTQ6sWeT7ouaB2NxUhkeGikbYBWGs91tqa0e7HudJdgTEhIYF77rmH73znO9xwww384Ac/4A9/+AOJiYk89NBDfOxjH3OOSUxM5M033+SNN94gOzubgoICXnnllT7n/vjHP873v/99rr32Wvbv38/s2bP5xCc+wfTp00lJSaGwsJAvfvGL3HbbbVx//fUkJSWxfPlyNmzYAEBlZSV33HEHycnJzJkzh4suusipFPnFL36RF154gdTUVB566KFz88MSEREJY1dNu8oZ9bHWcrzhOG8deYuffPAT/vO9/+SFfS+wv2p/UADWn+P1x3l619P8cN0PWV+8Pqj95OTJ3HHBHRpF6iHGHUNSdHDREQVtMlzMuVqLyxjT3GtTLPBTa+0XzvK8DwP3A/OBp6y19/XanwL8ArgBaAS+a6396RDO/xvgUWvtjtO0ywcKCwsLyc/PD9pXXl5OTs7py/XK2KD3U0REwl1tay0v7HuBY3XHBlx31RXhItoVjbWWWemzuHXurURGRLKvah/ri9dTUl/S55j0uHRWTVnF4pzF42aNteH0+JbHOVp71Hl81bSruHra1aPYIwlHRUVFFBQUABRYa4tCOeacpUdaaxO67xtjEoBK4I/9tTXGLLbWbu+1bR5wxFrb+7JQOfBt4DoCgWBvPybwOnOAacCbxpj91to1xpgs4Ol+jnnIWnswtFcmIiIiEl7S4tL49IWfprWzlcMnD3Og+gCHTx6mzdPmtPH6vXg7vQBsr9hOfXs9Hb4OyhvL+5xvWto0Vk1Zxcz0mRpdG0R6fHpQ0KaRNhkuozWn7XagCljbe4cxJg943Rjz99bal7u2LQbeAG4D1vdsb619vqvNhUBer3PFA3cCi621TcAOY8zjwKeBNdbaSuCK4X1pIiIiIuEhLiqOhdkLWZi9EL/1U1JfwsHqgxysOciJ5hNBbQvrCoMeR5pIFmQvYNWUVWQnZp/Lbo9ZvYuRJEcraJPhMVpB26eA39p+xuuttaXGmNXAq8aYe4Ay4HXgC9ba9b3bn8ZMAimg+3ps2wF8KJSDjTFvAXOB2caYx621v+i1/xHgX4bYJxEREZFzLsJEkJ+aT35qPtfNvI7WzlZ81sfm0s28ffRtp507ws3FUy5m5eSVWjR7iHoXI9FImwyXcx60GWOmAJcDfzdQG2vtRmPM7cDzgBf4J2vtM2fwdAkE5rH1VA+E9Alkrb3mNPsfAR6BU3Pahtg/ERERkVERFxUHBOZdxUfFs7ZoLXnJeVw34zpSY1NHuXdjk4I2GSmjMdL2SWCdtfZ0AU4p0A7EAUdP03YgzUBSr23JBMr5i4iIiAiwYtIKVkxaMdrdGPMSoxPJTcqlrLGMySmTiXZFj3aXZJwYjaDtXuDfB2vQNRr3NvAdAqNXfzbG3Gyt3TjE5zoEWGPMHGvt/q5ti4A9QzzPWbPWauLuOHCuqq2KiIjI2GOM4b4l93Gs7hjT0qaNdndkHDmn67QZYy4GchmgamRXmwwCAduj1tqfWWtfJ5BK+bIxZkE/7V3GmBggEog0xsQYY9wA1toW4Dng28aYxK7jPw08PtyvbTDR0dHU1dXh9Xr1pX8Ms9bS3NyM260SxyIiItK/uKg4Lsi8gFh3f0XNRc7MuR5p+xTwfFclx4HUA1+x1j7XvcFa+5Ix5l4CRUl6+wbBxUDuAZ4A7ut6/Hngl0AFgfltj1hr15zpCzgTaWlpNDU1UVNTg9/vP5dPLcPM7XaTlpY22t0QERERkfPIOVtce7wbbHFtEREREREROLPFtc9peqSIiIiIiIgMjYI2ERERERGRMKagTUREREREJIyNRsn/8SoSoLS0dLT7ISIiIiIiYapHvBAZ6jEqRDJMjDGXAGtHux8iIiIiIjImXGqtXRdKQwVtw8QYEw0sI7C0gG+UuzNe5BEIhC8Fui9JFAIFo9Yj6Wk43ov+3mMZmrHwO3G+vM9j4b0YCeH4/p6v78VIOdP3WO9D+Oj5XoTj7+z5pBCYDmQDm621HaEcpPTIYdL1Aw8pUpbQGGO675Z2l0M1xhBqaVQZWcPxXvT3HsvQjIXfifPlfR4L78VICMf393x9L0bKmb7Heh/CR8/3Ihx/Z88nXe/FUeDoUI5TIRIREREREZEwpqBNxppvjXYHxKH3IjzofQgfei/Ch96L8KD3IXzovQgfZ/ReaE6bhC1jTD5dOdgavh+f9B6fH/Q+j296f8c/vcfji97PsUkjbRLO6glcjagf3W7ICKpH7/H5oB69z+NZPXp/x7t69B6PJ/Xo/RxzNNImIiIiIiISxjTSJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iInJeM8a8Y4zpNMY0G2MajTF7jTEPDOF4a4y5YuR6KCIi5zsFbSIiIvA9a20CkAJ8C3jMGHPZuXpyY4zLGGPO1fOJiMjYoqBNRESki7XWb619FqgFlgMYY1Z0jcadNMYUG2O+bYxxde3b23Xoa10jdX/s2l5kjLmv57l7jsgZY67oenyXMeYI0ArEd237nDFmQ9f5dhljLu5xjiuNMVuMMQ1d/VlvjEkd2Z+KiIiMNgVtIiIiXbpGvO4GJgAHjTGzgLeAnwCZwGXALcA/A1hr53UdeoO1NsFae+cQn/IOAsFhEtDSte3vgU8SGPV7F/hdj/ZPdvUlBcgG/i/QOcTnFBGRMUZBm4iICPSGweIAAQAASURBVHzFGFMPtBMIkr5mrX0Z+DzwgrX2j9Zar7W2GPg34P5het5/ttbWWmvbrbW2a9sPrLVHrbVe4DFgqjFmQte+TmAakGOt7bTWvm+tbenvxCIiMn4oaBMREYF/t9amAKnAr4FrulIgZwB3GmPqu2/AL4GsYXrewn62lfe439z1b2LXv6uBqcBWY8xhY8y/GGMih6kvIiISplyj3QEREZFwYa1tMsZ8HthPYJStEvittfbBwQ7rZ1sTEN/9wBiTM8Dz+YfYv93A3V3nXAS8AZQQCDRFRGSc0kibiIhID9baDuBfgW8AvwE+aoy53RgTZYyJNMZMN8Zc3+OQSmBWr9NsAe42xiQbY5KBfz/bfnU9//3GmIldmxoAX9dNRETGMQVtIiIiff2OQAXJa4DrgIeAMuAk8BwwpUfbrwJfN8bUGWOe7tr2DQKFRUoJBHB/HqZ+3QHsNca0EChS8hsCxUlERGQcM6fmPYuIiIiIiEi40UibiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTOu0DRNjTDSwDKhA5ZdFRERERKR/kUA2sLlrmZnTUtA2fJYBa0e7EyIiIiIiMiZcCqwLpaGCtuFTAbB27Vry8vJGuy8iIiIiIhKGSktLufTSS6ErfgiFgrbh4wPIy8sjPz9/lLsiIiIiIiJhLuQpVSpEIiIiIiIiEsYUtImIiIiIiIQxBW0iIiIiIiJhTEGbiIiIiIhIGFPQJiIiIiIiEsYUtImIiIiIjJDDJw/z4ac/TFNH02h3RcYwBW0iIiIiIiPke+u+x4sHX2Rv9d7R7oqMYQraRERERERGQHVLNX/Y/QcAGtobRrk3MpYpaBMRERERGQG/3PZLOnwdADR2NI5yb2QsU9AmIiIiIjLMPD4PP938U+ZOnAtAQ4dG2uTMKWgTERERERlm60rWUdZUxj9d/E+A0iPl7ChoExEREREZZk2dgWqRcyfOxWA00iZnRUGbiIiIiMgw8/l9ALgj3SRFJ4U80rapbBOff/XzWGtHsnsyxihoExEREREZZj4bCNoiTWQgaAtxpO21w6/x0y0/dQqYiICCNhERERGRYdc90hYZEUlyTHLIQVt3sOb1e0esbzL2KGgTERERERlm3UFXpIkkOTo55PTIdm87EKg+KdJNQZuIiIiIyDDrTo90RbhIjkkOeZ22Dm9gpM3jV9AmpyhoExEREREZZkHpkdGhp0dqpE36o6BNRERERGSY9SxEMpT0SM1pk/4oaBMRERERGWZnW4hE6ZHSk4I2EREREZFh1rsQSaev00l9HIzSI6U/CtpERERERIaZkx4ZEVinDQgpRVKFSKQ/CtpERERERIZZd3pkd/VIIKQUSY20SX8UtImIiIiIDLPehUiAkMr+qxCJ9EdBm4iIiIjIMOtdiASUHilnblwEbcaYFGPMs8aYJmNMmTHmc4O0fbirTZMx5hljTFI/bdKNMTXGmA9GtuciIiIiMh71N9Km9Eg5U+MiaAN+DLiAHOAm4FvGmCt7NzLGXAv8S1ebXMAN/Kif830f2DdivRURERGRcc2pHjnUkTaV/Jd+jPmgzRgTD9wJfMNa22St3QE8Dny6n+b3Ab+21u6w1jYCXwc+ZoyJ63G+y4EZwK9Huu8iIiIiMj456ZFDHGlz0iM10iY9jPmgDZgJGGttz5GxHcAF/bS9ANjZ/cBau7/r7gwAY0wUgVG7zwN2oCfsSsfM73kD8s7mRYiIiIjI+OGzPiJMBMaYIZX8706PVCES6ck12h0YBglA71I89UDiAG17/7Y09Gj7FeAta+1OY8ziQZ7zSwTSLEVERERE+vD5fUSaSCCQIhnvjg9tpE3pkdKP8TDS1gz0LiaSDDSF2DYJaDLGTCeQPhlKMPYoUNDrdmnIPRYRERGRcc1nfURGRDqPk2OSQyr5H26FSP7pzX/iveL3Rrsb573xMNJ2CLDGmDk90h0XAXv6absHWAg8BWCMmQ0Y4DDwUSALOGSMAYgFYo0xlcAUa21H90mstfUERvMcXceIiIiIiASNtAEkRyefdqTN6/fit34gPEbavH4v39/wfay1XDblstHuznltzI+0WWtbgOeAbxtjEo0xCwgUIXm8n+a/Ae43xiwwxiQC3wGesda2As8AUwkEfIuAbwK7gUU9AzYRERERkdPx+r19RtpON6etuwgJhMdIW/fIYHfKpoyeMR+0dekuHFIBvA48Yq1dY4yZbIxpNsZMBrDWvgl8u6tNBeAHvtC1r81aW9l9IzDXzdN1X0REREQkZD7rwxVxKqktlJG27tRICI9CJHVtdQB0+jpHuScyHtIju9MV7+xnewmB4iM9t/2I/tdm633sbwiMzImIiIiIDEmf9MiYZIrqiwY9pueIVjikR9a31wMaaQsH42WkTUREREQkbPQpRDLEkbZwSI/sDto00jb6FLSJiIiIiAyz3iNtSdFJQ5vTFgYjbXXtgfTInv2S0aGgTURERERkmHmtt89IW5u3bdARtKD0SI20SQ8K2kREREREhll/c9qAQddqC7dCJArawoeCNhERERGRYdZf9Uhg0Hlt4ZYeqUIk4UNBm4iIiIjIMPP5fX3WaQMGndcWboVIVPI/fChoExEREREZZj7bKz0ylJG2Myj5/9axt/jVtl+dYS8HV99RD6gQSThQ0CYiIiIiMszOZKStZ3AU6py2X2z9Bd9b+70z7OXgNKctfChok/NOcX0xJ5pPjHY3REREZBzz+r1DHmk7k/TI5s7mESta0p0eqTlto09Bm5x37vrTXfyfv/6f0e6GiIiIjGO9F9dOik4CTjPSdgbpkS2elhErWqKRtvChoE3OOzWtNc5ikSIiIiIjwefvVT1yCCX/493xoQdtnS0jNtLmVI/UnLZRp6BNzjttnjZdMRIREZER1bsQSVRkFDGumJBK/idGJw4pPXKkKk12X+TW96bRp6BNzjttXgVtIiIiMrJ6FyKBwLy2UNIj493xIY+etXhGZqSt3dvujPxpTtvoU9Am5512b7uCNhERERlRvUfaIJAiebpCJAZDnDtuSOmRIzGnrTu4TIxK1PemMKCgTc4r1lraPG1hsWCliIiIjF9ev7f/kbbTpEdGu6JxR7pD/q4yUiNt3amRmQmZdPo6sdYO+3NI6BS0yXml09eJxeqKkYiIiIyo3oVIoGukbZD0yHZvOzGuGNwR7pBGzzw+D52+TvzWj9/6z7rPPXUXIcmMzww81whVqJTQKGiT80p3braCNhERERlJ/aZHnm6kzddBdGToI20tnhbn/nCPtjlBW0IgaNN3p9GloE3OK23eNkAfPCIiIjKy+itEkhSdNGjJ/w5fV3pkhDukIKyl81TQNtxTP7qDtoy4jEDfVPZ/VClok/NKm0dBm4iIiIy8AUfaQkiPdEW4QkpHbO5sdu4P90hbXdupOW2g706jTUGbnFc00iYiIiLnQr8l/2OSaepswuf39XtMh/fM0yOHe85Z7zltKvs/uhS0ybjXc3Ju95w2TaYVkbPxq22/4r4X7hvtbohIGPP6vf2OtAE0dTb1e8xQC5H0TI8ciTlt0ZHRJMcE+qwL3qNLQZuMe3f/6W7uf/F+QOmRIjI8Xjz4Iq8cemW0uyEiYcxn+68eCQyYIunMaQtxpK1neuRwz2mra68jJSaFqMioQN80p21UuU7fRGRs23Vil/MhqfRIERkOxfXFQWlJIiK99Zse2TXSNlAFyQ5vhzPSFlIhkhGuHpkam+oEbfruNLo00ibjXnVrtZM+0J0e6fV7h309ExE5fxQ3FNPubR9wXorIcPL4PMM+iiIjr99CJKcZaRtqIZKg6pEjMKctJSaF6MhoQEHbaFPQJuOaz+/jZOtJ50pUd3okDH8agYicH+rb652S3a2e1lHujZwP7vnzPU6av4wdPn/foC0pOgkYZKStR8n/oaZHDnv1yN7pkSpEMqoUtMm4VttWi8U6V6K60yNBV4xE5MwU1xc79xW0yblQVF9EUX3RaHdDhsjr9w6YHjnQWm1OIZLIEAuReEZ2nbbUmFSiXRppCwea0ybjWnVrNXDqQ607PRJUQVJEzkxxw6mgTfPa5Fzw+DxKxR2DziQ90in5fwaLa4/EnDYVIgkfGmmTca26pSto62zBWhuUHqkrRiJyJnqOtPX8wiQyUjx+T9BFRxkbfP5+qkeerhCJb2jrtAVVjxzGi9HWWura6k47p81ay1ff+ir7qvcN23P3tKlsE1c+caUCRsZJ0GaMSTHGPGuMaTLGlBljPjdI24e72jQZY54xxiR1bY82xvyvMaa4a99OY8zqc/cqZCTUtNYAYLG0e9uVHikiZ00jbXKueXwK2sYin+1bPbK7MuSwFSIZoeqRLZ4WfNZHakzqoHPayprK+Pf1/85dz901It+r3j/+Pu8UvUNVS9Wwn3usGRdBG/BjAqmeOcBNwLeMMVf2bmSMuRb4l642uYAb+FHXbhdwHLgcSAa+AjxljJk54r2XEdOdHgmBD6Cef/QUtInImegZtGlOm5wLnb5OBW1jUH+FSIwxJMckD1ryfyiFSEZqTlt9ez1AYKRtkDlt3cHn7qrdfG/t94bt+bt1X2xXEZRxELQZY+KBO4FvWGubrLU7gMeBT/fT/D7g19baHdbaRuDrwMeMMXHW2hZr7SPW2iJrrd9a+xpwCFh2bl6JjITu9EgIpDEpPVJEzlZxfTFpsWmA0iPl3PD4PUGZIjI29DfSBoEUyf6CNmstHb4OpxCJz/qw1g76HCOVHlnXVgdw2jlt3cFdQUoB3137XXad2DVsfYBTVb/1nW0cBG3ATMBYa3sm0+4ALuin7QXAzu4H1tr9XXdn9G5ojJkIzAH29rMvxRiT3/MG5J3xK5Ah+eXWX/LxP308pLa9R9qUHikiZ6u4oZi5E+cCSo8ca2paa8j+r2zWFq8d7a4MidIjxyav39tnpA0CxUj6S4/s/l7SXYik+xyDaelsIcJEhNR2KLqDsdTY1EHntHUHnz+64UekxaZx/4v3D+uInzPSpjlt4yJoSwB6102tBxIHaNv7t6Shd1tjjAt4Enima+Suty8Bhb1uY+svwBj2t6K/8ebRN0NqGxS0dSo9UkTOTpunjaqWKuakzwE00jbWbC7bTGVz5bCPBoy07vTI0426SPiw1uK3/j6FSCCwVlt/Jf+7UwCjXYFCJHD60bMWTwspMSmBtiOUHjnYnLbu4HNa2jR+euNP2VaxjR9s+MGw9aN7pE3pkeMjaGsGknptSwaaQmyb1LOtMSYC+F3XwwcHeM5HgYJet0uH0mk5czWtNSH/8galR/YaadPi2iIyVCUNJQAaaRuj9lTtAQau3BeuPH4Pfusf9pLuY0mHt2NMXSTxWz/AkNIjuy8sdxcigdN/V2nubHaCtpEYaesZtA020pYcncztc2/njrl38Mi7jwxbNcnuecMaaRsfQdshwBpj5vTYtgjY00/bPcDC7gfGmNmAAQ53PTbA/xIoaHKbtbbfoRhrbX3X3DfnBpQOw2s5LxXVF/Hd974b8hXEk60nQ04TqW6tJjshG9CcNhE5e91FSLqDNhUiGVv2VAe+GnR/IR0rur+4n88pkp999bNc//vrR7sbIfPZwLp6Q0mP7A5MeqZHnnakrbPFWUZgWOe0tQfmtPWsHtnf96bu36Xu9ed+cuNPSIxK5NMvfnpY1hZUIZJTxnzQZq1tAZ4Dvm2MSTTGLCBQhOTxfpr/BrjfGLPAGJMIfIdACmT3X92fEZjHdnOPbTLCfrfzd3xjzTc40XIipPY1rTV4/V7nKtZgqluqmZIyBVD1yKH4yaaf8Kd9fxrtboiEne412mZNmIXBjKkr/wK7T+wGxmDQ5j+/gzZrLa8efpUjtUdGuysh6w5YznSkzUmPPM1IW8/0yJEYaUuOScYYgzvC3e9oV0N7A64IF7GuWAAy4jP40Q0/YmPZRh794NGz7ofmtJ0y5oO2Lp8HLFABvA48Yq1dY4yZbIxpNsZMBrDWvgl8u6tNBeAHvgBgjJkCPERglK6i67hmY8zXzvmrOc8U1hcC9Jvf3Z+TbSeB0/8CW2upaa0hPyUf6Bpp87YR44oBFLQN5sebf8zPt/58tLshEnaKG4qJNJHkJuUSHxWv9MgxxOf3OSlbYylo8/l9zkXK8zVoO1BzgKqWKmrbasfMvL5BR9qik2nsaOzzWoLmtIVYiKRnemSo0z7aPG2n/Q5U315PQlSCk6YZ7YoeMD0yJSaFQLJawF0X3MXqWav5xppvUFhXGFKfBusraKQNxknQ1pWueKe1NsFam2Ot/WnX9pKubSU92v6oq02CtfajXaX/sdYWW2uNtTama1/3bfgXnZAgRfVFAAMuNNlTm6fNSUc63R+vxo5GPH4P+cn5QNecNk+bk0agoG1gnb5OShuV8Svhr93bzv954/845alH2oGaAxSkFuCKcBHnjtNI2xhypPaI88VvLM1p65nyFq5BWyh/v8/Gu8XvAoG/TWMlJbk72Op3pC0mGb/1B5Xrh17pkSEUIrHW0tI59JG2m566ic+/+vlB29S115Eak+o8joqM6jdwqm+vd75XdTPG8K9X/Cvt3nbeL30/pD4NRCNtp4yLoE3GNidoC+GPaPcoG5z+qkt35cieI23t3naSogO1aBS0DazT10lZY9lod0PktNYWr+WHH/yQvxX+7Zw8347KHSzKWgRAvDueVm9oXyDHyujAeNZdhCQ9Ln1MjbT1HD0Jx6Btfcl6JvznBOdv+VDtOrHrtGl03UEbQG1b7Rk9z7nWnR7ZX/XI7iCn9/eeoRYiafe2Y7GnRtpCmNPW6etkXck6jjceH7RdfXu9c14IBJIDjbR1z2frKTE68bT9D4XWaTtFQZv8/9k77/i2qrv/f46mLct7JF6xE2eQnZBFQkLCLjNAS6FlQ8sqFEqhT9tfy+h6CqW0T8tsKauMtqxSNqQhIRBCBtk7jlfs2PFesjXP74+rc32vdCVdyZItO9/36+VXYvnq6kr36tzzOZ/vGFY8Po88cOhZqWt1KERbhFUXUTmyNLNUyj3xV48Ug0s8E3ZHG06PE92ubt0hqwQxXBxsOwgA6HZpFQwOjdvrxqb6TVE9p8vZhcr2SswZMwcApPBInU7bZa9dhhvfDlWQmBgKdh7bCQaGxSWLR5ZoU9yrkrHB9vam7fByb8xhcC9sfwE/+PAHIYtWcM6xpnqNvOA6YkRbhEIkQHBaiFZ4ZLi5inDqonHa9jTvgdvnjrjwHSjaQjltnf2dqu2U2wODF1tUiGSAhIo2xlgmYyzV/3/GGLuGMXZlIl+TGFk0dDfIg4wep63F0SL/X6/TVpBWIIcxUXikPsRnQ24bkewcaD0AAOh2Rifant32LBY9vQiNPY26nyN6eymdNj05bR6fB+8efBd7W/ZGdYxEfNl1bBcm5kxEob1wRIk25b0qGZ02EUofq5gSwkNUKwzkYNtBNPY04rxJ54XdLtkIV4hECNDAxepoC5GI8UeuHqnD1dp6dCuAyAvf7X3tyE4dCI8MldOmFR4JDIi2wS6QyzltFB6ZcKftHQCz/P//OYAHAfyWMfbLBL8uMUJQrszpctoU4ZGRbl7Cacu35csFAyg8Uh/is6G8NiLZidVp+/LIl+DgUYm2bY3bAChEm06nbUfTDjjcjhGX//blkS+x+G+LVa1SRjI7j+3EzDEzkZWSFXUOltfnjdqZHQwv73wZT21+CkDyh0eK+0SsYkqItlCib221FBp58QkXh90u2YhUiAQIXqzWKvkfzj0TY0o0TtvWRkm06SlEEuS0aVWPDBEeSU5b/Em0aJsKYIv//1cAOAtSE+qrEvy6xAhBGQMftdMWKTzS77Tlp+XLK+J9nr6oRZvb6z7u8lFkp62bnDYiuYnVaRMTl2gKmGxr3IY8Wx6K0osAADazTVdRhPV16wGMvJ5uX9Z/iQ1HNoyKcaDP3YdDbYcwI38GslKy4PQ6oxJAH1Z+iIVPL5Tz4hLNI188gqe2+EVbkhcikUVbjMWAhGhTpj8oWVOzBmPtY7GoZBGA6EXbV0e/ijnfbjCELfnvFzmBiweq8EgdhUiE0xZNTpsY+3SFR1qz5N8tRot2Tlt/p2o7gRCdgxZt5LTJJFq0GTnnHsZYEYAMzvkOznkVgNwEvy4xQqjuqAYDQ4opJfqctkjhkb3NsJltsJlt8op4tOGRXp8XFX+qwOObHo+47WjB6/PKK4TktBHJjNvrlt36aJw2l9clT76jcQdEERJR2lpveKSonjbSRJuYTI+G3NYdTTvg4z7MHjtbnjBHEyIpFgyHQrT5uA/7WvbJ97hkD48Ueeniu7SjaQeWP7dc93UTzmnjnGNt9VosL1uO3NTckNuF49uvfxs/W/2zqJ4TD+TqkVE4bdEWIhGfnbimIzltPu6TIwbCiSCvz4tOZ6c6PNJoDZp3eX1edLu6yWkbIhIt2g4xxq4BcDOA1QDAGMsDMLJiRAhNWhwtWPDXBXKeRyxUd1ajKL0Iuam5UVePjBge6WhGni0PgDS56nZ1w+1zy4OLnoFkf+t+1HXV4XD74YjbjhaUnwvltI0ujnYfxYs7Xhzuw4gbVR1V8gJDNMJCJOID+t0Bt9eNXcd2yUVIAL9o0xHy+EUdibbhZlODFNq4sHih7EpEEyIpzt3+lv1xP7ZAjnQdQa+7Vx6Lkzk8knMe5LR9WvMpPq35FOtq1unaRzjRdrj9MOq767GifAVsZhssRkvUoq3F0aKaOwwVYmzSrB4ZymnTCI8M67T5x590SzqMzBgxp62yrRI9rh6YDKawIkh85wPDIwPnTWI7rZw28b4HI9o45/I1T05b4kXbjwD8GlJopOh3dj6AzQl+XWII2Fi/EZsbNstx97FQ3VGN8qxyZKZk6poYRBsemW/LByDlngiXzm6xg4HpGkhEwu5Im2wNBuXncqSbnLbRxPPbn8dVb16V8J5KQ4UIjWRgUTlt4nsN6F+139+6H06vU85nA6CruXZTTxOqOqqQakodcY24xYRwNIi2jfUbUWgvRHF6sTwRjcZpE/eAA20HEnB0ava17AMwMBYnc3hkW1+bfEzCaRP36Y31G3XtQw6P1BBWa6rXAACWly0HYwzZKdlRiTbOObqcXcNyDYcLj0wzp8HIjGGdNhEeGTanzT+mpFnSYDKYIjptIjRyztg5YedA4ruhKvmvUYhEHL9W9UjGGCxGy6BK/iuvd3LaEizaOOefcM5LOOcVnPPd/odfAnBxIl+XGBoq2yoBAK/tfU13Q8dAqtqrMD57PDKtmbqdNqvRCiDyF7jF0YL8NL9oM6fJN5JUU6rugeSro18BSM4yy4lC+bmS0za6iJTwP9I42CoVIZmcOzmqnLZtjdtgM9tgMph0h0cGFiEB9OW0idDIpeOWot/TDx/36T7O4WY0OW0b6zdiQfECMMYGJ9paEy/a9jZLVUbFwmQyO23KEHrxXRJFwL6s/1LXPsKNS2tr1qIgrQAn5J0AAMhJzYlq/HJ6nXD73MMj2sIUImGMIcOaEXRcQhRZjJYBp01HeGSaOQ1mozliTtvWo1thMphw4tgTwy58i3MZ1Fw74DniO6QVHglIeW2DcdqUcy9y2oaoTxtjLJsxNo4xNg5Aof+HGOFUtkui7VjvMXxa82nUz/f4PDjSdQTlmZLTpmf1v8XRIhcB0NOnTem0yaLNnAqzUd9A8lWjJNqOR6fNZDBRTtsoQ1zHo0W0HWg9gJzUHJRnlUfntDVuxewxs5Gdkq07PHJb4zZYjVZMyZsiP5ZmToPL6wq7aPVF3RcwG8xYNm4ZAIyoSow97tEh2jr7O7G/dT8WFi0EMBDKFY1oE+ftQOuBhBemEq0hxFiczDltIp9N+V0SRcA21m/U9VmFK0SytmYtTik7Rc4jjVa0iWs32Zw2QCr7H7hYLUSX2WjWV4jE74bbLXZdTtu2pm2Ynj8d6db0sAvfmk6bRnNtMW/TCo8EQhcv0Yty7uXyRbefnU078eruV2N+7WQk0X3aFjPGDgFoAVDl/6n2/0uMcCrbKzEpZxLSzGn4565/Rv38I11H4OVelGeVaw5eWrQ6WlGcUQxAX06bLNrMafKKTYopRddAwjmXw6iOJ6dNfC5lmWVodjTT6lYE2vvaR4yoH22i7WDbQUzKmYR0a7pup00k4s8dOxfZqdlROW0zx8xU5aekWdIAIGxe2/oj6zGvaB5yUnMAjKwFoNESHrm5QcrIWFC8AMDARFTPPUcgzluXswtNvU3xPcAARHikmFSrmmsnmegXC3szx8wccNr8oq29v11uyREO2WnrV49L1R3VqO2sxYqyFfJjOak5URUPEtfucISEhytEAkBzsVq4aiaDSVchEmV4pNlgjhhBVNtZi4qcCqmoSJh7u5Zo02quHS48UjxnUE6bO3an7Y8b/ogr3rhixI9fShLttD0B4D1Ivdom+H/G+/8lRjiVbZWYUTADF065EK/vfT3quGVRglcOj4zWaQuzSuRwO+BwO1ThkQIRHhlpIKnqqJIHpJE00Ros4nOZkC19TRu6G4bzcJKeU58/Fd9773vDfRi6GG2i7UDrAUzOnYx0S7pup+1w+2F0u7oxt3Cu7lV7zrlUOVJRhAQYGFdC5aq5vC5sbtiMxSWLYTPbwm4bDh/3YepjU/Hs1mejfu5gGC3hkSK3an7RfAAYVHgkkPgQyUCnLdnDI43MiKl5Uwectt5mTMyZCCByXpvb65bv5YHfRTmfrXy5/Fjgd7bH1YPb3rsND69/WHP/SqdtqFv3hCtEAkAzLcTj88DADDAwg65CJKKoiMVo0eW0tThakG/Lh9VkhZd7ZTcwEPHdiNRcO1J4pMVoGVRzbVV4ZJQ5bV2uLrh9bnx46MOYXz/ZSLRoqwBwJ+d8N+e8RvmT4NclEoyP+3C4/TAqsivwzenfRGtfq5y7oRch2soyy1SDV2d/J748EhwL7/K60O3qRnG65LSFW3VRNtYGBlbEASk80mK0RLTaRT5bTmpO0oo2j88jT6wGQ1NPk/yZic9ViLbR0KMpUXh8Huw6tgtv7397ROQqies41ia4yYTD7UBdV53ktFn0O23CPZ87dq4U0qXjs6jvrkdrX6sqnw2ALMQcbgfWVq/FP3b9Q/X37Y3b0e/pV4m2WMaSw+2Hsa9ln1xEYKgYLaJtU8MmTMqZJLudNrMNRmZUiTa3143HNz0eUhQ5PA65hHkiRVtbXxuO9R5DhjUDHp8HPu5L6kIkR7qOoCi9CHm2PHT0d4BzjhZHC04ZdwrsFrvmvVyJchEjMDxybc1a5KbmYlr+NPkxpWjb27wX8/8yH49tegz/9+X/ae5fXLscfMgLAUUKj9R02nxuWazpKkTi6oXdYpe3DyeQfNyHVkcr8mx5EcvxCwGuctoMwTltiQ6PHIzTJu4Jbx94O+bXTzYSLdp2ABiX4NcgEkBHf0fIFRhAKlDh9DpRkVOBiuwKAFJuWzSIATo/LR+ZKZno9/TD5XXhT1/+CSf97aSgVWUxUAvRFu7mpWysDaidNr3hkSJhd0HRgqQLSRH834b/wwmPnjDo/Vz22mW46Z2bAAwM4uOzxgOgXm3hECG+rX2tqoqEycpoctpEIaTJuZOl8EhXt66V9K2NW2FkRkwvmC6FR+rIadMqQgKowyN/+/lv8cOPfqj6u1jIWlw6ONG2s2kngKEX26NFtIkiJAJRjEQ5YX5j7xv43nvfwzsH3tHcR5+7DxOyJ8BqtCZUtIkiJLPGzAIgjcfJnNN2pOsISjJKkJ2SDS+Xenu1OFow1j4W84vmRyxGolx0DByX1lZL+WwGNjBVzUnNQY+rBy6vC3d8cAdaHC24fMblONJ1BI09jUH7V167Q30dhytEAmg7bW6vWxZregqRtPe3y6ItktPW0d8BL/ciz5YXsaBbR38HDMwg7xsIXz0yZCESnfUDQjEYp01cW+8dfC/mYnnJRqJF24sAXmOMXcYYO0X5k+DXJQZBj6sHZX8sC9vPSRQhqciuQLo1HQCiqt4GSAMoA4PdYh9oNNnficMdUk+077z9Hfx737/l7UUhET3hkWGdNp3VI79q/ArT86WJ3VA5bbuP7cZ5L5+n+/W+avwK9d31gxKVnHNsb9ouC93A8EiqIBka0dgZAD6q/GgYj0Qfo0m0iYmzCI/0cZ+u3NOtjVsxLX8aUkwpup02IdrERFqgDI+s6ahBQ3eDalL9xZEvUJJRgpKMEnkMikm0HZNE21CfN+FMRJP7lWw0dDegvrteLkIiyErJQoezQ/793/v/DQA41HZIcz8OtwN2ix0TcyZif2vierWJfDYRiuv0ONXhkd7kEm11XXWSaPOH0VW1S70T89PysbBoIbY1bgsrNMXEekzaGFXJ/9rOWlR1VGFF+QrV9qKaYXtfO7Y1bsPFJ1yMW+ffCgDY0rAlaP9aoq26ozqq0NhYiei0aaSFeHweOZxSTyGSDUc2YO7YudL2hvBOm5hD5dnyYDX5RVsI96qjvwNZKVkqwayZ09bfKc+ptIiX05ZiSoneaXN1w2q0SpFgddFFgiUriRZtjwE4EcArANYofj5J8OsSg6CqvQpdzi5UdYSuFyNWuStyKpBu8Yu2KKq3AdIAmm5Nh4EZBhpNOjtxpOsIZhbMxIKiBbj8tcvluHbhzBWkFcDIjOHDI/0CRNlcW5BqTtVVhnbr0a2YWzgXNpNtyAqRPLftObx38D3sOrZL1/a1nbUAosvNCKS1rxUd/R3yjVV8LgVpBbCZbceN07avZZ/uvkIC8R3Js+Xho8MjR7TprZiYzIgCBxNzJka1cCS+18BAxbtIoa3bGrepXkegdNrEd1GEfQPA+rr1WFyyGMBAKKWeZtyBDJdoGw1O26b6gabaSjJTMuVx0+lx4t0D7wIYuLcF4nA7YDPbMDl38qCcts0Nm/Hk5idD/n1vy16kmFIwKXcSAGk8FhNxAzMkldMmGmsLpw0YWEzJt+VjUckiuH1ubG/cHnIf4hoblzkOXc4uWaCurV4LQOrPpkSEuO5r2YdmRzNmFMzA3MK5YGBywRklymtXCKRTnz8Vv1z7y5jecyi8Pi/+9OWfVOcnotOWIjltyggBZXhkpEIkDd0NONh2UP6MIjltQrTl2/Jlpy1keGR/e1BxES0B1tHfEdJlC/WcaBBzr+yU7Kidtm5nN86qOAtmg3nUhEgmWrSlc84NGj/aVzCRFIjJR7gbdWV7JUwGE8ZljpPt81ictgxrBoCBeOguZxfqOuswJW8K3v32u5iQPQEXvnIhth7dqlolSjGl6HPa0kI7beEGkm5nN5p6m3BC7gm6ejHFi1VVqwAMnIM+d58sWrWo6ZDSQwcTNiV6XQkRLD5Xq8mKkoyS4yKnrbqjGsueXYYb/nNDVM+raq+CgRlw5cwr8Xnt53HJL0wkstPWPzqctkJ7IdKt6boXjhp7GtHU2ySvTOek5oCDRxQl2xq3BYVGAgOLQUe6jsiulHBfG7obUNtZiyWlSwAgPuGRQyi2OedJK9r+uOGP+Lz2c13bbqzfCJPBFHT+slKyZNG2pnoNul3dsBgtchRJIEK0Tcmdgsq2ypjDrZ7a/BR+vOrHIf9e2V6JiuwKpJpSAajDI9Mt6Ukh2uo663DFG1fgw8oP4XA7UJpRKospIdrybHlYVLwIQPh+bUrRBgzcy9bWrEV2SjZmjpmp2l68ztoaSdTNKJgBu8WOqflTsfloeNHW5eyCj/tQ21mLY47o0jki8Xnd57jjgzuw6vAq+TG5emQYp83j86jOqWZ4ZAj3TAhb4UaajeGrRyrnUMIZCxceGSjarEarnGcp6HR2hsxnA+JQiMTvtGWlZEXttPW4elCcXozl5cvx/qH3Yz6GZCJhoo0xZgTQyhjT9kyJpKWmUxICkURbeVY5TAYTrCYrzAZz1BPWTmenLNrEv539ktNWkl6CXFsuPrrqI2SnZuPsF8+W80Nybbmwmqxhb14tjhaYDWZ5MIk2p01Z2TLVnDokOW3Nvc1yGJYQbU9/9TROe/40zf41bq9bFlSDcdqEYxHotFmMFhSnF496p63H1YOV/1iJFkdL1E5GVUcVSjNKcd7k8+D2uWPqVziUDHV4JOc8poptu4/tjihuDrYdlN0I4YBFEhfKIiTAQGW0cGKoy9mFyvbKoMqRwIAQE9X+AKloCAA5HEc4bWIMila09bn75O/oUDptyv5zySTa+tx9uPuju/HsNn2VNDc2bMTMgplINaeqHlfmtP1737+RZk7DhVMuDCna+jx9sJltmJQ7CW6fWx6jo6WlryXsvaetry1oUi0m4unW4RdtnHPc/O7NeHnnyzjnpXMAQBUeeaDN77Sl5aM4oxjF6cW6RFtZZhmAgWt8bc1aLCtbpgrPAwZEmxhrZxTMAADMK5ynKzyys78TPu6L+0KscqFVIMIjQ1WPlOc9ivBjDw8Ojwy1QLC2Zi0yrBnygoRep01veKSysTYAzeIlnc7OkOX+gfg1185KyYp6P92ubtgtdswqmIXD7YeHvHpoIkiYaOOcewHUAbAl6jWIxCDcm3Cr1pVtlXIBEgByIYBo6HJ2yaJK2Os1nTXodfeiNLMUgHQz+PiqjwEAv//i9wCA3NTciD1Gmh3NyLPlyQ05NatHhhkARNhbeVY5bGYpPDLRX/jVVavl/4tzsK9lHzi4piir766XV7wGswIvVka1RFsinTaH24EtDVuGteqij/tw9ZtXY9exXVhQtCDqXj5VHVUYnz0eS8ctRYopBf89/N8EHWl8GGrRds5L5+COD+6I6jktjhbMfWountj0RNjtDrQewOScyQAw4LRFcPtF9UUxyZHzY8I41Tuadqieo0SMK3ua98iPibHjiyNfwGq0yqGYsZb839uyFz7uw8SciWjraxuyiYfyOJNJtO06tgte7tV1TD7uw+aGzUGhkQCQZZWcNh/34a39b+GcSedgev501HXWad5bHG4HUk2pGGsfCyD6wluCVkdrWOehva8d2anZ8qRaGR6ZYc0Y9qJYr+15De8dfA/3Lb8PF59wMRgYpuZP1QyPBKSw1HAVJAOdtra+NtR31eNQ2yFVfzaBEG1fHPkCebY8FKQVAJDaORztORrUoiZQtAnhEm/RVtcpNRlXOld6wiMBdQ85t1dRPTJCIZI11WuwbNwy2cmLlNMmIpD0FCLRCo9UXpOChIdHKp22KMIjhYOZbk1HUXoRHG5HUo1jsZLo8MifAfgLY6w8wa9DxJFIThvnHIfaDqlFWxR9kgRa4ZEil6s0o1TebnLuZLx/xftIt6TDZrYh1ZwKq8kaPjzS0SyHRgLR92mTnbas8XKYSqJXOFcdXoVMayam5E5BbZe0aidWfbUmesqV3kQ4bVajFcXpxWjoboirsOr39OOif1yEnAdzMP+v8/HBoQ/itu9oeWDNA3hz35v4/Vm/x3mTzkOvuzds1dRAqtqrMD5rPFJMKSjLLMOR7uR2JYc6p21P8x68suuVqK6fz2o/g9vnlos9ONwOzHlyjipMuLO/E8d6jwU5bZHGoK2NWzEhe4I8yRDuQDgRG6pyJDAwrginLd+WP+C0HfkC84rmyavTkcIjm3qaNB11MSYuL1sOL/cOWQiueJ3c1NykmuwI4a2nOMqhtkPo6O/AgqIFQX8TOW2b6jfhaM9RXDTlIkzMmQgOrpnPLcIjc1NzAQSXp9dLi6MFHp8npPgWYWmy06YoRDLc4ZGd/Z34/gffx4mFJ+Jnp/wMr3/zddTfVY8ZBTMGnLbWAacNABYVL0Jle6UslgKRnbYsyWlrdbTKoY/K/mwCZZP6GQUz5IVZ0YMvMK9N6QQlUrSJ+7Eqp01HIRJxjAK3byA80mgwgoFpCrGj3Uexv3W/qlCLHqctxZQCm9mmKcCUaIVHKq9JQWd/5PDIWESbuGcIpy0zJTOq8EhxXaVb0uXidaMh1SPRou0VAN8AUMkY8yp/Evy6xCCIJNra+trQ6exERU6A0xZlTpsyPFJMonY37wYgOWxK5hXNw6qrV+HRcx4FIIU4hi3539ssr/QBaqdNhEeGW5Gqaq+CzWxDni1vULkoeuGc4+PDH+PU8adiQvYE+QYgKplpFS8QbhwQn5w28XmKgVE4bR6fJ+ZVZS32Nu/FW/vfwhkTzgCgLtwwlLy6+1X84tNf4Lo51+GORXfI16LexYd+Tz+O9hyVWyNkp2YndVVGzvmQO23drm60OFo0CwSEQoQ9ietiX8s+bG/ajs9qP5O3EQsNk3Mlp00+d5GctqNb5dBIYGACGE7Ebm/cjjxbnnzjVyLGlar2KqSYUrCgeAGqOqrg9DixpWGLHBoJRBZtp71wGooeKcJVb16FDUc2yJP6nU07YTVaZbdoqM6dmPQUpRfJ7ViSASGi9QhJUVhI02lLyUKvuxev7nkVJoMJ5046V16I1CpGIos2m1+09cUu2oDQeUrt/e3ITslWFYoQn32GNWNYRdtP/vsTHOs9hr+c/xeYDCYwxlCYXghAWsAwGUzo6O+A3WJHiikFALCoRMprEwVhAtFy2tZWr0WmNROzx8wO2j4zJRMMklCbkT9DfnzO2DkwMEPQWNPl7JLbBCXUaevyO22e+DltgCTEtJw2MU4qC7VEzGnrkxprM8Y0BZgSrfBIreIlkcIj9VTqDmR11Wpk/G8GmnubZact05oZldMm7gXp1nQUZ0jnP9CFHYkkWrSd6v85TeOHSFKEGAh1U1SW+xfYLfaoV4DDOm2ZpUHbLyxeiOvmXgdAGjzEF7jF0RI08Q/ltBmZEWajOWLvkOrOaozPGg/GmJwLkUjRdrj9MGo6a3DG+DMwLnMcajtr4fF5ZAGt5bSJvwGxOyecc3kCLD5PVU6bf7CLZ16bmOzctfguALGHGelle+N2PL7pcdVjW49uxTX/vgZLSpfgifOeAGNMlVepB/E9GZ/tF20p+np+DRdunxte7kWaOQ19nr6ET/6UhSzeO/ie7uetq10HYOD6Fs7V0e6j8jZiNX9Sjt9p01GIpLO/E5XtlSrRpic8cluTVIRErOgrMRvMMDIjODjGZY5DRXYFDrcfxtbGrXB6nSrRZjaaYTaYNccRzjkq26Q84bf2vYXFf1uM+X+dj2e2PoPNRzdjav5UeRFqOEQbEH2hqWjhnOORLx4JalAeiOy06fiebqrfhDRzmqo5s0BMNF/c8SJWlK9Admq2vBCpVfa/z903aKfNx33y+Kd1/3F73ehx9SA7JVud0+Yb/py2L+q+wJObn8T3F34f84rmBf2dMSZ/n0TVZkBywAzMEDKvLVC0tfa1Yk3NGiwdt1TToTIwg3zuRD4bIC2KTMufpinaclJzYDPb5B5yQPT3c845Hl7/sGYvOGBAtA3WaVOW/AdCN8xeU70G6ZZ0Ofwa0Oe0iXMTLjzS5XXB4XaEdtoUz+no74i707a6ajV63b043H4YfZ4+WIwWpJpSo3LaxL3AbrHLYxiJtghwzteG+knk6xKx4/Q4cbRHmhyFFG3+VciJORPlxwYbHmk2mpFqSsWRriMwMiMK7YVhn2s1DeS0/ejjH+Gif1yk+nsop00IsIg5be1VKM8qBzCwQp7Isv//rZJyoc6YcAbKMsvQ4mjB3ua98gAcymkrSCtAmjkt5vDIxp5G9Lh6kJuaC5fXBR/3BeW0AfHt1SYmO2PSxiA3NTehok0kzX/vve/J8fxNPU1Y+Y+VyLXl4o1vviGHiYhVT72hYCKESjhtOak5Se20iUmKOKeJFphOr1O+fvVW7up2duOro1/BbDCjpqMGPu6TRVtj78Bk6WDrQTAweZKtp+T/9iap7LhykhMpPNLj82Bn007NIiSANFEVY0tZZhnGZ41Hl7NLLh+/uHSxanub2ab5Xe5x9cDpdeK7J34X9XfV47FzH0O/px83/OcGrKleg5kFMwdcwSFqsC2OU0x4EhkiyTnH3R/djR9+9EM8vP7hkNt5fV45x1CX09awEScWnqg5aRYTzabeJlx8wsUApPDWdEt6UDESt9cNt8+NVFMqMlMyYWCGmJw2kUMn9hmImLxnpWSpc9r829ot9mERbW6vGze+cyNKMkrwy9NCl8oX3yflvddusWNa/rSwos1qtCI3NRdGZsTuY7txoPVAUH82JeK7oBRtgCQQtxzdogo9FfOMDGuGymmLtvVGTWcN7vn4Hry+53XNv2vltMnVI6Nx2hThkYC0MKQlxNbWrMXScUvVAk9HTpss2sIUIhHziUg5bS6vC/2e/rA5bbE01xbf8WaH5LSlmiKnxASiDI8U80kSbREIbKhNzbWTH7FaJAY4LcQNTTRfBqIPj/T6pNwM5QqN+OIXpheGXJkSKEv+N/U2qb6MLq8Lnc5OtWjzO20iP01PTpuYjIvnJNJpW3V4FUoySjA5d7K84vhJ9UA7Q82ctq5alGWWISslK+aJnHDZRFllp8epKvkvwkoS4bTl2nJRkFaApt6muO07kM9qP8OGIxsADIST/PyTn6PZ0Yy3Ln8LY+xj5G3FAoJu0dY+UKwGgO5GzcOFuH6Fe5pogSlummPtY7GpfpMsmsOxvm49fNyH8yafB6fXiWO9x+RFIpXT1nYA4zLHySFYctsRxcJRr6sXv/r0V/KkRFSOVOamifzWUAJ2f8t+OL1OzXw2gRhbxmWOk8fEl3e9jLLMsqCQylDtQ8TCRb4tH+nWdNy64FbsumUX1lyzBt+Z+x3cOO9GeaI61E6bmPAkUrT96tNf4ZENjyDPlof9rftD5nsdaD0Ah9uhK8/O5XVh69GtmqGRgHpCeuGUCwFIIrwipyJItIkFO5vZBgMzIDc1N2SOVjiUz9G6/4jrMDs1WxW+5vK6YDKYkGpKHRbR9vsvfo9dx3bh0XMflb9rWginTRnlAkh5bRvrN2qe1x5XD+wWu+TUpWbjPwf+AyC4P5sS8V2YXjBd9fj8wvk41ntMdb8KFG3i/hPt/Vx877Tuxb2uXnns1+rTFqp6pLLVkSAwPFIr5LGppwl7W/YGCVuzUVvgCfQ6bUK0CREuCAypFMI33DVhMUTvtIm+lC2OFqkAkDkVVqMVLq9LdyEmZXhkmiUNmdbMuC4+DxeJDo9co/HzCai5dtIiQr5mFMxAt7Nb8wtS2V6JovQiVQnlaJ02sa2YKCv/ryxCEgqrcaDkf7ezWxVeoCxrKxBumZjkhRtI2vva0enslMPeZKctQVW7fNyH/1b9F6ePPx2MMU3RphV6WtNRg7KsMmSnZsfstIl8tpkFkmhT5q5YjBYUpBXAZDDFNYFXnJ/c1FyMsY9JqNP24OcPynmJa2vWwsd9+M/+/+CiEy7CiYUnqrbVClUJR1VHFaxGq5zTkZOag87+zqgKmQwlgU5boif/4qb5janfAAfHh5UfRnzOutp1MDIjLp9+OQBp8eRwh99p61E7bSKfDZBCptLMaaqFo1WHV+Hnn/xcLnSzrWkbCtIKVC6+COkKJbbDFSERqJw2/5hxuP1wkMsG+EWbJ3iy2OyQBK2ohCeObXn5cvz1wr9i6biluoqmxJPA8MhEirZ3Dr6DJaVLcN/y+9Dj6pGjPQIRoZGnlJ2Cbld32O/armO74PQ6I4q2BUULVDnUFdkVQeGR4rsj7gW5ttyYnDalaNNyROTJckBOm9vnhsVoiZjLHS86+jsw7y/z8Icv/oDKtko8sPYBXDL1ElnchkLLaQMk0dbW16bZTkGINgCyGA4M+wskJzUHJRklQU6QVjGSUE5bzKJNw6ETi91AdOGRIkIgbHikhnumlc8GhM5/EyhFm1b5fkFIpy0gp028VzGv0iLa8MguZ5ec7tLc2yy32ohUOCUQZXgkIC1WNvSQ0xaWwKbaAEoAvAjgkkS+LhE7Io9kZsFMeLlXMyQwsNw/EH1Om5gAKEWbmDQHFiHRQhke2ePqkW16ILixNiANmimmFF3hkWLAEA5KonPatjVuQ1tfm1yYQ4i2tdVr5YTrwBsF5xy1nfFx2swGszwBdnqd8udiNphhNEihqnqcNh/34eH1D2N/y/6w27U6WpFhzYDZaEZBWkHUou2DQx9g7MNjIwrVXcd24d2D7+L2hbdjSekSrK1Zi80Nm9HU24TzJ50ftH3UTltHFcqyyuQ+Qtmp2eDgukXfUCOLtvShEW1iPDil7BTk2fLwSVXktbpPaz7FvKJ5cg5STUfNQHhkT6Pc9+1A6wGVaAOC246I9yfCskQRksDctJzUnLCizWq0YkrelJDHrHTahDsPQJXPJm9rSQvvtAU4FIHHCQxd5c9oRNtb+97CdW9dF/NrdfZ3oiSjBFNypc9Z5CwGsq1xGyxGi9y0Odw9RxQh0aocCQwIjItOuEj1eEV2Baraq1SCUCzYyaItNTemnLaITpv/OlRVj/T3aTMbzEMm2nYd24Wvjn6Fuz66Cyf97SSYDWb86Wt/ivg82WkLEG1COGuV/leKNnGNnzzu5JDuFAD8z8n/gz+e/cegx2eNmQWTwaRbtEXTPiOc0yZCI4HoCpEYmAHplvSw4ZEmgylItK2pXgO7xR608BgqlBKQHDxlBFK48EgxxkTKadMr2qJpri3qGgDS96XP4w+P1CiCEg5leCQgjWMUHhklnPMGAN8H8NBQvi6hn5qOGqnvSt5UANo36sr2SlXlSMDvtEURHqkp2vzhkXqdNjFwiImaGPjEqnXgjSPNnKYrPDIwVylUTtvv1/9eVcExVlYdXgUAOH386QCkwcXADGjvb5fzBgNvFGIwG5c5Dtkpg3Da2g5iQvYE+aYpnDazwSxPbvX2avvVp7/CPR/fgz9v/HPY7Vr7WuVk/gJbAZp6oguPfGzTY2jqbYpYdfLZrc/CarTiewu+h+Vly7GzaSee3/Y8DMyAcyadE7R9LOGRykn6UE+qo70BBYZHJjqUU+mmj88aH3GVs9/Tj431G3HKuFPk8t+V7ZWo6aiRi6d0ObvQ7GhGp7NTLkIiCHT7xSRrY/1GOD1O7G7erSpCIghX9XNb0zbMHDMz7ARSjA/jMsch3Zour2RribZQOW1ioUnptAUiJi5D5bSJMUeItlCLEZxz/L/V/w/PbXsu6jwhQadTKhsuxHGohZ+tjVsxo2CG/BmHWyDZWL8RebY8efEtkBkFM/C7M3+HW+bfonp8Ys5EuH1u1UKV+O6IBbxYnTal0NNyRJThkYF92sxGs5wWkOhefaJ68VWzrkKLowUPnvGgPG6EQ6sQCSCFMdrMNs28Ni3RptWfTcmp40/F16d9PejxVHMqpudPx+ajkmgTi7kZ1gxkWjNVoo2DR5UjFc5pU7bficZpA6R5j6rkv0Z4ZKAQW1OzBieXnqwSd4C2wBOI6zWq8MgIzbX1iLZoc9pEPpvZYB7IafO3eQp1vFoowyMBaRyj8MjY4ADCV5mIEsZYFmPsX4yxbsZYPWPs1jDb3ubfppsx9k/GWEYs+xmt1HTWoCi9SP5iB05gHW4HGrobgpy2dGs63D637uo+Yr/KBFbhtGlVjgxEueIoVlTEwCcG5cBV6zRLmjy4hCuNG5irpFWqu9XRirs/vhtPbn4y4rFGYtXhVZieP10OszMbzfJEaWr+VJgMpqAbhXBEZactRqFQ21mLsqwy+XPp9/TD6XHKAyQgTfIjOW3vH3wf96+5HwxMziELRWtfq1w2e4x9DDqdnbqvmxZHixzuFmmle03NGiwuXYxcWy6Wly0HB8dfvvoLTi49WZ4cKNFKCg9HVYdatIkb3FBMqj+r/QzFjxRjXc063c8Z6vBIeaXTmq7LUd1UvwlOrxPLypYhw5qB7JRsrKtdBy/3ymXDG3sa5ZBeTafNGSzaNjVsws5jO+HxeTRDrkJV/eScY1vjNs2y40rk8Ei/0JyQPQEpphTMHhv8PD05baEQOT9DntOWHj6nbX3derlVi3LyGg2i11NJRglSTalyjz4lnHPZLdWzwLKxfiMWFi/UrPoJSC7H3UvuDsrbEQuSylC+wPDIvNS8hDhtyrA05QTZ5XXJ4ZFA4nuGisXIJ857Ai33tOCWBbdEeIaEHB4ZcO81GUyYXzQ/omgT9wWt/mx6mV80H1sapGIkYjwQTpuyeiQQXfSMGCM0nbauOjAwFNoLoypEAkjznojhkYq5yrHeY9jTvEezUEs4p03ZWBsYXCES8RzxXuMZHrmzaScyrBmYmj9V5bRFalEQSFB4ZHoxjvYcjWvP2eEg0YVIrg74uQXAuwDWx/mlHgVgAlAE4DwADzDGTtU4njMB3OffphiAGcCfo93PaKamU8qTCnVTFKFKysqRgL6S20rExDjm8EjjQHikGJhlp603jNOmMzwy05op34CEO6fMaRMD95ajWyIeazj6Pf1YV7tODo0UlGVKE8CK7AqkmdOCbhTiplqWVTYop62xpxGF9kJ51U04bWKABKRwuvqu+pCruz7uwzX/vgYzx8zEHYvuwPam7WFvhq0OhdPmdxaEOxqJV3e/Kt+Uwk1eO/o7sPXoVnnFdmHxQqSYUuDxeXD+5ODQSEC6PhiYLqety9mFtr42OYcJGJiw6HWwPqr8KObzJnIantv2nO7niHMy1j4WBmYYspw2u8WuS7SJ97R03FIA0qKJEKUnl54MADjac3Sg3H9usNOmPHfiPHQ5u+Qy8qGcNq1z1tDdgBZHS9h8NmDguhHj1sopK3HN7GtU3yHltlrfjWZHM+wWuypPWItwoZzxpsfVA4vRIn9XQ30v/vLVX+T/K9uQ6MXtdaPP0ydXZZyUO0lTtB3pOoLWvlbMHTs34gJLt7Mbe5r3hAyNDIdYkFTmtWnltLU4WqJ2vCLltIlzqyr575FK/ovwSCDxoq22sxa5qblIs6TJQkoPocIjASmvbVvjtqBJt1K0lWWWISc1B/MKg1sK6GV+0Xy09rWiprNGFdGjDI8Un200oi1SeORY+9iglgyRCpEAfqctXPXIgJL/ofLZxOuEWowOzPUPF26oDNNVEsppE/vSwmK0hG0mH8iOYzsws2Am8m35aqctjDOoRY+rBwxMDl8vSi+Cx+eJqYBQMpFop+2BgJ9bABwEcH28XoAxlgbgUgA/45x3c863AXgmxGtcC+BZzvk2znkXgP8H4DLGmC3K/YxYOvo7woYx1nTUoCwztGgTldy0ctqA8DkGSgYdHukv/+rjPnkQFatVzY5mMLAgN6UovQhj0qRqgRajBV7u1Uxkr+qoUoXUaDlt4v+bGzZrDkacc3xc+XHEVaEv6r5Av6c/SLSJvLaK7ArYLfawTlt2ajY6ndEXwOCco6mnCWPtY1WTgUDRVpxRjF53b8hJW21nLZodzfjegu/htPGnwePz4KujX4V8XWUytBBtevPaXtr5knwOw4UnfVb7GTi4vGJrNVlxUslJABBStIlebXpy0oQbG2t45D92/QNnv3h2UP84vYjFgtf2vqZ7AieuWbvFPiQ95ZQ5BUK0hbtxr6tdhxkFM+TPsSyrTP5uC9HW2NOIg20HYTKYgsLetHLaxI3+uW3PId2SHhTWDYR22vQUIQGkiU1JRon8nfnpsp/iyfO1HfhwTlu40EjBULaVEJNpUTFR6/vf3teOf+3+l/ydiiVcXHzfxKLdlNwpmjltogjJ3MLITttXR78CBw9ZhCQc4lwqG2wrq0cCUk6b0+uU86L0FqnSUz3SarSqJqmi5L9oiwMMgdPWWSPfg6IhlNMGSAtnLq9Lbr0hUIq2Hy/9MbbfvD0o7C8alMVItERbe3+7PMeIJpw3UiGS0sxSVdoGoDM80hohPDLAaVtbvRY2s01+n0rCVY8MjEDS6rkm6OjvkK9DJbEWIgFCN5NXwjnHzqadmDVmFvLT8tU5bQqXr7GnEU9seiLsvKHb2S1XJQUGwrxHeohkoguRjA/4mcU5v96f2xYvJgNgnPM9ise2AZihse0MAPKIwTnf6//vpGj24w+jLFf+QCqyknT8a/e/8Jctf8GfvvwTzn/5fOQ9lIeM32ag+JFinP7C6bj13Vvxfxv+D2/vfxv3fnKvXNxC3BQDBZ7cWDswp01HnyQl4QqR6A2PdHqcqgmQ2GdzbzNybblBA+UrX38Fj58nTZLDDSTVHdUqB0WrEIkYuNv72zVzq/a27MVZL56Fuz68K+z7WHV4FYzMiFPK1F0wxA1zYs5EpFmCnbbazlrYLXZkpWTJq2HRVndr72+H2+dWiTanxwmXz6VaORMOQqgQSTHBmpI7RQ5j00o4F6hy2vwTVT15bdUd1fi87nPcOO9GAOGdtjXVa2A1Dgg1APjO3O/gG9O+IedrapGZkqnrc5TzHpVOm87wyOqOatz8zs0ABkobR8uWhi0oTi9Gl7NLd+NqpVuQnZqNtv4EO20utdPm8rpCfrYenwef132OU8YNfA/KM8sBSN9V0cz3aLfktE3InhC0eh2YV9vW14bZY2cjw5qB1r5WzB47Wy4aoyQnNUdz0UMUM5g1ZlbY93nf8vvw2jdfC7uNwGa2aa7UNzuaw4ZGKo91KHPaxKQnVAuYF7a/gH5PP+5ffj9MBlNMTptwGcSi3ZTcKahqrwoSNdsat4GBYdaYWRErvUYqQhIOo8GI8VnjNcMjhWgS7lNrXyte3/s6Ch4uCNl0WUlLn8Jp03BEOvo75PE8sLl2Ip02p8eJc146Rx63Rdh8tCwdtxTLy5ZrNjMXxWMC7w1K0WYz23RF2oRjZsFMmA1mTdHm4z74uE++v0bltPWHcdq66uQWJFpOW9jwyIB7TmB4ZGCemmg8riVsw+W0BTptJoMJDCxkeGSgywbEXogE0FdApK6rDp3OTswsmIm81DypeqSG0/bs1mdx63u3YtwfxuHGt2/E3ua9QfvqdnWrWhGI9kUjvRhJosMj/xni8Zfj+DJ2AIF3kw4A6SG2DRzlO/3bRrOfOwFUBfzoTy4ZQn7y35/gpnduwh0fSGFrP1z8Q/zmtN/gjAlnoNfVi5d3vow7P7wTF/7jQvx63a+xdNxSXDHrClmEaTltWSlZQS5WtOGRWqLtvMnn4aZ5N2GsfWzE54uS/8pJmrIQidYEKD8tXz7uUAMJ51xy2vwTRkARHqkoRKIc7LVCJEVPqcc3P473D4ZuLLyqahUWlSxSfQ7AgJM5OXeydnhkp+SIipLlQPSFJcQkI9Bpc3qcaqfNP9iFKkYiigZMzp2MgrQCjM8ajw312nltbq8bXc6ugZw2v2umx2kT4uTq2VfDZraFzSlZW7MWi0oWqW4mV8y6Aq9e+mrIHBcgfH9CJVpOm57wSI/PgyvfuBIcHCcWnqiqlKWXVocU+nPbwtswJm0MXtr5kq7nKUXbUEz+A3PagNDneXvjdvS4elSLF2LSWJ5VjtzUXFiMFtlpC8xnA6RzF+i05dny5Im7VmgkgJDfn48Of4T5RfODvpuBjM8er9vRGazTNpS9AHtcPXJokdb3gnMpR3Rh8ULMK5qHkoySoJw2znnEHJIgpy1vCrzcq3K6AMlpm5Q7CXaLPaLTtqlhE8qzysNW4wxHRU5F2PBIMfFtdbRiw5EN6HH14O39b0fcrzI0L1RYmhhHlIVIEp3Ttrt5Nz449AFe3/s6OOeS05YRvdM2OXcy1ly7RvM7U5JRgkJ7YVBem1K0xQOryYqZY2aqRFumNVN1TDGJthBOG+ccdZ11KM0oVVW1BqJw2iKERwr3rMXRgl3HdoXsYRcup03ZageQIktCNaxu72/XFG2BZffFew1biMTvGuoRbTubpEVM4bR1OjvR5ewKctra+tpgMVpwzexr8Pcdf8e0x6fhvJfPw+qq1XI0R4+rR57HAgNOG4m28ASXaJM4O46v0QMgcITIBKClHrS2zfBvG81+/ghgfMDPsmgOeqhYd9061N9Vj6a7m1BzZw0ePPNB/GTZT/D8Rc9jw3c2oP1/2tH4w0Z8dt1nOPrDo1hz7RrMKJgROjyyPbjcPxC909bp7AQDUw3W84vm48nzn9RcDQ/EarLC7XOrjk8ZHhnpZh3qximaOSodFLPRDJPBpBkeCUiuRyDKSk3X/+d6zQlye187Njdsxhnjzwj625WzrsTHV32M8dnjJactMDzS36MNGIg7jzbcTYi2MWljwoZH6nHa0i3pstg+qeSkkMVIxOcQ6LTpEW3r69aj0F6IiuwK5KbmhnSKupxd+OroVxErkGmhOzyyowrplnTV4kWKKQWpptSwYujXn/4an9d9jifPexJnTjgT+1v2h+2ro4VYJFhYvBCXz7gc7xx4R1duXKBoS3R4ZLezG0ZmhNVojXieRZ7GsrKBYVSEP07IngDGGMbax6KhpwEHWw8GVY4EtJ22nNQceYU/VJijuG6VTkl7Xzs2HNmAr1V8Tee71UeonLZjvceSzmlTTqZF5T0ln9d9jj3Ne3DjiZLzPS5zXJDTduPbN6Lw94X4+/a/hwyNDcxvFoI8MERSFCEBgosG/faz32JT/SZ5W1GEJFYqsqUG2+KYg3La/ONXi6NFPs639r8Vcb8tjha5T2ConDaxiGBkRtkJEeGR4UTbDz/8IV7eGdt6uFh429a4DR39Hehx9cTktIWDMYZFJYtUok2kN8RTtAFSk+0tR7fIY7moHikYlGgLWEDt6O9Ar7sXpRmlMTltgfeccOGRYpzUKkIChM9pa3Y0I9OaqRKEomF1IBGdNo/aaVMWLgv1HD2iTVSOVFaIbeptUpX8d3qd6HR2Iic1B09d8BRq76zFAysewKb6TTj9hdOx8h8rAUgGgjATgIFxnkSbBoyxUxhjpwAwMsaWid/9P9+FJJDixQEAnDGmjHmaA0BrCXsXALmkF2PsBAAMUp6d7v1wzjs459XKHwCRG1kNA0XpRShKL0JBWoGmGGKMYYx9DE4ed7JqpTeUaDvUdkgzLySWnLZ0a7ougaaF+AIr85qUhUgCSw4HIgbFwAFOhL0F5svYzDbNQiQpphS5vLAS4QL939f+D409jfJgq2RN9Rr4uC8onw2QQjLF46GcNrESKlZmoy1qoXTaxKCrJdq0YsEX/20xHvniEQDAgTapZ5ZwsE4qOQlHuo5oijx5tc/vtNktdqSYUnSJti+OfIHFpYvBmJSvGMpp+6z2M/i4L+SNLRxak1MtqjqqMD57fJBrl50aOlfs89rP8YtPf4GrZl2Fb838FqbnT4fb5w5q5AtIq7ef1X6muQgiFgnmjp2LC6dcCJfXFTYcVaAM8cpOia4KYXVHtZzjpRex0skYiyzaaj9FRXaFfK0B6mI8AFBoL8Tmhs3o8/RpOm3p1nT0efpUhWpyUnJwxoQzYGRGOS8uEK0V2I8Pfwwf92m2hhgMNrMN/Z5+lfvEOUdzb7PunLYeV0/UQj8WlKJNy2l7astTyLBm4PIZUiP0sswyVU7bJ1Wf4OmtTwMArv731bj2rWs1X0d22hThkQBUxUja+tpQ01kjizZl0SCnx4mf/Pcn+N363wGQxqmazhpZrMfCxJyJ6HH1yAWSgvq0KcIjhWhbdXhVxBypFkeLXI0z0mRZOCFyyf8w4ZGH2g7hkQ2P4LU9+sJ0A9nXsg+AJNqE8I4lpy0SJxWfhENth+R7g/i84i7aiuajo79DHrNEeKRA5LTFw2kT7rJWTptcPTKC0ybuu4Ak5lXVIxWFSNZWr0WqKVUzn01sG85pC5wXWYyWkOGRgVVVgUHmtOkYs3Ye24myzDJkpmSqFrFUJf89TrlFCCBFUN27/F7U/qAW18+5Hm8feBt97j45p00g+sLqaV+UzCTKaVvj/0kBsFbx+yeQqjf+LF4vxDnvBfAagF8yxtIZY7MgFQ95RmPz5wBcxxibxRhLB/ArAP/knDui3M+ox2q0wmwwB8Va13TWYGL2xKDtYwmPjBR2FA4xSCgTu1VOW4RV61CrPyI/TRn2BkgTXS2nbXHJYrm8sBIhJmcUSCmRWonqqw6vQpo5Tc4DC0WaJU0lhntcPWjrawt22qIMmxJ5ZKqcNn9zbeXKmdVkRb4tX77ROj1ObDiyAa/ueRWAtEqrnESLPDItIRHYK0ZM6Jt6w+e0NfY04nD7YSwpWQJAmjSFEh0fVX4UlM+ml2jCIwOvEcDvhGg4gB39HbjijStQnlWOR899FMDAtaEVIvn63tex7NllmPCnCXjki0dU18+Wo1swIXsCslOzMT1/OgAphzISDrcDVqMVRoMxasfmp//9KS577TLd2wPqnIJwoo1zjnU161QuGyA5bKmmVDmnbKx9rDy51BRt/jGox9UDj88jr8aeOv5UtPyoJWSDbC3R9sGhD5Cdkj0ot0YLraJGnc5OuH1uXaF8sYZCx0KvqzekaGvra8Oru1/FlTOvHGh5kFmG+u56uL1uuLwu3PrerZiQPQGHv38YN8y9AS/teElzUU/OafNPwjJTMjEmbYyqV5uYfIuWDcqiQUd7pFD0T6o/gY/78N+q/wIY6HsZC4EVJEM5bU09Tahsr8Si4kVwep34qPKjkPv0+rxo72sfcNpC9GlTTpYtRos8JocLj3xh+wsAEHNlPCGQmx3NcpSEWDSJJ6K32os7XgQwsMibCNEGAKurVgMIFm3xdNrquqTG2ppOm09f9Uhg4Hvg8XlCOm1ratbg5HEna1amFa/DwTWLkrU4WoLGmJDhkX3a4ZHxymnr9/TjgTUPBM2LdjTtwMwxMwGoe/3ZzDaVYOzo71C1ixLHIBZq67rqgsIjASnVg5w2DTjnBs65AcBe8X//j5FzXsI5/3ucX/J7kPq/HQXwAYD7OeefMMbGMcZ6GGPj/Mf1MYBf+rc5CsAH4PZI+4nzsY4ItJLPaztr4fF5NJ02ZXgk5xxf1H0RtlLcYEWbEBVKt6WzXyom0OpojVm0BfZoE9jMNs2ctmXjlmkWI2l1tMJuscsTEa1wllVVq7C8fHnIAViQZlaHR4qVPXFTFRO5WJw2i9GCrJQsdU6b1xl0TMUZxfIKlXDoNjdsRqujFbWdtfLqOCCFoVmNVs0QSXG+xKQHkMIzIzltX9R9AQBYUiqJtpzUHM3qkZxzvLnvTZxVcVbE8ulaBOYXaCHyHrVEm1YlQs45bn7nZhzpOoKXL3lZvu5PyDsBBmbA7ubd6HJ24dyXzsVre6RqkPd8fA+m5k3F3LFz8cOPfoiJf56IJzY9AZfXhS1Ht8glsQvSCpCdkq2ZiB2Iw+2QJ52iTYTenjUN3Q0Re/UF0uPqkYWUuAFrnee9LXvR2teqKkICSJOZA7cfwPVzpQK+YrILQDs8UjEGyc1h/RNgrQmIIFC0cc7xwaEPcGbFmWEnW7GgJdr0NNYWiHDcWEMkdzTtwMQ/TcTHlR9H3LbH1SMLssB7wQvbX4DT65SLAgFSDqKP+9DQ3YA/f/ln7GvZh0fPeRRpljRcNv0yeLkXn9d+HvQ6gU4bIOW1KZ02rUqeooCDOG8tjhbsPrYbqw6vQp4tT578xYLcq82fV+dwO8DA5HFRnIctR7fA4/Pghrk3ICslC/858J+Q+2zvbwcHl6+3UDltWdYs+XcRvhYuPNLHfbJo09s6JZB9Lfvk9yTCPBPhtE3MmYiTS0/G89ufB+c8YaJtesF0WI1WfHX0KxiYATazTTXfEAueekVbn7sP/Z5+GJghyGmr6/SLtsxSuUCaQIRHhosoEmOCmF+Icy0QxUVaHa3Y0bQjZD4bMBBBpOW2aTltgc6goKO/Q3UdCgLnTXr6tIn3orzeP6/9HPevvR+rDq+SH3N6nNjfuh+zCqRFOuWxqvq0eZ1yX8dARBG72s7aoPBIQBrrSbSFgXOuVcExEa/TwTm/lHNu55wXcc4f9z9e63+sVrHtn/3b2Dnn3/SX/g+7n+OVwBLaocr9A2qnbXXVaix5ZknYHmZKezsWAsMjDcyATmenfGOMNaetuqMauam5QSs0gQUExMAt3IHA9yoqJIrBTCn4AGmgP9B6QDOfLZDA8EhljzZgEDltvY0Yax8LxljYnDZAymsTk3Yx6Hl8Hvx9x9/BwVXOh8VowYmFJ2oWIxHnS9n7R08Pry+OfCHvF5BEn9bEdWvjVtR21uLiEy6O+P610OO0NTuag/IeBVp9tF7Y/gL+ufuf+MWpv1C5qqnmVEzInoDdzbvxys5X8P6h93H5a5fjG//6Bqo7qvHouY/io6s+wppr1mBC9gTc+t6tmPznyajuqJZFG2MM0/Kn6XbaxAQhw5oBDq675LXI9dQb/gyonTaL0YLslGzN8yx6sQVWUAWk604IJ5GTkGpKRXFGcdC2yjFIXBtaTdQDSTVL4aLiut7etB1He47inInxDY0EBhpxK8cSPY21BYMVbb9Z9xtUtlfi2298O6II73H1wG4Odto45/jLlr9gUfEiVQNxMcmv6azBiztfxOKSxXJ46ZLSJTAZTFhTvSbodQKdNgCYnDNZldO2tXGrHOYvEE6bMmx7ddVq/Lfqvzh9/Okxh94DUqQFA5MrSIrvjgiHNhvNyLRm4osj0mLS9ILpOHfSuXjnwDshW68IF0wsPmgVwQoMSxPha4Hhkcr7yac1n6KmswYFaQUxOW0+7sOB1gO45IRLAEifoTIPNd5cO+da7GvZh00NmxIm2ixGC2aNmQUOjgxrhrwIDUgCQwgCrUqQWojvW1F6Edw+t8olreuqg8lgwpi0MXKBNIHX5w2bzyaOFUDY8EiPz4N1tdI4GS7sXzxPK1+y2RGcNiLCbwFpQbXX1at5HSr3b2AG+T3q7dOmfH/AgMOqDFXc17IPHp9HXmxRzuG0wiO1FuLEGFTXWRcUHglIn91gwqaTgURXjzQwxn7CGDvIGOv0P3a2P6+NSHICJ7Chyv0D0hfTZDChx9Ujr5CGK+Me7/DIQnshOp2dIRtrax0voOG0BfRoE6SaUzWdtkXFi+TywkrEqlaocBY5hGdC5BCewEIkgTkHdosdRmaMyWkT1RvDNdcGpLACMcAqV6r++tVfASAo9OykkpOwuWFzUAiQltOmR7Str1uPeYXz5IFbhPcFurlv7H0DRmbEBVMuCLu/UGRYM9Dn6Qsbf69VOVKQnarOFfNxH+788E6cUnYK/ufk/wnafkbBDOw+thvPbHsGU/OmYknpErx78F1cdMJFOG38aQCA5eXL8em1n+KDKz6Qb7rKUMKpeVOjFm1iUULcPF/Y/gJOefaUkM6bWMEX3+nNDZs18zSVBIanFKQV4Jgj+Dx/WvspCu2FmJA9Iez+RC7QxJyJmhNypdMWjWgD1Cuw/z0sfTfProhnvSwJ8fkrv8/is43GaYuliMzh9sN4dc+ruHTapej39OOy1y4L218sVE7bZ7WfYW/LXpXLBgw4/+tq1mFb4zbVwkmaJQ0LihZgbc3aoNfpdHYi1ZSqchem5E1Bs6NZfp/KIiQCkX8qxqU8Wx6e2vIUGrobNPOEo8FqsqI0s1S+5/V5+uRzJ8i15crhk5NzJ2PllJVocbTIQi4Qca8STlvgxLrb1Q0f98mRE4B0n3L5wjttz29/HumWdFw16yq0Olqj7tdZ11mHPk8fFhQvQEV2BVxeF8ZljgtbZXcwXDrtUqSYUvDctucSJtqAgRBJMc8Q/+am5spVUfU6bWI8kfu7KcReXVcditOLYTQYNQuRhMtnA4LzxEKFR66pXoMUU0rYNhbiOxTotHHOpTlJauictrNfPBt3fXgXHG4H3D63pihijKny+2MtRCKLNsWCi2h/I8LhlXOEwEIkHf0dmov+otJ1bWetKtJDcPeSu/HE+U+EPNaRQKKrR94PqWH1/4MUdggAhyA12SaSnCDR1lYJq9GqKhYgYIzJ1dtEqGC4KnzxCo8UN8LijGJ09nfKE6DBOG1aDkqQ0+buhclgQro1HTPHzNR22my5cohe4ORo1eFVKEgrkPOawpFmTkOfp0+eUNd21sJkMMkrtowxZKVkaea59Hv6Q07wRGNtAKpCJE6PM2jlrCSjBC2OFvR7+uXJbVlmGfY0S20NA8PVTio5Cf2e/qA+ZC2OFliNVtUESIRHhgqndXld2NywWQ6NBKQB3ePzBOVQvrnvTZxSdkrEQjShECFayuve4Xaozp9WjzZBYHhkTUcNOvo7cNWsqzRv3tPzp2Nfyz5srN+I7574Xbx3xXv4xYpf4LFzH1NtxxjD2RPPxqbvbkL1HdWqz2Jq/lS0OFoirrIrRZuYJInPb8ORDVhXu06u3qXEx32y2Ba5hz/6+Ee46Z2bwr5e4EqnljjnnOPTmk9xStkpESeJ4lrVymcDBiZlnc5O+RzEItr2tuzFmLQxskiMJ8rwyJvevgkPrHlgwGnTk9OWqq8XYFtfGx5Y84C8iAUAf/jiDzAyI/74tT/i6Quexvq69TjxLyeqqi4KOOeqqn4Z1gz0unvh9XnlAiSXTVfnOIpFpCe3SI3FV56wUvX3FeUrVO6KoLO/Myg/RVmMpM/dh30t+4JEm7g/NXQ3wGq0YuWUlfLixWDy2QQV2RWqnLYg0eafVGanZCM3NRdnV5wNs8GMt/ZpV5GUFxhDFCIRi27KybJwQkLltPW4evDq7lfxzenfxLjMceDgUec7ijzRE/JOkMNP4105UklmSiYumXoJXtn1inztD6VoUy6mRi3aMoObctd11snXfmCOWLROm+gjF1jy3+1zY23NWiwpXRJWIMlOW8Cio8PtQL+nP2x4ZE1nDb5q/ErzOlSizO/v9/TDZDCFDSPX6okrxgDlAvCOph2wGC3yXMJsNMvHEOS0aYwZgPT5j7WPRU1nDXrdvUERU6OBRIu2qwCs5Jz/C1L+GCD1NCtP8OsScUDLaZuQPSFk2IkIpxSiLVyY2aBFmzFAtKUXR+W0acVZ+7gP1R3Vqh5tAq1CJOImPq9wXlAxklaHFB5pNpjBwFSrb5xzrDq8SncIT2BIVU1nDUozSlUiIDs1W9Npu+ejezDt8WmaE/rGnkZ5IiwGXqfHGdJpA6RBtqG7AWaDGZdMlcJpitKLggZHEYIQmNcmxKxygl6QVgC3zx10/G6vG+vr1uPHq34Mp9eJxSWL5b+Jybgyp3F/y37sad4Tc2gkEFw11ePzYOkzS3H565fL24TKexTH1evula8rMYk8Ie8Ezdebnj8dHBxmgxlXzb4KdosdP1/+c82FEUASb4ETKtEsPFJem5ZoEzdPId4+PPRh0PM6+jvk3AzhtNV11aGyrTJkpTKxb+VKp5Zoq+mswZGuI1g2LnLHFHGtauWzAQOioaq9alBO24HWA5iUq/0ag0V22ty9eGXXK3j4i4fl8TJe4ZEHWw/ipKdPwv1r78efN/4ZgPQ9+dvWv+HKWVeiKL0Il824DB9e+SF6XD1Y/LfFuPeTe4MKBfi4Tx57hEC5/f3b8dqe13DVrKvkvwlSzakoSCvAka4jmJI7JUhcLy9bDo/Pg/V161WPa4XKC+d+f8t+7Dy2E17ulYuQCDJTpPzT+u56FKUXyc70hOwJmgsq0VKRXaHKaQvMkRUh3qJybmZKJlaUrwiZ1xbktAVMrMVCQ7jwSHEM4n7yxt430OvuxbVzrpWvH6VQ14OIjFGKtlh6tEXDzfNuRkd/B/608U8Ahka0mY1mpJpSkWfLkx2jeDltQswFOm0enyei06Ysoy+uiUCnrdXRiu2N28PmsymfFzgui2tPsxCJ32nrdnbjQOsBWfQrHV8lNrMNDo9DPuZw+WzKY1KOL+LzU4ZH7jy2E9Pyp6kEqxCZSqetx9WDPk9fSFFZmlEq33cDnbbRQKJFWzqCS+EbAYS+0xNJQ6BoO9R2CBNzgitHCtItatEWrqBDZ39nfAqR9LXCYrQgz5YXk9OmXP1p7GmE0+sM6bQp3RaH2yGHWMwrnIf2/nbZgRHHlZsqiZNUc6pqIN/dvBtNvU26Q3jEDU2s7il7tAlCNd2t6axBY08jbnn3FpWo9Pq8aHY0qxqZixtOqJw2QOrV1tDTgML0Qjm2Xsv5GJc5DmPtYzVFW+BqnwgLa+ptwv6W/Xh046NY+Y+VyH0oFyc/czL+uOGPWFK6RJ6UAQMTJuXk9c19bwIALjrhoqDj0YvSrQGAP3/5Z2xt3Co7ioDktOXb8jUnGnJ1P/8ETKxiC2EViHBaV56wMmZ3cGq+X7RFCJFUhUda1OGRorXAB5UfBD1PKfibepvAOceRriNw+9yqEu+BKHPaAG3RJkIstfLZAhHVJENVWy3JKEGKKQWH2g7FJNqO9hyV83sm52i7eYNFjBkHWw+i29WNHlcPntn6DDKsGWFX0AVZKVkwMmPIghNrqtdg0dOL0N7fjhPyTsDre18HAPx9x9/R5+nDD076gbztWRVnYectO3HFrCvwy09/iZOePkmuZBoYtnbNnGtw3Zzr8JctfwkqQKJEhEiunLIy6G8njzsZRmbE2mp1iGSnM3jVfHzWeJgMJhxoPTBQOTLQabMMOG3FGcU4tfxUAPFx2QApDLfZ0YwuZ5dmeKT4virHv5VTVuJA6wFV5UtBpJw2rclypEIkz29/HhXZFTi59GT5eKItRrKvZR+yUrKQb8sfEqcNAJaOW4olpUvk738iRNu0/GlIMaWo5hkZ1gz53hGNaBPnRtwHxb3Yx31yY21AOl8en0cOUfVyb8RiRkqnTYgt5XNMBhM6nZ3g4BHb2ITKaRPXnpbT5vK64PQ44fQ60eXsknNJQ4miwPDIcPlsge9PoJXTtqNpB2YWqIsHiYUIpdMm7iGhaiKMyxwn368TcV0NN4kWbTsBBC57XwBga4Jfl4gD4qYISO7Q4fbDmkVIBHaLHT2unohOm9fnRa+7d1CFSJQ5bemWdKnqn8JpU8ZDa6E1kIQq9w9Ig0ZgeKTstBVJRSFE/yyPz4OO/g755pBiSlHlw4mKSXpFm5joidWp2s7aoMpeWSlZmmGQnc5OGJgBr+15Df/c/U/58WZHM3zcpxJtIona5XUFDcSi8EN9Vz0auhtQlF6EpeOWgoGpKkcKGGOaTbaFA6lEiLYlf1uCEx47Abe/fzt2HduFb834Fl699FW0/KgFn1//uWoFWnbaFBUk39z3JhYULZBXPWNBXJNdzi7Ud9Xj3jX3goHhSNcRWfSKHm1ayDlH/pv83ua9yLflqwqvKJmaPxXXzbkO/2/Z/4v5mMdljoPNbFMJSy2U12wop+3z2s+DwteUK/dNPU1o62uTJ42BDZCVaDltrY5W1SrwpzWfIjslG9MLpkd8n3m2PDTd3aQpCACpGFFFdgUOth2URVu4qpFKitOL4fF5cLj9MJp6m0KGYA4W8flvapBCEi1GC5p6m3QXfTAwAwrTCzV7DT279Vmc9fezMNY+Fl9+50t8b8H3sKd5D/Y278UzW5/BwuKFQRUVs1Ky8PxFz+PNy95EfXc95v1lHh5e/3CQaLNb7Hhm5TPYf9t+vH/F+3LeSSBiXLpwyoVBf7Nb7JhfNB9rataoHteqBGc2mjEhewL2t+7H1qNbkWnNDHK2lYVIitKLUJheiJcveXlQ3yUlygqS4cIjldeKyKXVarTd6mhFiilFFqiBE2utsDRR8t/tc8NiUIdH1nbW4pOqT3D17KvBGJMXKqMtRrKvZR9OyDsBjDEsLF6INHNakECON4wxVY5vIibXJoMJ186+ViXiH1jxAG6ZL2XnxMNpO9Z7DG6fW35c2ToHiD48UlwTqvBIv1NlNVojtiAJldMmhLxmnzavU5VmIFr1hAyPNKvDIyM5bXpy2lodrWjobggaV7ScNpEXrRUeCUjnSMw9KTwyen4M4DnG2PMAUhhjTwJ4GnHs00YkDmX1yKbeJvS6ezWLkCi3b+xplAeIUDltYp/xCo+0W+zITJEaVNZ31+tatdYaSMKFvdlMwSX/xU18ZsFMmA1mOa9NDPDKAUfptK06vAqTcibpLqkswpB6Xb1we92o764P6qETKjyyo78D50w8B4uKF+HWd2/F0W6pp5Eo2y8KkQADTptWyX+V0+YXbTmpOXj+oudx50l3ah73ScUn4WDbQVUIowiPVDJn7BzMGTsHp40/DU+e9yQqv1+Jyu9X4qkLnsI3pn1D0y0REyax7yNdR7CxfuOgQiMBdXjkvZ/cC7fXjdsW3oZ+T798XkP1aAOCc472te4LGRoJSBOLZ1Y+oyplHi0GZsCU3Cmy0xaquIRmTpvfYet2SuWR3T43PqlSdzlRTgIbexpVVQdDiTavzwuH2xHktHFw1fWwrnYdlo5bqrvSn2jWHYpJuZNk0ZZpzdRdsl+ErInqhokOjxSFi25bcBsAfaGRAmUlV0Ba7f/xqh/j+v9cjxXlK7D+hvWYkD1B/i785L8/wc5jO3H9nOtD7vOiEy7Crlt24bxJ5+Gej+/BG3vfABA8ma7IqcDXJn4t5H4WFi/ExJyJIXskrihfgU31m1Q5QVpOGyDlte1v3Y+tjVsxZ+ycoPMuxvzazlo5fPtbM78VN5dILFBWtusXbeMyx2Hu2Ln4z/7gEMkuZxeyUrI0w8UA7fBIZU6b2WhWhdv/fbtUuffq2VcDwKDCI8XCW0FaAZrvacb5k8+Pah+xcP7k8zEtfxqAxDkiT5z/BO5ecrf8+03zb5LdqsCqzIH0unrx+/W/R11nHdr62mAymORFTnH9Ksv9A1DlXQE6C5GYBgqRaIZH+oXY4tLFEQVSqJy2kE6bPzxSucC+sWEjAGhWjwTUYrffq1+0KY9JiLb2/nb0ufvk3PdwTpvJYAID0+W0CSg8Mko4518CmA+gA1JzbTOAiwAkfkQgBk2GNQMOtwMenydsuX9BuiVdDgcDQjtt4vF4hEe29bUh3Zouf4Er2yt1TYDCOW2hqkcG5rQJMWU1WVXFSAIrJCqdNrdXSiiOJoRH6bTVd9fDx31Boi3Lql2IpLO/UxZXfZ4+3PjOjeCcqxprC1JMKapGrkoyrBmwW+yo7/Y7bXZpknvV7KtCihK5yXb9QJPtFkdLkNOWn5aPrTdtxWvffA03zb8pYhVBIDi359/7/g0Acp5drMjhkf2deO/Qe/j6tK/LeQR1XXXw+ryo7awNKdoCq/vtbd4bMjQynkzNn4o9zXtw23u3IfehXE3XLVz1yG5XN04dfypsZhs+OKQOkRSLMOmWdDT1NukSbWIyFFg9EhgIb2nsacSB1gO6QiP1MilnEirbKtHS16I7NBIIFm2JctrEmLHz2E7k2fJw95K7YWTGqMqrF6cXyyvUnHN8+/Vv48HPH8TN827Gu99+V14hL84oxpLSJXhr/1tIMaXg8hmXh9mr9D38xzf+gbH2sXj4i4el4zWnhX1OID86+UfY9719ISeqK8pXwO1zqyoshuq5NCV3Cg62HsSOph2azo/4rjq9Tlm0xZNApy3VpM5p0wqPBCSXcX3d+qBQ4C5XF9It0qKDyWAKzmnzj99BTps/18lsMMvtWfrcfXh++/NYXrZcvl+J49HjtHHOsbpqNb7xr2+gobtBVRAr1ZyasMqRSgzMgD+c/QdcPfvqiCF2iSCc07apfhPmPjUXd398Nx76/CG09bUhJzVnYAHVP74pG2sDCApfjdVpU5X89wu4FWUrIr6niDltAXMjUYhELN4BAwtKYcMj/fMZPTltWnMtpVhu6G7AziZ15UiBcuGbMalPoliUCJnTpoi0ofDIKGCMLWWM3QVgIuf8DkhhkdsBvAbgm4l6XSJ+iJtit7M7bLl/Qbo1Xf5iMrCQTpvIdYtHyX8f98lOGyDl3empwqbptHVUYUzaGM2mzIE5bb2uXtXKq7IYSWAvMmVy8tbGrehx9ajysyKhdNoCe7QJpuVPw7HeY3KIpqCjvwNZKVmYkjcFvz39t3jnwDt4bttzstOmN6cNkFb4D7YdREd/R8hCGUrmF82HgRnkEEkf96Gtry1i6KoeAsMj39z3JqbmTQ1qPRAt4jra0bQDjT2NOLn0ZJXLWN9dD7fPHTI8UuSjtPW1ocXRgta+1rBOW7yYmjcVR7qO4LFNj6Hf048/f/nnoG3CFiJxdiM3NRenjT8NH1aqi5GIG/6Mghkq0VaUXoQDbdqiTUwCAp02YEC0fVb7GQDoKkKil0k5k+D0OrG9cXvIlWItlKKNgYVdnBoM4vP3+DyYlj8NhemF+N2Zv8N3T9TfBUfptNV01uCfu/+Je5bcg8fPe1wVVgUA35j6Denfad8IGU6kxGK04HsLviePD7FMesI5CyeXSnltyn5toXp2TsmbAqfXiT5PX1AREkC90q5nPIqWDGsG8m35ONR2CH3u4Jy2lSesxM9P+XmQO7ByykpwcLx74F3V48riW2aDWbN6JANT3RflnDbfQMPlFFMKPqn+BAfbDuKa2dcMbGuyIt2SHjanrbO/E3/+8s+Y9vg0nP7C6VhTvQb3LLkHty64NYpPJn6cVXEWnr/o+SERiYGEEm3dzm6c9sJp6Pf0Y9aYWfjo8EcDoi2gVUCQ06YoSw/oc9qUTaOF2AqsHglIrV8iES6nzciMQWOAcHKVC+zinhDKyQqsHhkpqkmr6JsyBL++ux47mnYgNzVXNR8BBkSb+O5ZTVa5gnGo8UzltFF4pD4YY98BsBbATwC8zRj7HwAfAPg+gHsARE5gIIYdZahYZVslDMyg6UIJRCNWQBJ3kZw2PZOIUChX5uwWuzzA1HbW6nLatEJUQpX7B6SByul1ygnGgeEyymIkgU6bshCJmADrDY0EBla7e1w9qO2s1Xz+tXOuRbolHb9b/zv5MR/3ocvZJX82ty+6HcvLluOOD+7AxnopBGKMfSA80mpS5LRpDMTF6cVyeXA9k6Q0SxpmjZkli7bO/k74uC/mghtKzEYz0i3paOtrQ6ujFWur1w46NBIYuOZFQY4lpUtUoi1cjzZgIKSkvb9druYoCoUkkmXjlsHIjPjD2X/AtXOuxQs7XggKlw1X8r/bJYVHnl1xNirbK+VS54AUbmUz21CeVY6mHkm0GZgBp5SdEtJpEzflwJw2YEC0fVrzKWxmm9wwPR6IQkl7mvdE5bSJyUJ9dz3GZY7TXLiJB0q3ZlqeFBr2g8U/wHmTz9O9j+L0YnS7utHl7JLP07mTztWc+F424zJMz5+OOxbdoXv/N827SR5f471SnW5Nx7yieXK/No/PA4fbETI8UhDOaQOg2Ww9HlTkVIQMjyxKL8IvTv1F0KR8ztg5KM0oDcpr63Z2y8dsMVqCJtbtfe3ISslShQqLnCPlQlqKKQVbjm6BzWzDN6Z9Q7WPPFueptO2o2kHbn7nZhQ/Uozvf/B9ZFoz8fxFz+PIXUfw0JkPBb2344FQou2/Vf9Fj6sHL1z8Aq6fcz0OtB7A1sataqfNNeC0pZhSVFE1wIDT5vF5oipEohUeOdY+FjmpObqaQofMaettRq4tNygM3WKwqMIjRZEcu8UetAAkUIVHDiKnTXwX6rvqsfPYTswaMytoDJuWPw2pplR5Id5qtEYMjxSuJ0DhkdFwB4DLOef5kMr+/wpSqf9pnPPnOQ/RwZVIKlSirb0S4zLHaTowArGqYTVaMTl3csjqkfEMjwSkL6a46fu4L6rwSGWISqjG2sDASo8YjJXVI4GB8sJbGrZoOm3CpRODXTQ3SWVIRmBjbUFmSiZunn8zXt3zqiwselw94OByGIGBGfDsymfh4z48vvlx2C121aQsxZSCHlcPfNwX0mkTq7h6V7ZPKj4JX9Z/CR/3yW5tvFbFc225aO1rxdsH3oaXewcdGglIk2qTwYQdTTtgt9gxo2AGxtrHwsiMkmgL06MNGAjZaOtri1g5Mp4sL1+O7p90486T7sRtC2+Dw+3Ac9uek//u4z70e/rl685itMBitEjXCOdyI2yRr6Qs/d/SJzWKH5M2RnLauo+g0F6IaXnTUNtZq5lDJ8RgOKft05pPsaR0ScjJQSyIXDQOHpVoMxvN8vElKp9NvI6YkIl8nmgRiwj1XfURw9aL0ouw69Zd8vikh/y0fFw16yoACCrrHw9WlK3Al0e+hMPtGFjA05iAibBDq9Gq6VYrhV4inDbAX/Y/hGgLBWMMF065EB9VfqT6biidNovRolk9MjDkS4RHKhsui0ny16d+PchJyE/LVzltnHN889VvYvaTs/H89udx2fTLsPm7m7HhOxtw9eyrI064RzOhRNt7B99DhjUDJ5eejLMnng1AiuBROm3K8MjSjFJZbMiFSJQ5bYMMj7x1wa04dPshXQtJIXPa/GN4IKKvnBivxTgRroBTYPXIWEWb+H7XddVh17FdQY41IC1GNd3dJI/lYmE53DGOsY+RvysUHqmfUs75q/7/i5J1P+Ccu0I9gUg+xCqFWNGNFDIkti/LKkNWSlZic9pCOG2Avia1gQNJpFwlZVNcQF2JD5BCx0QxEuG0aRUiEc+PZjIk3yj84ZFj0sZoDpR3LLpDcls2/AHAQDUy5eRmfPZ4PHL2IwDURUgA6YYjzo2WaFPmjegWbSUnocvZhf0t++VcqVPHn6rruZHITc1FW18b3tz3JsZljouLY8PYQHjSouJFMBlMMBqMKEovQl1XHaraq8DAQjqlJoMJmdZM7Dy2E3tb9sJmtg2qmmU0iJv6iYUnYknpEjy26TG5Ibu4ySoXGkS1V4fbAR/3Id2Sjok5EzEhe4IqRLK5txn5tnyMsY9Bj6sHB1oPoCSjRBY3SldOIDttikllVkoWTAYTjvUeQ0d/B3Y07YhraCQgXZfCzcpJ0S/agIHrO1Hl/gXiux+raBOu0pGuI6hsr4TVaI2703T/ivtx3/L7wrZ4iZXl5culvLa6L+SFPS2nrSCtAJnWTGls1RD2KqctATltgOTc1nXWodvVHZTTFo4Lp1yIPk8f/lv1X/mxLmeX/H0wG81BE+uO/o6gkF6r0SrfM5ThkQBUoZGCfFu+ymmrbK/Eq3texU3zbkL9XfX428q/ydWOj3e0RBvnHO8feh9nTjgTZqMZU3KnyM5Ndkp2kNMWWMlZLCarctoiFSIxDhQi0QqPNBlMukO9w+W0aYo2o7oQiV7RJj43p1d/TpvSWe519aIovQhp5jR8VvsZet29mhVpGWOqe4hy3hdq/mhgBnlhi8IjY9gv59wLoJtzHrpMD5GUyDltLimnLaJo839ByrPKkWHJCJnTdrj9MIBg0RANyoFC6bQB+iqxBYq2+u56eHyekE6bmBCLwSpw5VUUI9ncsBktjhZYjBZ5gqwsRCIG+8E4baGqoxVnFOPr076OV3a9AmAgdzBwFfu7J34Xl0y9JKjCW4opRV5xC+W0CaIRbYDUZPv9Q+9jftH8qIouhCMnNQe1nbX4qPIjXDTlorjlRYjrfknpEvkxkUdU1VGFkoySsI7zLfNvwRt738DTXz2NKblTdFdGjCe3L7wdh9oOyUJZy+G1W+zodnXL51x8f8+uOBurq1bL3w1xwxff122N21CaWSqvlGqFSGrltImb6UeHP8La6rXg4HEtQiJeQwiNaJw2YOCaTlQREoE4B4N22rrrUdleifHZ4+N+jRVnFOP+Ffcn5NoV1ULX1qyV7xFaThtjDDfOuxE3zL1Bcz/ie5qdkp2wcNaK7ApwcHh8nqjG7OVly5FuScdb+wZCJLucXciwKJw2X7DTFtjQWLjh4v+AdC8qzSjVXPzKs+Wpqkd+VPkRAOCHi38Y9fdhtJNmTgsSbbubd+NI1xGcM/EcANI1eFbFWQCk8cRkMMFitAw4bZ11qkW5oEIkUThtoZprR0O4nDateVFgTpsQbaEaawMaOW0RishopaL0uHpgt9hRnFGM1VWrASCoHYkWQhTbLfawYlgI6WgLKY0EEjWbsDLG7hU/kMr93xvwGJHkiJvi2/vfRoujJWwREmBgglaeWY7MlMyQTtsn1Z9gRsGMkL2r9KAMj4yH0xauRxswMNES4iswPBKQ8tq+OvqVXCFRiAhlTltM4ZEKp02rR5uSE3JPQIujBW6vW54QBa6aMcbw2qWv4cVLXlQ9bjVaZaGnNRCL1fwUU4ru/leTcichKyUL7x16DxuObJBvhvEg15aLXcd2od/TH5fQSIG4lkKJtlChkYJfn/5rXD7jcnS7uoekCIkWl0y9BIX2Qvx5o1SQROu6S7eko8fVIwss4ZR/beLX0Ovuxee1nwOQqkfmp+XL+Y8OtwMl6SWYlCM5bQfbDga9vlZOGwD89vTfYnPDZtz87s0wG8y68jSiRTiAsYq2RIZHAtI5yErJCkq614s4ziNdR1DZFnkxLdnIsGbgxMITsaZ6TVinDQAeOvMh3LLgFs2/ie9pokIjAXXhrWjGbKvJinMmnYO3D7wt93cMLEQSVD2yLzg80mqyygJBTH4fWPEAnln5jKagzrdJ4ZHiNT8+/DHKs8oT4piOdGxmm6r1BCCFRgJQtbVQijbA3yrA1QuPz4OjPUdVOVRBhUh0OG2RwiOjQTh0WiX/tZw2i9ECL/eiva8dDEzOHY3ktIn8/sGER9rNdhSnF6PX3QsGhun5kUtdiM830vyjNLMUNrMt4mc/EkmUaPsCwKmKny8Dfl+RoNcl4oi4wTy++XFMyJ6AS6ddGnZ7ZXhkhjUDLq9L1Z8MkFaTPqv9DKeV66+eqIXJYJJvWunWdJVVrqfQReBAEq5HGzBQQMDhdsiDVeBNfH7RfLT3t2PL0S0qQarMaRM34GgmABajBUZmlAuRBJb7VyIEa2tfq2Z4pEDLlYoUHilW+IvSi3S7WgZmwKLiRXh9z+vwcV9cRZsIf8uz5WHpuKVx26+4lpROpCzawvRoExiYAc+tfA43nnij3ENpqLEYLbhp3k344NAHONh6MKTT1uPqCXLaTi0/FSaDSXbpWhwtyEvNUznjJRklSLemo9BeqO20aeS0AVJhjOvmXIfGnkYsKF6QEIdEiMlkddrSzGmYmjc1Zmc4xZSCPFueHB450kQb4M9rq/9SrlIZqqhAOMT3NFFFSAB1rmC0xToWFC1AU28Tul3dkovic4fNaevo79B02gRiQn7+5PNxxoQzNF8zz5aHfk8/HG4H3F43VletxlkTzhqW6ozJjgjzEwIXAN4/9D5mj5mtuqbOmHAGslKy5NzkNIvU362huwE+7lOJNq1CJNHktGmFR0aDEHvK8Egf96HV0RoyPBKQxvh0azrG2sciw5oRNhxTmd+vR7SFqh5pt9jlMbcip0JXyoj4rCKNF9fOvlbVvH00EZucjwDnfEUi9ksMLYXphbh8xuWYO3Yu7lh0R8TSrsrwSNGnqsvZpfpSf1n/Jfo8fVGVvA9FiilFbuBrNprlQVhPeKTRYAQDGxBtHeFzlWSnzd0nu22BN/F5hVKuwPam7XJvLwBIMaaonDaL0RLVShpjDHaLHTWdNejz9IUXbYoGq2IVW68rJvq0AeFz2qJd2T6p5CR8WPkhclJzsLB4YVTPDYcQxhdOvjCuK2rFGcU4sfBE1edWmlEKh9sBh9sRUbQB0gr5Uxc8FbdjioWb5t+EX6/7NR7b9JhcWCIoPNLZHeS0pVvTcXLpyfiw8kM8cOoD6HH1qJw2YEDAT8ufho8Pf4z2vnbVjV4rp03wp3P+hN3Nu3H59PB9w2IlVtF28QkXo6mnSdf5HQy/Ou1Xgw7bKU4vltuHRIqASEZWlK/Aw188LOdOxlJJOMWUArPBnFCnrSCtQF7ciFa0KXs2BvZHNBvNwdUjNQqRKCMe9ITMiUW7Zkcz6rvq0eXskp0iQo3NbIOXe+H2uWExWtDl7MJntZ/h7sV3q7bLSc3BsbuPyeJDNOUOLPcPaDfXjnSvF38PVT0yGsTzlNdWR38HvNwbshAJIF0vGdYMMMbw/EXPh+2VqkwV0dOnzcAMqr6EPu6T+9wWG6Q5hVY+mxbieCONF6dPOB2nT9DfC3ckkRDRRowOTAYTXvn6K7q3n1kwEzMKZmBJ6RKsq1kHQMqrUuYwra5aDQMz6Oo5EgmRpC1W8zOtmZJo0xEeCajLLld3VKMovSikMFUOVKGKiYhiJG6fWzVAKsMje129MU3Y0ixpcsPkUDltgPqmLTttOlexlYOvlmjLT8uPaZIkHKuzKs6Kq7gSk6J4hkYCwGPnPhYUXqLM54sUHpksjLWPxaXTL8Wz257F2RVSFTRVeKQ1Hcd6jwU5bYAUHvST//5EbnqaZ8tTfY/F5/Gr036FU549BVe+eSXe/tbbsvsthKDWtW632PHld74MejxeLCheAJPBFHWY4+yxs/HE+U8k6KgGOH/y+YPeR0lGieyEjkSnTeS1vXPgHQCxOW2MMdy28LaEihLGpJ5925u2R+0Ki/Gpra9Ndj5COW3CtQh0OJTjcLg8WoFYtGtxtOCjyo9gYIa4LJCORpTFxSxGC1YdXgWPz4NzJgVHgyidrzSLFB4Z2FgbCNFcO8I9jzGm6scHxB4eqeW0icI0kZw2cW1edMJFYV9D+bnpyWkD1Nd7n7sPHBx2i10+Jq3KkVqI14plvBgtDH2GPDFqKc4oxs5bdqI8q1xeCQnMa1tdtTrIxYgVIbCEQyBeU4/TBqgHkki5SsqctlDFREQxEgCqBtLKQiTRlI5WkmZOw/7W/QDC93hTOW3O8PkigSgHXy3xamAGXD37alww+QLdxw0Ai0sWozyrHFfPim+o4LmTzsWNJ94YMlQoVnJSc1SuEhAg2hLsxMST2xfeji5nF57c8iQA7fBIrfwzIfJe3vkyAOmGbzFa5PAt8XmcVHIS/vi1P+K9g+/hV5/+Sn6+cCaGI6dg1phZ6P5Jd8yFPkYCxenF8HKpZ+RIdNoyUzIxd+xcuTx9rD07Hzn7EVX+USIQn2+sTltbX1tQxeTAnDaxwBYYHqkch/WEzIlJcHNvMz6s/BALixdG1WT+eCKwIvT7B99HpjUTi0sWh31eWKdNq7l2hPBIYKAf32DDI7Vy2oRoC1WIRGyjt6eZci6kJzwSUDeTF/cbu8UuR+9E67TFY/44UiHRRiQEcXNSVpDsdfViw5ENg85nEwQ2gM20ZiLVlKq7nL5StFV3VIdtHK7MaZOdNg0XQYRIKnPaUk2pcHld8HEfet29MfU+SrOkyat3enLajvUeQ2d/J6xGq+5ePJGcNgB4+sKnceWsK/UeNgBpQlZ1R5XmCuZgmJw7GU9d8FTEsN14MBKdNkBqWzCvcB7+s/8/AIILkXS7FOGRCqdt9tjZGJM2Rq5EKm74Y+xjwMBUbust82/BVbOuwv1r7sf7B98HIOW0DWePnNHef0pcjwxsRC0iKFlRvgKAdK70uEjDxcRsqYhHPEVboNMm0gm0+rQJogmP/Mfuf+DL+i9xyQnxjUIYTShFm1zqv+LMiIJJOG21nbXIsGao8uljcdqAgeshXtUjlU6bqCYaqhAJMBAeqQfxufW4euD2uXWNtcrrXeT12y12nD7hdNw6/1acOeFMXa9NThuJNiJBiC+V0mn7vO5zuH3uuIVriMFCTDYzUzJ1h0YC6oHySNeRsJMfZU5buAqQomRuoNMGQE4Qj9VpA6SJdrhVptzUXDAwOTwymhVsPaLteKUwvRAGZoDFaEloDk28YYzh9oW3y7+HLUSiWGk1MAPOqjgLTb1NAAZu+GPtYzHWPlY1sWGM4cnzn8TMMTNxxRtXoKq9SmrWrXPllogeUSihJKNkSBYtEoHI+032CVg8nDbxHZOdtoCcNtlpG2R4pPievrD9BUzInoDbF90e4RnHL8qeazuP7UR9d72uQlk2s01y2rrqgqJetHLa9DptcakeqZHTpic8stXRqlu0iQVssdAQrWgTTluaOQ1ZKVl47LzHdPdT05vTNpoh0UYkBNlp6x9w2lZXrYbZYI5bpT9lzw4A+FrF13DxCRfrfr4YSOq66uDjvrBOm3JVLlwFyAVFCwBAVc5b5EII0RZrThsg5bOFqwRmNBiRa8uVwyOjmRApB189cerHEyaDCYX2QpRllg1L37XBcNmMy+QbdqBo6/f0yxPGQGdMhEgCAyv4X6v4mmbOg81swxvffAM+7sPX//V1NDuah9VpG+0Ip20khkYKlpUtAwNL+gnYqeWnYl7hvKiriopQR6XTJhYygpy2/nbVcwSqQiQ6QuYyrZnyxP2PZ/9x1DvOg0F5TxcRAnpCbUXJ/7quOlU+GxCieqQOp030S5OdtkGGR+rOafPPoTi4buEkPjdxzepZNFLWD1CGR0aL3pL/oxkqREIkBK2cttVVq3FSyUkxhQdqERge+YPFP4jq+RajBd2ubrncfzinTU8hEgCYWzgX/7n8PzizYsDuFwN5n7sPve7emBwIIfTC5bMJRK+eHldPVIMbOW3hmZY/LeknmFqkmFJw87yb8eDnD6pWU8V1eLT7qGb+2VkVZ4FBWiAQk8n/WRq6jHJFTgVevORFXPCKlPMYzzYMhBqRCzISi5AIslKyMLdwbtIvEE3KnYTNN26O+nmp5lSkmFKkptlO6fsTKqctXuGRjDGMzx6PybmT41LwZjSjFG3vHXoPc8bO0RVFIXLaHJ0OzC+cr/qbOEfKPm16XLOgnLbBNtcOyGkLlTai/O6Jxu+REJ9bW18bAH1Om9mondMWLRQeSaKNSBCBOW0d/R3YcnQLfn7Kz+P2GnJ4ZIxhWMvGLcM/dv9DTjwOl6uUakoFA0OPqydig+wLpqgLdQSGRyr7XelFdtrC5LMJ8tMk0ebyuqISGcoVMxJtwbx66asjzmUT3LfiPnxr5rdUq6niptnQ06D5HcpPy8eJhSeiprNGd0GR8yefj5+f8nP88tNfktOWQEozS2E2mEd8sZXnVj6ncgVGGzmpOWjra5NdjlA5baHCI6MtRAIA665bJ5dvJ0Ij7t9He47i89rP8aOTf6TreWmWNHT0d8Dj86iKkACSaE4xDbT4Ga7wSJXT1qfdWFu8rkB3eKR5cOGRopBbLPcHuU/bCFw8jRck2oiEYDFaVM2aP635FD7ui2v54cDwyGj5/qLv45ltz+Chzx+CkRlVxSYCMRqMGGMfg/ruermHid4cBxED3u/pl0r+x1KIxByFaLPly+0Bwr2nQMhpC89IvlGYDKagCb743hztPhoyNOZnp/wMe5v3RvVa9y2/D3VddZgzZk5Mx0pEJsOagc03bpZ70o1URLXd0YoQbV3OLhiYQb5nKJ0HYCDULJzTpndMVrbmIEIjzsV/9v8HXu7FuZPO1fW8NHOaLIoCwyMBqEVbrIVIBtlcW5nT1tzbHFK0KRcFoi1EIq7ZmHPaYpgHyTlt5LQRRPzJsGbIOW2rq1Yj1ZSKRcWL4rZ/YZXHGm45e+xsLC9bjrU1a1GeVR5xdas0oxR1XXVhq0dqIYdHeqQiJjZT7IVIwvVoE4jwSLPBHHtO2wgtbkDoRwi1oz1HUWgv1NzmohMuiti3JxCjwYhnVz472MMjIqC3TDYxfAjR1u3sRrolXXa/LAaLamItGnAHCrNom2sT+hHi492D7yIrJUvuJxoJ5Xwj0GkDpHMWayGSwYZHhsppCynaFNdXtDltIjxSb582ymmLDyMz1ocYEWRaM9Hlkpy21VWrsXTc0riKAavJijRz2qBC1u5YdAcAhC1CIijNLEVdZ13E8MhAlIVIBlPyH9CZ05aWj1ZHK9r722MWbeS0jX7ETbOpp0n3DZsgCP3ITpurS+VkBDptHf0dQUVIgICcthjdF0IbZU7bmRPO1B2SqFysDem0eaNz2gKbaw/aaQvIaYun0yYih6LJadNy2mISbVQ9kkQbkTiE03as9xh2HtsZ19BIQBosBjvZvHDKhZiWP03urxYO4bSFqx4Z6jiBgXYBsZT8FwOc3vBIDo5+T39UK1LKFTMSbaMfcU1xcCrPTxAJICdlIDxSOSm2GC3qQiT97ZpjNeUZJw6l+NIbGgmonTat9AOracBp8/g8+guReJzyNRFrTptw9QKdNq3G2uJ1BVHntEURHqlsrh3t/EkJFSKh8EgigWSmZKLL2YVPqj4BgLiLtgsmX4BxGZGdp3AYDUZsvWmrrnCE0oxS9Lh60NDdAKvRqrs4g1iZ6nZ1w+PzxFTy/7Lpl8FkMOmqbqXMaaA+bUQolEKNnDaCiD85qTlo728PEm3KSSwgTYADi5AA0VePJPQjxAegr9S/QNy/8235qn0IBlOIZLDhkYwxmAwm2bFze93odHbqCo/UK9oMzCBVRY2yEIkoStfj6oHNbIspQmrO2DmYM3bOcZ23SaKNSBgZ1gwc6j2E1VWrkWHNwImFJ8Z1/5fPuByXz7h80PvRK1BE/Pr+1v1RrRKJQa3V0QogthWmsqwy3LX4Ll3bKhuMx1ryP9nLcBODRxmeQk4bQcSfnNQcONwONPc2Y4x9oGqwMscHkMIjtULtKDwycQjxMTVvqqqvaiSE06aVzwb4c9oUJf+jKkQyyPBIQBJ8QvyF69EGqJ3caO4BNrNtIKdNZ582ZXhkrMXjzqw4E1srtsb03NHCiA6PZIxZGGNPMcY6GGPNjLFfRNj+UsbYYcZYL2PsI8ZYseJvDzPGDjLGuhlj+xljNyT+HYxuMq2S07a6ejWWly2P2fJPFkQoxP6WGEVbnyTa4tWnLhTKUAjKaSNCQaKNIBJLTmoOAKCms0Yzp41zDkAqRKIZHkmFSBLKivIV+O6J343qOcJp0xLZwOCcNhEeqec5oTAZTPJ+Ioq2GJw2QIoeijanTRzTYEQbMfKdtnsBzAIwEYAdwCrGWBXnPKh0GWNsKoBnAFwM4HMADwF4GcBy/ya9AC4AcADAPAAfMsYOc84/Sfi7GKVkWDNQ31UPL/fiewu+N9yHM2jEIH205ygm507W/TwRQjEYpy0alE5brH3aRrrAJiKjEm0UHkkQcUeEPHb0d6iaF4tFMS/3wsRMugqR0EJa/Hn/ivejfo7stIUQbVaTVe5F5vXpE21W00AhEpPBNKgee2ZjsNOmnBMoiSWnDZDmMPXd9QCib67d6+4l0TYIRrTTBuA6AL/knLdwzqsB/B7A9SG2vRLA+5zzVZzzPgA/A3ASY6wCADjn93HO93HOfZzzTQDWAFiS8Hcwism0ZsLLvQDin882HBSmF8px2INy2mLIaYuG3NRc+f+xhEdajVZqzHocYDQY5XxLctoIIv4Ipw1AUE4bALi8Lnh9XnQ6OzVz2mJprk0kFtlpCxEeGeS06QmPNFjg9Drh8XkG7agqc9qiCY+MVrTJ+9BZ8l8ZHpnoOdBoZsSKNsZYNoAiANsVD28DMCPEU2Yot+WcdwKo1tqeMWYFsBDA7hCvncUYK1f+ANDfxfg4Qbg8ebY8zCgIdVpGDspCINEMOmJiLERbop02s9Esr9rGEh5JK7rHD2LFk5w2gog/oUSbGGNFoQhAe4GNCpEkH6WZpZg9ZjZWlK/Q/Lsypy2a6pEiPHKwUS7KnLZmRzOA0KLNZDDBwAwwG8xRtWNSFmDRFR5piE9OGzGywyPFWe9UPNYBINTswx6wbbjtH4cUJvmfEPu6E8B9Oo7xuEbcpE4tP3VQvdSSidKMUhzpOhKV8BKD4VCFRwJSOESoMtKhINF2/JFuTUezo5mcNoJIAErRplwYEa6Zy+tCt6sbADTDI1U5beS0JQV2ix3bbt4W8u8qp01neKSyEMlgz7OW06aMvgnEarRGPSdRbq87p03RXLvQXhjV6xEDJO1MmjH2AWOMh/ipBtDj31Tp6WYC6A6xy56AbTW3Z4w9COBEAJdwzn0h9vVHAOMDfpbpe2fHD8LlGQ2hkQIREhHNIGdgBliN1iErRAIMlP2PJuRBTBBItB0/kNNGEIkjotPmc8ul08lpGx1YjdbowyMVJf8He54Dc9oyrZlhhaDFaIlqngAEhEfqcOhUOW0uymkbDEnrtHHOIzbOYIw1AJgNoMH/0BwAu0Jsvsu/rXhuBiSxtUvx2AOQipEs55x3hDm2DkgunfJYIh3uccfcwrmYUTADF0y+YLgPJW6I5ONohVeKKUWutjQkTpstH3aLXXcvOWBg8I0mTIIY2ciijZw2gog76ZZ0GJkRXu7VFG0ur0tuUhyuT5uBGaIay4nhI8WUIjfXjqYQiWiuPdjwyMDqkaGKkChfO1bRZmTGqMI/AcppGyxJ67Tp5DkAP2OM5THGygDcBalCpBYvAjiHMXYaYywVwC8BbOCcVwIAY+wnAK4AcDrnvDnxhz76mZw7GTtv2YnijOLIG48QhGizmaITXkrRNhQD1qwxszA1b2pUzzEZTDAZTOS0HUcIsUZOG0HEH8aY7LZpFSJxe93o6O8AoB0eaTQYYWRGctlGEDEVIjFawMHR5+kbdHhkYJ+2UPlsAqvRGvX4L/L09YRGAgOijXNOOW2DZKSLtgcgOWWVALYA+Key3D9jrIcxtgwAOOd7AdwA4GkArQCmAvi2Yl+/AVAK4KD/eT2MsSeH5m0QI4VYwiMBKXFXDKRD4bTdt/w+bPjOhqifl2JKIdF2HCFunnQTJYjEIESb0s1WOW1hwiPFtjQmjxysJnUhEr05bQDgcDviWj2y2dEcWbQNwmmLRrQB0vXe5+mj+80gSNrwSD1wzl0AbvL/aP3dHvD7qwBeDbEtxTcSERlMeKRgKHLaGGNgiP6SthqtNEE4jqDwSIJILJpOm99NcfvcYcMjAWlSPVoKeR0PpJhS4PF54PV54fV5dYcPAlIPs0FXjwzIaZszdk7Y7eeOnYspuVOieo1YRZtwlUm0xc6IFm0EMdTE7LT5wwkYmK6+JsNFiiklqY+PiC8UHkkQiUVLtCmdh47+DpgMppBh8xajJaYFOGJ4EPfPfk8/OLju8EhAKtIRl+qRXjc451J4ZGp4p+1fl/4r6tcQ8xm9+e/CPZRTRIZg4Xq0QqKNIKJgTNoY3L34blw45cKonidWpNIsaUldtIbCI48vcm25SDGlUGI4QSQI4aCFymlr75Nas4S6L1iNVnDwxB8oERfEvd7hdgCAvkIkfqHX6+4dfPVIf06bw+1Av6c/YiGSWIjVaROijZy22CHRRhBRwBjD7876XdTPE80ohyKfbTCQaDu+uH3h7Ti74uykXkggiJFMToo/p80aIqetv12zCIlyWxJtIwfhPvW6ewEgaqctUg5aJEwGE/o8fREbaw+GWEWbCAUm0RY7JNoIYggQg1uyi7bijGJqfHkckWvLxWLb4uE+DIIYtawoX4GDbQfVPdcUOW0d/R0hi5AAkgjw+ryJPkwiToh7fa/LL9qiKETS6+5FoXFw91+z0YxuV7fcWDsRok0sQkcr2vY27wUAFKUXxf2YjhdItBHEECCHRyZ5GNqrl76q6yZDEARBRObiqRfj4qkXqx4LctpCFCER23qYJ6HHSMQPZagjgOgKkbgGHx4pctoSKdrE4rPe/HexSLG6ejVSTakRi6MQoaGSRAQxBIjE3WR32jKsGZQkTBAEkUDExFwUIgkXHkkVfUcWQTlt0YRHugdfiMRsMMPpdcqiLd+WPDlt62rWYVHJIrqeBwGJNoIYApSFSAiCIIjjFzFpVRYiCbctNdceOcg5bVGER4rn+Lhv0CX/Z42ZhT3Ne7C6ajWA5Mpp63X34uTSk+N+PMcTJNoIYggYKU4bQRAEkViEm6KnEMmsMbMws2DmUB0aMUjknLYYCpEAGLRAv2PRHci0ZuLZbc/CyIzITMkc1P60EPOZaEUbACwdtzTux3M8QaKNIIaAkZLTRhAEQSQWZbNhj88TNqft0XMfxV8v/OtQHRoxSIRreqz3GIDoCpEAGHR4ZHZqNu5ecjcAqdBUIhqzyzltOvu0iffHwLC4hApfDQYSbQQxBIyUkv8EQRBEYhFuipjYhwuPJEYWE3MmAgD2tewDEL3TNtjwSEBy2/JseQkJjQQU4ZFGfU6buN5njZmVEOfveIKqRxLEEEBOG0EQBAEMTNKbepsAIGx4JDGyyLBmYEzaGOxtkcrb6xFhyiqM8chfTLem4x9f/wf6PH2D3pcWsZb8p3y2wUOijSCGAMppIwiCIICBEDhy2kYnk3InDTht0YZHxqnozOkTTo/LfrSIthCJCP89dfypCTum4wUKjySIIWCkNNcmCIIgEouYpAvRFi6njRh5TM6ZjIbuBgDDEx6ZaKLNaZucOxmbvrsJX5/69UQe1nFB8l8dBDEKoJL/BEEQBBCc00bhkaOLSbmT5P8PdSGSoSDNnIb5RfOjapI9v2h+4g7oOIJEG0EMAVSIhCAIggAk98XADBQeOUqZnDtZ/v9Ql/wfCowGIzZ9d9NwH8ZxCYVHEsQQQIVICIIgCIHZYEa3qxsAibbRxqSc6Jw2ZZjhSAiPJIYPEm0EMQRQIRKCIAhCINyVDGuGLjeGGDmIsv+APhE20sIjieGDRBtBDAGU00YQBEEIxOScXLbRR6o5FaUZpQD0hUcqQyJHQngkMXyQaCOIIWDmmJk4u+JszCucN9yHQhAEQQwzwl2hIiSjE1GMRE94JGNMFmsUHkmEg0QbQQwBOak5+ODKD1CYXjjch0IQBEEMM2KSTk7b6GRyjlSMRG/oqxDxFB5JhINEG0EQBEEQxBAiO23Uo21UEo3TBgwUI6HwSCIcJNoIgiAIgiCGEAqPHN1My58GQH/xMXE9UHgkEQ4SbQRBEARBEEMIFSIZ3ZxVcRb+c/l/sLB4oa7tKTyS0ANJeoIgCIIgiCGEnLbRjYEZcMGUC3RvL4s2Co8kwkBOG0EQBEEQxBAiJueU00YAFB5J6INEG0EQBEEQxBAiJukUHkkAgNXoL0RC4ZFEGEi0EQRBEARBDCFick7hkQRA4ZGEPka0aGOMWRhjTzHGOhhjzYyxX0TY/lLG2GHGWC9j7CPGWLHGNlbG2D7GWGPijpwgCIIgiOMVctoIJVSIhNDDiBZtAO4FMAvARAALAHybMXad1oaMsakAngFwI4A8APsBvKyx6Y8BHEvI0RIEQRAEcdxDOW2EEsppI/Qw0kXbdQB+yTlv4ZxXA/g9gOtDbHslgPc556s4530AfgbgJMZYhdiAMTYZwGUA/jexh00QBEEQxPEKVY8klFB4JKGHESvpGWPZAIoAbFc8vA3Ab0I8ZQaAjeIXznknY6za/3il/+EnANwDoC/Ca2cByAp4uETXgRMEQRAEcVxDfdoIJVYTFSIhIjOSnTa7/99OxWMdANLDbN8Z8Ji8PWPsagBdnPN3dbz2nQCqAn7W6XgeQRAEQRDHORajBVajFanm1OE+FCIJoPBIQg9JK9oYYx8wxniIn2oAPf5NMxRPywTQHWKXPQHbytv7XbsHANyh8/D+CGB8wM8ync8lCIIgCOI4ZmzaWJRnlQ/3YRBJAoVHEnpIWknPOf9apG0YYw0AZgNo8D80B8CuEJvv8m8rnpsBSWyJx4sAbGSMAYAFQKa/guRSzvmhgGPrgOTSKY8l0uESBEEQBEHg58t/jrsW3zXch0EkCRYDVY8kIpO0ok0nzwH4GWNsE4A0AHchdBGRFwF8yRg7DcAXAH4JYAPnvJIxVgegTLHtEgBPQhKBzYk5dIIgCIIgjkdsZhtsZttwHwaRJFB4JKGHkX51PACpfH8lADeAJzjnz4o/MsZ6AJzDOV/HOd/LGLsBwNMAxgL4DMC3AYBz7gLQqHheGwAf55x6tREEQRAEQRAJQy5EQuGRRBhGtGjzi62b/D9af7cH/P4qgFd17HcNJGFHEARBEARBEAmDmmsTekjaQiQEQRAEQRAEMdqh8EhCDyTaCIIgCIIgCGKYoOqRhB5ItBEEQRAEQRDEMGE1UnNtIjIk2giCIAiCIAhimKDwSEIPJNoIgiAIgiAIYphYUb4C35rxLeSm5g73oRBJDEl6giAIgiAIghgm5hbOxctff3m4D4NIcshpIwiCIAiCIAiCSGJItBEEQRAEQRAEQSQxJNoIgiAIgiAIgiCSGBJtBEEQBEEQBEEQSQyJNoIgCIIgCIIgiCSGRBtBEARBEARBEEQSQyX/44cRAI4cOTLcx0EQBEEQBEEQRJKi0AtGvc9hnPPEHM1xBmNsKYB1w30cBEEQBEEQBEGMCJZxzj/TsyGJtjjBGLMCWADgKADvMB/OaKEEkhBeBkAsSVQBGD9sR0Qoice50DrHRHSMhO/E8XKeR8K5SATJeH6P13ORKGI9x3QekgfluUjG7+zxRBWAiQAKAWzinDv1PInCI+OE/wPXpZQJfTDGxH+PcM6rxWPi/8TwEo9zoXWOiegYCd+J4+U8j4RzkQiS8fwer+ciUcR6juk8JA/Kc5GM39njCf+5qARQGc3zqBAJQRAEQRAEQRBEEkOijRhpPDDcB0DI0LlIDug8JA90LpIHOhfJAZ2H5IHORfIQ07mgnDYiaWGMlcMfg032/eiEzvHxAZ3n0Q2d39EPnePRBZ3PkQk5bUQy0wFpNaJjeA+DSCAdoHN8PNABOs+jmQ7Q+R3tdIDO8WiiA3Q+RxzktBEEQRAEQRAEQSQx5LQRBEEQBEEQBEEkMSTaCIIgCIIgCIIgkhgSbQRBEARBEARBEEkMiTaCIAiCIAiCIIgkhkQbQRAEQRAEQRBEEkOijSAIgiAIgiAIIokh0UYQBEEQBEEQBJHEkGgjCIIgCIIgCIJIYki0EQRBEARBEARBJDEk2giCIAiCIAiCIJIYEm0EQRAEQRAEQRBJDIk2giAIgiAIgiCIJIZEG0EQBEEQBEEQRBJDoo0gCIIgCIIgCCKJIdFGEARBEARBEASRxJBoIwiCIAiCIAiCSGJItBEEQRAEQRAEQSQxJNoIgiAIgiAIgiCSGBJtBEEQBEEQBEEQSQyJNoIgCIIgCIIgiCSGRBtBEARBEARBEEQSQ6KNIAiCIAiCIAgiiSHRRhAEQRAEQRAEkcSQaCMIgiAIgiAIgkhiSLQRBEEQBEEQBEEkMSTaCIIgCIIgCIIgkhgSbQRBEARBEARBEEkMiTaCIAiCIAiCIIgkhkQbQRAEQRAEQRBEEkOijSAIgiAIgiAIIokh0UYQBEEQBEEQBJHEkGgjCIIgCIIgCIJIYki0EQRBEARBEARBJDEk2giCIAiCIAiCIJIYEm0EQRAEQRAEQRBJDIk2giAIgiAIgiCIJIZEG0EQBEEQBEEQRBJDoo0gCIIgCIIgCCKJIdFGEARBEARBEASRxJBoIwiCIAiCIAiCSGJItBEEQRAEQRAEQSQxJNoIgiAIgiAIgiCSGBJtBEEQBEEQBEEQSQyJNoIgCIIgCIIgiCSGRBtBEARBEARBEEQSQ6KNIAiCIAiCIAgiiSHRRhAEQRAEQRAEkcSQaCMIgiAIgiAIgkhiSLQRBEEQBEEQBEEkMSTaCIIgCIIgCIIgkhgSbQRBEARBEARBEEkMiTaCIAiCIAiCIIgkhkQbQRAEQRAEQRBEEkOijSAIgiAIgiAIIokh0UYQBEEQBEEQBJHEkGgjCIIgCIIgCIJIYki0EQRBEARBEARBJDEk2giCIAiCIAiCIJIYEm0EQRAEQRAEQRBJDIk2giAIgiAIgiCIJIZEG0EQBEEQBEEQRBJDoo0gCIIgCIIgCCKJIdFGEARBEARBEASRxJBoIwiCIAiCIAiCSGJItBEEQRAEQRAEQSQxJNoIgiAIgiAIgiCSGBJtBEEQBEEQBEEQSQyJNoIgCIIgCIIgiCSGRBtBEARBEARBEEQSQ6KNIAiCIAiCIAgiiSHRRhAEQRAEQRAEkcSQaCMIgiAIgiAIgkhiSLQRBEEQBEEQBEEkMSTaCIIgCIIgCIIgkhgSbQRBEARBEARBEEkMiTaCIAiCIAiCIIgkhkQbQRAEQRAEQRBEEkOijSAIYhTAGCtnjHHGWLn/92sZY9WKvz/JGHtyuI4vETDGzmaMHWCMdTPGHtCxfVw/E8bY/YyxNbE+fyTAGFvDGLs/iu13M8au8P9fdU0SBEEQsUOijSAIIgnwT45djLEexliXf/L73Xjtn3N+M+f85njtbygJI47+DOAJznk65/y+aPebDJ9JtKIoxD6SRhxxzqdzzl8a7uMAgkU6QRDESIZEG0EQRPLwG865HUAWgAcAPMUYO2V4D2l4YYyZw/x5AoCtQ3UsRPIQ4bqI92tZhuq1CIIgQkGijSAIIsngnPs45/8C0AZgoXicMbaSMbaVMdbJGNvDGLtB7z4ZY88xxp5T/F7NGPt/jLH3/eGFBxljKwOe8yPGWC1jrIMx9ixj7BXlPkK8xiuMsWf8z6lhjP0wYJuljLH1/r8fYoz9mDFmVPydM8buYIx9yRhzAPg2gJ8CWOZ3IXsYY/MYYz0AjADe9z+2gDFmZIz91L/fDv/rLIniMylljL3OGDvGGGtgjP2NMZYd+aNlDzHGmhljjYyxBxljJsUfixljLzPG6v37fYUxlu//25MAlgH4qf89NPofX8EY+4Ix1sYYa2WMvc0YGx/mGHaLf/37+X0s74cxZvK/l0b/+/ktABawzV/910SP/5q5LeDv1YyxazX2nc0YcwSeD8bY38NdUwH7vY8x9jFjrBvATf7z/UPG2F7/d2ILY+x0//bLADwJYJziurnI/9nygH0Hhs2K6/ivjLEWAC+JbRhjN/uv607G2D8ZY+mRjp0gCCIekGgjCIJIMvyT528DyAWw3//YSQD+BcmBywFwM4BHGGOXDOKlvgtJEGUC+AuAFxhjdv/rXQHgfwBcCiAPwFoA39Cxz28A+Nz/nMsA/D/G2GX+fZYB+AjACwDyAVwC4FYAdwTs4yYA1wBIg/SefwNgHefc7v/Z4nckAeAc/2ObAPwQwI0ALvbv/yUAHzHGSiMdtF84vgugG0AFgNkAxgF4PsJTlwBwACgBcCqkz+uH/n1aAfwXQB2AyZCcQQ+AlwEpPBPAOvgdVs75WP8+3QB+AGAMgEkAvABeDHMM08W//v38MMb38yNI5+9U//vp978/JRsAzAOQAeB2AL9njJ0ZZp/wv9d2AP+EdH4ASELO/3p68wpvAvAz/2s/A+DnAK4AsBJANoBfAXiLMVbBOV8H6TtSq7hu/q3zdeA/rnUAxkK6FgGgGMBEACcAmApgPoA7o9gnQRBEzJBoIwiCSB5+zBjrgDRZ/juAn3LO3/b/7ToAb3HO/80593LOPwXwVygmwTHwF875Vs65D8ATkCbDU/x/u9b/9y855x7O+XMAtujY51ec87/5n7PBf4zX+//2bQC7OOdPcs7dnPMdAB7SeA+/55zv4xJ9UbyfGwA8xDnf6d//YwD2QZrYR2IhgGkAvs857+acN0MSThcwxsaGeV4zgF9wzp2c870AfoeB93seABuAH3POeznnPQDuBnAGY6wk1A45559zzjf430MbJKG+mDFm0/E+BvN+rgPwO875Xs65E8AvALQEHNvfOOfNfjf4AwAfADhD5zE9AeCbjLFM/+9XAzjgv0708Df/9cg55w7/+7mHc37AfzxvQhJa39K5v3Bs4Jy/4L+OHf7H3JDOZR/nvAHAm1A44QRBEImERBtBEETy8FvOeRYk1+BZSJN7EWpXCuBwwPaHILknsdIg/uMXFAAgwr1KAFQHbB/4uxZVGr8Lp0vvewjch14G8xmVAmjhnHcFPBcRnl/rF70C5fudBKAIQLs/XLMDknPqDLdPxtgcxth7/pDGLkguJ4PkHuollvdTAsVn739fNYrjYoyxnyvCETsAnAOgQM8Bcc43AtgL4Er/Q98F8JSe5/qRj40xNgbSIsOb4rP1H88pkByxwaJ1DR7jnHsUv/dg4PtCEASRUEi0EQRBJBmc824A3wMw3v8vIIXYBeY1VQCoTdBhHAFQHvBYmY7nBT6n3L8vQP978EX4PRSD+YzqAOQF5ChV+P8N9/xxjDHlvbQcA++3EcBhznlWwE8K53y9fxut9/YvAHsATOOcZwBY7n+caWwbah+xvB/VOfe/L6XA+xaA2wBcDiDbv8Dwfpjj0uIJAN/157aVI3zYZyDK99kByZH+WsBnm8Y5v0Vje0E3ADDG0hSPFUV4LYIgiGGHRBtBEEQSoghP+xljLAPAcwAuYoxd4C/AsBSSU/F0gg7heQDfYVKBDxNj7GpIuUyRmMcYu87/nIX+Y3zW/7dXAMxkjN3IGDMzxmZAyqOK9B4aAZT5c8TC8QyAHzHGpvv3fwukEMGXdRz3Jkgu0P8xxuyMsTwAjwB4l3PeGOZ5+ZDy9iyMsSkA7sHA+30DQAqTWhZkAgBjrEDk+Cne2+SAfWYC6ALQ5XeUfhHh2JshiYwpisdieT/PA7iHMTaFSRUTfwa1u5cJKSevRXor7GIAEfPZAngFklj7M4B/BDiBuvF/P54E8DvG2FS/C5jKGDuFMSY+z0YA+UxdfOUAJOF2E2PMwBibg8GFGBMEQQwJJNoIgiCSl79DqiB5D+f8C0hOxy8BtEMSOj/inL+WoNd+CdIk/w1Ik/RTAfwHkrsRjtcghai1AHgdwIOc81cAgHNeDeBrkHKnWgC8BakAyh8i7POfkEL7jvrD4OaE2O73AP7mP84WSDlTX+OcR3Ta/GFv50MKTa0CsBNS+OjVEZ66HlKIXD2ATyF9Xg/799kNYDEk92+nP9RxPaTPR3nMM/zvSzh0N0AKIewGsMq/z3DH3gepoMzz/v08FOP7eRDAv/3vox5SIZj1ir8/5//bHkiC6BxI51A3nPNeSNf1iYguNFKLuyG5kq9Cct6qAfwEgGgHsBpSMRZRTfRC/zm5BpKD3QXgfyFdgwRBEEkN45xH3oogCII47mGMbQbwOuf8f0P8/TkA4JxfO4SHRYwwGGM/AHA153zucB8LQRDESIGcNoIgCEITxtjl/pCzFMbYHQBmQXI1CCIm/GGatwH44zAfCkEQxIhixIs2xthtTGqo6WIRGnQyxi5ljB1mjPUyxj5ijBUr/mZhjD3lD6FoZoxFyiEgCIIY7dwEKQzuGICrAKzknB8K/xSC0IYx9hCkapQbEFCAhDEmGoMH/QzLwRIEQSQZIz48kkmNZX0AzgaQGioshzE2FcBGSE1XP4fUG2gW53y5/++/AnA6gAsA2CHlEfyac/6s1v4IgiAIgiAIgiCGghEv2gR+0VUSRrT9GsAkzvk3/b9nQlo9nsY5r2SM1QP4Luf8Pf/fbwHwbc75siF5AwRBEARBEARBEBqYIm8yapgByWkDAHDOOxlj1ZCqdrVB6tOyXbH9NgC/0doRYywLQFbAwxYAEwAcBOCN0zETBEEQBEEQBDG6MAIoBLDJ38IkIseTaLMD6Ax4rANSqWa7//dOjb9pcSeA++J3aARBEARBEARBHGcsA/CZng2PJ9HWAyAj4LFMSH1wRKJzhuL/4m9a/BFSvxolZQDWrFu3DiUlJYM9VoIgCIIgCIIgRiFHjhzBsmXLAOCo3uccT6JtF4DZ4hfGWAakhqe7OOftjLEG/98b/JvM8T8nCM55ByQnToYxBgAoKSlBeXl5XA+cIAiCIAiCIIhRh+6UqtFQ8t/EGEuBFBtq9PcTMmts+iKAcxhjpzHGUgH8EsAGznml/+/PAfgZYyyPMVYG4C4AzwzBWyAIgiAIgiAIggjJiBdtAH4GoA/AjwFc6f//XwHA3+NlGQBwzvcCuAHA0wBaAUwF8G3Ffh6A5KxVAtgC4J9U7p8gCIIgCIIgiOFm1JT8H24YY+UAqqqqqig8kiAIgiAIgiAITaqrqzF+/HgAGM85r9bznOMpp40gCIIgCIIgiAh4vV60tbXB7XYP96GMWAwGA2w2G9LT0+XaF4OBRBtBEARBEARBEDJtbW1ISUlBXl5eXATH8QbnHF6vF11dXWhra0Nubu6g9zkactoIgiAIgiAIgogTbrcbdrudBFuMMMZgMpmQnZ0Np1NX7+yIkGgjCIIgCIIgCEIFCbbBE8/PkEQbQRAEQRAEQRBEEkOijSAIgiAIgiAIIokh0UYQBEEQBEEQxIji9ddfx4wZM5CWloaysjK88cYbw31ICYWqRxIEQRAEQRAEMWJYvXo17rzzTrzyyitYsmQJWltb0d3dPdyHlVDIaSMIgiAIgiAIYsRw77334t5778XSpUthMBiQn5+PCRMmaG577bXX4uabb8Z5550Hu92OxYsXo6GhAffccw9ycnIwadIkbNiwQd7+wIEDOOOMM5CdnY0pU6bgueeeG6J3FR4SbQRBEARBEARBjAi8Xi82btyItrY2TJ48GUVFRbjuuuvQ2dkZ8jn/+te/cP/996O1tRXp6ek4+eSTMXnyZBw7dgxXXHEFbr/9dgBSq4Pzzz8fp5xyCpqamvD3v/8dd911F9auXTtUby8kjHM+3McwKmCMlQOoqqqqQnl5+TAfDUEQBEEQBEHERkNDA4qKiuTf/+/dnUP22necNzPs3xsaGlBcXIw5c+bg7bffht1ux1VXXYW8vDw8++yzQdtfe+21YIzJf3viiSfw0EMPoaqqCgCwd+9ezJ49G/39/Vi/fj0uvvhiNDY2wmg0AgDuvvtudHR04Omnn47p/QR+lgBQXV2N8ePHA8B4znm1nv2Q00YQBEEQBEEQxIjAZrMBAG677TaUlJQgKysLP/vZz/DOO+/g5ptvht1uh91ux8033yw/Z8yYMfL/U1NTg353u91wuVyor69HSUmJLNgAoLy8HPX19UPwzsJDhUgIgiAIgiAIghgRZGVlobS0VLNx9ZNPPoknn3wy5n0XFxfjyJEj8Hq9snCrrq5GcXFxzPuMFyTaCIIgCIIgCIIISaSQxaHmO9/5Dh599FGce+65SEtLw29+8xtceOGFg97vokWLkJWVhf/93//Fj370I+zYsQPPPvssXn/99Tgc9eCg8EiCIAiCIAiCIEYMP/3pT7F06VJMmzYNFRUVyMnJwR/+8IdB79dsNuPtt9/G6tWrUVBQgG9/+9t46KGHsGLFisEf9CAZFYVIGGNZAP4C4BwAXQB+zTl/XGO7JwFcqXjIDMDFOU/3/30NgJMAePx/b+KcV+g8hnJQIRKCIAiCIAhihKNVPIOIjXgVIhkt4ZGPQnovRQAqAHzMGNvLOf9EuRHn/GYAclYiY+w5AL6Afd3JOY89GJYgCIIgCIIgCCKOjHjRxhhLA3ApgLmc824A2xhjzwC4HsAnEZ73dQDnD8mBEgRBEARBEARBxMBoyGmbDCnMc4/isW0AZkR43tcBNAP4NODxXzHGWhlj6xljp2k9kTGWxRgrV/4AKInt8AmCIAiCIAiCIEIz4p02AHZIeWxKOgCkR3jeNQBe4Oqkvv8BsAeAC8DlAN5mjM3hnB8MeO6dAO6L9YAJgiAIgiAIgiD0Mhqcth4AGQGPZQLoDvUExtg4ACsAvKB8nHP+Jee8m3Pu5Jw/D2AdtMMn/whgfMDPshiPnyAIgiAIgiAIIiSjwWk7AIAzxqZyzvf6H5sDYFeY51wF4HPO+eEI+9Ysrck574Dk5sloNfgjCIIgCIIgCIIYLCPeaeOc9wJ4DcAvGWPpjLFZkIqQPBPmaVcDeE75gD9P7WzGWApjzMQYuwLAKQDeT9ChEwRBEARBEARBRGTEizY/34Pkih0F8AGA+znnnzDGxjHGevzhkAAAxthiSEVDXg3YhxnAryAVJ2kBcDuAizjn+4biDRAEQRAEQRAEQWgxGsIjRbjipRqP10IqVKJ87AsAaRrbNgNYkKBDJAiCIAiCIAiCiInR4rQRBEEQBEEQBHEc8Oijj2LevHmwWCy49tpr5ccPHDiAlStXIj8/H9nZ2TjzzDOxZ8+e0DsaQZBoIwiCIAiCIAhixFBUVISf//znuOGGG1SPd3R04MILL8S+ffvQ3NyMpUuX4rzzzoO6w9fIhEQbQRAEQRAEQRAjhksuuQQXXXQRcnNzVY8vXLgQN9xwA3Jzc2EymfCDH/wA1dXVaGhoCLmv8vJyPPjgg5g9ezbsdjuuueYaNDc344ILLkBGRgaWL1+OY8eOydu/9957mDVrFjIzM3HSSSdh48aNCXufSki0EQRBEARBEAQx6vj000+Rk5ODwsLCsNu99tpr+PDDD3Hw4EF8+OGHOOOMM3DvvfeiubkZVqsVv/vd7wAABw8exKWXXooHH3wQra2tuPHGG3HOOeegvb094e9lVBQiIQiCIAiCIAgiMWzZsmXIXmvevHlx2U9DQwNuueUWPPzwwzAYwvtUt912G8aOHQsAWL58OWw2GxYskOoTXnzxxXj99dcBAP/85z9x9tln45xzzgEAXH/99Xj88cfx7rvv4sorr4zLcYeCnDaCIAiCIAiCIEYNLS0tOPPMM3HDDTfguuuukx+fPn067HY77HY7XnrpJfnxMWPGyP9PTU0N+r2npwcAUF9fj7KyMtVrlZeXo76+PlFvRYacNoIgCIIgCIIgRgXt7e0488wzce655+L+++9X/W337t2D2ndxcTG++uor1WPV1dW46KKLBrVfPZBoIwiCIAiCIAgiJPEKWYwXHo8HHo8HXq8XXq8X/f39MBqN6Ovrw9lnn40lS5bIeWjx5Jvf/Cb+93//Fx9++CFOP/10vPTSSzh8+DDOO++8uL9WICTaCIIgCIIgCIIYMfzqV7/CAw88IP/+4osv4pprrsGpp56KTZs2Yffu3Xj++eflv7///vtYtuz/s3fn8XVXdf7HX5+sTZukK23pXgpltRQEAWXXQVRAHWREUMAFZEZHGHUURX9sisq4MK6oiCCLwMCMG4IbIFUWQRbZ1y50hS5pm6VZz++P7024SZM2XZLcpK/n43Ef995zz/fc873fmzbvnPM938O2+X1nz57NjTfeyKc//WkWLVrE7rvvzm233cbo0aO3ue3NiaFw3YJCEBEzgPnz589nxowZA9wbSZIkaessXbqUSZMmDXQ3hoTuPssFCxYwc+ZMgJkppQW9aceFSCRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJHXiYoXbbnt+hkMitEXEqIi4OSLWR8SSiPi3HuqdERGtEVGbd3vLlrYjSZIkDVVFRUW0trYOdDcGvebmZoqLi7dLW0PlOm3fJduXScAs4A8R8XRK6a5u6j6YUjp4O7QjSZIkDTnDhw9n3bp1jB49mogY6O4MOiklmpubWb16NSNHjtwubQ760BYRI4CTgP1SSuuBRyPiKuBDQK/D1vZqR5IkSRrMqqqqWL16NcuWLRvorgxaxcXFjBw5koqKiu3S3qAPbcBssouEP5VX9ihwTA/150TESmA1cD3w5ZRSy5a0ExGjgFFdiqdsRd8lSZKkghIRjB07dqC7oTxDIbRVAuu6lNUAVd3UvQfYG1iYu78JaAMu2cJ2zgUu2Mr+SpIkSVKvDYWFSGqB6i5lI4H1XSumlF5KKc1PKbWllB4HLgbes6XtAJcDM7vcDtvaHZAkSZKkngyFkbbngBQRe6aUns6VzQWe6MW2+etw9rqdlFIN2ShcB0/SlCRJktQXBv1IW0qpDrgFuCQiqiJiDtniIVd1rRsRb4uICbnHewBfBP5vS9uRJEmSpP4y6ENbzsfIRs2WAXcAF6aU7oqIablrsU3L1Xsz8I+IqAN+C/wv8OXNtdNfOyFJkiRJXQ2F6ZHt0xVP6qZ8EdkCI+3PPw18ekvbkSRJkqSBMlRG2iRJkiRpSDK0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSARsSoS0iRkXEzRGxPiKWRMS/9VDv9Ij4e0Ssy9X7ZkSU5b1+dUQ0RURt3q28//ZEkiRJkjobEqEN+C5QAkwC3gFcFBFHdVNvOHAusBNwAHAY8Pkudb6ZUqrMuzX2XbclSZIkadNKBroD2yoiRgAnAfullNYDj0bEVcCHgLvy66aUfpD3dFlEXAscvxXvOQoY1aV4ypa2I0mSJEmbMxRG2mYDkVJ6Kq/sUWCfXmx7OPBkl7KzImJ1RDwcEf/Sw3bnAvO73OZtSaclSZIkqTcG/UgbUAms61JWA1RtaqOIOA04FJibV/xt4FPAWuAY4OaIWJ5SuqfL5pcDV3cpm4LBTZIkSdJ2NhRCWy1Q3aVsJLC+pw0i4gTg68AxKaXl7eUppYfzqv02Iq4DTgQ6hbaUUg1ZMMxvcyu6LkmSJEmbNhSmRz4HpIjYM69sLvBEd5Uj4ljgKuCElNKjm2k7bY8OSpIkSdLWGvShLaVUB9wCXBIRVRExh2wRkqu61o2Io4HrgRNTSvd38/p7IqIyIooi4hjg/cAv+3YPJEmSJKlngz605XyMbFRsGXAHcGFK6a6ImJa71tq0XL0vkk2dvC3vOmz5C5GcAywhm/r4X8CZKaU7+20vJEmSJKmLoXBOW/s5Zid1U76IbKGS9ufdXbstv/5h271zkiRJkrQNhspImyRJkiQNSYY2SZIkSSpghjZJkiRJKmCGNkmSJEkqYIY2SZIkSSpghjZJkiRJKmCGNkmSJEkqYAN2nbaI2B04EhgPRHt5SunigeqTJEmSJBWaAQltEXEScD3wFLBX7n5v4C+AoU2SJEmScgZqeuQXgQ+nlOYCdbn7T5CFNkmSJElSzkCFthlkI23w2tTIK4EPDUhvJEmSJKlADVRoWw8Mzz1+NSJm5p5XD1B/JEmSJKkgDVRouxd4d+7xb4BfA3fi9EhJkiRJ6mSgVo98P69Ni/ws8CrZKNvXB6g/kiRJklSQBmqk7a0ppQ0AKaWmlNKlKaXzgIMHqD+SJEmSVJAGKrRd10P5z7amsYgYFRE3R8T6iFgSEf+2ibofz9VZHxE3RUT11rQjSZIkSf1hoEJbbFQQMQpo28r2vks21XMS8A7goog4qpv3+CfgglydyUAp8J0tbUeSJEmS+ku/ntMWEfOBBFRExEtdXt4JuG0r2hwBnATsl1JaDzwaEVeRXT7gri7VzwB+mlJ6NLft+cAjEfGvZEGyt+1IkiRJUr/o74VILiQLRz8ALsorbwOWk60guaVmA5FSeiqv7FHgmG7q7gP8tv1JSunpiADYjWzUsVft5EYFR3UpngIwc+bMLey+JEmSJPWsX0NbSukagIh4IaW0vZb3rwTWdSmrAap6qLu2S9naXN3YgnbOJZtmKUmSJEl9akCW/E8p/SV3Qe33AZNSSh+PiN2AkpTS01vYXC0bX5R7JNkFvHtTtzpXt2gL2rkcuLpL2RRg3vz585kxY8bm+ixJkiRpB7RgwYItnp03IAuRRMTRwD+AQ4HTc8UT2brrtD0HpIjYM69sLvBEN3WfAPbN68ceZCNsz29JOymlmpTSgvwbsHgr+i5JkiRJmzRQq0d+DXh/SuntQEuu7CFg/y1tKKVUB9wCXBIRVRExh2zxkKu6qX418MGImBMRVcCXgJtSSvVb2I4kSZIk9YuBCm27pZR+mXucAFJKDcCwrWzvY7l2lgF3ABemlO6KiGkRURsR03Lv8QfgklydZWQLoPz75trZyj5JkiRJ0jYbkHPagKURMSul9GJ7QW6q4lZNMUwp1ZAt19+1fBHZ4iP5Zd+h87XZNtuOJEmSJA2UgRpp+wlwU+7C1UURcTDwY+BHA9QfSZIkSSpIAzXS9i2ypfT/j2zFxjuBK4DvDlB/JEmSJKkgDdSS/21kF9q+MCLGZ0Xp1YHoiyRJkiQVsn6fHhkRH42I70TESRFRDtwMLI+I+V2W25ckSZKkHV6/hraI+BLZCNsE4NvAjcArwAnA34Cv9md/JEmSJKnQ9ff0yFOBo1JKz0TE64BHgfEppVURcS/wTD/3R5IkSZIKWn9PjxybUnoGIKX0OFCfUlqVe74GqOjn/kiSJElSQRuoJf/bNQ/w+0uSJElSQevv6ZHlEfH/8p5XdHle1s/9kSRJkqSC1t+h7T7gqLzn93d5fl//dkeSJEmSClu/hraU0pH9+X6SJEmSNNgN9DltkiRJkqRNMLRJkiRJUgEztEmSJElSATO0SZIkSVIBG/ShLSJOioiXIqIuIn4fEZN7qDc+In4eEUsjYm1E3BsRb8p7fUZEpIiozbtd1H97IkmSJEkbG9ShLSL2BK4CzgLGAc8CN/RQvRJ4EHg9MBq4EvhNRIzqUm9cSqkyd7ugTzouSZIkSb00qEMb8H7g9pTSH1NKDcAXgIMjYlbXiimll1JK30wpLUsptaWUrgISsHc/91mSJEmSeq2/L669ve0D/K39SUppbUQsyJW/uKkNI2IfstG357q89GJEJOBPwH+mlF7pZttRwKguxVO2sO+SJEmStFmDfaStEljbpawGqNrURhFRBVwHXJpSejVXvBI4EJhONoVyBPDzHpo4F5jf5TZvi3svSZIkSZsxqEJbRJyat0jIk0AtUN2l2khg/SbaqAB+DTwCdCw0klKqTSk9lFJqSSmtAD4OHB0Ro7tp5nJgZpfbYVu/Z5IkSZLUvUE1PTKldD1wffvziPgysG/e82qyAPVEd9tHRDnwC2A58OGUUtrU27Vv1k0/ashG9PLb7sUeSJIkSdKWGVQjbd24DnhbRBydG0G7BLg/pbTR+WwRUQrcAmwA3p9Sauvy+kERsXtEFEXEWODbwJ9TSqv7fjckSZIkqXuDOrSllJ4GPky2fP8qYE/glPbXI+KKiLgi9/SNwHHAPwE1edMsT829vgtwB9nUyieARuDkftkRSZIkSerBoJoe2Z2U0v8A/9PDa2fnPf4z3Ux1zHv95/S88IgkSZIkDYhBPdImSZIkSUOdoU2SJEmSCpihTZIkSZIKmKFNkiRJkgqYoU2SJEmSCpihTZIkSZIKmKFNkiRJkgqYoU2SJEmSCpihTZIkSZIKmKFNkiRJkgqYoU2SJEmSCpihTZIkSZIKmKFNkiRJkgqYoU2SJEmSCpihTZIkSZIK2KAPbRFxUkS8FBF1EfH7iJi8iboLIqIhImpztzu3ti1JkiRJ6g+DOrRFxJ7AVcBZwDjgWeCGzWz27pRSZe529Da2JUmSJEl9qmSgO7CN3g/cnlL6I0BEfAF4JSJmpZReHMC2JEmSJGm7GNQjbcA+wGPtT1JKa4EFufKeXBMRr0bEHyJiv61pKyJGRcSM/BswZVt2RJIkSZK6M9hDWyWwtktZDVDVQ/1TgRnAdOBO4HcRMWYr2joXmN/lNm9LOi5JkiRJvTGoQltEnJq3iMiTQC1Q3aXaSGB9d9unlP6aUmpIKdWnlL4CrAaOyL28JW1dDszscjtsK3ZJkiRJkjZpUJ3TllK6Hri+/XlEfBnYN+95NVmAeqK3TeY9fqK3baWUashG4cir38u3lCRJkqTeG1Qjbd24DnhbRBwdERXAJcD93S0cEhHTIuJNEVEWEcMi4j+BnXhtWmOv25IkSZKk/jKoQ1tK6Wngw8CVwCpgT+CU9tcj4oqIuCL3tAr4AbAGWAIcCxybUlrZm7YkSZIkaSBESmnztbRZuRUk58+fP58ZM2YMcG8kSZIkFaIFCxYwc+ZMgJkppQW92WZQj7RJkiRJ0lBnaJMkSZKkAmZokyRJkqQCZmiTJEmSpAJmaJMkSZKkAmZokyRJkqQCZmiTJEmSpAJmaJMkSZKkAmZokyRJkqQCZmiTJEmSpAJmaJMkSZKkAmZokyRJkqQCZmiTJEmSpAJmaJMkSZKkAmZokyRJkqQCNuhDW0ScFBEvRURdRPw+Iib3UG9aRNR2uaWI+FTu9SMjoq3L6x/u372RJEmSpM4GdWiLiD2Bq4CzgHHAs8AN3dVNKS1KKVW234DXAW3ArXnVXsmvk1L6SR/vgiRJkiRtUslAd2AbvR+4PaX0R4CI+ALwSkTMSim9uJltTwPuSSkt6OM+SpIkSdJWG9QjbcA+wGPtT1JKa4EFufIeRUSQhbZrurw0NiKWR8T8iPjviKjsYftRETEj/wZM2Yb9kCRJkqRuDfaRtkpgbZeyGqBqM9sdCkwAbskrewbYN3c/nSzQ/TfQ3Xlt5wIXbHFvJUnSkLFq/QaeX7aWppY2mltaaWlLNLe20dLaRnFREW/cfQJjq4YNdDclDQGDKrRFxKnAD3NPFwIvANVdqo0E1m+mqdOBW1NKte0FKaXlwPLc0/kR8RngDroPbZcDV3cpmwLM28z7SpKkIeDZpTX87tGXSannOstr6jn5TbtSVVHafx2TNCQNqtCWUroeuL79eUR8mWx0rP15NTATeKKnNiKiAjgJePfm3g6IHvpRQzail9/uZpqTJElDweOLVnPn40s2W6++sYVfP7SAt86dSmlxEYtW1pJSYq+poykuGuxnqEjqT4MqtHXjOuCBiDgauA+4BLh/M4uQvBtYA9yVXxgRRwEvAYvIRs2+CvxfX3RakiQVlta2NooiNvlH2Na2xLynlvHYwlUdZWMqy9l76hhKi4OS4iJKiotobG7lzieWkBK8um4D193zfKd2Xl23gaNf1+0ViiSpW4M6tKWUns5dS+1KYCLwF+CU9tcj4opcvbPzNjsduDaljSY07EcWAkcDq8gC2/l913tJkjTQ2lLirseX8MTLawAoLy2mrKSIYaXFlJUUU1oc1De1Urehmfqmlk7TIXeqHsa7D5pJRVn3v079qYfRuCdeXs3+u4xj1Ijy7b4/koam2Di7aGvkVpCcP3/+fGbMmDHAvZEkSZvT2tbG7Y+8zIvL123xtrtOrOaf9p1CWUlxj3VeXL6OpxavZnlNA00trZQWF9HQ1ArAnlNGccy+U7e67+o/jy9cxZ+fWsao4WXMmTGWiaOGU5IbWS3Nja6WFG16lFbKt2DBAmbOnAkws7eXHxvUI22SJElbo7m1jd88tJBFK2s3XznPiPIS9ps5jv13GbfZX9JnTaxm1sTX1ktbsrqOW+57CYCnF9dQUlREcVFQVBQUR3ZfVVHK7EmjKC3u/TlvbSlR39hCfWMLFWUlW7TwSVtKbGhqpagoKCspoqgXwSOltMMElNW1G7jryaWkBKtqG7nriaXd1isuCvaYPIoj9p60RcdO6i1DmyRJGvRaWtuob2xhQ3MrxUVBeWkx5aXFnUZAWlrbWFvfRENTC/c9u4Kla+o7tt9/5jjetOdEmppbaWxpY0NTC40tbTS3tDG8vIQR5SUMLy+hZBt+IZ88ZgRTx1Xyci4oPr5odbf17n12BQfO2ok5M8Z2G6LqG1tYtqaeZWvqWFZTz4qaBlrbXps5VTmslCljR7DLhGqGl5VQ19hMfWMLdblgV9fYTN2GFuqbsuf5SouLKCspYtKYEczeeSQJqKlrpKauiZr6RtbWNVHX2EJ1RSnjqivYqXoY46qGMWHU8CGxSmZTSyvNrW0AVJSVcPeTyza5Qmi71rbEky+v4ZW1DRx3wHSqK8r6uKfa0Tg9cjtxeqQkSQPjyZdXc9cTSzsFl3ZFkZ2nVlJcRO2G5m5/AT9ot/EctNv4fhk9Wl5Tz833vtirILDXlNG8Zc5kIoKmllb++sxyFr5ay9r6pj7v59YYUV7CzqOHM35kBSXFRdkS3AFBEJGFzZdXZv0vKymmclgJe00dzexJo3o1wtcXNjS1sHhVXXZbXceq9Rs6Xisuik7fqYN2G8+S1XU0NrfmrseXaGlto7m1rVO96opSTj18t01OndWObWumRxrathNDmyRJ/eOVtQ38Y+EqqipKGVdVwW0PL+xVCOrOYXvuzP67jNu+HdyMV9Y2sLymnra2RFvKpii25S7M/fTiNdTljX7NnTGWw/famXueWsajC1b12OawsmJGlJWwrqG5Y6Sot4aVFtOWEk0tW7bd9jKivISqijJGDCthwsiKjuC3JaEn5fq/obmVhqYWNjS1MnJ4GaMrN17spXZDM4+8tJJFK2tZmRfSNmXf6WM5cp9JPb7++KLV3P3EEtqz2+umjXGFUPXIc9okSdKg19rWxqr1jdQ3ttDY0toxZbGpuZWa+iaeX7a22+3KS4upHFZKa1sbTS1tNDa3bjT6Vl1RyohhpQwvL2GvKaPZZUJ1t231pfEjKxg/sqLb1w7abTx3PrGEpxfXAPDoglWUFhd1mkpZXBSMz4WbnUcNZ+cxwxlRnk1NbEuJV9Y2MH/F+o7z9fKnd44YVsqI3PMRw0qpKCuhuCgb5UopC45r65t4dkkNS1bXM6y0iJEjyhk1ooxRw7P7EcNKqalrZOW6Dby6bgOvrG3glbUNWxwW29Xlpm4CHYvCRMC4qmFMHDU828/Rwxk5vKzTaOjymnrufXYFK9c1sKG5tdvgPmOnSqaMrWRdQxPFRdnUz0fmr+wxoEZkITYl2NCcLRozangZB+8+YZP78Lpp2WUffvfoYiALcbMmVjN9p6ot/jyk7jjStp040iZJ0tZJKfH8srW8vLKWFWsbWLV+A93MdNykirJi3nfobhudV9XS2kZjS2vHuWmDYcpaW0rc/vAiXuhmVcsJIys46Y27FNzFudtSYtX6DSyvaWBNbSNtKUGCROoIU8VF0TGK1tqWeGH5Wh6dv6ojHG1OUUBJcVFuamUpy2vqN7/RZkTAhJHDmTJ2BFPGjmDn0cM7viMbmltZV9/EqBFlvfrepJS47eFFHcGzuqKUM47afYdZtEW950ibJEkadJ5avIY//qP7a5r1ZPpOlayubWR9QzPFRcE7Xj+924Uw2i94zSC6JFpRBMfuN5Wb732JV9Y2dHrt4NkTCi6wQdbnnaor2Km6+xHE7oytGsYBs3aipq6JDU2t1NQ3smxNPcvX1LOqtnGj+m0JmlqyUdTaDc0bvV5anF1fb1hZdg7jsjU9h7qRw8s4dI+JTNupssdANqy0mGE9jIh2JyI4ep/JLF6Vnfe2rqGZZWvqmTRmRK/bkHpiaJMkSQPq8YUbr6I4cnhZxwhHeUkRZbmLXpeXFDNx1HAmjh5Oa1sbS1bVMXJEOSOHD63V+oqLinj7/tO4Yd7zHVP5JoysYPpOlQPcs+2ruKiIsVXDAJg8dgR7Tx0DQGNzKytq6llWk4W45TUN3Y7IzdipkkP33JmRw8s2WtlzTW0jT768mubWNkYOL+9YPXRs1TDmTB+zTSuB9mR4eQm7TqzmydzF2p9fttbQpu3C0CZJkgZMTV0jK3KjSRFwwgEzmDh6OMNKNz8drbioiGlD+JyhkcPLOGbfqdz+yCIADt9r5x1mql15aTHTdqrqOL4pJVrbslt9Ywtr65sYXl7CTtXDevxMRleWc+ieO/dntwGYvfPITqFtRzpu6juGNkmSNGCeW/raoiIzdqpixvihG8K2xqyJ1Xwwd17U8PId99e2iKCkOCgpzgJdd6tCFoop4yoZVlrMhuZW6nLX1HO0Tdtqx/3plyRJ/S6lxPxX1vP3F1+lLSWW17x2ztbuk0cNXMcK2Ihhg/+i1TuSoghmOUVS25mhTZIk9Yslq+v46zPLu10goqQ4mOkom4aI/CmSLyxf5xRJbTND23Z22rfvpGL0pq/lAfC2/aZy7nFzOpVd/pt/cPsjL/fqfd5/+G584IjZncr+340P8sDzr/Rq+3Pe8Trevv+0TmUf+/G8bpcX7s5F7z2Ag2d33s/3feuPrO5mtafufPcjh7LbziM7lb31ktt6tS3ADee+uePEZYBV6zdwyuV/6vX2v/viOzo9f37ZWj5+5V96te2YynJ+/h9v6VR2/3MruOCmh3q1/a4Tq/nemYd1Kvvtw4v479se79X2B+02notPPrBT2bV/fo7r7nm+V9v73fO7l8/vnt+93tjW796M8VW8ff9pLHhlfUfZopW1PLGo8wIkv3pwYbfb+93zu5dvMP27N3XsCF43fWynKZJ+9/zuNaxZ0as28hXemrGSJGlIWb1+Q6fAVhQwxeli2oH0dEF4qbccaZMkaQfQ2pYoLgqaWlp5eWUtL63o3V/aIbtw8uOLVrO+vomioqC0uIj5K9ZvfsNu7DF5FAfPnsBfn1nOHY/2brRBGuycIqltFan9MvWDUETsDPwQOBCYyGauKh4Ro4AfAW8D1gFfTil9P+/1I4DvAbsA/wA+nFJ6spd9mQHMnz9/PjNmzNiKvZEkaeu0tiXWNzRRU9fE2vomVq5rYP4r66lrbOmoU11Rypv2mMi8p5d3e2Hi7aG4KJg0ZgRLV9fR2tb594uZ46t44+4TGVc9rIetpaGltS1x5R+f7ri+3EmH7OKCJAJgwYIFzJw5EzaTXfIN9pG2NuAO4CvAvb2o/12yfZ4EzAL+EBFPp5TuioixwC+BjwG3AOcCv4yIPVJKLT01KEnSpjy6YCXPLV3LhqZWNjS30NqWaP97aSIxrqqCQ/eYyOSxvftlLhspq2NFTT0r1jZQU9fI+g3NbO5vsOsamnt9Hs3WqCgr7rjG2praRu56cil1G5qZOb6K3SePYqfqij57b6kQFRd1XkXyzseXUFlRSnNrGy2tiZbWNoqLgjfuPtFLXWizBvVIW7uIKAGa2URajYgRwGpgv5TSU7myrwGTUkofiIgzgTNTSm/IvVYELAY+kFLa7BmPjrRJkroz7+llPPzSys3WmzAyCzWtbYmWtjZa2xJtbYmRI8rYZXw1bSmxbE09i1bWbjSK1ZPy0mJGDS9jdW0jza1tHeVlJUXsMqGaogiKi4KiCCKgqCgojqChqYVFK2tZ19BMcVF2fbDxIysYVzWMtpRobU00t2Z9bG5tY0R5CXNnjmPk8LKt+5CkIWrhq+v5xd8WbLLOsNJizjhqd8p7cUF5DQ074kjblphNFlKfyit7FDgm93gf4LH2F1JKbRHxeK68U2jLTbMc1aX96QCLFy/enn2WJA1yq1esZNWKzYe2VZtYTOzxpzf/PsPLSqgaXkr1sDKqKkqZMKqCCaMqKIpgTW0rf/zHYtZvaKZyWCmHz5nC6MrWnhsbBrOqh9HaVk5xUfs5OAlo6GGDJta8spQ1m++mtENpbUu0rn+VmvqmTda77Z469p+1Uz/1SgMtLy/0OqnvSKGtkuw8tnw1QFXe613/v8l/Pd+5wAXdvclhhx3WXbEkSQXjswPdAUkSwM7Ai72pOKhCW0ScSrbwCMDClNLeW7B5LVDdpWwksL6Xr+e7HLi6S1kZ2QImzwOb+POltsAUYB5wGNlUVYD5wMwB65HybY9j0d0x1pYZDD8TO8pxHgzHoi8U4vHdUY9FX9naY+xxKBz5x6IQf2Z3JPOBXckC24O93WhQhbaU0vXA9Vu5+XNAiog9U0rtE03mAk/kHj8BfKS9cmRrss4B/qubftSQjcJ19x7aTvKWxV3cPt83Iujt3F/1re1xLLo7xtoyg+FnYkc5zoPhWPSFQjy+O+qx6Ctbe4w9DoUj/1gU4s/sjiR3LF6klyNs7Qb9xbUjYhhQnntaHhHDopuLYKSU6shWhbwkIqoiYg7wIeCqXJX/BXaPiPdFRDnwaaAe+HOf74QkSZIk9WDQhzays6Jrc4+fyT2fDhARn4+I2/PqfozsTOplZJcKuDCldBdASmkV8C7gC2SjaO8B3uly/wXnooHugDp4LAqDx6FweCwKh8eiMHgcCofHonBs1bEYEkv+a2hqv4wCW7AcqgYXj/GOweM8tHl8hz6P8dDi8RychsJIm4auGrK/RtQMbDfUh2rwGO8IavA4D2U1eHyHuho8xkNJDR7PQceRNkmSJEkqYI60SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmSJElSATO0SZIkSVIBM7RJkiRJUgEztEmStklEzIiIFBEzcs/PiIgFea9fERFXDFT/eiMiro6Iq7exjc9HxO15z++OiAvzntdGxGHb8h49vO8HI+KX27vdgRIRCyLijE28/s6IuKsfuyRJA87QJkk7uFy4aMqFinUR8WREnLm92k8pnZ1SOnt7tVcIugYygJTSpSmlt/W0TUqpMqU0L7f9kRGRtkM/KoCvAud3KT8iIubljunqQgx1XcN+b6WUfglURsS7+6ZnklR4DG2SJIBLU0qVwCjgIuCHEXH4wHZJvfB+4MWU0hPtBbnj9ivgCmAnYCLw5YHpXp/5MfAfA90JSeovhjZJUoeUUltK6WZgNfCG9vLclLRHImJtRDwVER/ubZtdpx7mpr+dHxG3R8T6iHg+It7ZZZvPRMSiiKiJiJ9GxM97mr4YEW+PiDURMSyvLCJifkR8KPd8TERcFRFLI+KViLg1IqZsos+XRMQLuZGqhbnnRbnXrgAOAz6fe315rvzCiLh7E22m3AjbNOD2XFlt7vaJiLgxIn7UZZs35z6jqh6a/Wfgd13Kvgr8KKV0fUqpIaXUlFL6W0/9yr3P1RFxQ0T8OPeZL4uI90fEnIh4INeHP0fE5LxtNvmZ5tq8PiK+GxGrImJ5l9HJJ9vvc5/BN/Jem7yp7wfwe+DQiNhpU/slSUOFoU2S1CEiSiLiFGAs8Gyu7GDgZrIRuDHA2cA3I+Kft+GtzgQ+D4wEfgT8LCIqc+93KvBZ4CRgHPBn4D2baOt3QB1wYl7Zm3P7cFPu+XXAZGAOMAuoB34VEcU9tPkscCRQlXvvfwU+DNl0T2AeudHJlNLE3u50bvtFwNtyjytzt28DPwDe1/455JwFXJ9SWt9Dc/sD+aNsI4CDco8fyoWl+yLizb3o2j8Dvyb73C4Cfkg2QvceYEKuzpfy6vfmMz2R7PiNzz0+P147r2/v9vvcZ/CpvO16/H4ApJQWkB3z1/divyRp0DO0SZIAzouIGmADcC3w+ZTSr3OvfRD4ZUrpFyml1pTSPWTT087ahvf7UUrpkZRSG1lYqQZ2z712Ru71B1JKLSmlq4G/99RQSqkVuJpcqMr5MHBTSqkuInYmC0n/kVJamQtAHwf2BQ7soc3rUkqLU+ZB4HrgLVu/u5uXUvozsAg4BSA3ivQusvDUk9HA2i7Pi8imTZ5JNjXyKuDXEbHLZrrw55TSr3Kf58+A4cANKaWXU0r1wK3AAbm+9fYzvSel9D+5781fgcfIG8HdhE19P9qtI/sjgiQNeYY2SRLAV1NKo8h+6f8p8JaIKMm9NhV4qUv9F4Bp2/B+S9sfpJRqcw/bpwBOARZ0qd/1eVdXAUdExC4RMRp4N3Bl7rWpufuOfUgprQVepYd9iIh/jYhHc9Mua4CPko0W9bUryMIWwOnAYymlRzZRfzXZaFS79hG5q3Khpzml9GNgPvBW6DQlszYiPp+37bL2B7mQ1qmMbCSt/Rj19jNdSme1eW1syqa+H+2qyfZfkoY8Q5skqUNuxORjwMzcPcDLuef5ZpGNCvWFxcCMLmXTN7VBSukl4G6yUcFTgedTSg/kXn45d9+xDxFRTTb1cqN9iIg3ApcDnwB2yoXZHwKRV62tNzuyCT1t/zNgr4jYjyy8bWqUDbIRyPZphu3B6SWg68qUKa9OZd7t0i3ueWaLPtMebPVnGBHTgRFsYgRWkoYSQ5skqZOUUiNwMfCF3C/iVwPviojjI6I4Ig4lCxRXbqKZbXEN8JGIODB3jt1p9O7cpSvJplZ+BPhJe2FKaRlwB9l5eONy50Z9h2whjAe7aWck0Eo2atSaOwfr1C51lgOzt2ivNt6eiOg05S8Xum7I7ctE4MbNtPO/5EbQ8nwP+FBEvC53vD5IFoJv77rx1tqKz7Q7r5IFt67THnvjGOCvKaVXt2JbSRp0DG2SpO5cSzb17D9TSvcB7wMuAdaQBYrPpJRu6aP3vh74JlkgWQkcRbaE/YbNbPd/ZKMve5ItkpHv/cAK4HGyqYJVwPG587e6+h1Z6Psr2WfwiVyf8n0D2Ce30uLi3u3Wa1JKz5GFnL/k2vh43stXkC0wcl1KqW4zTd0AzIqIffLKvpVr43dkx+ss4B25xTu2py35TDeSUmogW2zkmtxncNkWvPdHyEZDJWmHEClt87U9JUnqUxHxEHBrSukrA92XvhYR48hG4l6fUnqsF/U/CLwrpdR1WfwhKSJOAD6ZUjpyoPsiSf3F0CZJKjgRcTLwS7JzsT4K/BewV0rphQHtWB/LLZf/X8B+KaWjBro/kqTCULL5KpIk9buP8triH88B79wBAttcsimZL5NdM02SJMCRNkmSJEkqaC5EIkmSJEkFzOmR20lElAMHkl2ItFcrZ0mSJEna4RQDOwMP5i6zs1mGtu3nQGDeQHdCkiRJ0qBwGPCX3lQ0tG0/ywDmzZvHlClTBrovkiRJkgrQ4sWLOeywwyCXH3rD0Lb9tAJMmTKFGTNmDHBXJEmSJBW4Xp9S5UIkkiRJklTADG2SJEmSVMAMbZIkSZJUwAxtkiRJklTAXIhEkiRJUuFqqIUVCyElKC6BMRNhxEiIGOie9RtDmyRJkqTC8/KzcP+v4al7oaW582tlw2DsJBizc3abNAv2PDgLdUPQ0NwrSZIkSYVh3Wp45gFoacrC1/KXYNVSGFYJVWOgegxUjs4eD6/KRtYen5eFtZ40bYBlL2W3djP2hpM/D6Xl0LA+C3DFJVBcmt0XFQ3a0TlDmyRJkqS+8Y974Nffhw1129bO+GkwvBqaGmD1MthQv3GdBU/Ctz6SBbqUNn59vzfDP5+7bf0YIEMitEXEKOBHwNuAdcCXU0rf76be6cAngN2A9cBNwHkppabc61cDpwBNeZuNTSk19mX/JUmSpCHn9ivh3l9uWxuvOwwOew/svMtrZSlB/TpYtSwLcEuehwd+k5U3NvTcVknptvVlAA2J0AZ8l2xfJgGzgD9ExNMppbu61BsOnAv8DRgD/Ar4PHBhXp1vppTO6+sOS5IkSUPWg3d0DmxjJsLub8gej5sCE6ZnAWv9aqhdk92vXwMbal+bNrnf0TB5t43bjsgWIhkxEqbtAXOPgl3mwC3fyEbZIrLplm2t0NoCrc3ZtMxiQ9uAiYgRwEnAfiml9cCjEXEV8CGgU2hLKf0g7+myiLgWOL7fOitJkiQNFWtXwmN3Z0GrrQ1SWzba1doCf//9a/X2OAhO/CQMG953fdnzYPjklVDzKuw0JVuopKvupkwOEoM+tAGzgUgpPZVX9ihwTC+2PRx4skvZWRFxFrAA+GpK6eauG+WmY47qUjyld92VJEmSBqGU4OVnshGylUvgT9duejoiZNMaT/pPKCvv+/61j771ZJAuQgJDI7RVkp3Hlq8GqNrURhFxGnAoMDev+NvAp4C1ZKHv5ohYnlK6p8vm5wIXbHWPJUmSpMHm1z+AB2/vff3hVfC+8/snsA1xQyG01QLVXcpGki000q2IOAH4OnBMSml5e3lK6eG8ar+NiOuAE4Guoe1y4OouZVOAeVvScUmSJGlQ+Mc93Qe2cZOzVRmLiiFyS+pHUbbE/m6vh9Hj+7+vQ9BQCG3PASki9kwpPZ0rmws80V3liDgWuAo4LqX06Gba7nbia0qphmw0L7/dXndYkiRJKngrl8ADt2XXPHv2b6+V7zQVqkbDLvvCG98FpWUD1sUdxaAPbSmluoi4BbgkIj4IzCRbhOS9XetGxNHA9cA/p5Tu7+b19wB3APXAW4D3A+/sw+5LkiRJhSWlbFTtjp9Ac1Pn18ZMhLO+3reLimgjgz605XwM+DGwjOz8tgtTSndFxDTgKWCvlNIi4ItkUydvyxsZW5hS2jv3+BzgJ0AA84EzU0p39t9uSJIkSQNo3Wr4xbfh+b9v/FpxSbaoiIGt3w2J0JabrnhSN+WLyBYqaX9+1GbaOWy7d06SJEkaDJ68F371XajPWxpi/LRsCmRrC0zbEybOGKje7dCGRGiTJEmS1EutrfDMA7BqSe7i0y3Z+WtP/rVzvTe+C97yAc9ZKwCGNkmSJGlHsW41/M9/wYJu1+zLjBwH//wfsMuc/uuXNsnQJkmSJA0FjQ3Z4iErFgIJ2tqyRUVI2X1jA6xftfHiIvnmHAHHnQ0VlT3XUb8ztEmSJEmDXUpwyzeyaY+9EQGvPwYqR2fXWCsugam7w8zX9W0/tVUMbZIkSdJgd/dNvQ9sY3aGd/27AW0QMbRJkiRJg1VK8Nf/gzuvf63sDW+HuUdnj4uKgMhG1krLYcTIbOrja5e/0iBgaJMkSZIGo7Y2+OV34OE/vla2yxx4+1lQXDxw/dJ2VzTQHZAkSZK0FR74TefANn0veO95BrYhyJE2SZIkabCpWwd33vDa87lHwzs/DiWlA9cn9RlDmyRJklQoljwPzz4I9euhuRHKK6BsGJRV5B7nnj91L2yoy7ZpX1ik2F/thyqPrCRJklQI1rwCPzlv09dR686xHzawDXGe0yZJkiQVgsfv2fLANmsu7PGGPumOCoeRXJIkSSoET/71tccHHgs7z8qmSDY2QFPDxvfDq+FtZ7p8/w7A0CZJkiQNtDUrYOkL2ePiEvinM6BixIB2SYXD6ZGSJEnSQHvy3tcez5prYFMnhjZJkiRpIDVtyM5na7f3mwauLypITo+UJEmSBkJK8Nsfw4O3Q2tLVlZUDHscNLD9UsExtEmSJEkD4eVn4f5fdy6bfQAMrxqY/qhgGdokSZKkgZC/WuSo8fC6w+FN7x64/qhgGdokSZKk/pYSPJW3+Mjx/wazXz9w/VFBcyESSZIkqb8tfRFqXskeDxsBs/Yd2P6ooDnSJkmSJPWVdavg+YehtByqx2a3qjGdR9l2f0N2bTapB347JEmSpL7Q2go/PR9WLtn4tYjXHu/9xv7rkwYlp0dKkiRJfeGVhd0HNsjOaQMoGwa77t9/fdKg5EibJEmS1BeWvvja45HjsqmR61bB+tXQ1paVH/rPUFo2MP3ToDEkQltEjAJ+BLwNWAd8OaX0/W7qnQ58AtgNWA/cBJyXUmrKvV4GfAd4L9AM/CCl9P/6Yx8kSZI0xCx94bXHB74NjviX7HFbG9StzaZIVo4akK5pcBkq0yO/SxZAJwHvAC6KiKO6qTccOBfYCTgAOAz4fN7r/w+YA+wKHAicEhEf7LtuS5IkacjKD207z3rtcVERVI02sKnXBv1IW0SMAE4C9ksprQcejYirgA8Bd+XXTSn9IO/psoi4Fjg+r+yDwJkppZXAyoj4Rq6dn/blPkiSJGmIaW2B5fNfez5514Hriwa9QR/agNlApJSeyit7FDimF9seDjwJEBGjyUbqHuvSzqVdN8pNxxzVpXhKL/srSZKkoe6Vl6GlOXs8chyMGDmw/dGgNhRCWyXZeWz5aoCqTW0UEacBhwJz89oBWNuLds4FLtiiXkqSJGnHkT81cpKjbNo2Q+GctlqgukvZSLKFRroVEScAXweOTSktz2uHLm311M7lwMwut8O2tOOSJEkaogxt2o6Gwkjbc0CKiD1TSk/nyuYCT3RXOSKOBa4CjkspPdpenlJaExFLgX2BpZtqJ6VUQzYKl9/uNuyCJEmShpRlecv9G9q0jQb9SFtKqQ64BbgkIqoiYg7Z4iFXda0bEUcD1wMnppTu76a5q4EvRMS4iJgOfLK7diRJkqQetba6CIm2q0Ef2nI+BiRgGXAHcGFK6a6ImBYRtRExLVfvi2RTHm/LlddGxJN57VxENrL2IvB34KaUkitHSpIkqfdefRmam7LHLkKi7WAoTI9sn654Ujfli3htgRFSSt1duy2/fhPw0dxNkiRJ2nKez6btbKiMtEmSJEmFwdCm7czQJkmSJG1PhjZtZ4Y2SZIkaXtxERL1AUObJEmStL24CIn6gKFNkiRJ2l7yr8+286yB64eGlCGxemQhOe3bd1IxesJm671tv6mce9ycTmWX/+Yf3P7Iy716n/cfvhsfOGJ2p7L/d+ODPPD8K73a/px3vI637z+tU9nHfjyPF5av69X2F733AA6e3Xk/3/etP7K6trFX23/3I4ey286d//L01ktu69W2ADec+2bGVg3reL5q/QZOufxPvd7+d198R6fnzy9by8ev/Euvth1TWc7P/+Mtncruf24FF9z0UK+233ViNd8787BOZb99eBH/fdvjvdr+oN3Gc/HJB3Yqu/bPz3HdPc/3anu/e3738vnd87vXG373/O753XtNr757ZWcD8La6Js7t8pLfPb97DWtW9KqNfIY2SZIkqS84NRKAlBIrV65k8eLFW7Td888/z0utG6irq6OhoYG1G1qB6PX2L774Im1tbYwdO5bRo0dvYa8Li6FNkiRJ6gvDqwe6BwOuubmZv/zlLyxfvjxX0vvP5Mknn2R4Sep4Xt8SQFWvt//b3/7W8bi0tJTikTv3ettCEymlzdfSZkXEDGD+/PnzmTFjxgD3RpIkSf3uvl/Db3+UPd5pKnzi+wPbnwHW0NDA3XffTU1NzUB3BYDp06fzxje+caC7wYIFC5g5cybAzJTSgt5s40ibJEmStK1Sgvt//drzg48buL4UgPXr13PXXXdRV1fXUTZjxgymTZvGqFGjKCkpoaamhjVr1rB69WpWr17N+vXrASgpKWHs2LFUV1dTWVnJiBEjGD58OCUlJRQXF1NcXExRUVHHfUQwf/58/vGPf9DQ0ABARUUFY8aMobi4mFdffZWGhgbGjx8/IJ/F9mBokySpP6UELc3ZrbUZ6tbC2pXQ1ADNjdlS4S1N2eOW5tfuR4yE0ROg5hVYuRjGToa5R8PowftLiDSkPPsgrF6WPR42Ivv5HIJSSrS1tZFSYs2aNaxZs4bm5mZaW1tpa2vruH/55ZdpbMwWLIkI3vCGN7DLLrt0amvChAlMmPDaQifNzc1s2LCBESNGUFS0ZYvc77LLLsycOZPGxkbKyso6bZ9Sora2lrKysm3Y84FlaJMkqS898Rd4/uHs2k2vvgwb6ja/TW/deX0W5KrGQOXo7L5qdN7z0UBAcQnsNAWi9yfwS9oCKcG9v3jt+QFvhbJhPVYfrObPn8+DDz5Ia2trr7cpLi7mTW96E5MnT95s3dLSUkpLS7e6fxHBsGEbf+4RQVVV78+FK0SGNkmS+tJLj8HDf+i79tesyG6bM2kWnPx5R+akvvDonTA/dxmBCHjDOzZdfxBau3btFge2srIyjjjiCMaNG9eHPdsxGNokSepLO03duKykNLsVl0JFJVSPhYoqKCmD0rLcfflrj4tLYN2qbGrkiJEwbgo8/3d44eHsL/y9sfRFuOJcOPDtMHJc1k77bXh11g9H4qTeSQkaG6CxPvvZbF98BOCg44bUH0fa2tpobGzkvvvu6xTYioqKGDFiBOPGjWPYsGGdzjMrLi6mpKSESZMmUV5ePoC9HzoMbf2koaGBdevWbdFfJ6T+UF5ezpgxYwh/WZP6xqy58PYzYfy0LMBVjdk+4eiQ46FpQ/YL4/rVsH4N1K557fH61VC/Nqv76mJobYH69fDnm7pvr6goC48HnwBvfCcsfAqWvZgFxOl7DcmpXlKvpQQP3g73/Sr72Wps6L7e2EnwT6f3b9/6SGtrK08++STPPvssLS0tHeVFRUW89a1vZdSoUQPXuR2Qoa0fNDQ0sHbtWsaMGUNpaam/HKtgtJ9EvH79eqqrvZaM1CfGT8tufaFsGIybnN02ZdEzcOOlWZjrSVsb1LwKd/wE/vbb1xZUgCxkVo+FMTvD7ANh7zcNqZEEaSMpZX8QefVlqF8HT94LT9276W0i4J/PhbLBP7K0dOlSHnrooU4rP7abM2eOgW0AeJ227WRT12lbsWIFo0ePHtQr1mjoamlpYeXKlUycOHGguyKpL9Wvh6fvz85/W78K6tZlI3F167JfSrd0gZQps2HvQw1wGnyWvAB//T9YtzK3imtLtpJra0t2a1+1tWnDptspGwblw2HYcBhWCQe+DfYb3CtG1tfX8/e//53Fixd3Ki8rK6O8vJzJkyczd+5cByC2kddpK1Ctra3btBKO1JeKi4tpa2sb6G5I6mvDq+D1/9Tz681N8Mefwb2/zJ5HZKNqNStgxcKN6y9+Lrv97iqYunu28MLrDsvOv5O2p5Rg9fLsjwtFRdkfHl5+NjufrP28zMpRufMzc88rKmHRU9kfKpobs2nJpeWw9lV46He9Pxe0q4PeAUefmi3pv4VL0hea1tZW6urqaGxspLGxkZqaGp5++ulOUyHLysrYd999mTVrlkFtgA34v6wRMT2l1M3/BkOLX3QVKr+bkoBs0ZO3fQR2e3224uXeb4LJu2WvNTdloxKLnobH58GLj0Jb3jnaLz+b3e74SXZOz+gJMHNO1lb1mAHZHQ0STY3ZHwZGjc9CVc0r8Mqi7A8FryyCVxdlUxSbm/q/b8OGw/jpry0UtNchsOt+/d+PPvDiiy/yyCOP0Nzc3GOdmTNnMnfu3G6X0Ff/G/DQBrwQEX8ArgB+k1LyT/6DwN13383JJ5/M8uXLt2r7s88+mwkTJnDRRRdt1Nbee+/Nf//3f/OWt7xle3ZZktQbu+638S+mpWVZGBs7CfZ7czbV8pkHsmvQ5Qe4urXZbdHT8Njd2S/h7/0s7H5gf++FBkpK2bmRba1QVJyNRkVRdl9cmgWhCGhthb/dBn+8NpuGGJGtqNpf4WyXOXD4SVBW8dpKrsUlucclnfs6hDQ1NfHoo4/y4osv9lhn5MiRHHDAAYwf77TnQlIIoW1P4EzgR0BLRPwEuDKl9PLAdmvHcOyxx7Lffvvxla98pVP5X/7yF4499liWL19OZWXlNr3H1VdfzRVXXMH999/fUXbFFVf0WP/JJ5/seHzhhRfyzDPPcOONN25THyRJ29HwKtj/Ldmtbl22qt79v84CW77mRvjFt+ETV0DFiIHpq/rWgiezAD9uSvZ83v9kUxl7EpGF+ebGzlMUU9p0YBsxEkbulD0eNiKbkls9Nvv+1a2FuprsvrYmm0ZZvy6bMrn3odlCQLVrsnPVImDybNjjDUMukAHU1dVx7733UltbS0lJScfFqktLSykuLmbp0qWdpj+Wl5czYsQIhg0bRnl5OePGjWOXXXahaJBP/RyKBjy0pZReAD4bEecD7yILcOdFxO+AH6aUbhvI/g11Z5xxBp/5zGf48pe/3OkH9JprruE973nPNgc2SdIQN6IajnwvHPaebJrbutWw5LlsoYfamuz255vg2A9lv5TnX5Zg1E6vTcHU9lG/Hpa+kH3uTRuy0a7yiuxW1s19admWh5eUsuM375YsrG/ptl0X+BheBQ212WvDq7IpieOnwYTpsFNu9dURW7jCcUpDMpRtyoYNG7jrrrtYv359r+pPmzaNgw46iJKSAY8D6oWCOUoppZaI+F+gBdgJeCtwcETUAB9KKf1lIPs3VL3rXe/iX//1X7nrrrt485vfDGSXKLj55pu59tpr+dCHPsRtt91GaWkpJ598Mpdeemm3q2Bedtll/PCHP+SVV15h6tSpfPWrX+WEE07g6aef5uyzz6a5ubkjAK5du5YPf/jDTJw4ka9+9asbtTVjxoyOkbhLL72UlBKVlZVMnjyZL3/5y1x88cX84x//6Kj/ox/9iOuvv54///nPffERSZJ6o7j4tSmUM/eB6nHwP/+VvXbvL+Dvv+9+hcpTzoc9D+7Xrg4qKcHzD2cLaFSOzlYs7BpGWltgwRPw7N+6XzRmUyKyFRBHjMwW66ganb1PUXE2xbGxHjbUw4ba3H1dturohvqe2yyvyC7YntqyS0m0tWb3LU2dA9vw6uyagIf+c/Z6c+P2u8j7DhbY1q5dy3333derwFZdXc3ee+/N9OnTPa99ECmI0BYR08lG2D4INJFNlXwbsAr4OHAdMGOg+jeUDRs2jPe+971cc801HaHtF7/4BWPGjOHWW29l5cqVPPfcc9TX13PCCSfwla98hQsuuGCjdmbNmsW8efOYOHEiN954I6eccgovvvgie+65J1dcccVG0yN749hjj+Xzn/98p+mRjY2NfPSjH+Wxxx5j3333BeDaa6/ljDPO2LYPQpK0fb3usOycpYVPZcGjp0sK/OV/DW3dSQmWL4Df/CA7R7Av32dDXXZbtXTr2pg1NwuTdWuzxWcOPj47H6w7rS3Z4iNl5Z1XGi0mG/XTFmlqauKRRx7hpZde6lR+8MEHM3bsWJqbmzvdhg8fzoQJEwxrg9CAh7bcNMijgN8DHwVuS50vHnd5RFwyIJ3rK188vv/e65LNT1s444wzeMtb3sL3v/99Kisrueaaa3j/+9/PZZddxoMPPsjIkSMZOXIkF1xwAeeee263oe3EE0/seHzKKadw6aWX8tBDD/GOd7xju+5OeXk5J598Mtdeey377rsv8+fP5+GHH+a225xFK0kFJQKO+1f4yXmvBbaiomwUp2oMLHspG4FZ9HQWFsZOGtj+DrTW1uxzWvBEtkz9gsdh7cotb6eoGCbNyi6EXl6RhaTGBmhq6Hzf/ril59UDN6m8Ipu2eODbYO7RvR/ZKi6BigH/9bOgNTU1sW7dOoqLiykqKiKlREqJtra2jscpJZqamnj44Yc3ugD2gQce2H4NMA0hhfBT8zDw0c1cWG5aP/Vlh3TwwQczdepUbr31Vv7pn/6JP/3pT1x00UV86UtfYvr06R31ZsyYwZIlS7pt4+qrr+Zb3/oWCxdm0zJqa2tZuXIr/rPphTPOOIN3vvOdfO1rX+P666/nhBNOoLp6C+e6S5L63sQZ8Mkrs/BRNTqbDtf+y/31X8oWsAB45E/wlg8MWDf7VUpw18+zVTfbR7g21G36Qs7FJdloZHNjduvOqAmwx0G5Ua/y3venPdTV1uTONVydPSZlqz62Xzy6ojJbAKQ89zj/WGq7WbduHX/605/YsGEzF/buxs4778ycOXMYM8bLbAxFhRDaSroLbBHx1ZTSeQAppTWbaiAiRvHalMp1wJdTSt/vpt4+wDeAA4AxKaXo8vrVwClkUzTbjU0p9fAv5NBx+umn87Of/YwVK1ZwyCGHcMABB1BWVsbChQuZM2cOkF29ffLkyRttu3DhQs466yzuvPNODjnkEIqLi9lnn31oHzDdliH47rY98MADGTNmDH/84x+57rrr+OY3v7nV7UuS+lhFZXbrav+3vBbaHr0zu2DxjrBi3TMPZKGtN8qGwS77wj+dDuOn9k1/ikuyxT+GV/Xde6hHzc3NvPjii6xbt46RI0fyzDPPbHFgKykp4aCDDmLaNMc4hrJCCG0fBf6zm/KzgPN62cZ3yfZlEjAL+ENEPJ1SuqtLvWbgZuD7wC96aOub7WGxz/RiymJ/+8AHPsAXv/hFnn/+eS644AKKi4s5+eSTOf/887nuuutoaGjg4osv5v3vf/9G29bV1RER7LRTthTvlVdeyTPPPNPx+oQJE1iyZAmNjY2Ul2/BX/9y295+++20tbV1Wt3y9NNP5zOf+Qw1NTW89a1v3cq9liQNmNkHZKM19euykbj/Phtm7ANvevfQDg/tQbWr9gVBRu0Eu78hG1mbuEu2wIsGtZdffpn58+fT2tra8Qft9vuamhqamja+1EFxcTFVVVW0trZSVFRERHTc8p9XVlay1157UVVV1a/7pP43YKEtItr/HFAUEVOB/CGV3YFejW5FxAjgJGC/lNJ64NGIuAr4ENAptKWUngWejYhdt7X/Q83kyZN585vfzLx58/iXf/kXAL797W9zzjnnMHv27I4Q97nPfW6jbffaay8+9alPcfDBB1NSUsLpp5/OQQcd1PH60Ucfzb777svOO+9MW1sbq1at6nW/TjrpJK677jrGjh3LpEmTOq7h9oEPfIDPfe5zfOITn6DY/9AkafApLoF9j4T7fpU9X70suz3yx2yK386zYKcp2blZY3bOrrk12Kfjta8E2e69n4Upu782BXGw7586SSnxj3/8g6eeemqLtisqKuLwww9n4sSJfdQzDUbRec2PfnzjiDaguzcPoBX4fErpv3rRzn7AAymlsryy9wGfSSnt18M2uwLP9zA98oTc0wXAV1NKN3ez/ShgVJfiKcC8+fPnM2PGjE4vLF26lEmTdvATrLezpqYmJkyYwF133cXcuXMHujuDnt9RSQOibi3c9LVshcm21k3XLRv2WoAbOym7n30AVG/B+Tv3/QruvhH2fhMc/2/9H5KWL4Dv/Xv2uKISzrt+x5gSugNqaWnh/vvv5+WXX95s3crKSqZPn86aNWvYsGEDc+bMYeedd+6HXmqgLFiwoH2xmJmbWdejw0BOj5xJFtCeAPbOK28DXk0p9XZCbyXZeWz5aoCtGSf+NvApYC1wDHBzRCxPKd3Tpd65wMZLKKrf/PjHP2b27NkGNkkazEaMhA9dml10e3HugtzP/q37uk0bYPn87NautBw+cGF2XbjNeexu+O2Ps8cP3gGvOxxmvm5b92DTGuqy6Z9jc7+Av5A3yjZrroFtiFq7di1//etfWbt2bUfZpEmTmD17NvDa+foRQUlJCaNHj+50CojUnQELbSml9qs/dnN28hapBbouHTgS6N3l4Dv3Ke9fU34bEdcBJwJdQ9vlwNVdyqYA87b0PbXlZsyYQWtrK7fccstAd0WStD2UlmXBa+Y+sGoZLHkeXlkEq5dmz1cv7f5izs2NcMOXsuA3bsrG1/lqaoRlL2aXFbjz+s6v3f+b3oe21pYsLLa2QFkFTJi++VG6VUuzyx2sXwMHHQfvOAue//trr+/2+t69twpGSomWlpaOpffby9rL161bx8svv8yCBQs6bbfbbrux//77G8y0TQYktEXE+1JKP889Pq2neimln/WiueeAFBF7ppTarz45l2wEb1t1O3c0pVRDNprXwYsU9p+u/xhKkoaQsTu/NjLVLiWoX5+d87ZqaXb/4O3Z0vQb6uD752T1xuwMe7whC3OLn4MVC6Ctrfv3efo+qHk1W/hjU577O/z6e1ndduOnwZvfny2x390v4g11cP0lWWADeOA3UFeTTQNtt2u3Z3CoAC1YsIBHHnlki1d1LCoq4sADD2SXXXbpo55pRzJQI23nA+3r3V7UQ50EbDa0pZTqIuIW4JKI+CDZtMsPAe/tWjeyZFUOlOWeD8u1sSH3/D3AHUA98Bbg/cA7e71XkiRp+4uAEdXZberuWdkeB2UjWfnXN1u9DO79Zc/tjBgJ1WOzC3unBL/6Xhbaal7Jrk/W1AhtLdmIWmtLduHp7q6f9soi+PmlWXszX5ddz6y5EVqastvalbBmRedtnvjLa48nzsj6oYK3du1aHnjgAdp6Cv89mDBhAvvttx+jR4/uo55pRzMgoS2ltE/e4+1xyfaPAT8GlpGd33ZhSumu3AqVTwF7pZQWAdOBvMnwNOTu24fJzgF+kns+HzgzpXTnduifJEnanibNglO+AL/+fjaK1bRh41G1iGza5JTZ2W2fw2D+43DjV7LX86crbk5FJYybDCsWvhbk6tZ2DmPdmbZnNj0z3/7H9P59NWDa2tq47777OgW24uLijZbgb79VVVUxcuRIpk2b1nEZJGl7KYTrtG2z3HTFk7opX0TeOXO51Vl6nMeYUjqsD7onSZL6wqx94dwfZo9bmuGlx2DBEzBsRLZmS2ULAAEAAElEQVSU/s6zoGJE5232OAhGT9h4JKwnxSXZoiXHfigbWatbC/NuzS4IXrd209seeTIc9T74y63ZOXETZ8KM18G0PbZ8X9Vn2traePXVV1myZAkrVqwgpURxcTH19fUdUyKLiop461vfyqhRowa2s9phDdQ5bVf1pl5K6UN93RdJkjQElJRmlwCYfcCm6xUXw/svgL/9Nttm5E4wanw2TbJsGBSVZEGtpLTzfbsRI7MA99YPwtIXspG34hIoKctWsyzN3Y8YBaPHZ9scvtHflTXAGhsbWbZsGUuWLGHZsmU0Nzdvsv6cOXMMbBpQAzXS5qodkiRpYIyfCsd9dNvaiIDJu2U3DSqLFy/mvvvuo6WlZbN1i4qKmD59Onvs4eioBtZAndP2wYF4XxWWI488kpNPPpmzzz57yL7/3Xffzcknn8zy5cu3avuzzz6bCRMmcNFFF23U1t57781///d/85a3vGV7dlmSpCGrvr6e+++/f6PANnz4cCZPnsykSZMYPnw4zc3NDBs2jBEjRrhUvwrCkDinTdvmyCOP5P7776ekpISioiJ23313vvWtb3HooYcOdNd2KFdffTVXXHEF999/f0fZFVdc0WP9J598suPxhRdeyDPPPMONN97Yp32UJGkwSSnR2tracW21Bx98sGMqZEVFBbvuuitTpkxh5MiRXr5JBW2gzml7PKX0utzj+fR8PTQvbNFPLr/8cs4++2za2tr44Q9/yD//8z+zYsWKIfkPWEppi5fulSRJhWfNmjWsXfvagjD5F71evnw5S5Ys6XEa5Bvf+EbGjx/fL/2UttVAjfd+Je/xhWTXauvupn5WVFTEqaeeyquvvsqrr2YXEm1ra+NrX/sau+66K2PHjuXEE0/seG3BggVEBNdeey0zZ85k9OjRfPzjH+/4RxPgqquuYu+996aqqordd9+defPmdby2ZMkSjjrqKKqqqjjkkEN48cUXO16LCL73ve8xe/ZsKisr+dznPsfChQs57LDDqK6u5l3vehf19fUArFu3juOOO47x48czevRojj/+eJYsWdLR1pFHHsl5553HYYcdxvDhw3n88cc77ferr77KAQccwBe/+MWNPpObbrqJfffdt1PZj3/8Yw4//PCO9/7Qhz7EhAkTmDJlCp/+9Kdpamrq9vO97LLLmDVrFlVVVey111786le/AuDpp5/m7LPP5sEHH6SyspLKykpaW1s544wzOO+887pta8aMGdxxxx3ccccdXHrppdx6661UVlay++67c8sttzBnzpxO9X/0ox9xxBFHdNuWJEmDSUtLCw888AB33HEH9913X8ft/vvv5/777+eBBx5g4cKFPQa23XbbzcCmQWVAQltK6Ya8p79KKV3T9QZs4uqY6istLS1cc8017LrrrowbNw6A73znO9xyyy3ceeedLF26lAkTJnDWWWd12u4Pf/gDTzzxBA8//DA///nPuf322wG49dZb+cIXvsBPfvIT1q1bx+9+9zt23nnnju1+9rOf8Z3vfIfVq1czbdo0Pve5z3Vq9/bbb+ehhx7iwQcf5Fvf+hannXYaV111FYsXL+bFF1/kpz/9KZAFyw9+8IMsWLCAhQsXUlpayjnnnNOpreuuu47vfe971NbWstdee3WUv/zyyxxxxBGceuqpXHLJJRt9JieccALz58/vNB3xhhtu4NRTTwXgE5/4BCtWrOC5557jwQcf5M9//jNf+cpXNmoHYNasWcybN4+1a9fyhS98gVNOOYUVK1aw5557csUVV3DggQdSW1tLbW0txcXFmz5YOcceeyyf//znOfHEE6mtreXZZ5/tCK2PPfZYR71rr72W0047rVdtSpLUW71Z0KM7DQ0NPPHEE/ztb39j3bp1m6ybUqKxsZE1a9bw5JNP8tvf/paXXnqpV+9TXFxMaWkpZWVlDBs2jClTpjB37tyt6rM0UArhnLaFQHU35S8BY/q5L/3i5z//eb+91/ve975e1fvkJz/JeeedR0NDA0VFRdxwww0dJ95eccUVXH755UybNg2Aiy66iAkTJnRcuwTg4osvZsSIEcycOZOjjz6ahx9+mLe//e38+Mc/5lOf+hQHH3wwkI0O5fvgBz/IPvtk11o/7bTTNgpa//mf/0l1dTXV1dXsu+++HH300ey2W7ZS19vf/nYeeeQRAEaNGsWJJ57Ysd3nP/953va2t3Vq67TTTusYfWoPRM8++yyXXXYZX/ziF/ngB7tfH6eiooJ3v/vdXH/99Vx66aUsWbKE+++/n1tvvZXW1lZ+/vOf8+CDDzJy5EhGjhzJBRdcwLnnnssFF1ywUVv5fTzllFO49NJLeeihh3jHO97R7XtvrfLyck4++WSuvfZa9t13X+bPn8/DDz/Mbbfdtl3fR5K042pqauLee+9l2bJlVFVVMWnSJIqKimhra+v24tNNTU2sXr2a+vp6ioqKqKur65iZs3DhQvbff3/Kysqor6+noaGB+vr6jscNDQ20trZ224/x48czbNgwgE6ndYwYMYJp06YxatSoIXm6h3YshRDaNvopigiX6eln3/zmNzvOabv33ns57rjjmDlzJnPnzmXhwoWcdNJJnVZPKisrY8mSJR3hZ+LEiR2vjRgxgtraWgAWLVrErFmzenzfnrZrN2HChI7HFRUVGz1vr19XV8c555zD73//e2pqagBYv359p7amTp260fvfcMMNTJ06lVNOOaXHPgKceuqpfPSjH+XLX/4yN954I8cccwxjxoxhxYoVNDU1MX369I66M2bM6DQ1M9/VV1/Nt771LRYuXAhAbW0tK1eu3OR7b60zzjiDd77znXzta1/j+uuv54QTTqC6uru/j0iSdhStra3U1dV1BKLuzvGOiI5RqYjoOBc8pdRxa2tr4/HHH+/0f+6zzz671f1qaWnhb3/72xZtU1payv7778/MmTMNZRryBiy05V1gu6ybi23vCjzdz10S2Tlthx56KLvttht//OMfmTt3LlOnTu3xfKgFCxZssr2pU6d2Ok+tr3zjG9/gueee429/+xsTJ07koYce4sADD+xUp7t/0L/4xS9y99138573vIdbb72VsrKybtt/85vfTENDA/feey833HADn/3sZwEYN24cZWVlLFy4sGMUb8GCBUyePHmjNhYuXMhZZ53FnXfeySGHHEJxcTH77LNPx18Zt+U/nO62PfDAAxkzZgx//OMfue666/jmN7+51e1LkgpfSomGhgZqamrYsGEDTU1N1NfXd4S0uro6GhsbB7qbnYwbN44NGzZs9Efb7pSUlFBRUUF1dTXTpk1jypQplJQUwviD1PcG8pseeff5v3G2AfOAH/V7j/pJb6csDpT777+fp556ir333hvIrhX2hS98gZ/97GfMnDmTlStXMm/ePN797ndvtq2PfOQjnHvuuRx22GEceOCBLFq0iObmZnbdddft2ufa2loqKioYNWoUq1at4uKLL+7VdiUlJfz85z/npJNO4l/+5V/4n//5H0pLSzeqV1xczMknn8xFF13E888/z/HHH9+p/Pzzz+e6666joaGBiy++mPe///0btVFXV0dEsNNOOwFw5ZVX8swzz3S8PmHCBJYsWUJjYyPl5eVbtP8TJkzg9ttvp62trdOI6Omnn85nPvMZampqeOtb37pFbUqSBo8lS5bw0EMPdSzQ1V8iggMOOIBhw4axZs0aioqKOv4f6joyV1RUxOjRoztmfRQXFzN8+HCampp4/PHHWblyJcOGDaOiooLhw4d33Nqfd/f/s7SjGLDQ1n6B7Yh4LqXU/aoN6jfnnnsun/70p4FsyuKXvvSljnPCzjnnHFJKHHvssSxbtoxx48Zx4okn9iq0nXTSSaxZs4bTTjuNxYsXM2XKFK688srtHtrOPfdc3ve+9zFu3DgmT57Mueeey69//etebVtaWsrNN9/MiSeeyMknn8xNN93U7V/uTj31VN7whjdw2mmnUVFR0VH+7W9/m3POOYfZs2d3hLiuC6oA7LXXXh3n95WUlHD66adz0EEHdbx+9NFHs++++7LzzjvT1tbGqlWrer3/J510Etdddx1jx45l0qRJHYumfOADH+Bzn/scn/jEJ3q9sIkkaeCllFiyZAmtra1MnDix2z/mtbW1UV9fz6JFizotPLUpEUFFRQUjRoxgxIgR3f7f0NbWRmNjY8eoXNdz04qKiogISktL2XXXXTtWYZwyZcpW7WtZWRmvf/3rt2pbaUcR+Uuza+tFxAxg/vz58zdabGPp0qVMmjRpILqlHVxTUxMTJkzgrrvu2uRKWX5HJalwbNiwgfvvv59ly5Z1lI0ZM4aqqioigrq6uo4pj12VlJQwatQoKisrO85Law9oI0aMoKKiwvO/pAG2YMECZs6cCTAzpbSgN9sM+ETgiBgGnA+8BRhP3lRJL64tbZsf//jHzJ4926WNJalAtLa2smbNGtavX8+GDRs6bg0NDR2PuzvvbPXq1axevXqTbY8dO5bDDz+8YyVFSUPHgIc24OvAMcD3gS+TBbiPAdcMZKekwW7GjBm0trZyyy23DHRXJGmHtGTJEl555RWKiopobGxk9erV1NTUsCWznEaNGtWxQmN32qc6Tpgwgb333tup8NIQVQih7Z3Am1NKz0XEBSmlyyPiTuCyge6YNJhtbmVPSVLfWbBgAffdd99Wbz9y5Ej2339/Jk6cSGNjI2vXru24AHVlZSUjRoxg+PDhhjRpB1EIoW1kSum53OOWiChJKf0jIg4e0F5JkiRtoZQSK1eu3OQ1x6qqqhg1ahTDhw9n2LBhHbeKigqGDRtGeXl5p5WAy8vLGT9+fMeCH5J2PIUQ2hZFxMyU0nzgBeD4iFgFbBjgfkmSVHDq6up4/vnnqauro7W1leLiYkpLSykrK6OsrKzjcfv9qFGjvJZVH2hf5Xf16tXU1tZSV1fXcd/S0tJRr6qqihkzZlBUVMSYMWMYM2ZMj9cElaSeFMK/4t8H9gXmA98A/odsMZIvDGSnJEnantpHYBoaGja6flVKidbWVpqbm2lpaem4b2lpISI6rQj4wAMP0NTU1Ov3LS4uZsKECUyePJlJkyZRXl7ecU5Vex/aH3e9b2tro6mpqaMf7cu8t4fCHW1qXltbG8uWLWP+/PksW7asUzjrTllZGUcccQRVVVX91ENJQ9WAh7aU0vfzHt8SEdOBqpTSM5vYTJKkQWH58uUsWrSIxYsXd7sqYF9rbW1l6dKlLF26dLu3XVRU1BHe2traiAjKy8s7pvtVVlYyffr0jospD1bNzc288MILPPfcc726eHV7yN5///0NbJK2iwEPbV2llJYMdB8kSdpenn322e0emMrLy9l3330pKyvrGKFramqiqamp43FzczN1dXWsX79+u753vvaLMOdraGjo9PyJJ55g1KhRVFVVUVFR0XEbPnw4I0eOLPjl6ZuamvjDH/7QsQhIvuHDhzNhwgSqq6sZMWJExwIh5eXlXgtN0nY1IKEtIu4CNrvebUrp6H7ojtTJjBkzuOKKKzj22GO3eNt58+Zxxhln8OKLL27U1qWXXspzzz3H1VdfvZ17LKmQTZ06tSO0DRs2jLFjx1JUVEREdNy3T4HMv5WWllJSUkJKicbGRhYvXsyKFSsYM2YMhx56KCNGjOjV+69fv54lS5awZMkSVq1aRUqpI1Dk3/dUVlpaSmlpKZCFtObm5o5bW1tbr/pQU1PT7bL1EcGRRx7JxIkTe9VOf0spcf/993cKbOXl5eyyyy7MnDmTkSNHDmDvJO1IBmqk7e4Bel9twrHHHsu8efNYvny50zl6KSJ4+umn2WOPPQA47LDDOgJbV5///Oc7Hi9YsICZM2fS0NBQ8H9llrRtJk+ezO67787UqVMZN27cVo/AzJ49u+N8sy1po6qqij322KPj36ntJf+ct/YFUdra2jouDt3Q0MDSpUtZsmRJj9clSynxwAMP8I53vKNgFktpbGykpqaGtWvX8sorr7BkyWsTgObOncvs2bN3uHP5JA28AfkXMqV00UC8r3q2ZMkS/vjHPzJy5EhuvvlmPvzhD2/X9ltbWzv+oixJO5Ly8nL233//7dJWIf0bGhEUFxdTUVHRqTx/BHDWrFkd1xhraGigvr6ehoYGGhoaWLZsGc3NzdTX1/PUU08xZ86c/t6FDsuXL+fpp5+mpqaGDRu6X7x69913Z8899+znnklSpmjzVfpeRIyIiH+JiE9HxEkR0bs5H9purr32WubOncvZZ5/NNddcA2R/bRw9ejSPPPJIR73169czfPjwjtGk2267jf32249Ro0Zx8MEH8/DDD3fUnTFjBl/5yleYO3cuw4cPZ+3atVx22WXMmjWLqqoq9tprL371q1911G9ra+O8885j/PjxTJkyhauvvpqI4Jlnnunoz2c+8xmmT5/O+PHj+chHPkJdXd1G+9Kbfl999dXsvvvujB49mre85S0899xzG7UD8NBDD3HIIYcwatQodt55Zz7xiU/Q3NwMwOGHHw7A61//eiorK7nmmmu4++67e5zmc+GFF3LyySd32nbcuHFUVlby+9//nrFjx3b6/NauXcvw4cN56aWXum1PkgaD9muMTZ8+nT333JP999+fN73pTcydO7ejzlNPPcXvf/97Hn744X5frGXhwoXcfffdLF++vMfANnHixE79laT+NuChLSL2BJ4F/hs4MXf/bETstQVtjIqImyNifUQsiYh/66HePhHxu4hYFREbzdWIiLKI+GFE1ETEqxFx8Vbu1qBzzTXXcOqpp3Lqqafyl7/8hZdeeony8nJOPPFEbrjhho56//u//8u+++7LrFmzeOSRRzj99NP5/ve/z+rVq/n3f/93jj/++E4ra91www384he/YN26dVRXVzNr1izmzZvH2rVr+cIXvsApp5zCihUrAPjJT37CrbfeygMPPMAzzzzD7373u059PO+883jyySf5+9//zksvvcTKlSv5whc2vjLE5vp9991388lPfpJrr72WFStWcPjhh3P88cd3hLF8xcXFfPOb32TlypX89a9/5Y477uCHP/whAPfccw8Af//736mtreX000/v9efdvu3KlSupra3lmGOO4eSTT+baa6/tqHPLLbfw+te/nl122aXX7UrSYDFr1izGjh0LZNMkV61axbPPPstvf/tbnnrqKR577DEef/xxXnjhBZYuXcqaNWtobGzscarl1njppZe49957O7VZXFzM6NGjmTlzJnPnzuWoo47iyCOP7HSxa0nqb4UwgfxbwLXA+SmltogoAi4BLgeO6WUb3yXbl0nALOAPEfF0SumuLvWagZvJrg33i27a+X/AHGBXoBL4Y0TMTyn9dIv2qBeu/fNzXHfP872q+7b9pnLucZ2njVz+m39w+yMv97jN+w/fjQ8cMbtX7d9///08//zzvO997+v4a+I111zDRRddxKmnnsppp53G1772NYqKirjhhhs49dRTAfjRj37EmWeeySGHHALAqaeeyqWXXsq8efN461vfCsC///u/M2PGjI73OvHEEzsen3LKKVx66aU89NBDvOMd7+DnP/8555xzDjNnzgTg4osv5sYbbwSy/9B/9KMf8fDDDzNu3DgAzj//fE444QS+9a1vbbRPm+r3ddddxxlnnMEb3vCGjna+973v8cADD3DooYd2ame//fbreLzLLrtw1lln8ec//5mPf/zjvfpst8QZZ5zB8ccfz9e//nWKi4u59tprOe2007b7+0hSIYgIDjroIO66665OK05u2LCBxx57rMft8i8zUFVVxcSJE6msrCSlRFVVFaNHj+7VNNIXXniBBx98sON5dXU1hx56KNXV1QU1DVWSoDBC2+uBE1JKbQC54HYJsLg3G+emUp4E7JdSWg88GhFXAR8COoW2lNKzZKN4u/bQ3AeBM1NKK4GVEfGNXDvbPbQVkquvvpqjjz66Y1rfqaeeyne/+10uvPBCjjjiCFJK3HPPPey1117cc889XHfddUA2peSaa67hBz/4QUdbTU1NnZa2njp16kbv9a1vfYuFCxcCUFtby8qVKwFYunRpp/rTpk3rePzqq69SX1/PQQcd1FGWUupY1rp9ZbN2m+r3kiVLeN3rXtdRt7i4mKlTp3Y62bzds88+yyc/+Un+/ve/U19fT0tLS6c+bE8HHngg48aN43e/+x377LMPf/vb3/jlL3/ZJ+8lSYVg5MiRvPOd76S+vp6VK1fy8MMP9zhFsV3+ZQbq6+s7Zmu0Kysro6KiotuLhec/zp8VMmrUKI466igXhpJUsAohtNUB4+kc0nbKlffGbCBSSk/llT1K70fpAIiI0WQjdfl/3nsUuLSbuqOAUV2Kp2zJ+xWKDRs2cNNNN9Hc3NwR2pqamlizZg1//vOfOfLII3nf+97H9ddfz5w5czjqqKPYaaedgCyQffazn+WCCy7osf38v1YuXLiQs846izvvvJNDDjmE4uJi9tlnn47/RCdNmsTLL782erho0aKOx+PGjaOiooLHHnuM6dOnb3a/ioqKeuz35MmTO0IjZL8AvPzyy0yePHmjdv71X/+VuXPncuONN1JVVcXXv/51fvOb32z2/Tenp7/inn766Vx77bXMmTOH4447zuWkJQ15EcGIESMYMWIEEydO5Pnnn6e+vp6Kigra2to2WsCku6ns+dqvV9dbo0eP5qijjqK8vHxbd0WS+kwhhLZbgV9ExPnAfGAm2fTIW3q5fSXQ9YqXNcCWrllfmbtf24t2zgV6Tiq98IEjZvd6+mJ3zj1uzkZTJrfGL37xC1JKPPnkk53+wzrrrLO4+uqrOfLIIzn11FM5+uijeeSRR/iP//iPjjpnnnkm73znOznmmGM46KCDaGho4J577uHggw9m9OjRG71XXV0dEdERnq688sqORUYA3vve9/LNb36T4447jp122okLL7yw47WioiLOPPNMPvnJT/L973+fCRMmsGTJEh577DHe/va3d7tvPfX71FNP5T3veQ+nnHIKc+bM4bLLLqO6urrbEbTa2lqqq6uprKzk6aef5oc//GGncDdhwgReeumlLV5Ke6eddqKoqIiXXnqJvfZ67fTND3zgA1xyySU89NBD3U77lKShrLy8nH322WeTdVpaWmhubqalpYVXX32VV155hZaWFtra2li1atVmR+ry7bzzzrzxjW+krKxsW7suSX1qwEJbRPwJ+AHZeWSXAf8HDAM2AFcD5/eyqVqgukvZSGD9FnapNndfnfe4p3YuJ+tjvinAvC18zwF39dVXc/rpp280enXOOefwzne+k+9+97vMnTuXnXfemaeffpp3vetdHXUOOOAAfvKTn3DOOefw3HPPUVFRwRvf+EYOPvjgbt9rr7324lOf+hQHH3wwJSUlnH766Z2C0kc+8hFefPFFDjzwQMrLy7ngggu44YYbOsLkZZddxsUXX8whhxzCypUrmTx5Mh/5yEd6DG099fuoo47isssu45RTTuGVV15h//3359e//vVGUywBvv71r3PmmWfy9a9/nf3335/3vve9/OUvf+l4/cILL+TDH/4wDQ0NfOc739loOmhPhg8fzvnnn88RRxxBc3Mzv/zlLzniiCOYOHEihx12GA899NBWXdxbkoa69ouPQ3YNuvzFmlJK1NbW0traCvR88fD2C5t3vVyBJBWq2J6rMG3RG0dcCbyXLBRdBVxJNiVyZdqCTuXOaVsNzE0pPZ0r+yowOaX0gR622RV4PqUUXcqXAB9JKd2ee342cGpK6bBe9GMGMH/+/PmdFt6A7FytSZMm9XaXlPP000+z9957s2HDhh3qr6D/9m//RllZGZdffnm/vaffUUmSpP6xYMGC9oX3ZqaUFvRmmwFbvzal9BGyc8i+DBwPPA/8BNii4YWUUh3ZVMpLIqIqIuaQLR5yVde6kRkGlOWeD8s9b3c18IWIGBcR04FPdteO+kZDQwO/+c1vaG5uZuXKlXz605/muOOO26EC2+LFi7nxxhs566yzBrorkiRJKhADetGRlNL6lNL3Ukr7AkcAa4BbI2J+RHxuC5r6GJCAZcAdwIUppbsiYlpE1EZE+zKE04EG4Mnc84bcrd1FwBPAi8DfgZv6Yrl/dS+lxMUXX8yYMWPYfffdGTZsWMc10XYEX/ziF9ljjz34+Mc/3uk8N0mSJO3YBmx6ZE8iYh+ya6jNTCkVD3B3es3pkRrM/I5KkiT1j0E1PbKriHhrRPwv8DDZQiD/NsBdkiRJkqQBN6BL/kfETsCHgTPJzm/7H+CIlNJ9A9kvSZIkSSoUA7nk/83ACcDLZEv//zSltGqg+tPXUko9XlBZGkiFNkVakiRJnQ3kSFspcEJK6fcD2Id+UV5ezpo1a6iurqa4uNjwpoLRfk2j7q5RJ0mSpMIwYKEtpfTugXrv/jZmzBjWr1/PypUraWtrG+juSJ2UlpYyZsyYge6GJEmSejCg57TtKCKC6upqqqurB7orkiRJkgaZglk9UpIkSZK0MUObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBWwIRHaImJURNwcEesjYklE/Nsm6n48V2d9RNwUEdV5r90dERsiojZ3e7F/9kCSJEmSujckQhvwXaAEmAS8A7goIo7qWiki/gm4IFdnMlAKfKdLtXNTSpW526y+7bYkSZIkbdqgD20RMQI4CfhCSml9SulR4CrgQ91UPwP4aUrp0ZTSOuB84L0RMby/+itJkiRJW2LQhzZgNhAppafyyh4F9umm7j7AY+1PUkpP5x7ullfnSxGxKiLujYiju3vD3HTMGfk3YMq27IQkSZIkdadkoDuwHVQC67qU1QBVPdRd26VsbV7dzwJPAU3AycCvI2JuSun5LtucSzbNUpIkSZL61FAYaasFqruUjQTW97JudXvdlNIDuSmWjSmla4B5wHHdtHM5MLPL7bCt3QFJkiRJ6slQGGl7DkgRsWfedMe5wBPd1H0C2Be4ASAi9gAC6DqS1i51W5hSDdloXoeI2MJuS5IkSdLmDfqRtpRSHXALcElEVEXEHLJFSK7qpvrVwAcjYk5EVAFfAm5KKdXnzlN7a0QMi4iSiDgVOBy4vZ92RZIkSZI2MuhDW87HyEbFlgF3ABemlO6KiGm5661NA0gp/QG4JFdnGdAG/HuujVKyEPcqsDJX/q6U0jP9uieSJEmSlGcoTI9sn654Ujfli8gWH8kv+w4bX5uNlNKrwIF91EVJkiRJ2ipDZaRNkiRJkoYkQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBUwQ5skSZIkFTBDmyRJkiQVMEObJEmSJBWwIRHaImJURNwcEesjYklE/Nsm6n48V2d9RNwUEdVb044kSZIk9YchEdqA7wIlwCTgHcBFEXFU10oR8U/ABbk6k4FS4Dtb2o4kSZIk9ZdBH9oiYgRwEvCFlNL6lNKjwFXAh7qpfgbw05TSoymldcD5wHsjYvgWtiNJkiRJ/aJkoDuwHcwGIqX0VF7Zo8Ax3dTdB/ht+5OU0tMRAbAbWYDtVTsRMQoY1aV4CsDMmTO3sPuSJEmS1LOhENoqgXVdymqAqh7qru1StjZXN7agnXPJpllKkiRJUp8aCqGtFqjuUjYSWN/LutW5ukVb0M7lwNVdyqYA8+bPn8+MGTM212dJkiRJO6AFCxZs8ey8oRDangNSROyZUno6VzYXeKKbuk8A+wI3AETEHmQjbM/n7nvVTkqphmwUrkNumqUkSZIkbVeDfiGSlFIdcAtwSURURcQcssVDruqm+tXAByNiTkRUAV8Cbkop1W9hO5IkSZLULwZ9aMv5GJCAZcAdwIUppbsiYlpE1EbENICU0h+AS3J1lgFtwL9vrp3+2w1JkiRJ6mwoTI9sn654Ujfli8gWH8kv+w6dr8222XYkSZIkaaAMlZE2SZIkSRqSDG2SJEmSVMAMbZIkSZJUwIbEOW0Fohhg8eLFA90PSZIkSQUqLy8U93abSCn1TW92MBFxKDBvoPshSZIkaVA4LKX0l95UNLRtJxFRDhxIdrmA1gHuzlAxhSwIHwa0/0liPrBll5BXX9kex6K7Y6wtMxh+JnaU4zwYjkVfKMTju6Mei76ytcfY41A48o9FIf7M7kjmA7sCOwMPppQae7OR0yO3k9wH3qukrN6JiPaHi1NKC9rL2h9rYG2PY9HdMdaWGQw/EzvKcR4Mx6IvFOLx3VGPRV/Z2mPscSgc+ceiEH9mdyS5Y/Ei8OKWbOdCJJIkSZJUwAxtGmwuGugOqIPHojB4HAqHx6JweCwKg8ehcHgsCsdWHQvPaVPBiogZ5OZgO3w/NHmMdwwe56HN4zv0eYyHFo/n4ORImwpZDdlfI2oGthvqQzV4jHcENXich7IaPL5DXQ0e46GkBo/noONImyRJkiQVMEfaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZIkqYAZ2iRJkiSpgBnaJEmSJKmAGdokSZ1ExIyISBExI/f8jIhYkPf6FRFxxUD1L9eHIyMiDWQfBkJEHBYRtduhnWsi4j+2R58GWtfvaw91vhURF/ZfryRp+zK0SdIQExF3R0RTRNRGxLqIeDIiztxe7aeUzk4pnb292utOROwUET+JiCW5/VgWEbdHxM59+b6FJCIujIi788tSSvNSSpXb2O4BwJuB73Up/2hEPBURdbnP+/xteZ++0PUPCFvgy8A5ETFpO3dJkvqFoU2ShqZLc7/cjwIuAn4YEYcPbJe2yHVkfX99bj/2BX4O9NnoWkSU9VXbXd6nKCKK++O9evAfwM9SSk15ffoc8BngI0A1sDvwq4Hp3vaXUloJ3A706R8bJKmvGNokaQhLKbWllG4GVgNvaC+PiHdGxCMRsTY3uvLh3rYZEVdHxNV5zxdExPm5kbD1EfF8RLyzyzafiYhFEVETET+NiJ/nt9GNNwLXpJSW5/bjlZTSz9qf57X77oh4Ljei+Lv8kbiI+FhulHF9bsTuexExvMt+/DwifhwRK4Hr86bafSQins61+8eImJm3XXFEfCr3+tqI+HtEvHkTn1d7mx+OiCeAemDPiDgpIh7OtbEiIq6PiHG5bU4FPg8clhtprI2I/bpOC8315fMR8ULus703It64ib6UAMcDv8srGwl8EfhESunelFJrSmldSunxTRyf9uP+/yLiT7nRuSdyfXxv7juwNnesS/O22Tsifh8RqyJiYUR8PSKGdWmz2+9SRBwGXAFMy/tM3pXXpUMj4h+57e6NiD26dPn3wLs3tU+SVKgMbZI0hEVESUScAowFns2VHQzcTDYCN4Zs9OGbEfHP2/BWZ5KFjJHAj4CfRURl7v1OBT4LnASMA/4MvGcz7d0DXBYRZ+eCQEkP9d4NHAhMIxsh+lLea8uAd+bK3wwcA3Sd8vceYB4wETg9r/zDwFuAnYEFwK/yRse+CJyaa3t07j1/GRGzNrNPpwPHApXAc8D6XNkY4PXALsB/A6SUrgcuBeallCpzt0e6afNTwFm5z2En4Hrg9xExtYc+7AZUAU/klR0CVAB7RcSLEbE8In4ZEbtsZn/a9+nfyUZFHwVuBf4JmAvMIQuIpwBERDXwR+BBYDJwBNlnfFmXNrv9LqWU5pF9VxflfSa/yNvuA7n33glYTpfpn8DjwD75IVGSBgtDmyQNTedFRA2wAbgW+HxK6de51z4I/DKl9IvcqMo9wI/JfvnfWj9KKT2SUmoDfsBrU+wAzsi9/kBKqSWldDXw9820917gGrJQcC+wMiIu7+YX7vNSSmtTSjVkgaVjNDGl9L8ppRdS5hng+2QhId/9uRG8lpRSfV75xSmlJSmlOrLphHvmtf0fwH+mlJ7LjWT+H1nwe99m9umilNLi3Hs1pZTuSCk9njsGi8nCS9f+bc6Hgcty7TSnlL4HPEMWKrszOne/Nq9sXO7+HcCbgF2BlcCvY/PTOK9MKT2VUmoGbgBmAl9MKdWllBaShe8D8toH+H8ppQ0ppQXAF4CPRETktbmp79KmXJRSWpFS2gBcRd53IWdd7n5ML9qSpIJiaJOkoemrKaVRZL+k/xR4S95o1VTgpS71XyAbrdpaS9sfpJTaVzesyt1PIRutytf1eScppdqU0ldSSoeQjbicRhY2P9+l3tK8p7V570lEvCci7o+IlRGxlmwxivFd3mp+D13oKE8prScLMVMjYgJZiPi/3HTEmlw4Ppxs9GhTOr1XRBwV2aIxKyJiHVm47tq/zdnSY7k6dz8yr2x97v7LKaXlueN3HrAXMDtyK1bm3Q7L23ZZ3uN6gJRS17L2YzIVWJhSau3S1wqy0bF2m/oubUrX70LXBVuqc/erkaRBxtAmSUNYLnB8jGwE5GO54pdzz/PNAhb1UTcWAzO6lE3v7ca5UalfkU2tm9ubbSJiCnAT8HVgckppJNnUyOhSta2HJjr6m5vmOY5sP2rIRi+PTSmNyruNSCn962a61fFekS168mvgF8AuKaVqsul9velbvi09ls+TjTjtnVfWPu0yf5GXjsftK1bm3eb1ol899XV6ROT/7jELaABe7WUbvflMerIP8GRuJE6SBhVDmyQNcSmlRuBi4Au584quBt4VEcfnFrI4lOw8oiv7qAvXkE2BOzB3jt1pZOdw9SgivpmrPyyy1RaPBI4im4bYG1Vk/8etTCk1RsQcXgutvfHFiJgU2cIl3yA7H/CB3Gd5BfBfEbFnZCoi4vCImL0F7ZcBw4CalFJd7vyx87rUWU4Wcso30c5VwGdyC3yURsS/ko2Q3dBd5dwo16+At+aVLSILkOdHdqmF4WTn0z1Odu7d9nIbWWi+KCLKI2I6cAlwVUqpt6uCLgd2iojRm625sWOA/9uK7SRpwBnaJGnHcC3ZtLD/TCndR3b+1SXAGrKw9pmU0i199N7XA98E/pdsmuFRZMFhUyMeRWTTOl/J9fH7ZKNm3+jNG6aUniY7X+qm3NTDrwM/24I+/xT4E1lI2A14Z960vk+TLeTyP2QjbwuAzwGlG7XSc/9qgY8CF0d2sezrc7d8N5FNH1yWm4Y5t5umvgH8hOzzXEk2jfTYXBDryeXA6dH5EgenkY0kPg8sJJuueHyXqYzbJKW0jmyhkEPIplXOA+4G/nMLmrmTLPy1r5Z5Qm82ioixwNvIArckDTrR+z9u/X/27jM6rurqw/izR90qlnu3JdvYYIxtegmmhxIg9FBDQk/oaSRvQqhJSCAhtJBAgFACCYRQQ++YXm0w2Ni49y6r19nvhzvyjGSVkS1pRtL/t9Ys3XLuvXs0wmjrnLOPiIhI+zCzj4D/uvt1iY4llpkVEMw9K4wUyuiWzOw+YLq7/znRsXQGM7sRKHH3KxMdi4jIllDSJiIiHc7MTgKeJJgrdR5wAzDB3b9OaGCN9JSkTUREuhYNjxQRkc5wHsFQw9UEBTeOSraETUREJFmpp01ERERERCSJqadNREREREQkiaW23kTiESnJvCtBRax2q7YlIiIiIiLdSgowBPgwspRMq5S0tZ9diX/9IBERERER6dmmAm/F01BJW/tZATBt2jSGDx+e6FhERERERCQJLV26lKlTp0Ikf4iHkrb2UwcwfPhwCgoKEhyKiIiIiIgkubinVKkQiYiIiIiISBJT0iYiIiIiIpLElLSJiIiIiIgkMSVtIiIiIiIiSUxJm4iIiIiINM09eElCKWkTEREREZHNzf4Arj0e7vwplJckOpoeTUmbiIiIiIg05A7P3QU11bB0Djz790RH1KMpaRMRERERkYYWz4L1MWs/z3gNvvowcfH0cEraRERERER6gro6+PQV+OLt1uepffrK5see+gtUV3VMbNKi1EQHICIiIiIineCTl4LEC+C7V8K4XZpuV10FM6dF99MyoKYKitfBvOmw3e7B8TVL4c3/QOkGqK2Buprga20NhEKw62Gw++Ed+pZ6CiVtIiIiIiI9wZyPGm43l7TNeheqKoLt/sOCdu88GewvmxNN2p68FRZ92fzznrkDttsT8vpufew9nIZHioiIiIj0BCsXRLeXf918u9ihkTseCCO2je4v+Sr4WlkezHtriTssnNn2OGUz6mkTEREREenuykugaHV0f8V8qKuFlEbpQNEamD8j2DaDyftDOBw9v3xukIwtmR2dFzdgBBzxA0hNh9S0IOl77+ng3MLPYdI+Hfe+egj1tImIiIiIdFVzP4Hpr7VeWCS2lw2CeWerF2/ebkbMvUZPht79IX8A5OQHxyrLg7lsi76IXjNmCoyeBCO3haFjYLs9oucWfN7WdyRNUNImIiIiItIVLZ4F918J/70RXn+45bYr5m9+bPm8hvvuDYdG7nRQ8NUMho+PHl/6VcO5bKMmNLzPiG2jPXhrl0HJhpZjk1YpaRMRERER6Yo+ezO6/eqDLZfjbyppWza34f6S2bBuebCd2Qu2jekxGz4uur1wZlCQpN7IRklbWjqMiEnyYnvlZIsoaRMRERER6YpK1jfcn/Fa821XLdj8WONiJLG9bBOnQnpGdD+2p+3TV6CmOtjuO7jp6pCjJka3NURyqylpExERERHpitYsabj/7pNNz22rqW56/trKBUExEth8bbYdD2zYdtg2wTDJxkZt33RshUra2lO3SNrMLN/MHjGzEjNbZmbnt9D2wkibEjN72MzytuQ+IiIiIiIJU1cbHcpYb83SoDBJY6sXRytA9h0CfQZF77FqUbA9+72gyAhAv6ENy/xDMFxywIjN791c0hY7r23NkuhzZIt0i6QNuI1g+YKhwOHA1Wa2f+NGZvZN4MpIm2FAGnBrW+8jIiIiIpJQ61ZAuG7z47G9ZfVi564NGR30mtV74R9BT9wnL0eP7Xhg071qU49vuERAKBRUmGxKembDxbun/bfpdhKXLr9Om5llAycAO7p7CTDdzO4BzgQaD+z9PvAPd58eufZXwKdm9kPA2nAfEREREZHEWR3Tc5WZDZVlwXbjoh8bVsMrD0T3h46FgSNh5lvB/vwZcP8V0WqQZjDlgKafOWV/2GYnmDcjKEQyanvoM7D5GKceD7PeC7Y/fwMOPK3l9tIs89bWdEhyZrYj8L67p8ccOxm4zN13bNR2BnC9uz8Yc6wS2J2g1zHe++QD+Y1CGQ408acNERERERGRzRS6+8J4Gnb5njYgByhudKwIyG2m7cZGxzZG2lob7nMpwTBLERERERGRDtUdkrZSIK/Rsd5ASZxt8yJtQ224z03AvY2OqadNRERERETaXXdI2uYAbmbbufusyLEpwMwm2s4EJgMPAZjZtgQ9bHMjX+O6j7sXEfTCbWKRyZoLFiygoKBgK96OiIiIiEgL6mrhmuOjhUgufwSWzoF7Lw/2s3KCOW7106B2PxyO+EFiYgUoL4F/XhMs3g3BvLnz/tSwIEpjbz0OL9wT3Z+8Pxz/446Ns5MsXLiQwsLCNl3T5atHunsZ8ChwrZnlmtkkguIh9zTR/F7gDDObZGa5wG+Ah929vI33ERERERFJjNjKkfkDICMLRoyHUEpwrKI0mrAVTITDzk5MnPV65cL3fwOFOwT77vDMHU2vKVev8cLfn70eFDVpar25HqDLJ20RFwAOrACeB65y99fMbKSZlZrZSAB3fwm4NtJmBRAGLmrtPp33NkREREREWuAObz8e3R8wMviangnDxjZsmz8ATvpFwzL9iZKeAUddFI1lyVfw/jPNt18xr+G+Ozz0W7j1AvjXdcEyBT1IEnyCWy8yXPGEJo4vJig+EnvsVhquzdbqfUREREREEs4dnr8bPnkpemzb3aLbIycEyRBAWjqccjlk9+7cGFvSbwjsfSy88Uiw/8wd8MXbcMCpUDgx2q6yHNYua/4+X74D/yyFk38VLPrdA3SXnjYRERERke7t1YfgnSej+1MOgF0Pi+7vemjQ45aWAcf9OFhIO9nscwL0HRLdXzgT7vk/+MevYGFkjbkV86PnBxfAIWfCyO0azoGb/1lwTVnjwvDdU5dfpy1ZmFkBsECFSERERESk3U37L7x4b3R/wl7wncsgJaVhu5pqqKkK5pElq+L18OqD8Okr0bl59UZPhj6D4OMXg/0dD4RjL42ef/NReOm+6H7/YcF8ud79Ozzs9hJTiCTuddrU0yYiIiIiksw+eLZhwrbNzvCdn22esEEwLDKZEzaAvL5w9EVwyd9gp29CKCYlmT8jmrABDG00T2+f4+HbFwQVKCEYRvn3n7U8nLIbUNImIiIiIpKsPn0Fnv5rdL9wBzj5l8lRXGRr9R0Mx1wMF/8t6FELNZGaNE7aIBgG+p3Lot+DjWvh75fBmqUdG28CKWkTEREREUkWHzwLj/4JFs8KinQ8fnP03IjxcOqvg9607qTfkGAI5Fm/j/ag1RvczHpmE/eG064I5u8BlBcHQy67KSVtIiIiIiLJYN2KoFdtxutBz9EjN0TXMhtcCN+9KliTrbsauV3Qi1ifuBVMDJYKaM7YHeGUX0X3l87p2PgSqBv0q4qIiIiIdAPrGs3Lqi/S0X8YfP9ayMrZ/JruZrs9gh63uR/Dzge33r5wh2CYZF0tFK2GijLIyu74ODuZkjYRERERkWRQXrL5sfyBQXXEZFpvraONmhC84pGSCgOGw8qFwf6axUGPXTej4ZEiIiIiIsmgvDi6ndkLph4P59zQpcrZJ8Sgguh2ffLWzainTUREREQkGcQmbXsdDfufnLBQupTYpG3VwkRF0aHU0yYiIiIikgxih0dmJflaa8mkQU/bgoSF0ZHU0yYiIiIikgwqYpK2XnmJi6OrGVwQ3V48C+79NaxdCgU7wIQ9g+ImjZcS6GKUtImIiIiIJIPY4ZG91NMWt9y+wfervqdy3vTg64zXgteIbeHoi2DgyISFuLU0PFJEREREJBloeOSWMWs4RLKxJbPh9kvglQeDpQG6ICVtIiIiIiLJQMMjt1zjXrTRk+EbxwRLAkCQrM39GKxrpj8aHikiIiIikgxih0dmK2lrk8GjG+4ffRH0GQQ7HQRP3ArL5sBRF0GoayZtXTNqEREREZGuyh0+fgkevwVWLQqO1VQHLwh6h9IyEhdfV7Td7tF5gEf8IEjYIOiBO+d6OPt6GFKYuPi2knraREREREQ6S1kxPH4TfPVhsL9+BZx1XaMiJHldvtphp8vuDZfeCRWl0Hdww3NmMGJ8YuJqJ0raREREREQ6w8Iv4D83QPG66LH6dcVii5CocuSWycoJXt2QkjYRERERkY7kDm/+B175Z7Adq7IsGBZZocqR0jwlbSIiIiIiHaW0CB79U3TtMAh60mproLoy0mbD5sMjRWKoEImIiIiISEdwh3/8qmHCNmoCnH8LDBgRPVayXgtrS4vU0yYiIiIi0hFKi2D14mDbDPY5AfY/BVJSILdvtF3Jei2sLS1S0iYiIiIi0hFie8/6D4eDvhvdj03aitdrYW1pkYZHioiIiIh0hJaGPDbuaSvT8EhpnpI2EREREZGOUN5C71lun+h2yXpVj5QWaXikiIiIiEhHaKkiZOOetuqK6H62hkdKQ0raREREREQ6QrxJW+mGYK22euppk0aUtImIiIiIdIS29LTFLrqtOW3SSJee02ZmQ8zsKTNbYWZuZgWttM83s0fMrMTMlpnZ+Y3O72tmM82s3MzeM7PtO/QNiIiIiEj3FVtcpPGQx+zewTIAEMx9qyiNnsvM6fjYpEtJSNJmZtlm9h0z+2nka/YW3ioMPA8cG2f72wh6F4cChwNXm9n+kZj6AU8C1wF9gMeBJ81MvZEiIiIi0nYt9bSFQpDTh81kZgfruInE6PSkzcy2A74CbgaOA24CvjKzCW29l7uvcvfbgQ/jeG42cAJwubuXuPt04B7gzEiTY4E57v6gu1cBNwC9gH3bGpeIiIiISItJGzQcItlSO+nxEtHT9mfgAWCYu+8JDAfuI0jeOtI4wNz9y5hj04GJke2JwIz6E+4eBj6POb9JZJhlQeyL4H2IiIiIiARaTdqa6GnL69dx8UiXlYihfzsD344kRbh72MyuBZZ28HNzgOJGx4qA3JjzG1o4H+tS4Mr2C01EREREup2WFteGphO07fbouHiky0pET1sZMLDRsQGR4y0ys1PNrDTy+qKNzy0FGv+JozdQEuf5WDcBhY1eU9sYj4iIiIh0V3W1UBVZey0UCuaqNdZ4TpsZ7LBPx8cmXU4ikrb/Ak+Y2SFmNs7MDokce7S1CyPzzXIir7ZWdpwDeGROXb0pwMzI9kxgcv0JMzNgUsz52DiK3H1h7IuO7ykUERERka4itnJkVm60UmSsxnPaxu7U9JBJ6fESkbT9CviAoDrj7MjXjyLH28zMMoGMyG6GmWVGEq4G3L2MIDG81sxyzWwSQRGSeyJNHgPGm9nJZpYB/BQoB97YkrhEREREpAdrbT4bbJ60TTmg4+KRLq3TkzZ3r3T384FsYBCQ7e7nu3vlFt6ygmBoIwRJYAUwCsDMfmlmz8W0vQBwYAXBUgFXuftrkbjWAUcDlxPMZTseOMrda7cwLhERERHpqWKTtuzeTbdp3Kum+WzSjIStQebuDqxph/s00de86dzvGu0XEZT9b67964AW1BYRERHpjtybHqbYEVorQgIwdCyMGA9LvoKDvw9p6Z0SmnQ9nZK0mdnn7r5DZHsBQW/XZtx9dGfEIyIiIiI9zMIv4F+/gz6D4IzfQkZWxz4vnuGRZnDODVBR2nxiJ0Ln9bRdF7N9VSc9U0REREQk8NZ/g0SqvBg+eRn2PLJjn1ceU4C8pQWzzZSwSas6JWlz94didp9y98broWFm+Z0Ri4iIiIj0MO6weFZ0f/Z7nZC0xdHTJhKnRFSPXNTM8fmdGoWIiIiI9AxrlgZDEOstnNmwJ6wjKGmTdpSIpG2z2Z9mlog4RERERKQniO1lAwiHYc5HHfvMeAqRiMSp06pHmln9emjpMdv1xgKN/msSEREREWkHS5r4NXPWezBl/457Zpl62qT9dGYPlzXzcmAacEonxiIiIiIiXVldLbzyILz8AFS3stxv4542gK8/gaqKjokNNDxS2lWn9bS5+xkAZjbH3a9rrb2IiIiISLM+eRle/3ewvWYpnPSLptdgKyuGtcuC7ZRUyOsHG1YFid5tF8KR58O4nds/PiVt0o46fS6ZEjYRERER2WqLvohuf/kOvP1E0+2WzI5uDx0Dex8b3S9aDQ9cBY9cD8Xr2y+22ppo718oBTJ7td+9pUfq9KTNzDLN7Foze9fM5pnZ/PpXZ8ciIiIiIl3UqoUN91+6N1hAO1ZVBbz3dHR/5ATY9TA45pKGxUE+nwa3ng8fPBcsD7C1YitTZuU03QMo0gaJqNr4R+BE4GFgMHALUAc0Lk4iIiIiIrK5utpgSGSscDjoMSuJLAdcvB7+/jOYNz3aZpudgwRqp4Pg4r/ClAOi5yrL4Onb4abz4Om/wtI5wfFPXobfnQyP3RR/QldZFt3OymnruxPZTCKStqOAI9z9JqA68vU4YO8ExCIiIiIiXc26FUHiBsF8sfo5YyXrg8Strg6euQNWxSwPPPV4GDM5up/dG477EZzxW+g3NHp8/Qr44Fm46+dBz90zdwRrvH36Ciz/Or74KmJ72lTuX7ZeIpK23u4e+dMFtWaW6u6fAXskIBYRERER6Wpih0YOHwff+Vl0COLCmfDIH4J5bvWOvRQO/l7T9xo9CS64FfY7CdIyosfrauH+KxpWppw3Y/PrP58G910Bn70ZPRa7kLd62qQdJCJpW2xmhZHtr4EjzWwfoJVarSIiIiIiNEzaBhXAmCmwf8zqUV++G92euDfseGDL90tLhwNPhf97CE7+ZTQBrKlu2G5+TNLmDq/9O+jZ+/pTeOIWqK4KzqmnTdpZIpK224H6vuk/Af8BXgNuTkAsIiIiItLVxA57HDgy+LrficGctVihEBx4Wvz3TUuHCXvCLoc0fX7xl0EiFw4H895efTB6rqYK1kbm2amnTdpZIpK2e939CQB3fxQYBWyvpQBEREREJC6rY5K2QQXBVzM4/ieQPzB6bqdvQv9hbb//gadBZnZ0PyWytHFNNSz4HB7+A3z4XBNxLQ6+KmmTdtapSZuZpQDrzSy9/pi7L3P32S1cJiIiIiISqK6E9SuD7VAIBgyPnuuVC6f+GgYXQsFEOOi7W/aM7N7wnctgcAHsdXRQbbLew79vOF8uduHsTUlbo5L/IlsptTMf5u51ZrYE6AVUt9ZeRERERKSB+sQIoN8wSE1reH5wAVxwy9Y/Z5udghfAF2/Dh88H27GFSb5xDAwZDY/+KdhfsyT42qCnTXPaZOslYnjk5cCdZlaQgGeLiIiISFe2cmF0e9Coznlm4aTNF8g+5Ew49EwYGBODhkdKB0lE0vYv4HhgnpnVxb4SEIuIiIiIdCULPotuDxndOc/slQujI3X0Qilw3I9h72OC/f7DogndhpXBvLdKJW3Svjp1eGTE/gl4poiIiIh0deEwfP1JdL9xtciOdNyPYeY0KNgBhhRGj6elQ98hsG55sAzA2qVQHjOnLVNJm2y9Tk/a3P2Nzn6miIiIiHQDS+dEE6LcvkHBkc6S2wf2/HbT5waMCJI2CIZIxg6P7KU5bbL1EjE8UkRERESk7eZ8FN3eZufN55klSv1acRAkbRoeKe1MSZuIiIiIdA1zY5K2cbskLo7GYpO2pV8FwzgB0jOja7yJbAUlbSIiIiKS/IrXw/J5wXYoJVoYJBnEJm1Lvopuq5dN2omSNhERERFJfrPfj26PmgBZ2YmLpbF+MRUka6qix5W0STtJSNJmZnlmdoqZXRbZH2RmgxMRi4iIiIgkOXd47+no/nZ7JC6WpqRnQJ9Bmx/XwtrSTjo9aTOzKcBcgkW2r4gc3hG4rbNjEREREZEuYP4MWLMk2E7PhCkHJjaepgwYufkx9bRJO0lET9tNwFXuPgGoiRx7G2jzn0zM7HAze8vMisxspZndY2b5LbTPN7NHzKzEzJaZ2fmNzu9rZjPNrNzM3jOz7dsak4iIiIi0s7efiG7v9M3kGhpZb2ATSZvWaJN2koikbQfgjsi2A7h7CbAl/ce9gd8AQ4FtgYEESWFzbiNYm24ocDhwtZntD2Bm/YAngeuAPsDjwJNmppI/IiIiIomyZinM/TjYNoM9jkxsPM0ZMGLzY+ppk3aSiIRkA0FytbL+gJmNjN2Pl7s/FLNbbmZ3An9qqq2ZZQMnADtGksTpZnYPcCbwGnAsMMfdH4y0vwG4BNgXeCXemE6/5VWymhrT3MhhO47g0iMmNTh20/8+47lPl8T1nNP22Ybv7juuwbEr/v0h789dHdf1lxy+A9/aqeFfhC74+zS+Xlkc1/VXn7gLe4xr+D5P/vPLrC+tauaKhm47e2+2GdK7wbFDrn0mrmsBHrr0QPrlZm7aX1dSySk3xf0x8cKvD2+wP3fFRi686624ru2bk8G/fnRQg2PvzVnFlQ9/1MwVDY0dnMdfzpna4Niznyzm5mc+j+v63bcZyDUn7drg2ANvzOGfb86N63r97OlnL5Z+9vSzFw/97OlnL6E/e8M+iR4YvxvvrQtx5e3xxd/pP3vpP2iwe9jSWi5t1EQ/e13oZ6+D/t2r2LAqrnvESkRP2yPAP8ysECBSgORm4MF2uPc+wBfNnBsHmLt/GXNsOjAxsj0RmFF/wt3DwOcx5zeJDLMsiH0Bw7c+fBERERHZJFwHn0+L7u9zQuJi2RJao03aSSKStquBVcA8IB9YBoSBP2zNTc3sAOBs4FfNNMkBGv9ZoYjosMwcYGML52NdCixo9JrWRDsRERER2VJV5dHtCXvCiPGJi2VLpKYlOgLpJszdE/Ngs77AWGCluy+O85pTic6HW+Tu20eO7w78DzjV3V9s5todgffdPT3m2EnAz919RzO7Gchy93Njzj8PPOfuNze6Vz5BwhlrODBtwYIFFBQUxPN2RERERKQ58z+Df0T+Fm8GF/4FBjYxbyyZPHA1zIkZPvf9a2HMlISFI8lp4cKFFBYWAhS6+8J4rknk4tppBD1s1fFe4O4PuntO5FWfsO0IPA2c01zCFjEHcDPbLubYFGBmZHsmMLn+hJkZMCnmfGwcRe6+MPYFLI33fYiIiIhIC9zhpfui+zsemPwJG2xeQVLVI6WdJGKdtv5m9iywAvgAWGZmz5pZ/y2410TgeeBid3+ipbbuXgY8ClxrZrlmNomgCMk9kSaPAePN7GQzywB+CpQDb7Q1LhERERHZCrPeg6Vzgu3UNNj/lMTGE6/GSZuqR0o7SURP298ISv1PALKA7YHayPG2+gkwALjLzErrX/UnzeyXZvZcTPsLIs9eQZDsXeXurwG4+zrgaIJFv4uA44Gj3L12C+ISERFpqKoi0RGIdA11dfDyA9H93Q6H/AGJi6ctGpf9z9qSFa1ENpeIkjYHEIzfrC/6MdvMvgfMb+uN3P0M4IwWzv+u0X4RQdn/5tq/TpBEioiItI8V84OFgWe/Bz/6O2T3bvUSkS5r/UpY8DkMHxf0Opm1/R7TX4U1kZL4GVldq2Jk/Xt2D3oIM3slOiLpJhKRtBURWVQ7hhOs3yYiItK9PHkbLIus6fTBc7D/SVt2H3dY8hX0G6LET5JTTTXc+VMoi/xdvu8Q2H4v2G7PIImLJ4GrqYbXYpbh/caxkJ3XMfF2hPTMIMl89ynY+9gtS1pFmpCIpO1XwH1m9nNgIVAAXAf8MgGxiIiIdKy9job/3BBsv/+/4Be5tPQWL9mMOzx+M3z6StDzcPIvVZFOks/iL6MJG8D6FTDtv8Ert29Qsn+f70Be3+bv8cGzsHFtsJ3dG75xdIeG3CEO+i4ccCqEElnvT7qbRPw0PQgcBcwCKiJfjwEeNLO6+lcC4hIREWl/2+8FvSO1tso2wmdbUN/qzf8ECRsEc+MeuBo+e7P9YhRpDwu/aP5cyXp4/xl49I8Nj8/+AF5/GKoroaIM3nwkem7fE4Oeq65ICZu0s0T0tO2fgGeKiIgkRkoq7PFteCFSrPjtx2Gng+IbNrVqEXz4fNBDF6uuFh6/CQomttxrIdKZFsasknTsj4LKibPeg9nvQ3lxcHzB58Fw4WHbBPM9H/pN0JO8cCYMHw/lJUG7/IGw22Gd/x5EklSnJm1mlgocDlzh7pWd+WwREZGE2fngYJ5OdWVQYOGdJ5sf9rV6CXzxNnzxVpC0xSrYHorXB8POamtg4ecwad8OD1+kVTXVsPSr6P7YHSG3D2y7W1AN8r83wueR3uG3H4fvXBb8nHukzMG86bDgs+j1B54W/MFDRIBOHh4ZKZ9/thI2ERHpUbKyYZdDovvP3w0v3hf9hXXdcnjt33DbhXDr+fDqg5snbMO2gZN/1TBJq1/HSiTRls4J/pAA0H9YkLDVS0mBqcdH92e+BRtWw1cfNLxHOBx8HVygP0aINJKIP2G8YmYHufvLCXi2iIhIYux3MiyZHVSABJj2KPQZBGkZwVDH+l9YY6Wlw/jdgoRv9ORgSOXwcdHzStokWcQOjRzVxOpJQwqDn+H5M4I/Vjx/F6xc2PS9Djpdc8JEGklE0rYceMzMHgcWAJv+L+Xu1yQgHhERkY6XlQ3f/y088gf46sPg2Iv/COanxSZsaemwzS4wcW8Yv+vmhRhik7aV84PrNYxMEm1RTBGSgolNt/nGMUHSBvDlu9Hjmb2gsjzYHjUBxu3SMTGKdGGJ+Fd+EvAxMDLyqueAkjYREem+0jPgxF/AXy4KhkTW/6IKwZCyA05tOlGLld07KNJQtDqYR7R6MQwZHX8MG1YFvzBP2Av6DNzy9yJSr64WFs+K7jeXtG2zU3AutlcO4IDToLY6mO950Ola20ykCZ2etLm7qkeKiEjPlZYOR10I98QsT5qaFiRzgwviu8fwcUHSBsEQyXiTtjVL4e8/g4rSYHjm+TdDXr82hS+ymTkfQ01VsN13MOQPaLqdGRz5Q/jLxRCOWd1p/K7BdSLSLA0YFhER6WyFOwQVJesd/P34EzYIipLUi3deW8kGuP/KIGGDYM24h/8Q9JKIbI3PXo9uT5zactuBI2Gvo6L7A0YoYROJQ0IGwZvZWcBBwEBgUx+4ux+QiHhEREQ63ZE/hEEFwXDHHVr5RbexYTHz2pbPje+aR/8Y7Z2rt3gWPH8PHH5u254vUq+iLFiHrd7kOAZU7X8yrFwAy7+GQ8/suNhEupFO72kzs2uA3wOrgD2Bz4AdgBmdHYuIiEjCpKTCnkfCpH3aPodn2NjoNasWBb1mLSlaA/Mja2CZwQ77RM+99zTMeL1tzxepN+vdaKn/IaNh4IjWr0nPhNOvhv97SEVHROKUiOGR3wUOdfdLgcrI12OBoQmIRUREpOtJz4TBhcG2Ozz4m6AoSXPmTY9uj5kCJ/w0KERS78lbmy+/LtKS2IR/0n7xX6diIyJtkoikrb+7f1y/Y2bm7tMIhkuKiIhIPA48LfqL75LZ8Oifml7rDeDrT6LbY3YMrjv2UhgwPDhWUw3/+l0w1E0kXuUlsCCmB3fSPi23F5EtloikbaWZDYlsLwL2MrPxCYhDRESk6xq/Kxx2dnT/y3fg+bs3bxcOR9fGAhi7Y/A1IwtO+mV0eYH1K+C/NwY9dyLxWPB59Odl+DhVIhXpQIlI2v4F1M9SvRN4hWDdtn8mIBYREZGua89vN6zE9+5T8M6TDdusmBf0iADk9oFBo6LnBo6AYy6J7n/1Abz9eMfFK93Lgs+j26MnJy4OkR4gEeu0XRGz/VczmwHkAS90diwiIiJd3qFnwca18MXbwf7zdwc9HsXr4NOXG85VGz1l87lEE/cOlg2oT9beeRL2PrYzIpeuLrYHt3CHxMUh0gMkpOR/LHd/J9ExiIiIdFlmcNyPoWR9UMLfPVh/rSn1QyMb++bp8P7/giqAJeuDuW1Z2R0Xs2yZ6sogGa+piryqoTbyGlQA/Yd1XiwlG2DNkmA7JRVGbNd5zxbpgTo9aTOzbOBSYDcgN/ac1mkTERHZAmnpcOqv4e8/g7XLmm5jFlSObEpKKvQdAqsXB/vrlzdcwFsSa8MqmPYofPJy84uhp6TCWb+HEZ1UJiB2aOSIbSE9o3OeK9JDJWJO293AGcAc4I1GLxEREdkSvXLhu1cFi3XX2+NImLxfMFxy/1OCOW3N6Rez8s665R0VZc9WWgQrFrSt2MvSOXDbhfDh880nbBCce/bOziskU181EjQ0UqQTJGJ45CHAdu6+MgHPFhER6b76DobzboTprwa/SBdsH/+1TSVtNdVBL540VFUBa5fCkDEQivPv3xvXwq3nB9ce+UPY7VvxXffCP4JhkfXyB0JmL0jLgNT04LXgs2Bo69I58PmbMGnftr+ntnBvNJ9tUsc+T0QSkrRtBNYn4LkiIiLdX5+BsP9Jbb8uNmlbsxQeuDpY3+2QMxtWqOzpqqvgbz8KhqHu9E045uL4rvvsjSBhgyCpjidpWzwLFs4MtkMpcPpVQZXGxsVkXrwvGD4J8NJ9sN2eHZtsz/4A1kf+9p6W0XlDMkV6sEQMj7wO+I2ZJeLZIiIi0pTYpG32+zDno2CNt9f+BXV1iYurMxStCapmrlvRetvpr0bnDU5/Bco2xveMrz+Nbi+fF/SMNcUdpr8Gbz0Or8SshjR5v2BOYuOEDWDq8dFhsUVrYOZb8cW0Jerq4KV7o/s7HwypaR33PBEBOilpM7MFZjbfzOYDPycoRFJcfyzmnIiIiCRCv5jKgzVV0e3KMlg2p/Pj6Sx1dXDfr+G5u+Cuy4LKmc0Jh+GdJxrux5MgVVfBoi9inlkLK5r5tefdp4JFzl+4B+ZH5o2Zwd7HNX//rOyGvaFfdmBh7k9fDnpiIVigfb8TO+5ZIrJJZw2PvKqTniMiIiJbIrcPpGc2nD9Vb85HMLKblnSf81G056y0CN57uunhpe7B4uONi7TMeB12P7zlZyycuXkRkaVzNh9WuGE1vPzA5tdvt0ewEHpLJuwFL90fbM/7NPgc0zNbvqatVi8Jhl/Wi+3hE5EO1SlJm7vf13orERERSRizoOz/ygWbn5v7MRz03c6PqTN8+GzD/XeeCKpuxq5T9/w9QTLXVPXGJbOD+V19Bzf/jHmfbn5s6VfAkdF9d3jmb9Fezty+wWeSlRPMK2xN/2EwaBSsWhQUkJn7CWy/V+vXxWvD6qBHsrwk2M/rB3t+u/3uLyIt6rR5ZWaWamZpjY5938xuMrNjOysOERERaUbsvLZYy+cFiyl3N+tWBMlNrMoyeO+p6P7GtfD24w0TtpTUhr1kL90HC2YGyVJTGj8DIklbxJKv4J7/g68+jB476f/gZ/fChbe1nBDG2m7P6Ha8QyTD4SD20qLm25QWBQlb8bpgPz0TTv5l+/fkiUizOrN65MPAC8CdAGZ2OXAF8Blwnpld5O53dWI8IiIiEqu5pA2CSpI7Hth5sXSGj1+IbvfKg/LiYPudJ2GPbwe9bbHJFQRVHA84BfIHwZIbgmMz3wpe9cncqIlB0ZCC7YNEZ82SoF19wY7amqB3bvEsePuJzROsXQ+Dkdu2/f1M2BNe/3ewPefD4DmtFQl54hb49JUgMfzhzcFyArEqyuD+K6PDQlNSg4Xch49re3wissU6s4LjLsD/YvYvAs52912A04AftvWGZraDmX1sZhsir5fNrNlFacws38weMbMSM1tmZuc3Or+vmc00s3Ize6+le4mIiHQ7/Yc13B8yOro956POjaWj1dbAxy9F94++OPr+K8uiBUeWxhRh+cYxcPkjsM8JsO3um/eA1dXCwi/gjYeDnrNXHmz4fRu1fcPv6d8va5iwhVKCoZnfOmfL3tPgwmAdN4DKcpg3veX2S+cECRsESeSs9xqer66CB6+JFk0xgxN/DqO1LptIZ+vMpK2Puy8HMLMJQG/gkci5J4CCLbjnUuA4oC/QH3gK+E8L7W8j6F0cChwOXG1m+0di6gc8SbAkQR/gceBJM0vEWnYiIiKdr3FP2yFnRLfnfNR0kZKu6ou3oz1r+QNh/K6wX0wBkveegorShknbyO2i65+lZwQ9Uyf8FHY9dPOEF4L5crGJ0LhdYHgza5pN3Bsu/iscfu6Wl9A3C+5Tb/qrLbd/9aGG+zOnRbfrauHh38OiL6PHjr44KIoiIp2uM5O2MjPLjWzvAsx09/p//Y0tGKrp7hvcfaG7e+QedcAYs80XMTGzbOAE4HJ3L3H36cA9QP3s3mOBOe7+oLtXATcAvYB92xqXiIhIlzRgZFDGHYJhfqMnw4BI1cLqSvjy3cTF1t4+fC66vcshEArBDvvE9LaVw1uPwbK50XaNE67MXjBpX/j2BXDJ3+Cy+4OeqNy+wfnykqCIS73xuwW9bbEKJsJ5fwqu6zdk69/XlAOi27PeCxLPxurq4It3GsYGwVpy9YVGnrmjYS/hYWfDTgdtfXwiskU6sxdpGvBbM7uTYCjk8zHnxgNxrGjZNDMrAnIIktCrI0lcY+MAc/eYPxkxHTg4sj0RmFF/wt3DZvZ55PgrjZ6XD+Q3uv/wLY1fREQkKWRlw6lXBL/M73xw0HMz5YBomfdPX4Ep+yc2xvawcmG0BymUErxXCBK3/U+G//wx2H/rv0GhDoDe/SGvb8v3ze0T9HQtnRMUL4k1YHiQlPUZFCwRULQ6mLs2bpemF8zeUoNGwdCxsPzroLfs82mw22GwYVWQlH39KcyfEQwBbSxcFyTmoybARzHz/fY9seE6cCLS6Tozafs58CxwITATuDHm3KlAHKtTNs3d8yM9ad8DFjXTLAcobnSsCMiNOd+4NFbs+ViXAlduQagiIiLJrXBi8Ko3eT94+f6gJP2Cz4Jqir37Jyy8dhHbyzZhT8jJj+5PnAqvPxwUD6lP2ACGtaHwxg5TN0/axu0afA2F4IgftDnkNplyQJC0QTC/7u3HYX0zfxtPSQ2S1g8iSx/MnAaLvww+b4BtdoIDT+3YeEWkVZ02PNLdF7j7dkB/d5/k7utjTl8PXNzaPczsVDMrjby+aHT/MuBvwP1mNrCJy0uBvEbHegMlcZ6PdRNQ2Og1tbX4RUREupze/YNhkhD8Ij/jtcTG0x5mxQzz3O1bDc+FQg3nttVrS7XEoWM3L1Iyfrf4r99ak/YNkjEIqlc2lbDl9g2qgZ7x26CwSr150xvOhdvvpPbtCRSRLdKZc9oAaJSs1R8rcvfyOK590N1zIq+mKjuGCOahNTEbmDmAm9l2McemEPT6Efk6uf5EZF7cpJjzjeNdGPsiKIoiIiLS/cTOk3rvaaiqSFwsW6uiLLrmXGpaMKessYl7R+fy1WuugEhTzIL5cfUys4MiJp0lOw8mNFpYOy0dttk5mJt20e3BGnDHXhoMhezdPyjEUq++l61gYufGLSLN6vSkrT2Z2SFmNtnMUswsj2DI5QZgVuO2kZ64R4FrzSzXzCYRFCG5J9LkMWC8mZ1sZhnAT4Fy4I3OeC8iIiJJa8Je0eIaJRuia4F1RbG9Tn0GN92LFAoFa7HVM4NhY9v2nCkHRHu7Ju0LKSltj3VrHHk+TD0u6EU747fwy3/D6VcFc9MGjtj8fR/7o81L+e/7nU4LV0Ra1qWTNoLS/I8AG4F5wBjg0PqqlGb2SzOLGbjOBYATFD15HrjK3V8DcPd1wNHA5QRz2Y4HjnL32k55JyIiIskqPaNh+f93n4K1yxIXz9aITdpaWkx8+29Eh4VOOQDSM9v2nP7D4KzfB2XyY793nSUrGw7+Pnzz9CAZa20ZgV65cPo1MPX4oGdwl0OCBcJFJClY04UWpa3MrABYsGDBAgoKChIcjYiISDtzh7t/Ea26OHZHOP3qpnuqwmF48V7YuAYOPSu5Cpe8/jC88s9g+xvHwKFnNt+2ri54D30G9ax5Xe496/2KdLKFCxdSWFgIUBiZZtWqrt7TJiIiIp3BDA4/L/rL/Nefwuz3m2770fNBxcKZbwVrnSWT2J62vq2si5aSEhQU6WkJTE97vyJdgJI2ERERic+Q0cHaYvWe/TvUVAcLUd/1c7julKD64NN/jbZ57+lOD7NF65ZHt1saHikikkQ6c502ERER6eoOPC1Yy6u8JFggur4nrX7Y5CM3NGzf1rlgHS02aWutp01EJEmop01ERETi1ysXDvxudH/af+C9p6L75cUN24froiXkE62yHMo2BtupaZA/ILHxiIjESUmbiIiItM0uhwRDJSEYHlle0nzb2ppoopRo8ZT7FxFJQkraREREpG1CITjiB5sfT2lm1sXGNR0bT7ziLfcvIpJklLSJiIhI243cDibvH93vlQfH/6TptkVJkrRpPpuIdFEqRNIJ3J2SkhLKy8sJh8OJDqfbC4VC9OrVi9zcXExDX0REOs7B34dlc4Jk6NAzYeLeQeGRDatgxXz4+MWgXbL0tDWoHKmkTUS6DiVtnWD9+vWYGf379yclJUWJRAdyd+rq6iguLmb9+vX069cv0SGJiHRfeX3h/FugthqycoJj43YJvr75aLRdUiZtGh4pIl2Hhkd2gqqqKvr06UNqaqoStg5mZqSmptKnTx+qqqoSHY6ISPeXlh5N2GLlD4xuJ8vwyAYLaytpE5GuQ0lbJ1Gy1rn0/RYRSbDYcvrJ0NNWVQGlRcF2Sir07p/QcERE2kJJm4iIiLS/3jFJW9HqxMVRr0Ev2+CgAqaISBehf7GkRa+//jqDBw9OdBgiItLV5PaNJkZlG4P13BKpQeVIDY0Uka5FSZsA8M477zB16lTy8/PJz89nl1124dlnn010WCIi0lWFQpAXMwQx0UMkVTlSRLowJW1CcXExhx9+OGeffTZr165l1apV/PnPfyYvL69dn1NbW9uu9xMRkSSXTPPatLC2iHRhStqEOXPmUFNTw/e+9z1SU1PJyMhg6tSp7L333pva3HrrrQwZMoQBAwbwu9/9btPxjz76iD333JP8/HyGDBnCxRdfTE1NzabzZsatt97KuHHjGDJkyKZjN998M2PGjKFfv35ceuml1NXVbbrmmWeeYccddyQ/P5899tiDTz75pBO+CyIi0u4azGtLpp42JW0i0rUoaRPGjRtHZmYmp512Gs888wxr165tcH7t2rUsWbKEhQsX8vzzz3PVVVfxxRdfAJCSksKNN97I2rVrefvtt3n++ee54447Glz/+OOP884777B48eJNx/773//ywQcfMGPGDF544QX++te/AvDpp5/yve99j9tvv53169dz0UUXceSRR1JeXt7B3wUREWl3sUnbhlWJiwMaFSLR8EgR6Vq0uHYi/PrIznvWtU+32iQvL4933nmH66+/nvPPP5+lS5ey3377ceeddwIQCoX4zW9+Q3p6OjvvvDOTJ0/m008/Zfvtt2fHHXfcdJ/Ro0dz7rnn8sYbb3DhhRduOv6LX/yC/v0blla+7LLLNi18/aMf/Yj77ruPCy+8kDvvvJNzzjmHPffcE4BTTz2V3/3ud0ybNo1DDjlkq78dIiLSifrEFLJ6/2nY/hswpLDz46iqgJINwXZKasNkUkSkC1BPmwBBb9tdd93FokWLmD9/PqmpqXz3u98FoG/fvqSnp29qm52dTWlpKQBfffUVhx9+OIMHDyYvL48rrrhis566ESNGbPa82GOjRo1i+fJg2MqiRYu4+eabNxVEyc/PZ8GCBZvOi4hIF7L9N4IqkgCV5fDAVbAhAeX/Y3vZ+gxSuX8R6XL0r5ZsZtSoUVx00UV8/vnnrbb94Q9/yPjx45k7dy7FxcVcc801uHuDNk0tdL1kyZJN24sXL2bo0GB+wYgRI/j5z39OUVHRpld5eTlnnHHGVr4rERHpdFnZcPrVkNkr2C9ZD/dfAeUlnRuH5rOJSBen4ZGJEMeQxc40e/Zsnn76aU488URGjBjBmjVruOuuuzYNUWxJaWkpeXl55OTkMGvWLO644w6GDRvW6nV//OMf2WuvvaioqODPf/4zP/jBDwA455xzOOqoozj44IPZfffdqaio4M0332SPPfagT58+W/1eRUSkkw0ugFMuh/uugLpaWLsM/nkNfP83kJ7ROTGocqSIdHHqaRNyc3P56KOP2GuvvcjNzWXKlCnk5ORw3333tXrtH//4R/71r3+Rm5vLeeedx4knnhjXM4855hh23XVXdthhBw466CDOP/98AHbZZRfuvvtuLrnkEvr27cvYsWO56667tur9iYhIghXuAMf/BOpHXiyZDY9cDzGVgzvUOiVtItK1WeOhbLJlzKwAWLBgwQIKCgoanFu+fPmm4X8SDJecNWsW2267bYc+R993EZEk8+7T8Oyd0f2dD4ajLowmcx3l75fB4lnB9veugbE7ttxeRKQDLVy4kMLCQoBCd18YzzXqaRMREZHOseeRMPX46P7HL8Ks9zr2mXM/iSZsAAM2L44lIpLslLSJiIhI5/nm6TBx7+j+gtaLXm2xqgp46rbo/g5ToXf/5tuLiCQpFSKRTqchuSIiPZgZbLs7zHwr2C/d0HHPevFeKFoTbPfKhcPP67hniYh0IPW0iYiISOfKiakGXFrUMc9YMBM+eDa6f/h5kN27Y54lItLBlLSJiIhI58rJj253RE9bdRU8cUt0f/xusMM+7f8cEZFOoqRNREREOldLPW0lG7Z+8e1XH4yuzZbZC759fsdXqBQR6UDdJmkzs6vMzM3s0Bba5JvZI2ZWYmbLzOz8Ruf3NbOZZlZuZu+Z2fYdH7mIiEgP0ysXQinBdmUZ1FQH2/NmwA3fgz9+H1Yv2bJ7L50D7zwR3T/kLMjrtzXRiogkXLdI2sxsHHA8sKKVprcRFF8ZChwOXG1m+0fu0Q94ErgO6AM8DjxpZirWIiIi0p7MGs4vq+9te/txcA+SuOmvtv2+tTXw+M3BPQBGT4adv7nV4YqIJFq3SNqAvwE/Aaqba2Bm2cAJwOXuXuLu04F7gDMjTY4F5rj7g+5eBdwA9AL27cjARUREeqTcmCGSZUVQUQbzZ0SPLZvb9ntO+y+sXhxsp2XA0RdpWKSIdAtdPmkzs9OBde7+QitNxwHm7l/GHJsOTIxsTwQ2/d/C3cPA5zHnY5+Zb2YFsS9g+Ja/i+Rw6KGHkp2dTUnJVs4lEBERaU12fnS7ZAN89QHU1UaPLZ8b7TFrTjgcLJ69bnmw/eFz0XPf/B70GdSuIYuIJEqXTtrMrC9wFXBpHM1zgOJGx4qA3JjzG1s4H+tSYEGj17Q4Ykhay5Yt4+WXXyYzM5NHHnmkXe9dV1entdlERKShxj1tX77T8HxleZCMteTVh+D+K+H2S+DjF6FkfXA8uzfs9q12DVdEJJG6VNJmZqeaWWnk9QVwPXC7uy+L4/JSIK/Rsd5ASZznY90EFDZ6TY3rTSSpBx54gClTpvCDH/yA++67j6qqKvr06cOnn366qU1JSQm9evVi3rx5ADzzzDPsuOOO5Ofns8cee/DJJ59saltQUMB1113HlClT6NWrFxs3buT6669nzJgx5ObmMmHCBJ566qlN7cPhML/4xS8YOHAgw4cP595778XMmD17NgBVVVVcdtlljBo1ioEDB3L22WdTVlbWSd8dERFpd7E9betXwNefbN5m6ZyW7zHt0eBrdSU89Zfo8Yl7Q0rKVocoIpIsulTSFplvlhN5bQ8cBFxmZivNbCUwAnjIzH7VxOVzADez7WKOTQFmRrZnApPrT5iZAZNizsfGUeTuC2NfwNJ2eIsJc99993Hqqady6qmn8tZbb7Fs2TKOO+44HnrooU1tHnvsMSZPnsyYMWP49NNP+d73vsftt9/O+vXrueiiizjyyCMpLy/f1P6hhx7iiSeeoLi4mLy8PMaMGcO0adPYuHEjl19+OaeccgqrVq0C4O677+a///0v77//PrNnz+aFFxqOdv3FL37BF198wccff8z8+fNZu3Ytl19+eed8c0REpP3F9rR98nK0gmSslua1lW2EcF3T57Qmm4h0M9aVh62Z2QAg9k9pHwKXAU+7e2kT7R8EMoAzCHrHXgZOdPfXItUj5wE/BB4DLgbOA7Z199rG92ri3gXAggULFlBQUNDg3PLlyxk6dGiDYw+8MYd/vhnfJOvDdhzBpUdManDspv99xnOfNl8O+bR9tuG7+46L6/7vvfcee++9N0uXLmXw4MHstNNOHHnkkey3336cfvrpLFq0iFAoxCGHHMKRRx7JhRdeyA9/+EPy8/O57rrrNt1n++2358Ybb+SQQw6hoKCAX/7yl5x77rnNPnfixIn84Q9/4PDDD+eAAw7g2GOP5cILLwRg7ty5jBs3jlmzZjF+/HhycnL45JNPGD9+PAAffvgh3/72t1mxovmCoU1930VEJEl89ib854bNjw/bJpqsjRgP5/6x6etnvQ8P/Wbz4737w0/uUQESEUlaCxcupLCwEKAw0vnTqi7V09aYu69x95X1L6AO2FCfsJnZL80sZlYyFwBOsDTA88BV7v5a5F7rgKOBywnmsh0PHBVPwtbV3XvvvRxwwAEMHjwYgFNPPZX777+fffbZB3fnzTffZPXq1bz55puceOKJACxatIibb76Z/Pz8Ta8FCxawfHl0/sGIESM2e87kyZM3tZ89ezZr164FggQrtv3IkSM3ba9Zs4by8nJ23333TdcedNBBFBUVUVNT02HfFxER6UCxPW2xvnFMdHv5vIbFSWItmd308YlTlbCJSLfTrdYgc/eCRvu/a7RfRFD2v7nrXwd61ILalZWVPPzww9TU1GxK2qqrq9mwYQPTpk3j5JNP5sEHH2TSpEnsv//+DBgwAAgSsp///OdceeWVzd7bYv6nuWjRIs4991xeffVV9txzT1JSUpg4ceKmAiVDhw5lyZJoz+HixYs3bffv35+srCxmzJjBqFGj2vX9i4hIgsTOaatnBtvsDH0Hw/qVQcK27GsYue3mbRd/ufmxUAgm79/uoYqIJFq3Stq6ku/uOy7u4YtNufSISZsNmdwSTzzxBO7OF198QUZGxqbj5557Lvfeey+XXnopBxxwAJ9++ik/+tGPNp0/55xzOOqoozj44IPZfffdqaio4M0332SPPfagT5/N/3paVlaGmW1K+u66665NRUYATjzxRG688UaOOOIIBgwYwFVXXbXpXCgU4pxzzuHHP/4xt99+O4MGDWLZsmXMmDGDb31L1cFERLqkpnra+g+HzF7BEMn1K4NjD14Lx/0Ixu0SbVdX23C+26V3wOfTYOgYGFLYsXGLiCRAlx4eKVvv3nvv5Xvf+x6jRo1i8ODBm16XXHIJjz76KGPHjmXIkCHMmjWLo48+etN1u+yyC3fffTeXXHIJffv2ZezYsdx1113NPmfChAn85Cc/YY899mDw4MHMnj2b3XfffdP5s88+m6OOOopdd92V8ePHs99++wFsSiSvv/56tt12W/bcc0/y8vI46KCDmDVrVod8T0REpBNkZkNKo78dj4j0qO1xZHSIY3kxPHA1PH9PdKjk8nlQGxke33cw9BsK+53YMLETEelGunQhkmTS1kIk0rJZs2ax/fbbU1lZSXp6+hbdQ993EZEk98czYOPa6P63L4BdDw22F3wO//ljdO01CHrgTvhZsKbbi/cGxybvD8f/uNNCFhHZWj2uEIl0HxUVFfzvf/+jpqaGtWvX8tOf/pQjjjhiixM2ERHpAnIaDZEcPj66XbgDXHArjN81emzZXLj9Ynj5/uixkbEr+YiIdE9K2iQpuDvXXHMNffv2Zfz48WRmZnLHHXckOiwREelIHm64P3Bkw/3sPDj113DoWdGhlNWVEI5cl90btt+r4+MUEUkwFSKRpNCrVy8++OCDRIchIiKdqWh1w/2UlM3bmME3joaC7eGR66MFSgp3gKMuDBI3EZFuTkmbiIiIJMb234APnw+2t9m55bbDtoEf3gzTX4W8frDdHlqPTUR6DCVtncTdG6xbJh1LBXZERLqAqScEBUcg6DVrTWYv2OOIjo1JRCQJKWnrBCkpKdTU1KioRieqqakhpalhNiIikjz6DISL/6oeMxGRVqgQSSfIy8tj/fr1VFdXqweog7k71dXVrF+/nry8vESHIyIirVHCJiLSKvW0dYKsrCwANmzYQF1dXYKj6f5SUlLo3bv3pu+7iIiIiEhXpqStk2RlZSmJEBERERGRNtPwSBERERERkSSmpE1ERERERCSJKWkTERERERFJYprT1n5SAJYuXZroOEREREREJEnF5Atxr09lKkHfPsxsb2BaouMQEREREZEuYaq7vxVPQyVt7cTMMoBdgRWA6vq3j+EEifBUoP5PEguAwoRFJLHa47No6jOWtukK/030lM+5K3wWHSEZP9+e+ll0lC39jPU5JI/YzyIZ/5vtSRYAY4EhwIfuXhXPRRoe2U4i3/C4MmWJj0UXXF3q7gvrj9VvS2K1x2fR1GcsbdMV/pvoKZ9zV/gsOkIyfr499bPoKFv6GetzSB6xn0Uy/jfbk0Q+i3nAvLZcp0IkIiIiIiIiSUxJm3Q1Vyc6ANlEn0Vy0OeQPPRZJA99FslBn0Py0GeRPLbos9CcNklaZlZAZAy2uu+7J33GPYM+5+5Nn2/3p8+4e9Hn2TWpp02SWRHBXyOKEhuGdKAi9Bn3BEXoc+7OitDn290Voc+4OylCn2eXo542ERERERGRJKaeNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhERERERkSSmpE1ERERERCSJKWkTERERERFJYkraREREREREkpiSNhER6VbM7Coze72nx9AZzOw5M/vlVlxfYGZuZgXtGJaISLeTmugAREQkeZlZacxuOpACVMQcm+Dui9vxea8DewHVMYcvc/fb2+sZ0n7c/bBExyAi0hMoaRMRkWa5e079tpldBezn7vt18GN/5+5XddTNzSzN3Ws66v49gZmlAnXu7omORUSkJ9DwSBER2SJmNsLM/mtmq81suZndbWZ9Ys6/bma3mNkTZlZiZnPN7NQOiOO7kXuXmNljQJ9G5+vjeNTMioDrzGyImT0Tib3YzD40swNirvmvmV0Ts/+hmS2O2b/AzN5uQwx9zeyeyPdpdeT+wyPndjCzSjPLiuwfHhkyeGZk38xslZl9M+b93GhmD0ViX2Jm57byPXIzu9TMPo7E+L6Z7dSozelmNsPMNprZF2Z2Usy5/SL3OMnMvgbKgexILFfFtNvezF40s3VmtsjM/mhmmTHnx5jZK5G4ZwEHNIphspm9YWZFZrYhEu/4lt6biEhPoKRNRETazMxSgGeAEmAMMBkYCdzXqOnZwN8JkphLgXvMbPdWbn9h5Bf22Wb2ezPLaa6hme0F3BW5dx/gbuCcJpqeGYmjL3AFwTDPu4BCoD/wJPC4mfWPtH8JqE+S+gLjgZSYBOKbwIttiOGfwDBgEsH3qxx4ysxS3P1zYAOwT8y959Y/n+B7mwdMi7nfGcCdQD7wE+B2Myts7vsUcT5wWuT9Pgc8Z2a5kffwfeCayPepD3AecIeZ7d3oHscDu0XiKYs9YWZ5wMvAh5H3ui9wEHB95HwK8DSwABgSOdf4+3Q78EokxgHAWUBRK+9LRKTbU9ImIiJbYjdgAnCxu5e4+xrgR8CRZjY4pt3T7v6Mu9e6+zPAEwSJQXN+CYwD+gHfIfjF/u4W2p8BPNHoGU830e5xd3/B3cPuXu7uS939cXcvc/dqd/8N4MCukfYvAbuaWX4khmnAC8DBkaGB+0fatBqDmQ0BDgN+5O5r3b0EuJAgGat/3svAwZHtgyPfh4PMzCL709y9Mub9/MfdX4+8n0cIEpsGPWdN+LO7z3L3KoIELQwcETn3Y+Bad/84cs+3gIeA7ze6x8/dfb27VzYxNPLwyNcrIucXApcDZ0fexx4En+2PIt/3ZZE4YlUTJP+jIt/L6e6+qpX3JSLS7SlpExGRLTECWOvuxTHHvo58HRlzbEGj6xZErm2Su78TSQrC7v4ZQe/VcfVDB5swvJlnNNbgWMxwxYWRoXpFBL1HAyNxzAMWEwzf+yZBglbf+1bfU/hBnDHUv9/5Me9zI7CG6PfqJeCbZjYMGAQ8BqwHdox5fqzljfZLgdwm3neTMbl7GFgUE9s2wM2RYYlFke/Hd4GhLbyvxkYAi9y9LubY10AWQa/ZcIKfmZIW7vd9guT51ciwzz+bWXYr70tEpNtT0iYiIltiCdC/fnhdxJjI19hqkgWNrisAlrbhOeHIV2vm/NJmntHcfer9nmBo5DeA3gRDAosbPeclgl6u+qGQLxEMYTwceM3da+OMYUnk66bhi5GhhP2Jfq9eBiYCpwOvRJKqF4GjgL3ZPGnbEptiMrMQQcJY/1msBM519/yYV467fyv2BpG4mrMEGBW5d70xBNVG10Se1b/RcNeCmG3cfZG7n+Puowh6Mw8GLmvDexQR6ZaUtImIyJb4EJhF0DuTE5kLdiPwjLuvjGl3pJkdZmYpZnYYcAzwj6ZuaGaDIm2zI8U3JgA3AU+5e3kzcdwHHNPoGUfGEX9vgmRiA5AJ/AZoPHfuJeAkIMXdv3T3tcA8grlhsUlUizG4+wrgeeBGM6tPWm4FviD4PuLuy4EvgZ8TmSsX+XoJwbzBGXG8p9ZcambjzSydYNhiKvC/yLmbgCvNbBczC5lZhpntamY7t+H+zxAkvVdHrh8FXAvcExlK+T5Bz9ufzKyXmQ0Ffh17AzP7vpkNjwynLAZqgTpERHo4JW0iItJmkV6mIwh6qBYAnxMM2Tu9UdO7CYpaFBEkKue4+7vN3DYTuDpynxLgKeB14HstxPFW5P63Rp5xLkFRkNb8miBxWwN8Baxi8x7AVwiGHMYmaC9Grtt0LM4YTos843OC71cucGSjoYQvRe5dn7S9BvQCXm6n0vp/I5intp7gs/tW/fBWd7+ZYH7ZHZHzy4AbgLiHJkbu9U1gT2AFwTzA14GfRc7XEiSz2xD07L0C3NPoNvsTDDstJUhU343EISLSo5mWWBERkY5gwULZr3fkmmsSHzNzYH93fz3RsYiISNupp01ERERERCSJKWkTERERERFJYhoeKSIiIiIiksTU0yYiIiIiIpLEUhMdQHdhZhnArgQVs1SeWEREREREmpICDAE+dPeqeC5Q0tZ+diUobywiIiIiItKaqcBb8TRU0tZ+VgBMmzaN4cOHJzqWFlWsXkEoLb3VdiVLV5Ca1Xit2ebN/WA2oYEDtya0uK2dOZ/t9prY5uvKi0rZ9uBd+Mcd/2LQ4P4dEJmIiIiIJJtVK9dyxnknJzoMAJYuXcrUqVMhkj/EQ0lb+6kDGD58OAUFBQkOpWXlGamE0jNabVccNlJ75cV939L+6wkNGrI1ocUttKyE4UOGtfm6soxiCgoK6Ne3PwMHDOqAyEREREQk2dRWk4y/o8c9pUqFSERERERERJKYkjYREREREZEkpqRNREREREQkiWlOWyepqKiguLiYurrErwZQW16BVVS32q46LY2Q18Z93+xxQ7CsrK0JLW5Ddi2kJqeFvzlU15FaDYZ1SjwiIiIiIh1FSVsnqKioYOPGjfTt25e0tDTMEptI1JQUYykprbarKiomlNZ6wZJ6KRWO5cRfbXJrlFbAwL5NV390d0oqyqjcUEZa4nNkEREREZGtouGRnaC4uJi+ffuSnp6e8IStJzAzsjN7QUbTP96lVbXUuD4HEREREekalLR1grq6OtLS0hIdRo8SMoNQ04nZmf/4kBdLe3dyRCIiIiIiW0bDIzuJetg6V0vf79kri6msyaTOnRR9LCIiIiKS5NTTJh2qsrKSM394Jtvvsj1n/OCMVtuP3HYkX8//GoD/u/L/+NMtf2rXeMprneLKWqo9xNKKdr21iIiIiEiH6PJJm5ldaGYfm1m1md3bStsTzGy+mZWZ2YtmNizm3L2Re5TGvOKvwtGFHXjooeT07Uf+wEEMGjGSw486mq/mzGnzff58x21c8OMLGhx75oVnWLlqJdPfnc4//vaPNt3vuquv4ycX/6TNcbRkdVV40/bXpepmExEREZHk1+WTNmA5cC1wd0uNzGw74B7gXKA/8BXwUKNmN7p7TsyrqiMCTkZ/uv4PFK1exbxZX9InP5+zzvtBm66vrW16aYBly5dRWFCYNHP6VlcHSVsKztw4k7aNNVAbbr2diIiIiEhH6PJJm7s/5u5PAOtaaXoa8Jy7v+zuFcDlwB5mNqajY+xKcnJyOOXkk5j5xRfMnTePw487hqHbjGbynrvxwL+jOe5vrv8DJ37vu5x9wQ8ZPKaAm26/jb/8406ee/E5tt1pW/Y7dD+u//P13Hz7zZuO3f/Q/bg7t//9dr5x4DeYvMdkzr3oXFavWd1kLD/+xY+57k/Xbdr/z2P/Yb9D92PibhM58yfn8fX8eW1+f2siPW1j0ytYWAY1rSRj1WG44asQL69Wr5yIiIiIJEZPKkQyEfigfsfdN5rZwsjx+t/+zzWzc4GFwO/d/ZGmbmRm+UB+o8PD2zfcxCguLubBf/2Lidtvzwnf+x4nnfAdHv/Xw8yY+TlHn/QdCkaOYupe3wDguZde5L47/s6dt/6Fqqoq1q9ax7xlS/jLjX/ZdL/U1FTmLZi36dh/HvsPDz78IA/c9QBDhwzlit9ewcU/vZh/3/fvFuN69/13ueYP1/DA3x9gwrYTuOnGP3LK2afz9guvt6kXb01VmPSUENtlVPBVdS8WlsE2uc23n18GlWFjdgkcOtjjfo6IiIiISHvpSUlbDrCx0bEioP5X9luAn0TaHAw8YmYr3f3NJu51KXDllgZy9dNf8OXy4i29PC4ThuZx5ZHbx93+Z7/4Py6/8iqyMjPZbddd+P1vruX4k07m5z/6MSkpKey6086cfvKpPPSfRzYlbTtP2ZFjjvw2AFlZWXE957GnH+Os089idOFoAC6/7HIm7T6JFStXMGTwkGave/zpxznh6BOYMmkKAOeddjYP/+9RPp7+CXvsunvc73N1VZih+ZkM92pCkSGS2+Q2n4x9VRL0sC2rgPJa6NWT/osRERERkaTQ5YdHtkEpkNfoWG+gBMDdP3H3de5e6+7PAv8EjmvmXjcBhY1eUzsi6M5yw++vY82ypSye9zWP/vvfLF+xgmFDhpCSkrKpzciRI1i+YsWm/eHDhjV1qxatWrWK4cOinZJ5uXn0zuvNylUrW7xu5aqVDIt5XkpKCsOGDGX5yhUtXLW51VVhhvXJIt2cEb1gQVnLwx6/KjFyUh3HmF/WpkeJiIiIiLSLntRvMBOYXL9jZnkEydbMZto32/3i7kUEvXSbtGUdtrb0gCXK0KFDWbZiBXV1dZsSt8WLlzB0SLQ3rPF7jud7MGjQIJYuW7ppv6S0hI3FGxk8aHCL1w0eNJhly5Zt2g+HwyxbsZyhLfTONWVNVZjJ+VmwAQp6OW+vM2rDkNrEny/WV8PqKuNbg8O8tCqoNjmxt4ZIioiIiEjn6vI9bWaWamaZQAqQYmaZZtbUJKd/AoeZ2QFmlkVQcfI9d58Xuc/xZpZjZiEzO5igcMmTnfU+ks3uu+5Kfl5vbrj5z1RXV/Px9E954N8PcfLxJzR7Tf++/Vi6bCnhcPPVPY454hjueeAeFixcQGVlJb+9/rfstvNuLQ6NBDj6iKN59IlHmfH5DKqrq7nzwbvJzcll5yk7xf2equuc9TXO0PxgKOeobKfWjWWVTbefExkauX2eU5gNX7fSKyciIiIi0hG6fNJGUAWyAvgFQaJVAfwdILLW2lQAd58FnAXcRVBpcjvglJj7XAIsI+hBuwE4x91f7Zy3kHzS0tJ45L57eeOtaYyaMJ4zfnAev7niKvb5xt7NXnP4QYeSkpLCpD0mceARBzbZ5vhjjuek407i1DNPZbd9d2PturXc8sdbWo1nrz324pc/+yUX//RidvrGTrz/6Yc8dNf9bStCUhksSzCsPmnrFRxf1Ewy9lWJkZ/mDMyAsTnOykqjpOmVDUREREREOoy5a7hXezCzAmDBggULKCgoaHBu+fLlDB06NBFhNammpBiLmavWnKqiYkJp8a8vvmbxKiwnZ2tCi1vpinUMLmy5d271+rWklUZ7/T5ZW8lP31/NQ+fszkePPc7QYYP47awQI3rB6aOi7dzh/fXGE8uNXfo4xw93FpfDLV+ncNrIMFPy9d+MiIiISFeyfNkqLv7ZOYkOA4CFCxdSWFgIUOjuC+O5pjv0tInEZVVFw542gIJsZ2FZkKgBlNXCfYtCPLosxOhsOCRS5n9YFqRakLyJiIiIiHSmnlSIRHq41RV1GDCkd0zS1gs+LTI21MDaKvj3khBldXDkkDBT+zuhyMjJFIOBGUFhkhZq1IiIiIiItDslbdJjrKqopU+akR5TKrIgO0jA/r0kxPwyY2CGc1ZhmGFNLDs3MMNZVK5iJCIiIiLSuZS0SZezoqKOleE0Wl4kIGp1RS2vLS/nk3WVDMxoOCJ4cCakh5z5ZcaefcMcOdRJb2bQ8MBMmLERqsM020ZEREREpL0paZMuZ15pHavCaewRdtJCLfd81bnzk/dWs6y8lmG9Ujl4UMNqkykGJ48IkxaCbXNbfu7ADHCMNVU02RMnIiIiItIRlLR1Endv0wLc0jQHiqqDSo9rK+sY0qvpH+H6qqjTVpSzrLyWX+/Yj/2HZlO2vniztjv0ju/ZgzKCe66uNIZlaV6biIiIiHQODfLqBBkZGWzYsIHa2lq0xMLWqaxzqsL1yVNdk23cncqaKrw6zL/mFTM8O5V9hvTa6mcPyADDWVW11bcSEREREYmbeto6Qd++fSkpKWHt2rWEw+HWL+hgteVlWKj1ddqqS8sIpca/eHVRSRFW27EZzbqqMKGKWgxYvjaFIWQ23bAmzMwVlcwtruEnO/QlpR16OVND0C8dVitpExEREZFOpKStE5gZeXl55OXlJToUAMpXLCWU3vqi2cUbikhNi3/y1rI5KwgNaXnB66317OIKHltSwY4plcyxLJ44eDihZhKyf31dTL+MFL45LLvdnj9AZf9FREREpJNpeKR0KQvLahmaFWJcqIbSWmdxaS3rq+pYWlbToN2cjdV8vLaS4wpzSU9pv7mEgzKdNVVQp5xNRERERDqJetqkS1lQWsd2vVMpLK4F4K2V5Ty9uJSww8MHDt3U6/bvecVkpxpHjMxp1+cPzIA6NzZUQ9ihX0ZQgVJEREREpKMoaZMuY2N1mPXVYQqyUxhQUkdeWoh75mzcdH7uxmrG52ewrKyGN1eU850xeeSktW9ncn0FyX8sDLGqytiht/PdkWFaWXlARERERGSLaXikbLWwO68sKqG2g4cMLiwLetcKc1Ixgwl90gH48Q59MeC91ZUAPDK/hJQQHFfQysJrW2BgJqSYs7EGJvUO8/lG47mVythEREREpOOop02a9M7CjRTUhMmPo+1LC0v4vzdXcFb/EAd2UDzVdc67a6sBKMhOoQQ4Z9t8jhhZy16DevH8klLeX1PBkaNyeH5pKQcPy6ZfZusVMtsqKwUuHhsmPw16pcBjy8O8tiZEv/Qwe/TTRDcRERERaX/qaZPNzFxZxpn/+Yq/f1EaV/v/RoYovlva/klSTdh5cUUlP/qkiDdXV7P3gHR6pQY/toW56ew1KFh/bfeBWXxVVM09XxVRG4bvjO64Sp3DsiA7Fczg6KHO+FznsWXGnJIOe6SIiIiI9GBdPmkzswvN7GMzqzaze1tpe4KZzTezMjN70cyGxZxLN7M7zKzIzNaY2TUdHnySuu+jlQC8sLiC2nDLvUeLNlbz0cpyBmSlMqvS2FDdPuvQ1Yad11ZW8pNPNnLv/HIGZqZw+cRczh/XdGGR3Qdm4cCzS8qYOjiLETnxry+3NVIMvjsyzKBMuH9RiJWVnfJYEREREelBEp60mdk2ZjYgst3LzK40s8vNrPWFxALLgWuBu1t5znbAPcC5QH/gK+ChmCZXAJOAscCuwClmdkab3kw3sLKkmue+Ws82/bNYXxXmveVlLbZ/fG4RqQa/3WcIjvFeZAjj1lhYWsvPPt3I3+eV0zvN+MWEXK6YmMuE3s0nYmPz0uibEfw4nzSmc9fDy0yBMwvCpIXg7gUhSmpav0ZEREREJF4JT9oIEqf6FZl/A5wAHA/cGM/F7v6Yuz8BrGul6WnAc+7+srtXAJcDe5jZmMj5M4Br3X2tuy8E/gSc2ZY30h08+Mkqwu7cctRYeqcb/5tX3Gzb6rowT88rZp8ROewyuBej0sO8u6Zqq2P416JyKuqcn2yXwzWT8pjUJw1rZgHteiEzjh6VyyHDs9k2P958v/30SQ8St9JauGdhiNfXGM+sMKYXGZH6KSIiIiIiWyQZCpGMAWZGto8D9gdKgU+BC9rxOROBD+p33H2jmS0EJprZemAoMCOm/XTgd03dyMzyYbMaHcPbL9Std9xf32HRujLSUkKkpYRITTEqquvYUF5NTW10CGN9MlSfEtWEnUPG9aGwbxYHj8ziyfmllFTXkZvecL5aXdi54q2VbKis48Rt+wCwZ06Yf6+v44uiGrbP37LhiSsq6vi8qJbjR2axc9/0Nl172ja9t+iZ7WVELzh1ZJj7F4VYUhEihBPGCOFcNDbMiF4JDU9EREREuqhkSNoMcDMbDbi7zwcws/Ye45YDbGx0rAjIjZyj0fn6c025FLiy/UJrf/uPH8CKjbnU1IWpqXOq68L0SkuhT3Y6VlGKpaTiROereWQzZMbxOwwA4PBRWfzn63JeWFDC8ePzY9o6f3h/FS8uLOHSnQew65AgG5maW8dr5en87osSjhqeyQkjs1rtIWvs5RWVpBgcMKjze8vaw8TecOWEYN22jBDMKYW7FqSwrMIY0UvVJUVERESk7ZIhaZsB/AoYCbwIECkQ0vy4vC1TCjROBHsDJZFzRM6XNjrXlJuAexsdGw5M29og28uFB2zT7LnyFUsJpbeeFG3XJ42x+ek8MXdjg6Ttb9PX8eicjXx/Yl9On9h30/HeKfC7yb35x/wynlhaycT8tBbnoTVWWee8sbqa3fulk5+eDCN3t0x2zH9V2+RACGeD5rmJiIiIyBZKht+MLwYOJSgAcm3k2EHAS+38nJnA5PqdSE9eITDT3TcQFDSZHNN+CtFhmw24e5G7L4x9AUvbOd6EMzOOGZfPl+sq+Wp9UBbxoS838PfP1nH0Nr25aKf+m12TlWqcVhj0vC0ojW8y1+dFNVz44QYu/LCI8jrnm0O6Zi9bU1IMeqfBhq2vzyIiIiIiPVTCe9rc/TNg70bH7gPui+d6M0sleB8pQIqZZQJ17t64b+OfwPtmdgDwLkGC+J67z4ucvxe43Mw+BLKBHwPXbdGb6ka+NTqPmz9aw2NzNrLDgCr++OFqDhiZwy/3GNTs0Me8tBB90o1FZXVxPeP9tdWU1zpTB2YwMDPEuNyE/1i2q/x02FBjgIZHioiIiEjbJcVvx2bWCxhPozlk7v5mHJdfTsP5ZacRJHzfN7NS4DB3n+bus8zsLOAuYDDwFnBKzHVXEywFMA+oAf7q7v/YwrfUbfTOSOHAghyenreRx+YUsevgXvx2nyGkhlqeqzYyOzXupG1uSS3j8tI4Y0x2e4ScdPqkOfPL2ja3T0RERESkXsKTNjP7NnA/m883c4Lesxa5+1XAVc2cy2m0/x/gP820rQbOi7wkxrHb5PPc/BIm9MvkxgOGkZHS+qjaUdkpzCyqoSbspLWQ4JXXOkvL69itX9sqRXYlfdKhuAjqPBguKSIiIiLSFskwp+0GgvXZct09FPNqNWGTzrHToCxuOXAYt39zONlp8f3IjOqVQp3DsvKWe9vmldbiwNjc7vtx90mDMEaxipGIiIiIyBZIhqRtiLv/0d3LEh2INM3M2Ht4DnkZ8SdWoyIlFFsbIjm3JChWMrabzWOL1Sc9mMtWpKRNRERERLZAMiRtb5nZpEQHIe1rcFaI9BAsKmu5guTcklqGZaWQnZoMP4odo36d8Q3VGhspIiIiIm2XDN0bbwFPmNkdwIrYE+5+f2JCkq0VMmNkrxQWt9DTFnbn65Jadu3bfeezQVA9EtBabSIiIiKyRZIhaTsn8vUHjY47QYES6aJGZqfy/rpq3L3J5QFWVIQpq3W2yUuGH8OOkxGC7BTXWm0iIiIiskUSOibNzELAEcA4dy9s9BqdyNhk643KTqGs1plf2nRv2+xIZY5tuvF8tnrRtdraZm0VvLDSCGuJNxEREZEeK9ETiRz4EIhvQS/pUnbsm0ZemvGbmcW8ubpqs/OvrapiWFYKw7IS/WPY8fqkQVEbe9rc4dFlIV5aHWJ5RcfEJSIiIiLJL6G/Lbu7EyxmPSiRcUjH6J+RwnVTejMmN5W/zS3jb3NLqawLuozmldQyv7SObw7JaHLoZHfTJ93ZUBMkYvGaXQJflwbfGy3OLSIiItJzJUMXx5+Bf5nZfmZWYGYj61+JDky2Xp/0EL/cPpdjR2QybXU1v55RzNLyOl5aWUlmCPYekJHoEDtFnzSoDhutLFtH2GF1Jayvhv+tCNE/3clPcxYoaRMRERHpsZJhMtFdka+vEgyXBLDIdvddcbkHCZlx/MhejM9L4y9zSvn1jI2EHfYdlEGv1J6RjMSu1ZbdxH917kHP2nMrQyyvjH5PTh9VxxcbjdklhjvEdkrWOby4ylhWYXx/VJhuvGqCiIiISI+WDElbYaIDkM6xQ34a103uzW1zSvmquJZvDu4ZvWwAgzODr9OLjGFZDcdILiiDZ1eGWFBm9Et3jhkaJGBpBjvkQUUtfFxkrKmCgZH7bKyBfy4ObeqBe2OtceBAVSsRERER6Y4SnrS5+6JExyCdp09GiF9NzKWo2umb0XO6hgZkwM75Yd5ca+zRz+mXDssrgp61WSVGbmqQrO3e1zfrMSvMDpKx+WXGwExnbgk8uCREVR2cMiLMZxuNl1cZO+f7pjXhRERERKT7SHjSZmanN3dOi2t3TyEz+mb0jGGRsQ4b7Hy20Xh8WYisFGd6kZGZAt8aHOYb/Z3mctgBGZCT6swvg5Ja48VVxsAM+MHoMIMzoSDbuf6rEP9bYZw2Sr1tIiIiIt1NwpM24OpG+wMJ4lqGFteWbiQ/HfYb4Ly0OkSawf4DnP0GOL1a+a/QDAp7wSdFQVa3U36Y44ZHk7y+6bDvAOeV1SEOrqzbNIRSRERERLqHhCdt7t5gTpuZpQLXAXMTE5FIxzlgoNM7LcyEPCcvLf7rJvZ2ZpXA0UOd3fs6jVdJmNrfeWON8+Za4/jh6m0TERER6U6SblKRu9cCVwC/jPcaM8s3s0fMrMTMlpnZ+c20SzOzP5jZUjPbaGYPmFlOzPl7zazazEpjXj2nWoZ0uLQQ7NGvbQkbwE75zm8nhtmj3+YJG0BOKuzcx/log1Fa2z6xioiIiEhySLqkLaI30KcN7W8j6DUcChwOXG1m+zfR7jJgX2AnYATQH7ilUZsb3T0n5lXV5uhF2pkZpLQyDXBqf6fWjXfX9bz5giIiIiLdWcKHR5rZFY0OZQNHA8/HeX02cAKwo7uXANPN7B7gTOC1Rs2PBv7s7qsj1/4eeN7MLnD3ii1+EyJJYHAmjM913ltvHDSw6R45EREREel6Ep60AY17xEqAB4E/x3n9OMDc/cuYY9OBg5toa5FX7H5m5B4zIsfONbNzgYXA7939kc1uYpYP5Dc6PDzOeEU6zLa5zlclIUpqafMQTBERERFJTglP2ty9qWGMbZEDFDc6VgTkNtH2GeASM3sVqAR+ETneK/L1FuAnwEaCpO8RM1vp7m82us+lwJVbGbdIuxuaGRQhWVahpE1ERESku0j4nDYze6+Z42/FeYtSIK/Rsd4EPXaNXQe8A7xP0LP2bOT4UgB3/8Td17l7rbs/C/wTOK6J+9wEFDZ6TY0zXpEOMzQr+Lq8UmMjRURERLqLhPe0Ads3c3y7OK+fA7iZbefusyLHpgAzGzd090qCXrJLAczsUIKEbVkz926ydrq7FxH05m1imkAkSSArBfqmO8s0Q1NERESk20hY0mZmp0c2U8zsuzScazYeWBfPfdy9zMweBa41szMIer3OBE5s4plDCXoXlwE7ADcCV7p7OHL+eIICKOXAQcBpwFFtf3ciiTMsE5ZXGM38zUFEREREuphE9rRdHfmaAVwTczwMrAQuasO9LgD+DqwgmN92lbu/ZmYjgS+BCe6+mCCh+ycwKPKMG939npj7XALcTZBALgDOcfdX2/rGRBJpaJYzs9iorIPMlERHIyIiIiJbK2FJm7sXApjZs+7+ra28VxFB2f/GxxcTFCqp33+bIHFr7j6alyZd3tAsxwmxohIKsxMdjYiIiIhsrYQXIqlP2CwwJNHxiHR1wzKDr8EQSRERERHp6hKetJlZlpndCVQAX0eOHWVmv0psZCJdU+806JXiLK9MdCQiIiIi0h4SnrQBfwRGAfsCNZFjnwAnJywikS7MDIZlweJyI6xaJCIiIiJdXjIkbd8GTnb39wmKkODuS4BhCY1KpAubmOesqDSeWm54HInbO+uMjzdoOKWIiIhIMkqGddrSCCo+bmJmWQTDJUVkC+zVz1lXHebNtSFSLMzhQ5xQMzlZcQ08udwYmAE791HXnIiIiEiySYaetg+B8xodOx14LwGxiHQLZnDkEGfPfmHeWBvib/NDbKhuuu0764w6N1ZXQZ1yNhEREZGkkww9bT8D3jSz7wDZZvY8sAuwV2LDEunazODYoc6oXmEeX2bcODfEccOcKfnRzKwqHCRtGSGnKmysq4KBmQkMWkREREQ2k/CeNnefDWwHPEGwsPU7wI7uPieRcYl0B2awSx/nR9uEGZAB/1wc4t9LgoW3Ad5fZ5TXGYcODhK5lVXB8fsXhbhnQWhTOxERERFJnIT2tJlZGrAIGO3uf05kLCLdWf8MuGBMmBdXGa+uNhaUGYMy4MsSozDb2b2v89RyZ2WlMS7H+XwjOMbf5oc4uzBMTjL0yYuIiIj0UAntaXP3GoIy/ypbJ9LBUgwOG+z8YHSYOof5ZXDIoDBnFYRJD0HfdFhVCQvKgoRt3/5hVlXCbV+HWN/MfDgRERER6XgJHx4J3AjcEOl1E5EONiYHfj4+zK+3C/PNQU5mSnB8UAasrDTmlxkp5hwy2Dl3dJiyuiBxW6F6riIiIiIJkQxJ26UE1SNLzGyhmc2vfyU4LpFuKy0EGSkNjw3OdNZWw9xSY0QWpIegMBvOHxMG4Pb5IRaUJSBYERERkR4uGWaqXJXoAEQEBmVCnRtLK+CAAeFNx4dkwoVjw/x9fog75oc4eJAzubfTLyOBwYqIiIj0IAlP2tz9vkTHICJBT1u9MTkNF2zrmw4XjA3zwKIQz64M8exK2G9AmCOGNGy3rgp6p0FqMvThi4iIiHQTCU/aRCQ5DMwAwzFgVK/Nz+ekwg/HhFlXDS+tMl5fE2JEVh2T86GsFp5ZYXywIcSoXs5ZBWF66V8XERERkXbRLf4ebmb5ZvaImZWY2TIzO7+Zdmlm9gczW2pmG83sATPLiTmfbmZ3mFmRma0xs2s6712IJFZaCPqnw7AsNhUnaUq/dDh+mDOql/PI0hD3LQrxu9khPtpg7JQfZmkF3DYvRJEqToqIiIi0i26RtAG3EfQaDgUOB642s/2baHcZsC+wEzAC6A/cEnP+CmASMBbYFTjFzM7owLhFksp3RoQ5bli41XapIfjuyGCpgEVlsGN+sID3KSOdcwrDFNfArfNCrKzshKBFREREurkun7SZWTZwAnC5u5e4+3TgHuDMJpofDdzi7qvdvRj4PXCymWVFzp8BXOvua919IfCnZu4j0i0VZsPwJoZGNiU/HX61bZjLtwtz/HBnSOS/orE5QcXJsMNf5oVY2EzFyfJaeGKZsbaqfWLfWnUONa3nqyIiIiKdLimSNjNLMbO9zOzEyH6mmcVbm24cYO7+Zcyx6cDEph5Fw4W8DcgExplZH4Keuhmt3ScyHLMg9gUMjzNekW4jNQQh2/z40Kyg4mR2CtwxP8QXxQ3Pu8MjS0O8tS7E/YtCCU2W3GHmRvj97BC3fR3CvfVrRERERDpTwpM2MysEPgNeIOghA/gW8Pc4b5EDNPqVkCIgt4m2zwCXmNmQSJL2i8jxXpH7AGyM4z6XAgsavabFGa9Ij9AvPUjcBmXCfQtDfFUSPffeemNmsTGpt7O80nhqRROZXydYUwV3LQxx76IUqsOwrNKYr7XoREREJMkkPGkDbgWeBPKB+tIFrwH7xHl9KZDX6FhvoKSJttcB7wDvE/SoPRs5vjRyHxrdq7n73AQUNnpNjTNekR4jJxV+ODpMvwx4cnmIOoeVlfDkcmNcjnPayDD7DQjz7roQN3wV4snlxpfFUFXX/D3DDhtrti6u6jA8t9L445xg+Oa3h4T5v23DZIac99YnJoEUERERaU4yFOXeHTjG3evMzAHcfUOkJywecwA3s+3cfVbk2BRgZuOG7l5J0Et2KYCZHUqQsC1z97CZLQcmA8tbuU8RQS/cJmb6RU+kKRkp8K3BYe5blMK764z31xuZKXDSiDAhg8MGO73TwswqNt5dZ0xbGyKEMyobxuU443Kc4b0gxYKE75GlIZaWw4/HhRmc2fZ45pbAw0tDFNUE1S6PGOLkpQXndunjvLveOLrWyU6Gfx1FRERESI6krYxgeOKmYYlmNgBYF8/F7l5mZo8C10YqPRYSFA85sXFbMxtK0Lu4DNgBuBG40t3rZ9TcC1xuZh8C2cCPCXrnRGQrTMyDUb2cJ5YHnftnFdRtSpRSDKb2d6b2d2rCsLAM5pQac0qNF1cZL6wKkWpOWijogctMATP4YL3x7aFtm4A2vcj41xKjXzqcP6aO0dkNz+/Rz3lrXYgPNxj7DdDkNhEREUkOyZC0PQfcbGY/ADCzEPAb4Ok23OMCgjlwKwjmt13l7q+Z2UjgS2CCuy8mSOj+CQwCVgI3uvs9Mfe5mmAZgHlADfBXd//H1rw5EQmSrCOGhLl9Xoip/Z3tGg9ojkgLwTa5sE2uczhOWS3MLTWWlAfVHdNDQYL332UhPikyDh/ipLTSyb2qMphDt7bKmF0CBdlwZkGYrCbWohucCYXZzptrjF37qLdNREREkkMy/EryC+AJYD2QQdDjNgv4Zrw3iAxXPKGJ44uJFhjB3d8mSNyau081cF7kJSLtqDAbfrltmPy0+K/JToUp+c6U/IbHd+0bZmZxCrOKYWLv5q9fUwV/nR+isg76Z8DufZ2jhga9ds05emiYW74O8Z+lIb43KoxGPouIiEiiJTxpc/eNwP5mthPBotYrgbdihiyKSDfRJ7197rNtLuSmOh9uCDGxd9P/VKyrhjvnByX8f7xNmIFxzn8blhXMs/vfihDvrTf27KdhkiIiIpJYCU/azGw/d3/d3T8BPkl0PCKS/FIMdsp33lgb4rezQvRJh77pTt906JMGa6vhjTVGqsEPRsefsNXbp78zp8R5fJnRK8WZnN9ye3d4ZqUxqpezQws9fyIiIiJbIuFJG/C0ma0E7gbudfeViQ5IRJLfAQOd9FCYddWwvtqYW2oU14ATjGec0jvMt4YEiVxbhQxOHxXmrgUhHlwcIsXCLQ7DfH+98fqaENkpzricMBlNzJcTERER2VLJkLQNAU4iqPh4jZk9D9wF/E9DJEWkOdmpcMjg+qGLwdfaMGyIrOE2IGPr7p+ZAmcXBsVTnl4RYvu8pue3rauCp1YYgzKcVVXG2+uMAwZqSKWIiIi0n4Qvru3upe5+l7vvRbAu2lfAncCShAYmIl1OaihI1rY2YauXmQJ79XPWVRsrKjc/X1wD/1wcIkSQ4I3PdV5fY1S2sDi4iIiISFslPGlrZCFB5chFwMDEhiIiAtv3dgzn840Nu9nmlcKf54ZYWRksFN4nHQ4ZFKa8znhnnUpOioiISPtJiqTNzPY0s7sIKkf+HHgcGJnYqEREIDc1WNttZnGQiLnDa6uNO+aHyAjBxWOj891G9oJxOc60tUatBneLiIhIO0l40mZms4CXCdZoO9Ldx7v77919RYJDExEBYIc8Z0WlsbQc7lsU4pmVISb2hku3CTMkq2HbfQeEKak1Pi1Sb5uIiIi0j2QoRHIL8FBkvTYRkaQzsbfz1Aq4dV6w7tu3h4SZ2t+bLEwyLgeGZDpvrjV26dN0GxEREZG2SHhPm7v/VQmbiCSzvulQ2MvJToEfjgmzz4DmkzGzYJ23FZXG7JLOjVNERES6p4T0tJnZM+5+eGT7NerrdTfi7gd0amAiIs04uzBMyCAtjj917ZjvvLjKuX9RiGOHOTvmO+V1UFYH5bVQXgc1YWO7PCdLa7qJiIhIKxI1PPKtmO03aCZpExFJFm1ZMDs1BBeNDfPg4hAPLw3x8NKm243Icn44Jkx6wsc8iIiISDJLSNLm7tfFbF+ViBhERDpSXhqcNzrMB+uNsjrISoFeKZCd4vRKhVWVxr+WGA8tDnH6qKAXT0RERKQpCS9EYmbL3X1oE8cXu7vK/otIlxUy2KNf0wMJhmU5ZXXw5PIQt80LceSQMIXZnRygiIiIdAnJMCgnt43HRUS6han9nROHhymqhr/MS+GxZVrfTURERDaXsJ42M7sispkWs11vHLCoDffKB+4EDgOKgd+6++3NtL0aOIsgKZwFXOru70XO3QucAlTHXNLP3avijUVEpC127etMzneeX2m8uTbEknLniCFhRmej5QJEREQESOzwyP1jYtg/5ngYWAmc2YZ73Ra5z1BgDPCSmc1y99diG5nZd4BzgX2AecDFwONmNtTd68cw3ejuv2jrmxER2VLpIfj2UKcwu45Hlob46/wU+qY743Od0dkwOtvpnRZt7w4baqB3GqQosRMREen2Epa0ufv+AGb2V3f/4Zbex8yygROAHd29BJhuZvcQJH2vNWpeCExz97mRa/8B/BnoD6zZ0hhERNrDDr1hXG6YmRuNT4uMTzYY764LsrJ+6c7obKd/BnyywVhVZaSZMyYHThoRJifhM5RFRESkoyT8f/Nbk7BFjAPM3b+MOTYdOLiJtv8GTjSzbYGvgXOAj9w9NmE718zOBRYCv3f3RxrfJDIcM7/R4eFbGL+IyCYZIdi5j7NzH6fOYUUFzC8z5pcZXxQb5XXGsCznyCFhNlTDu+uNp1cYJ4/QyikiIiLdVcKTNgAzOws4CBgIbBrsE+fi2jkE89hiFdF0IZOVwDTgS4JhmOsiz613C/ATYCNB0veIma109zcb3edS4Mo4YhMR2WIpBsN7wfBezj4DnLBDaS3kpkbnu2WkwCurQ+zWp44xOYmNV0RERDpGwqtHmtk1wO+BVcCewGfADsCMOG9RCuQ1OtYbKGmi7ZXAHsAoIBP4KfC8meUBuPsn7r7O3Wvd/Vngn8BxTdznJoKhlrGvqXHGKyKyRUIWrP8WW6DkwIFOnzTnsWUhVZ4UERHpphKetAHfBQ5190uBysjXYwmKisRjDuBmtl3MsSnAzCbaTgIecfclkcTsASAjcrwpTY43cvcid18Y+wKWxhmviEi7SQ/BMcPCrKoyXlylqiQiIiLdUTIkbf3d/eP6HTMzd59Gw2GLzXL3MuBR4FozyzWzSQRFSO5povn7wPFmNtjMQmZ2CpBNkPhhZsebWU7k3MHAacCTW/XuREQ62IQ82K1PmNfWGPPLEh2NiIiItLdkSNpWmtmQyPYiYC8zG9/Ge1xA0Cu2AngeuMrdXzOzkWZWamYjI+2uBz4CPiGY93YZ8B13Xx05fwmwLHLuBuAcd391y96WiEjnOWqo0zcd/rU4RElt023coU71SkRERLqcZChE8i+CddoeIlgg+xWgFrg73hu4exFB2f/GxxcTFCqp368CLoq8mrqP5qWJSJeUkQKnjAzzt3kh/jYvxA/GhMlt9C/8u+uNp5Ybe/Zz9h/g5KU1fS8RERFJLgnvaXP3K9z9ocj2X4EDgOMJKjSKiEicRvWCMwvDrK+Gv81r2OPmDm+vNdJDwdeb5qpwiYiISFeR8KStMXd/x92fd3cN4hERaaNtcppO3JZVwKoq49DBzgnDneJaY1VVYmMVERGR+CRkeKSZNVUkZDPufmZHxyIi0t1skwNnFYa5e0F0qOSHG4xUc6b0dko3JXLBQt0iIiKS3BLV02ZxvkREZAuMjSRu9T1unxYZ2+c5vVKhfwZkhJxlFYmOUkREROKRkJ42dz8jEc8VEelJxsb0uNW4sUufYBJbyGBoZtDT1sxylCIiIpJEkm5Om4iItJ+xOXDu6DD7DQgzLjd6fFhW0NMWVs4mIiKS9BJe8t/MFtDMn3rdfXQnhyMi0u0UZkNhdsN/ZodlQY0ba6tgYGaCAhMREZG4JDxpA65qtD8MOAe4o/NDERHpGYZHCpAsrTAGZqq7rSPVhuHfS4y8NPj20C37Xn9RDIMzoV96OwcnIiJdQsKTNne/r/ExM3sW+C3w+86PSESk+xuYCakWDJHcqU+io+m+wg4PLgnx+UbDcL7Rz+mX0bZ7LK+AfyxMITfV+eHosHpGRUR6oGSd0zYDmJroIEREuqsUgyGZsKxShXo7ijs8utT4fKNxwIAwIYM317b9+/3aGiMj5Djw1/kh1mp9PRGRHifpkjYzywIuAVYnOhYRke5sWJazpByWlCc6ku7pmZXGBxtCHDQwzLeGODvmOx+sN8pq47/HumqYXmTs0df5wegwVWF4dbUSbRGRnibhSZuZhc2srv4FlBLMc/tJYiMTEene9u7vZKXArV+HeHONEoH29Opq4/U1IfbqF+aQQcE8tv0GODVuvB7n9zrs8NpqI2SwzwBncCZsn+fMLDbqNA1RRKRHSficNmD/RvslwBx3L01EMCIiPcXgTPjxNmEeWRriqRUhqsJhvjlI2cDWem+d8ezKEDvmhzl6qGORHG1wJuyYH+a1NSHCHubwIU6oUf5WFYa5JfBlsTGrxCipNfboG6Z3WnB+Um/n06IQ80ppsISDiIh0bwlP2tz9jUTHICLSU/VKhdNHhXlkqfHCqhApFuaAgUrctkRxDXy0wXhupbFtrnPSiM2TspNGOL1SwryxNkRZXZiTRgTf6883wnvrg2Ss1o3MkLNtrjMhz5nUO/p5bJsL6SHns43GuFx9TiIiPUXCkzYAM5sK7AI0+Luhu1+TmIhERHqOkMF3hjthD/PsyhAhC7PfACUEbfHiKuOlVYZjjMtxTh8VJqWJUZApBscMczJTwryyOsS4nKBAyT8Xh+ib7uzVz9kuL8zobJq8Pi0EE3KdzzcaxwzzJtuIiEj3k/CkzcyuA34MzARip8M7EFfSZmb5wJ3AYUAx8Ft3v72ZtlcDZxEkiLOAS939vci5dOBW4ESgBviru1/R9nclItK1hAxOHBEkbv9bEfS4Te2vxC0e66vhldXGhDw4bHAdg+MoyX/wIGdeqfPfZcH8tIJeznmjw6TFMdN8Ur4zfaOGSIpIYH4ZbKg2du6jf7O7s4QnbQQLae/u7tO34h63EbyXocAY4CUzm+Xur8U2MrPvAOcC+wDzgIuBx81sqLs7cAUwCRgL5AAvm9kCd//HVsQmItIlpBicPNKpW+w8uTxEiDDfUOLWqlci1RyPGRomP87Fr1MMThkZ5sY5IXqnwRkF8SVsEAyRzE5xnlkZYnR2mNSElxQTkUR6dXWIhWWwU350Dq10P8nwT30ZQS/bFjGzbOAE4HJ3L4kkf/cAZzbRvBCY5u5z3T0M/AMYDPSPnD8DuNbd17r7QuBPzdxHRKRbSjE4dUSY7fOcx5eHeHW1UVGX6KiS19oq+HC9sWdfjzthq9c3HX48LswlY8Nkt+FPqOkhOGF4mGUVxgur9BuaSE+3pgoqw0ZRTaIjkY6UDEnbH4ErzLb4bwPjAHP3L2OOTQcmNtH238BYM9vWzFL/n737jo/sLO/+/7lGvWu12l1tL163XXfc1va6Y2xjG+NCM2A6xARjCAk8gYQaCMkv4ORJgAcIMQmEEpwQ04wNuGFsbIoN7m171a5Wvc9cvz+ukTWrVd2VNKPR9/16zUurM2fO3DMjac/33Pd93UQv32/cvdHM5hA9dY+OdRwzqzWzFZk3YMlBtl9EJKcUJuANy1KsqXJ+vDPBx59I8OMdCgeZHmuBzz+T4B+eSZAwDrp4S11xFIOZqGNq4LS6FHc3Gj/YbjzXjpYBEJmF+lIxRBtgR3d22yJTKxeGR34f+BnwPjNrzLzD3VeN4/GVxDy2TM0MKWqSthO4D3gCSAF7gQszjgPQMo7j3AR8dBxtExGZkQoTMWRvcyf8fHeCuxqNM+v9xdLzs90DexM098G6uc4xNU51Ft6XKxY6bX3GfXuMe/YkKE04h1fCUVXOUdX6rERmgz294MRFtR3dxppqXb3JV7kQ2r4DbAVuZv9CJOPVDlQP2VZDrPc21EeB04HlwA7gtcDtZnZ0+jikjzXw75GOczNwy5BtS4hAKCKSF8xgeQVcvijFE08X8Lt9xnlaDgB32NoFa6qdKxZl7/0oKYC3rEzRnYRn2+GpNuOpNuOPrQlsm/O6Zc6Jtfq8RPJZY098NZwdXdlti0ytXAhtxwH17n6wnbrPAG5mR7v7k+ltJzD8PLnjgO+6+5b09/9hZp8HjnP3X5rZduB4YPtox3H3ZqIX7kUHP7pTRCS3zSuJ6oa/2WecO08T3Vv6oCNpLC7LjUBUWgDH1sCxNY67s7MHvrc1wX9vMw6ryE4voIhMj8ae+IO8uhK2dxtRfF3yUS7MaXscqDvYB7t7B/A94JNmVmVmxxHFQ742zO6/Bq4xswYzS5jZ64AKIvhB9J59xMzqzWw5sRTBcMcREZlVTp7j7OoxtupK7ovvwZIcCW2ZzGBhKbx6SYq+FNy6LYHnXjNFZJLs7oGaImd5udPYE3PcckFXEm7bbrSoOMqkyYXQ9g3gv83sVWZ2duZtAsd4N3FpYQdwO/Axd7/LzJaZWbuZLUvv93fAb4DfET1lfwG8yt13p+//ONGz9jzwW+A7KvcvIgLH1zqF5jy0b5Z3swHbugzDWViW7ZaMbH4pXNzgPN5q/KJRn9lk6ujPdgtEBjX2GPNKYGGp4xi7cqAYSX8K/m1jgnv3JHisRX9/JksuDI/8x/TXbw/Z7kDBeA6QHq547TDbNzNYYAR37wHek74Nd5xe4J3pm4iIpJUVwAm1zgN7ExRZiksbfNauD7a1y5hfAiU5/vrPrne2daX4yc4EPckUlzRoaOuh+vlu4/adxptWpFg7dDa9yDRzjzltJ9Q6i9IXkXZ0G0vKs9e9nnL41hbjhQ6jwGK4tkyOrP+X4+6JEW7jCmwiIjI9rlnsnDU3xb17EvzH5qz/95E127pyc2jkUAmD1y51Tq9L8YvGBJ9/NsGjzWi45EHa0gk/3WkY8J0tCZp7s90ime3ak9CVjItIc4uhyDzrZf9/uMN4tCXBZQtTLC2DXd26UjRZZu//uiIiMiGFCbhysXPRghSPtxpbD6be7wzX2get/cbiHB4amSlhcPVi57VLY47bf2wu4OubElowfRipUcJsbwq+tSVBVRG8e3WKfoevbUzwva3G/243WjVvR7JgoHLkvBInYdBQGj1tY3m+nXH//U46/MtzCf59U4LdYwTCexuNe/ckOGtuinPqnQWlzs5uXSiaLFkfHmlmfz3Sfe7+ielsi4iIjG19vXNvo3NXo/GG5bPrf+Nt6SIkuVI5cjzM4CVzovz/vXuMH+8wbn42wXnznBNqndIRxrXs7I7hgC9vcGqLp7fN0+2hJuN/thkvXeCcN0yF1IebjN09xttXJlleDq9a4vz3NqOlxehOwW/2GVcuck6q1RBUmT6N6YA2ryS+X1ga81jdGfHnMOXw75sSzCuBP109dtWSJ1thQ2cMdXysJcH1y1OsrTlwv0eajdt2JDi2JpZCsXSI/HWT0daPqthOgqyHNuC8Id8vAlYCvwQU2kREckxZAZw+17mn0djT49SXZLtF02dTZ5wJzZSetkwJg3PnOSvKnVu3JfjetgS37Ygwd1qds7Rs/xO9uxqN3zcneKHDefvKFA2l2Wv7VLq3MU42qwudH+9MsK8vxSsXRc/FgN81GwtLnSOr4vsTaiPwAuzuhu9uTfCtLQkebXauXpLSwuY5yh1u2xFLYRwzTPDIJSlnv5/BoTr64Yk2o9CcOemft4Vl8NC+0UPS5s5YsqSny+lPMebc5AebEtQUOe9dneIfnknwWKuxtmb/i1bPt8c8tpXlzuuWpl5s94KS2G9Xt0LbZMh6aHP3oaENM7uJAxfMFhGRHLG+3rlvj/Gz3carl8y83oXm3rgCXGDQUOqsrR75yvSAZ9sjyBxROXLv1EywogLef3iKzZ3xHvxun/HrpgQLS50z50aA63d4rMU4vNLZ1Q3/8nyCd6xMsbT8wOMlPU6GZ1phGne4c7dxx67oHXjd0hR37DLuakzQ2udctyxFcQL29kRYv7Rh+F6J+aVww2EpfrnH+PFO4/97JsEVC52T58y834t89GRrXGhaUQG/bzbu25NgS6dzTE2O1MYfxm/3GT/aYbz38AMvAOztjQsNDzUZfW6cNXcwJC0sjZC0Y5SQ9ERr7Nzvxo5uhv2dHtDUC0+3wYXzY73HhWWwc8hacN1JuGVTgrnF8OYVKYoy/g4MXOjZ2WMcXjVzRifkqqyHthH8M7AZ9bSJiOSkmqIIbnc3JqgqjGqS2ThB7UrCPY3GKXOcuePs8WvqhS8+n2Bf32CD37kqyeGVIz9mWxfcsjFBfTG8flnunuyNlxksr4DlFTGU6ffNxoN7je9tS1BgKYoTTk/KOH9ekrkl8X59eUMMjXKPRXy3d8OOLmNXT5wU37AqxfwZ0huXdPjRjph/c/KcFNcucQoMXr7QqS1K8f3txhefT/CWlSl+1xw/JyfVjnzSmTA4e55zdLXz3S0JvrM1wZNtKd6wTMEtm7qTMRTQgdcuTfGDHbFcx+bO+NtRlqMXX7Z0xtzZ721N8JYVKcxiDtrdjcajLUbC4MRa59x5+/eAL0z/e0e3ceQIIenxVmN+ibO7x9jUaSwdpdLkr5vih/e0utinocR5eN/+wy83dUYxlNcvS1I+JFVUFUJ5gefEMgT5IFdD20pgFg24ERGZeS5tcHpSKe5qTJD0FJcvPPAEtTcFD+w1lpQ5h40Sig5GTwr+dUOCjZ3G/Xujp+ToMcZo7E0Htp4U3LQ6ybwS+OzTCX6xO8HhlcOHsb298NUNCcoK4O0rUwecmMx0pQWwLt3D9i/PJ/jhDmNRmVFVGJ9ZwuBPDkvxxecTfOmFwbPc6sJYq+6IKuc3+4x/3ZjgxtUpKnL8/XmyFX6wI8HunuiluGLIUMgz652aIuebmxP883MJUg6rKsY3r29eSbxXP9gRPTr7+pLU5fl8wFz2aEv0RtUWOf+xuQAjLlL87/YEz7bDcTk6RLK5L8Llk23Gj3YaWzqN5zuM0oRzzjxnfb0POwS3ojAW2t7RNfxx9/TArh7jFYtS3N0YgeusEdqQ9JjreVQVL/7szy+FnlQsmD2wbUOHkcBZPkyPnRksKD2wd04OTtb/tJrZ14ZsqgAuAL6bheaIiMg4JQyuWuQUEMsApDzFKxYNBrcnWuG/tyVo7jOqC50PHRXDzSZDfwq+vjHBpk64clGKh5qMr21M8K5VqRHD4d4e+OILEdjeuTLFkvRJxtnznB/uiGMNPfFo74evvJCg3+Gdq1J5XZAjYXDV4hQ3P5vg2XZjff3gsKu64iha8HirUV8cYa0q4wzi2Grniy8k+PILCa5YNPJnkG2NPVH1sb4Y3rQ8OeKw2GNq4F2rUnxtY4KOpHHh/PH3rg70gty3J3poFdqmVnNv9Jo1lB74Wf6myZhX4rz7sBT/tjHB6krnjLnOT3c6T7cZx9XkZpBo6YPDK6HPYzRDTZFz2cIUp9eNPTR74YsVJA98bQNDI9dUOS90GJs7Rw5TT7RCW7+xbu5gqdmG9PDLnT2Doe2FDmNRGSO2q6EkevJHK44i45P10AYM/Qh3Ae8HvpmFtoiIyASYwSsWOQmL4Jb0FK9c7GzphK+nK5RdUZ/ith0J7m00Llxw6CdJKYf/3JLgmXbjVUtSnFrnnFLnfOapBHc1JjhsmB6zPT3wpRcS9KbiZDyzkMi6OucXu52f7RocigTQk4yevOa+eEy+FuLItLgMzpzr/HKvceKQ4YA1RXDG3OE/v+UV8IZlKb63LcEXXyhgUamzsMxZVApHVjkLSnLjhO3pNsMx3rYyOeZw2uUV8J7VKR7eZ5wwZ2I/t4tKocCcLZ3GsTkaDPJB0uP3ek9vDPk7oTYK68wrid/5Dem5iJWF8VkOWF2Z/lnw6Rm+2t4PP91llBdAXRHUFTt1xRF8CoZ5/pa+mJ92yUJnUwccVTX+OaMLS51n242k73/snd1w/15jQUkMJV9e7vyxJUFb//4XYAY8uDfC4kDxHYAF6d+ZXd3GUVVRyGRzZ/TUj2RBKXSnjNZ+VKDnEGU9tLn7m7PdBhEROXhmcPlCp9BiEedeT/Fcu1FdGPOcygvhhY5YIuC0Oqdqgv9xdyWhNBHP4w7f22r8ocW4YmEENoCSBJw117l9V4Kd3XHVvSdJFJLojR62vnRgWzSk8mNJAZxdH4/9+qYEr1ycotAiGG7tgjctT7GiYpLerBngsoXOsTVJlo1SoGA4a2vgiKoUDzYZj7caz7Ubv91n/GBHLEb+lhWprFeQe67dmFM0/vmP9SVwScPEQ1dhIn4Gt3ZpWNhU+t0+Y09vDHPd3m3cuSsKyywpc8oLwPBh5yIeVeU81ppgd0+Eiqn2dJvxwN4EhuMZfRWGs7A0AuVAAY+kQ1s64FQVMuEqlwtLIenG7p74t6eHOX5/u1GcgDcuj/C6PD2XbXMnrB0yrHxvLzzTDi9d4PsFv4pCqCwcnKO2rSsKmqysGLkn+sXeuW6FtkOVtdBmZmuBK9z9M8Pc9yHg++7+1PS3TEREJsosTm4TluJnuxMUmvOnhw3O/3r5whR//3SCO3cbVy0e/0nsM23wrxsTHF/jvHqp8+MdxkP7Elw4P8XZ8/Y/zrq5zs93Oz/fbZQm4IGmBFWFTsrjtHm4wDbg/PlOgaX46S7jk08OjvO5dvHwaxLls8IEBz28sSgRBWrW18dns683Ch/8aIe9WIFyvIFpsqUcnu+IoZzTYWmZ82iLhoVNlaTDz3Ybi0o9PSzbae6NeWy/bzaeaY/eoOGGNB+RLtJx7x7j8oVTXw22Jb34+ifWpuhKRjGkpl7j2Xb4fXOCxh5e/NvU2gdOzMM7GAvTa0ju6IpjfG+r8WhLgsMrndcuHbxwsrgMEjjPtxtrh/xO/Hpv/MCeOkwP84KSmBcHMcQSYOUoF3gWpUPx1q6Ri6PI+GSzp+3PgftHuG838BfAW6avOSIicijM4OIGp644RVWhvzhnDKJAwyl1zkNN9mL56OHs6o6r0vUlTm1RVH4rK4DfNSfY2uUvFo942TDDLCsK4zl+tTcuWZ9Wl6IvFVXYrlg4cmCDmId03nxnbbXzWKtRlIi5GIdXjfwYGducYjir3lla7vzrhgT//HyCt6888LPoT8H3txudSTi9zlldOfoaVQdjW1dUuVtdOT0njkvK4MEmo6mXrAXVfPa7fcbeXuNNy5MvhuLaYjhnXhTraOoduTpkXTGcWJvi102xtt4Zc52z6kf+u3SoWvugNOGUFUSbYp5jDBv+fTM09w2GtoGAV1N8cD+n80tiaO7vm42f7IyiIZc2pDh33v4Fd4oTcEQV3LsnQXcyxeWLon1Jh4f3GWuqGTbwLih1fpeuILmxM+a4jjZ6orwQ6oudraPMn5PxyWZoOwu4aYT7bgU+PH1NERGRyTIwZHGo8+ZFaLun0bh8UezjHsNm/tASQx7jCu6gqkLnPatTPNYSCyC/pDaq/Y3Uc3HePKep11lfn8qYizH+E4X5pXB+qU4sJtvy8ljL7CsbEnzh+QRvXZliZXrIaW8qwvlTbUZZgfOHlgQn1qa4btmBn0PS4anWWC9qogU+nmuPH5rpC23xPFu6jLkl+pmaTH0puGOXsbjMDxjaN2Csn4/rljnr65Pc3Zjgrkbjnj3GyXOcc+fFnLjJ1NJvwwbCgVDU3DcYaJrTS5Ec7FDCAovesCfbYijwuw9LsXyE4d3XL4+1Ce9pNNr7jbesTPF4ugDJaXXJYR+zoCTmqDX2wIYOOGYcPddLypyNnepuPlTZDG3z3b15uDvcvcXM5k1ze0REZArVl8AJtc4DTcbR1c4zbRHU9vRGeetVFbBuboo11c7O7jjpOL0uJuyfPc85piZJbdHoPTBziuFtK2f+Omr5qKEU3n1Yiq+8kOD/vZDgjcujuMs3NifY0gnXLE5x8hznJzuNe/YkOLVucO28/hT8Zp9xV2P0rqyqcG44bGKf87PtUYRhuubVNaSLkWztghNqp+c5Z4v79xr7+oxrlyQPaejpsvKY47WnJ9Z7fHhfLFp9+UI/YPj1oWjtGz6EVRXGEMWB3jUY7GmrPYSf0zPnOlu7nEsX+qhr0RUlYm3CkgTcvivB1s4oQFJb5Bw1wiiDgTlq//J8gq4kHD/K+oUDlpbDIy1GWx8TntMsg7IZ2jrMbKm7bxl6h5ktBUZYZUJERGaq8+c7v2+O9b4SxDC4c+alOKZ6/yE2dcWwZsgVXJVOn/nqiuHdq1N8dUOCWzYmXlwC4o3LUxybnjt4cYPzhxbntu0J3n1YVG+8u9Fo6TOWljkr56T4zb7hl2gYSUd/9AqcNkIv8FQoTMR8ni0Zw8LubjSebzfeqgsLB62zH36+O+ZHHTFJw5frS+DqJc5FC5zvbUvwgx3G/NKRg8tEtfTBYRUH/uwlDKqLYtmCzH2LE07pISyPctpc57QJ7H9WvXPPHufWbQm2dBkvW5Aa8eLYQOGWpMcFsiPH8R4N9jrDGoW2gzZJK+YclHuB945w358Cd4/3QGZWa2bfNbM2M9tmZjeMsN+XzKw949ZjZm0Z999tZt0Z9z8/kRckIiKjW1gKr16S4lVLUnx0TYp3rEqxbu7EK0rKzFVZGEVhjqyKn4f3HT4Y2CCu/l+2MMWObuPjTyT43+0J5hbDO1YmuXF1iisXOWUFzl27x3cKs7cX/vn5BA6cOMHS/YdqSbmzpSvasL0LfrzDeLLN6FNmOyjdSfjeNqM7CZc1TP6bWFUEr1uWYmEpfGNTgj09h37MVEY1yOHUFg0OiYSY31ZTNL3Fa0rTFXS3dMVC2SMNcYf4/b1+eZL3Hj6+wAYxv9PwdDVVOVjZ7Gn7G+BBM6sDvgFsAxYD1wGvBtZN4Fj/TLyWRcBhwJ1m9qS735W5k7u/C3jXwPdmdgsw9Lf+Jnf/0sReioiIjNcp09jbIbmptIBRe5uOq4ETalL0pIzz5ydfnP828Ngz50aV0O1djFpgZktnVB9NphdHH2/P3GRZP9d5tNn48gsJShKQSpd739cb8ydl/J5pg+9sTdDaBy9bEAu8T4WSBLxpRYrPPZPgBzsSvHnFoYXDzmSU4K8eoRpkbVGEpQEtfXZIQyMP1ln1zr17nMMqxp5Pl3mRZTxKCqJAypaDKEbSm14LbvVBVrTNJ1nraXP3PwCXAmcAPwOeSH89E3i5u/9xPMcxswrgWuAj7t7m7o8AX2OMypPpx10NfP1gX4OIiIhMPjN4/XLfr2BJpjPrnUKDzz1bwKeeTPDg3gOv4D/RCl94PkGRwXsOG/44U21+aQwha++H7d3G+voIAE19YzxQ9vPAXuOrGxKUJuBPV6e4cJjqsZNpYB7t463Gls7oLXu0GXoOIr8NzFEbMbQVxz7ug/vXHGS5/0NRVgA3HR6jIKbC0vKY3+kTfGm/2mt86YUCdnRPSbNmlKwuru3udwNHmdlqYD6w292fm+BhjgDM3Z/I2PYIcNEYj7saaCSGaWb6lJn9DfA0EQR/MfSBZlYL1A7ZvGT8TRYREZGDVVUI7z08xVNtsZD397Yl6E0Nrt334F7j1m3G4jKyvqj3svLo5dvaZaypcu7bE2t0qfz52FIOP95p3N2Y4Kgq5w3LUpRM8ZpqA86ud365x/nJzgSl6aqmFy+YeGBsHSjhP8IZd21RLFDdnoSKgpGLlkyHuVM4b3hJWRQTmugSGM+nq74+0WosnOWVfbMa2gakg9pEw9qASqB1yLZmYKyRttcD/+6+X+b/INHj1wu8BviBmZ3g7s8OeexNwEcPsr0iIiJyiBpKo5LdWXOdb25JcNuOBI+1OpWFcYI93Sf5o1lWDsvKY6H3Aos1xGR0fSn41hbjDy0J1s2NuYwF0zzP69x5zo93JgCjNOE8024HEdqi0SNdOBhYRLulF1JFMYQ2Gz1tU+2wSieB8w/PJjip1rlikb9YiGgkKY8CQgCPtxoXzJ/4+zJwlp8PC9znRGg7RO3A0FU6aoC2YfYFwMyWAecCb8/c7u6/zvj262b2WuAy4PNDDnEzcMuQbUuA+8bZZhEREZkEhQl4/bIUd+4ynm4znmw11tWluHLx9J7kj0fCYE4RCm1jaO+Hf9uYYFOncdnCFOfUj7w241Q6c66zscM5vtbZ0Q337TF6UjHvbbxa+uNr1Sg9bRAFSFIvbsu/0LawFN6zOsWv9hoPNiWoL4kFv0ezozvWhGsodTZ3Gq19I4ffkXx3q/FUm7G+3lmZyrE/CBOUD6HtGcDN7Gh3fzK97QTgsVEe8wbgfnd/YYxjD/vTlF5frjlzm+VDhBcREZmBCiyWCri4wXHP7avqdcWwb4zhkY82Q2/KZmXRnsYe+OqGBC198IZlSY6vzV5bSgrgLemCOU+3wd2NCTZ0MKGlAFr7oLLQKRwh6NVkLLDt6Z+JbA2PnGpLy+HV5c7eXuf+PRGkhruw0p+KizEvdMSdL29I8a8bC3ii1Th97vh/Jx5pNh7el2BeSfSYVifm8b5kisKCbBbPP3gzs9UZ3L0D+B7wSTOrMrPjiCIkXxvlYW9kSE9ZetmAl5lZqZkVmtl1wNnAT6ao6SIiIjLJcjmwAdQVjz48Munw/e0Jbt81+EL6U8yKZQI2dMD/fS5BdxL+ZFUqq4FtqFUVUGjOs237/4C19sFt241PPZkYtlhGS59RPUoXSWVBHLe5D/b0xLHzNbQNWF+fYl+f8UTG5KZ9vXDXbuNzzyT4yOMJNnfCC+1GXXGsl1dXHIVhupLRU93ZH78rI2npg1u3xdqOHzgixXtXJzmzvG3GBjbIj542gHcDXwF2EPPbPubud6WHQT4BrHH3zQBmto4YyvhfQ45RBHwKOApIAk8BV7r7U9PzEkRERCTf1RVDR9LoSTLsfLun26CtP07e2/pi7bBbNkWQueGwkRc9nqlSDs+2wzNtxi/3GnVFsRxE/QSKVUyHogSsqIBn26OXtLUP7mo0HthrpDzmoj3ddmCxjLGG9JlFSGvuhSe6jSVlTkUOzMOcSmurYU6Rc3djgrZ+5/fNxoZ0r9qycqeiEP5zc4KuJBxdHUNj11Y79+1J8FeP7//mFJlTVhC/SyvLnWuWOAmDH+4w+lPw2qUpCix6+QpKurLxcidNXoS29HDFa4fZvpkoVJK57QHggMK/7t4InDJFTRQRERGhLj0crqmXYdca++2+wVS2rRtWF8Bz7VFh8JFm46RpXiB8qt25y7hzd4ICc46uglctSVGeo2enh1dGNclbtxoP74uwdtIc58L5zheeT7B9mEzQ2h+LrI+mtgieaDN6U8brlqZyvrf4UCUslu344Y6Yt7igxLl4QYoTap36kvh5/38vJHCMVRXx3p1T7xQnUlSkA1pvCrqS0JOE7hQ09xoP7UtweGWKJeXOI83GOfM8r9ZDzNFfCxEREZH8M6c4TkKb+g4MbZ39USXvJXNS/HZfgm1dRlnC6XejyJwf7TSOqRm76l42tfTBz3cbxYkoYV9RCBWF0XtUV7x/r5M7PLzPOLzSedOK1IQKfGTD4ZXOT4BfNxkvmeNcMN9f7BFcXAbbuvafq5j0KKoy2vBIiMIjz3ckqC50jqvJr1A+kjPnOkWWYmWFs7B0/2HNqyvhnHnOPY1RdRJiPbtLGkZ+b1LufP7ZGFa8ojzmuZ5Tn1/vpUKbiIiIyDQZ7Gk7sBjJ75qNfjfWz02xscPZ1mUUpk9mX73U+cbmBP+2McGCEqe0IMrSlybi62GVPmKFwul01+4YMpgwSPr+XUYJnMsWOuvT1SA3d0YBjosbcj+wASwti0qlS8r8gOGbi8ucp9qM3hQvhuq2PvBxlPCvTf9MnDF35IIl+aYoEb1tI7m0wTm9zse9dlzC4NJ0wZK9vcaZc1NU5dncwBz49RYRERGZHSoLYh5OZjGSzZ3w890JHm+NOU2LywZ6bsA9ijGcUOts7UrxSLOxpTNKzzuDoejoKuetK7NbraQvBb9tNk6odV631OlJQUcSOvrj9uumWE9vY6dz3bIUj7QYBeasrZ4ZPSJmcELt8G1dXOY4UYxkeXlsGyj3Xz1GaFte7tQVO+smUBkx3yWMCc9rPKoKVlY4mzoYczmBmUihTURERGSamA2W/d/Q4fxsV4Kn242yAueiBSnOmhu9UIvLYpHwzqRzdFWcgF62MHqqIAp49KagOwl3Nxr37zVa+rJbefCRZqMraZxeF/OyBnoDB3pLjqpKcXej8aOdCUq3Gk+3G0dVQVkeFN5YnB7quq3LWJ6ew9bSF9vG+kzWVMOa6llQHnSKmcF1S1Ps7YU54+yhm0kU2kRERESmUV0xPNEKj7UWUFHgXNqQ4oy5MeRxwJKyOPHvShorKg7sNUhkhKKz6p1f7k3wm33GBfOz18PwYJMxv8RZdUC5t2AG5813elIpfrY7xgG+vCE/wsqcIigr8P2KkTT3Rk9obZ4N08tltcWDw03zjUKbiIiIyDQ6vNLZ3WOcVZ/itLrhC4ssyihSsnKM6oP1JbCqwnm4yTh/nk9r9cHuJNzTaOzthU2dxhULx65+eNECZ29vimfajDUzZGjkWMxgUen+xUia+2INtvI86EmU7FNoExEREZlGZ89zzh5jzk1VIdQUOT1JWDCOsuWn1jnf3pJgQycj9nRNhYeaomR/TZGzutI5eRxLEiQMXrfU6U35sGvVzVSLy5xf7TWSHtULm/uily3fS/jL9FBoExEREclBJ9Q4fc64FtQ+tsb5n23Og3sH17aaDo+2GItKnfcfMbFhjmbDLy4+ky0ui/X0dvfAwlJo6bO8Haon02+WFBYVERERmVkuX+RctXh8AawkEb1tjzTbiwUwplpTekjk8SNUVJxtFpbG+7CzO1J29LTpvZHJodAmIiIikgfOmus4cP+e6RmP94eWeJ7jZ8mC0GOZVwKGs7s7FtZu7VMREpk8Cm0iIiIieWBuCRxTAw80GT3JqX++R5pt2IWmZ6uiRFQGbeyJwOaYQptMGoU2ERERkTxxTn2KrqTx0L6p7W3b3Q1bu0y9bEPMK4HdPUbzi2u06f2RyaHQJiIiIpInlpfD6krnpzunbm5bTwr+Y3OC0oRz0jiqRc4m80uc3T2xeDrk75phMv0U2kRERETyhBlcszhF0uF7WxP4JGeqpMN3tiTY2Q2vX56iRsP/9jO/JCpIbuyM7zU8UiaLSv6LiIiI5JH6ErikwbltR4L/2mqcUOusqoDCQ7hU35WEXzcZv9xjNPcZly1McVTV5LU5X8xPV5B8ts0oSThlebasgWRPXoQ2M6sFvgxcArQCf+PuXxhmvy8Br8/YVAT0unvVRI4jIiIiksvOqnd2dKf4XbPx0L4EJQnnyCo4uso5utqpHOcZ4L5euG+P8esmoydlHFbhXLU4ydEKbMOany7K0thrLCjR0FGZPHkR2oB/Jl7LIuAw4E4ze9Ld78rcyd3fBbxr4HszuwVITfQ4IiIiIrksYfDqpc4rFzvPtsOTrcYTrcYfWhIYzrLyCHDlheAOJ9Q6FRlnhVs74Z49xqPN6bL+tc459SmWlGfpBc0QFQVQXuB0JlU5UibXjA9tZlYBXAuc6O5twCNm9jXgLcCIYSv9uKuByw7lOCIiIiK5qjgBa6thbbXj7mzrgifajCdbjdt3DY6XvH+v885VKdr64Ac7EjzfEcP71tc7Z9U7c1RQY1zMordtYyfUFqunTSbPjA9twBGAufsTGdseAS4a43FXA43AvRM9TnoYZe2QzUvG22ARERGR6WYGS8phSblz0QKnsz8Ki+zohq9vSvD5ZxN09ENFIVy2MMVpdZqTdTDmlzgbO01FWmRS5UNoqyTmn2VqBsYabX098O/uL9ZVmshxbgI+OpFGioiIiOSS8vRZYFURvGNlim9sTnDGXOfiBoW1QzEvPa9NwyNlMuVDaGsHqodsqwHaRnqAmS0DzgXefpDHuRm4Zci2JcB9YzVWREREJNcsr4APH50ae0cZU0O6gmSdhkfKJMqH0PYM4GZ2tLs/md52AvDYKI95A3C/u79wMMdx92aiF+5FZnYwbRcRERGRPHJkFVy/PMmqimy3RPLJjF9c2907gO8BnzSzKjM7jige8rVRHvZGhvSUHeRxRERERERelDA4tia+ikyWGR/a0t4NOLADuB34mLvfZWbLzKw9PRwSADNbRwxl/K/xHmfKWy8iIiIiIjKCfBgeOTBc8dphtm8mCoxkbnsAGLbDeqTjiIiIiIiIZEu+9LSJiIiIiIjkJYU2ERERERGRHKbQJiIiIiIiksMU2kRERERERHJYXhQiyREFAFu3bs12O8bUtXsHiaLiMfdr276DwrLWcR93x57dJKbpMsCefY1s3bFtwo/rbG6nauNG9jbtoXDst0BERERE8sDepj1s3Lgx280A9ssLBeN9jLlrtfbJYGZnAfdlux0iIiIiIjIjrHf3X45nR4W2SWJmJcApxBpvySw3J18sIYLwemDgksQGYGXWWiSZJuOzGO4zlomZCb8Ts+VzngmfxVTIxc93tn4WU+VgP2N9Drkj87PIxd/Z2WQDsBpYCDzs7j3jeZCGR06S9Bs+rqQs42NmA//c6u4bB7YN/FuyazI+i+E+Y5mYmfA7MVs+55nwWUyFXPx8Z+tnMVUO9jPW55A7Mj+LXPydnU3Sn8XzwPMTeZwKkYiIiIiIiOQwhTaZaT6e7QbIi/RZ5AZ9DrlDn0Xu0GeRG/Q55A59FrnjoD4LzWmTnGVmK0iPwVb3fX7SZzw76HPOb/p8858+4/yiz3NmUk+b5LJm4mpEc3abIVOoGX3Gs0Ez+pzzWTP6fPNdM/qM80kz+jxnHPW0iYiIiIiI5DD1tImIiIiIiOQwhTYREREREZEcptAmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMREREREclhCm0iIiIiIiI5TKFNREREREQkhym0iYiIiIiI5DCFNhERERERkRym0CYiIiIiIpLDFNpERERERERymEKbiIiIiIhIDlNoExERERERyWEKbSIiIiIiIjlMoU1ERERERCSHKbSJiIiIiIjkMIU2ERERERGRHKbQJiIiIiIiksMU2kRERERERHKYQpuIiIiIiEgOU2gTERERERHJYQptIiIiIiIiOUyhTUREREREJIcptImIiIiIiOQwhTYREREREZEcptAmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMREREREclhCm0iIiIiIiI5TKFNREREREQkhym0iYiIiIiI5DCFNhERERERkRym0CYiIiIiIpLDFNpERERERERymEKbiIiIiIhIDlNoExERERERyWEKbSIiIiIiIjlMoU1ERERERCSHKbSJiIiIiIjkMIU2ERERERGRHKbQJiIiIiIiksMU2kRERERERHKYQpuIiIiIiEgOU2gTERERERHJYQptIiIiIiIiOUyhTUREREREJIcptImIiIiIiOQwhTYREREREZEcptAmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMREREREclhCm0iIiIiIiI5TKFNREREREQkhym0iYiIiIiI5DCFNhERERERkRym0CYiIiIiIpLDFNpERERERERymEKbiIiIiIhIDlNoExERERERyWEKbSIiIiIiIjlMoU1ERERERCSHKbSJiIiIiIjkMIU2ERERERGRHKbQJiIiIiIiksMU2kRERERERHKYQpuIiIiIiEgOU2gTERERERHJYQptIiIiIiIiOUyhTUREREREJIcptImIiIiIiOQwhTYREREREZEcptAmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMRkVnBzDaa2Zuy3Y5cYWa3mNkt2W6HiIiMTaFNRERyxkjByszuNrOPTX+Lpo6ZvcnMNma7HeOVj5+BiMhModAmIiIyDmZWlO02DCdX2yUiIpNHoU1ERGYUM1thZm5mrzezP5hZm5n9ysyOytin0sz+1cz2mtk2M7tpmOMcZWY/NLNd6X2+YGYVGfdvNLOPmtmdZtYGvMvMGs3s/PT9NWbWZ2b/nvGY/zKzv0n/+1wze8DMmtLt+IGZrUzftx74ErDMzNrTtysPsl3vHOU9epuZPWlmrWb2s4HnH+F9XWpmt5rZbjPbnn7/5qTv+xKwHvjLdFt3ju/TEhGRyaDQJiIiM9UbgJcC84CdwL9k3Pc54Lj07QjgGGDxwJ1mVg/cB9wBLAOOBw4Hbh7yHO8EPgJUA/8K/Dz9nADnARuAC9PHTADnp48J0Ae8D1iQPnYS+AaAu98HvAvY7O6V6dv3D7JdXxvlPXprun0LgY3AbWZWMHSn9LYfAW3AYennXQZ8Pd3ed6Xb9el0WxtGeU4REZlkCm0iIjJTfdzdd7l7NxFcToUXw9Mbgb92923u3kGEJ8t47BuBp9z9n9y9x933ECHojUNCzb+6+689dAJ3Ahel77sI+ArQbWbHAicDJcADAO5+v7s/6O597t4EfBxYZ2blo7ymg23XSD4x5D04euB9GuJUYA1wo7u3uXtjev/LzUwBTUQkywqz3QAREZEMfcBwc7SK0vdl2p7x73agMv3veUR42jBwp7u3mdmejP0PB04zs+aMbQY40ABsS2/bwP7uBL6S7hF7KXAtsDr97zLgHnfvBTCzE4BPAydktM3S7ds0zGs8lHaNZLj3YCnpYJlhKbDH3Vsztj2X/rqM6MkUEZEsUU+biIjkkg1EcHlRuudsFfD8OI/RCPQAKzKOUQnUZ+yzE7jb3WszbjXuXuru2zL2S2Ue2N03A88CbwOqgEeJoYwXpW93Zuz+XeAJYI27VwPnDDRnuGMfSrtGsWLgHxnvwdZh9tsC1JtZVca2w9JfN0/wOUVEZJIptImISC75N+BtZnaemRWmQ8TfED1Nt4/nAO6eIuaOfdzMFqWHI/7DMM9zspm9y8zKLSwdKAYyhjuBDwE/c3cn5rmdCaxj/9BWA7QCrWa2APjEkOPsBOYNFPuYhHYN56+GvAdPA78eZr+HgSeBf0wXcakn5gX+yN0Hetl2EvMDRURkmim0iYhIznD3bwF/Bnwe2EP0aq0FLnT35gkc6n1EL9dj6WM8SUYPU7rH7AzgZUQPXjPwU+DYcRz7TiKQ3ZE+VnP6eRrd/fGM/d4KvJ4o7vEz4L+HHOcXRPGP58ys2cyuOMR2DeffiFC5k+jBfIW7J4fu5O79wGXAHKK384/E8NM3Zuz2D8Ax6bYO11snIiJTxOIioYiIiOQLM1tBhK+V7r4xu60REZFDpZ42ERERERGRHDYrQpuZ1ZrZd9MLsG4zsxvS25ea2YNmts/M/mHIY75yCHMIREREREREJsVsKfn/z8RrXURUw7rTzJ4kSjUPLJT6OzP7lrv/xszOBOa5+/ez1WAREZGDlR4SaWPtJyIiM0PehzYzqyDC2Ynu3gY8YmZfA95ClD7+fnrtmt8Aq8zsEeD/A16drTaLiIiIiIgMyPvQRpQnNnd/ImPbI8R6Oj8DzjezB4GXAJ8C3g/cmq7gNSwzqwVqh2wuJtYRehY4oDKXiIiIiIgIUAAsBB52957xPGA2hLZKYp2cTM3EoqifAb4I3Ad8AWgHrgReamZfJMpM3+vuHxny+JuAj05Zi0VEREREJN+tB345nh1nQ2hrB6qHbKsB2ty9iYxhkGb2v8T6QNcTCfgc4A4zu9jdMxd1vRm4ZcgxlwN333fffSxZsmRSX0BWPPd7+Pk3oWYelFWMvF9fLzRuBUuAJ2HBCigomJw2uENnG7Tvg/5eKCmH48+DxYfDnV+HVBLmLBj9GO0t0LIb1p4F51wb27Y8DXfcAqUVUFk7OW0VERERkdzV2QpX3ghlldluCVu3bmX9+vUAO8b7mNkQ2p4B3MyOdvcn09tOIBZCfZGZvRLY4e4PmNkbgd+4u6fnuh0HvBja0gupNg95PABLlixhxYoVU/JCptW8OfDsvdDbFf8eyb6dMKccTn4ZPHYflAA1o+w/Hu7Q0wktjZDogjmVsGYdnH0tVM2B/j548k5o3Tt629wh2QwldXD566FuYfq11cETd0B3x+iPFxEREZH80GGwfDmUV2W7JZnGPaUq70v+u3sH8D3gk2ZWZWbHEUVIvjawj5lVAn8JfCi9aQNwrpkVA2cCL0xvq3NARQ0sXg293RF+htPXCx2tUFYF666AqrkRhA5VR0v03vX1wJIj4Y0fh5e/IwIbQGER1C+J8Daa7o5o/6LVg4ENoKIa5jRAf/+ht1VEREREZIrlfWhLezfgRBfk7cDH3P2ujPs/Dtyc7kED+H/AXKAR2Ar8z/Q1NYcc/hLAoKv9wPtSSdi7HVIpOPmiCHnL10ZISqUO/jndob0ZEgm48r1w3UdgwbID92tYAan+0YNbR/o4615x4H1Lj4whl8kxgps77N4MbU0TeBEiIiIiIpNnNgyPHBjOeO0o9//ZkO9bgJdNcbNy37KjY85Xe/P+Xcnu0LQjhk6uOh5Ovzy2rzoO/nB3DGsca67ZSPq6I/g1rIAjXjLyfnMXQ1Fp9KaVV4GnoKAo4zg90NUB1fXxOoZqWAnFpTG+uapulPb0xHP0dI2+n4iIiIjIFJktPW1yMCpqokeqt2uw98w9QllnG9QvhitugIJ09l92dNxa98KebSMPqxxNRxvg8JIxMvPchVFIpKs9hlLu3LB/D197cwS5014+fGGU+ctjWOdYwzl7OuN1eGrs4ZgiIiIiIlNAoU1Gd+SpkCiIHimI+WZt+6C8Gq75swhOAwqL4Kr3RVGSzraJDylMpaCrNapEjtbLBtGDVlYFXW0RrPr7498QQzc7W6Nta9YN//iKaqhbMPbwyJ5OMIPC4pi/JyIiIiIyzRTaZHTLjobquRHWujugeXeEs1e+F2rnH7h/IgHrr4a6hhhSOB693TFvbPemKG6y6ngoKRv9MYkELFgePWBlVTF0sTMd2jpaoldszRlQWj7yMRYdHs+XHKFwTyoF3Z2Dx+/pHN/rERERERGZRAptMrqSsghRvV0xjw3gpdfHsMmRlFbE0EofZxXTzraYf2aJCIinXza+x61ZF8Mcr7ppsJqke6zNVlgMp1w8+uPnLYn9ekYYItnbHb12y9fGcMykhkeKiIiIyPSbFYVI5BAd8RL4470xf+z0y+DY9WM/Zu4i2P5chKj0GnYj6uuO3rt3/H8xbHG8lq+Bt3w6jr9iLWx6PIZF9nXH92MVQ6lfHAuHd7XHcM+hBnrWjj4NmnfB84/GMMxC/dqIiIiIyPTR2aeMbfHhsPbMmDN2zqvHDmEQoc095owVFo28n3v0aJVWHNxihwNtWXRY9Aru2zVymf+hahdAaSW07hm+Xd0d0fbFh8c8u5KyCIXVqiIpIiIiItNHoU3GVlAIF10/scfUzEsPPewaPbQNrJU2b+n4wuBIFqyI3rKO1giMow3fHFBQAPOXQdP2/XsE+/tg387oaZu3NJY9SCSgrDLmuKHQJiIiIiLTR3PaZGrU1EfP1FjFO/p6IjAtW3Noz1dSFmu7JRIxhDMxTJn/4SxcGQVHBuardbVHUZSu9giCV70vtpdXQ+WcmOMmIiIiIjKN1NMmU6NmXnrx6rbR9+vtiQIkS4849OdcdwUUlcDRp4//MXMXQ3FZtNNT0NoECYOTXgrnvRaKijP2XQjbnx/fPD0RERERkUmi0CZTo7Q8Kki2N4++X293FPaYu+jQn3PeUrjkbRN7TP3imE/XvBvwGAJ58VvhiJMPDGa1CyKwpZKDC4qLiIiIiEwxDY+UqVO/OOasuQ9/f2YRkrKDKEIyGSpqYpkBT0HDSrj+E3DkKcP3pNXUxzy43u7pb6eIiIiIzFrqLpCpU5fuPUv2RVGSofp7ITUJRUgOhRlc8lbY+Ec45uz9h0MOVVUXQz57uqJHTkRERERkGii0ydSpqY/Kkd0dUDlMGOrtnpwiJIdqzoKx13SD6JEbCG0iIiIiItNEwyNl6ixcBRW10LQzgttQnW0xN2zF2mlv2kGpqIWi0pGHe4qIiIiITAGFNpk6lbVw7Z9DXQPs2gRtTYP39fdGkKuqi9L6M0FBQfQeDiwPICIiIiIyDRTaZGrNmQ/XfxJWHRc9bnvTC1l3tkUVxhMuiLXVZoq6hlh8W71tIiIiIjJNZtDZssxYJWXR43bKJdDRAjs3QEdrrKm29oxst25iauZF8ZK+3my3RERERERmibwObWZ2rpmlzKw94/bWjPv/3Mz2mNnjZnZsxvbDzOyXZlaQnZbnoUQCLnw9XPJ2SKViaOTClVBdl+2WTUx1fYTN3q54HSIiIiIiU2w2VI/c7e4NQzea2ULgL4A1wFXAZ4DL0nf/X+Amd09OWytni+PPgbkL4effhHWvyHZrJq66LkJb615oaYTSKph7wI+XiIiIiMikyeuetjEsA551993AXcAqADN7DfC8u/8mm43La0uOgOs/HvPcZprquVFBcqDsf8e+CHAiIiIiIlNkNvS0zTWznUAXcBvwYXdvB54DVqV73M4DHjezauADwPmjHdDMaoHaIZuXTHK7JReVVsCZr4DNT8G6K+AX34CnfxO9b1pwW0RERESmQL73tD0FHA8sIoLYicA/Arj7XuB9wI+AK4iw9mngs8BJZvYLM7vDzI4Z5rg3ARuG3O6b0lciuWPtmXDJW6F2Hrz8XbBgGTRujaqSIiIiIiKTLK9Cm5ldl1Fw5HF33+nuT7h7yt03EHPYrh7Y392/5e4nufulwHxgBXAr8B/Am4FPAF8d5qluBlYOua2fwpcmuaqkDK58L1RUw66N4CpOIiIiIiKTK69Cm7t/090r07e1w+0C2NCN6SqRnwduBOYBBe6+CXgYOGDilbs3u/vGzBuwdTJfi8wgdQ1w2Z+AJWDXZq3hJiIiIiKTKq9C21Bmdp6ZLbewFPhb4H+G2fVPgR+5+wvAXqDMzNYQc91emL4Wy4y18hg451ro64bm3RHcUkkFOBERERE5ZPleiORE4BvAHCKM/Q/w4cwdzGwR8BrgbAB37zezdwM/B3qIYZIiYzv5YtizDR65C9qbI7AVFEJ5NdTMhYSW/RMRERGRicvr0ObunwM+N8Y+24F1Q7b9J/CfU9g0yUdmcOEbwQpg0+MR1tqaYj03A2rnZ7uFIiIiIjID5XVoE5l2RcVwcUbnbG83fP2j0NWWvTaJiIiIyIyW13PaRLKuuBRKy2N+m4iIiIjIQVBoE5lqlbUKbSIiIiJy0BTaRKZadT0k+1VJUkREREQOikKbyFSrnBNf1dsmIiIiIgdBoU1kqpVXRbn//r5st0REREREZiCFNpGpVlEDhUWx8LaIiIiIyAQptIlMtfIqKCyGvp5st0REREREZiCFNpGpVl4doS2pOW0iIiIiMnEKbSJTrbwaCgtVPVJEREREDopCm8hUKyyC0krwVLZbIiIiIiIzkEKbyHSoqou12iYq2Q/tzeqlExEREZnFCrPdAJFZoXoupNILbJuN/3HNjdC+DywBFdVT1z4RERERyVnqaROZDhU1Ebwm0tvW2w2drRHyOtumrm0iIiIiktMU2kSmQ0VNLLDd1zv+x7TujZ65qnQvnYiIiIjMSgptItOhvHrsBbZTyRgOuf35uHW2Qe08OPq0WONtuHlt3Z3Qtk9z3kRERETymOa0iUyHylooLIHergPv8xS0t0BbU4SzknIoKYsQ99I3xjDJREEEtLKK9GM85rq17IH+vjhG9dxpfUkiIiIiMj0U2kSmw9xFsGA5PPf7CGOJggheXe3QuieCWVEJnHgBnHVVhLwBjVuhrBK6WiO0pVLQvCuCXnEpzFkA+3ZB5RxIqPNcREREJN/M6DM8M1toZreZ2Q4zczNbMcw+nzKzPWbWbGZfNLOi9PZCM/t2evvtZlad8ZjrzOzm6XslkvfM4MwrI2Q17YKeLmjcAnu2QX8/rDwe3vRJuPgt+wc2gLqGCG39fdDfG49rb4aaenjdh+GSt8XQy307s/DCRERERGSqzejQBqSA24GrhrvTzN4GvAY4GVgNnAB8JH33VUADMB9oAt6Rfkwt8H7gr6au2TIrNayEI06GjhbYvQl6OmH+Mnjt/4FXfSB644ZTUAgLVkTQ270lvi5bA2/8ODSsgMWHx3E7Ww9uLTgRERERyWkzeniku+8CvmBmI72ONwOfc/eNAGb2CeDLwEeBlcCv3L3XzO4Bjk8/5m+BT7u7aqzL5DvzStj6TPSanfdaOOqUGCo5loWr4PH7o4rkKRfDOa+K3jWIXrxTLoHnH4lhkvWLp/IViIiIiMg0m9GhbRyOAR7N+P4RYImZ1QCPAR80s1LgHOB+MzsNWOTut4520HRvXO2QzUsmqc2Sz2rnw1s/E/8eCF3jcdRpsHMDLD8W1px24ALd85dFj9uGP8ScN81tExEREckb+R7aKoGWjO+b01+rgB8D64GHgAeBW4A7gOvM7EbgGmArcIO7N7O/m4jeOpGJm0hYG1BeBZe+feT7zeCE82Hj49DRDFV1B908EREREcktM+pyfLpASHv69vg4HtIOVGd8X5P+2ubhQ+5+nLu/A3gXcBtQQcxvuwB4AvjQMMe9mRhemXlbfzCvSWTSrDgG5i6MIiUiIiIikjdmVGhz92+6e2X6tnYcD3mMwblqEIVItrp7Zu8bZraU6Fn7HDGk8g/u3gc8DBw3TDua3X1j5o3olRPJnsIiWHNGuspkX7ZbIyIiIiKTZEaFtuGk56SVpL8tMbNSsxcn/NwCvM/MlptZPVER8mvDHOZm4APpoLYBOMXMKoFzgRemsPkik2ve0liYu6s92y0RERERkUmSD3PaujL+/VT660pgI/BVYAXwW6AI+BbwqcwHm9llwF53vx/A3R8ysx8BW4CniR44kZmhdj6UlMeyAFVzst0aEREREZkEMz60ubuNcp8DH07fRtrnh8APh2y7iSg2IjKz1NTHAt69XWPvKyIiIiIzwowfHikiGQoKoa5Bc9pERERE8ohCm0i+mbcUkv2xXpuIiIiIzHgKbSL5Zk4DJAqgtzvbLRERERGRSaDQJpJv5iyICpLdqiApIiIikg8U2kTyTe28CG19mtcmIiIikg8U2kTyTVkVlFeDJ7PdEhERERGZBAptIvnGDOYtgb5ecM92a0RERETkECm0ieSjxUeCp6ClcXz7d3fEgtwiIiIiknOytri2mZ0JnApUZW53909kp0UieWTN6fDCI/D4r6CgCKrmjLxvKgVNOyHZB0uOjJ46EREREckZWQltZvZR4MPAo0BmiTsHFNpEDlWiAC59B3R1wAuPQn8v1M4fPpB1tcVQSjwW5S4qnvbmioiIiMjIstXT9k7gXHf/VZaeXyT/FRbB1e+DH38FnvhVDIGcvwwKMn7t3aG9GfDYv7dLoU1EREQkx2RrTlsx8ECWnltk9igsgitugEveFgFt+3PQldG53dMVt7qGqDjZm57X1tkKnW3ZabOIiIiI7Cdboe1bwCuz9Nwis8/x58KbPhlDJHdvhn27oueteTcYcNbVUFQCyWSEu+bdsHtTfBURERGRrMrW8Mg5wDfM7F5ge+Yd7v6W7DRJJM/VL4a3fAZ+8tUYLtm6N+a+LT0ajjgZfv+z6GHr7425bWVV0LInCpXMWaACJSIiIiJZkq3Q1gd8J/1vnQmKTJei4hguueo4eOyXcPLL4LATIpDVLYQdG2K4pDuccSXs2wGP3BXLB9QtVHATERERyYKshDZ3f3M2nldE0o45K26Z6hZGOOvuhIICWL4GTr0khk0+fHvcN3exgpuIiIjINMvKnDYze6uZLcnGc4vICGrqY0237nYoKI7hlGZw/nWw7hXQ2Q6NW6IXTkRERESmTbYKkbwT2GhmT5nZ/zWzK8ysasxHicjUqa6H4tJYs23uwqg8CRHczr4GzrkWejqjAmXLHkj2Z7e9IiIiIrNEVkKbu58KzAf+GigB/hHYa2b3TeQ4ZrbQzG4zsx1m5ma2Ysj9HzOzPjNrz7gdkb6v0My+bWbNZna7mVVnPO46M7v5EF+myMxSkw5tqSSsPHb/+8xg3RWxYHd5dVSV3LkxipQMSKWgbR/09Uxrs0VERETyXbZ62nD3JuB24Cfprx3AygkeJpV+7FWj7HOru1dm3J5Jb78KaCDCYxPwDgAzqwXeD/zVBNsiMrNV1EBJWfSwDQ1tA45dD+/+p1i0O5GAPVtjuGRXeywRsG8n7HghlhMQERERkUmRrTltHzOz+4EtRFh6Fljv7hOa5+buu9z9C8DDB9GMlcCv3L0XuAdYld7+t8Cn3V0rC8vsYgbzlkap//nLRt/3iJPh1JdHONv+XMx16++DFcdGQZNdm6FLv0IiIiIikyFbJf//GngGuAH4kbs3T+FzXWJmTcAO4Ivu/s/p7Y8BHzSzUuAc4H4zOw1Y5O63jnbAdG9c7ZDNKqwiM9+Fr4ej10Fpxdj7rrs8eto2/BGWrYGTL4JVx0eQ+9ZnYNfGKGZSUTPlzRYRERHJZ9kKbccALwVeB3zBzJ4E7gDucPdfTuLzfBf4MrALOA241cxa3P0/gB8D64GHgAeBW9JtuM7MbgSuAbYCNwwTKm8CPjqJ7RTJDSXlsGqEoZFDFRbBK2+MOXCJgsHtZZXwug/Df/0dbH02hk9W1h74+P4+2LcLqufGsMxsSyYBh4Js/VkUERERGV62CpE84e7/6O4vBxYA3wfeQwxTHFG6QMhAQZHHx/k829096e6/IgqeXJO+z939Q+5+nLu/A3gXcBtQQQzZvAB4AvjQMIe+mRhemXlbP46XLpJ/MgPbgNJyeM3/gRXHwN7t0Lp3//vdI7B1tsZcuGxWonSH9mbYtSHm42UWVxERERHJAVm5pJyu8vhS4CLgfKCICGx3jvY4d/8m8M1DeOphF5gys6VEmDubKFDyB3fvM7OHgfcO045moHnIMQ6hWSJ5qKgErv0AfP//wrO/BUtA1Zy4r705ipfUzoOerpgT1zDROkSToK8nKmF2tQ+Gz7amqKQpIiIikiOyVT3yWeDNwJPAlUCdu1/u7v800QOl56SVpL8tMbNSSycoM3uFmc2xcCpwI/A/wxzmZuAD7t4HbABOMbNK4FzghYm2SUTSCovgle+F5WsiHKVSEZRa90BRMVz5Xjjr6ti27VnYlw5Qo/V2uR96z1wqFWvN7doEXR0wfzm8/qNRgKVTBVREREQkt2Rr8ka9u7dM0rG6Mv79VPrrSmAj8Brga0So2wp81t1vyXywmV0G7HX3+wHc/SEz+xFR2fJp0sMpReQgFRTA+mvgv/4+hkQm+2Ie3OmXw8KVsGA5pPrhN3dEmGtLD6UsrYhKlqXlUFgc1S37e+MY3R0wfymUjKNgylA9XbE0QW93HPvMq+GkC2Iu25oz4K7/jBBZVDL2sURERESmQVZCm7u3mFkF8HJgGbCZqCI54cWd3H3EcYnu/tpxPP6HwA+HbLuJKDYiIpNhyRExv+3phyN8LVwVi3VDrPd26qVx62iBpx6GZx6OpQT27YyetYLCuCX7I/BZApr3wIIJhrbujphj5yk47AS46E37D4U8/CXw0I+jF65+8WS9ehEREZFDkq05bUcT89cKiB6x5cDnzOwid38iG20SkSlkFiFt0xMRmC6/IYZODlVRAy+5MG7usO05ePLXsPEP0NMJGByzHno64JG7YphjYoxR3sn+WDOuvy9CoXsMyVx3RbQr05z5sPjwmIOXTEYvoYiIiEiWZWt45OeB/wA+7O4pM0sAnyTmll2UpTaJyFRauAqueh94Euoaxt7fDJYcHrehNj4Oj/9q7KIhqSQ0boXerjheYTGcfQ2cfPGBgW3Auitg4x9h77axFxkXERERmQbZCm0vAa5w9xRAOrh9kph3JiL5avnRk3OcJUdE5cnmxpFDm6diKGRvVwzNPOfVsSZcRfXox25YEUM177sV2lugUouDi4iISHZlq3pkBzB/yLZ56e0iIqMrLILDT45iIk07oLUp1nzr6YrhkD2dsHtLVIKcvwKuvDGKnowV2AacdhksPiKO3dc9vsd0d0Bf70G/JBEREZGRZCu03Qp838xeZmZHmNnL0tu+l6X2iMhMc8xZMXyxoxWad8GebbBzQywdsGtTBLolR8K1748qkRNRWARX3BDryu3cOHYY6+2O59+1UYtzi4iIyKTL1vDIDwOfI9ZMKwW6gVvS20VExjZnPrz5UxGYWhojNO3dDnu2Q2cLnHghHHXq2IVKRlJTD6/5EPzn38DuzbB49fD7eSq9lEF/PJcW5xYREZFJlq2S/93ADWb2bqAe2OPuno22iMgMZgYlZdHjNhVFQ+YuikqTd349hl6WlB24T9u+GI659EjAYMfzUFV38GFRREREZIisnlV4aFRgE5GctewoKK+OcJbJPQqhtOyJMPfyd0YBEww6mrPRUhEREclT09bTZmYbgDHDmbuvmobmiIiMT91CmLMg5qsNSPbHwt+dbVBWBVe8O/apngsLlkURlKq6rDVZRERE8st0Do/8WMa/lwPvBv4N2ACsBK4HvjCN7RERGZsZHHY8bH06FuhOpaBpe8ylq18CV78vAhtAQSEcfz789F+hqwPKKrLbdhEREckL0xba3P3rA/82s58R67T9OmPbfwOfJhbZFhHJHUuPhtLK9BIAPbFo9xEnx5DIofPcjjgZHrgtiqMotImIiMgkyNactlOBh4ds+216u4hIblmwPIY7drbF92ddBVe+Z/jCJGUVcPRp0RPX3ze97RQREZG8lK3QthF445Btrwc2TX9TRETGUFgEL3lpDIO88kY485WQKBh5/2POgvKq6JlTnSURERE5RNlap+3Pgf81s3cSc9pWACcCr8xSe0RERnf8uXDcOTHHbSxzF8HaM+Dh26MoSXVdDKlMpdJfkxHmKmuhuHSqWy4iIiIzXLbWafupmR0NvBZYAvwQuM7dN2SjPSIi4zKewDbg/OtiqYD7boXdmwAbfHyiIBblbm+GhSuhqGQqWisiIiJ5Ils9baQD2qez9fwiIlPKDNZdAatOgI1/jKUBKmpi2GRpRSzWfevnYNcmWLgqKk+KiIiIDCMrZwlmtgW4A7gTuNPd92ajHSIiU27BsrgN5xXvge9+FrY9B3UNEeom0psnIiIis0K2CpG8C2gF/grYbWa/M7PPmtmFWWqPiMj0W3I4vOqDEdj2bo9hlKlktlslIiIiOSYroc3df+Tu73P3tcBS4LvAO4CfTuQ4ZvZyM/ulmTWb2U4z+5qZ1Q7Z51Nmtie9zxfNrCi9vdDMvp3efruZVWc85jozu/lQX6eIyJiWHA5v/zs47zXQ1wfbn4eudlWdFBERkRdlJbSZWYmZvdTM/h74CVFN8ufAn0zwUDXAp4BFwFHAfODmjOd5G/Aa4GRgNXAC8JH03VcBDenHNBGhkXToez/RCygiMvXM4PTL4dUfhNJy2L0Ztj0L+3ZCZysk+/ff3z3WgFOwExERmRWyNfO9mViT7RvAO4GH3D010YO4+39mfNtpZl8G/iFj25uBz7n7RgAz+wTwZeCjwErgV+7ea2b3AMenH/O3wKfdvW2i7REROSTLj4Y/+Uf43c/g0bugaSe07YtwVlQCZZVQVAwdrdDbBVgs5l23cPR140RERGRGy1Zo+yFwHvBqoA6oNbO73b37EI97NvB4xvfHAI9mfP8IsMTMaoDHgA+aWSlwDnC/mZ0GLHL3W0d7knRvXO2QzUsOqeUiIhCh7LRL49bdAc8/Cs/9HrY+DW1NsU9BAcxdHBUnd2+Cxq2wYHl22y0iIiJTJlvrtF1rZkYMW3wp8CHgO2b2kLu/9GCOaWbnA28DzszYXAm0ZHzfnP5aBfwYWA88BDwI3EJUtLzOzG4ErgG2Aje4ezP7u4norRMRmTqlFbFI99oz4vvOdtjyJFTXQ8OKGFb5q9vg3u/GPLiyyqw2V0RERKZGtqpH4u4OdKZvXUSAPH60x6QLhLSnb49nbD8N+A7wKnfP7GlrB6ozvq9Jf23z8CF3P87d30FUtLwNqCDmt10APEEEyqFuJoZXZt7Wj+uFi4gcrPJKOPKUWJB7YGmAky+CeUtiKKXmuImIiOSlbBUi+bqZbQV+A1wG3EMMbVww2uPc/ZvuXpm+rU0f60TgB8Db3f2OIQ95jP2D4AnAVnfP7H3DzJYSPWufI4ZU/sHd+4CHgeOGaUezu2/MvBG9ciIi06u4FM66GnBobsx2a0RERGQKZGtOWyPwVuBed+862IOY2THA7cCN7v79YXa5BfhzM/sx0EFUhPzaMPvdDHzA3fvMbANwiplVAucCLxxs+0REpsURJ8Pqk+Dph6CyNubFiYiISN7I1py2D0zSof4MmAd81cy+mnH8gYkdXwVWAL8FioBvEUsEvMjMLgP2uvv96cc+ZGY/ArYATxM9cCIiucsMLnwD7HgeGrfAwlWDwydFRERkxjPP0hwIMzuS6MmaD7x4duHun8hKgw6Rma0ANmzYsIEVK1ZkuTUiMis9+SD84Iux1tvcxQcGt95uaG+O3rji0my0UEREJDs6muG6v4byqmy3hI0bN7Jy5UqAlQNLk40lKz1tZnYt8E2i0Mea9Ne1wC+BGRnaRESy7qjTYPcWeOB/wXZCXcP+wa2tKUJbWxNU1MDcReqRExERmQGyVT3yr4C3uvsJQEf6641EaBMRkYNhBmdfAydfHFcUm3cP3pdKQnd7XGE86jTobI114ERERCTnZSu0rSB62mBwaORXgbdkpTUiIvnCDC64Do4/L3rUBipKdrVDfz8cdTqceSVU1UFXW1abKiIiIuOTreqRbUA5sY5ao5mtBJrYf001ERE5GGbwsjdBfx88dh9YAnq7oLAQjjsHaudDcRl0tox5KBEREcm+bPW0/Qp4ZfrfPyTWWfsFGh4pIjI5EgVw6dvhqFOheVf0qlXOgYYVUYSkph6S/dlupYiIiIxDtnraXs/gsMgPEuu2VQP/kKX2iIjkn4ICuPwG6OuF534Hx5w9WHhk/jLY+Bi4qxiJiIhIjpv20GZmRcC/A9cDuHsv8OnpboeIyKxQWARXvw+e+Q0sWzO4fe4iSCSgpxtKy7LXPhERERnTtIc2d+8zs/OB3ul+bhGRWamgEI4+ff9tcxbEvLaeDoW26ZBKxddEtmYliIjITJat/z3+B3htlp5bRERq50NJWSy4LVMr2Qe7NsGujTEcdaLcoWWPlmgQEZnFsjWnrRL4mpm9A9gApAbucHeV/RcRmWoVNVBWDZ3t2W5JfkslYc/2qN4JUbGzonZix+jphNY9kEzCvKVQoULLIiKzTbZ62nqA/wReAJwoSjJwExGRqWYG85dAf8/B9f7I2NyhaUeEriVHwLwlsXbeRLU3AwZzF8KerepxExGZhbIV2m4EvgX8lAhvN7r7m939zVlqj4jI7DNvaQSLjtZstyT/uMO+XdDZBvWL4er3w/HnRiXPnq7xH6evJxZGr6qDN3wsCsg075qqVouISI6a9tBmZjcA24GfEIHtp8B2M3vXdLdFRGRWO+r0CG57t0XAUI/b5GndGz1kVXVw7Z9DeRUcvS6+bx7ne+0ObfvAU3D65XGMY86K4Kc19kREZpVpDW1mdg7wOeDvgaOAcuDI9PefM7Ozp7M9IiKzWkU1vOGvYe2ZMWyvaWe2W5Qf2psjtJWWw7UfiIXMASpr4dizo6etacfwwS2Vip61fTthx/PQvg/KqmDtGXH/8jVQWnFwwyxFRGTGmu5CJDcAf+Xuf5+x7VngE2bWDrwbuHea2yQiMnsVFsPlfwJllfDbO6Ik/ZwF2W7VzJRKQmcrNDdCQRG88r2xiHmms66KIY8P/Th6ywbu7+6Ajpb4muyPOYfFZbD8GDjt5VHpE2DBCqiaCy27p/WliYhIdk13aDuVmM82nG+Ocp+IiEwVM7jg9VHh8A/3QqIQauZmu1UzS9s+aG2E/n4oKoaL3xK9YkOZwfmvg+JS+OX/QOs+KC6GPdui562sAlYeB8eshyWHQ1HJ/o8vLIJVx8GvfxQhMVEwPa9PRESyarpDW627DzuD2t13mdmcaW6PiIhA9LBd/LYYuvf0w/F9lf4kj0uyP0ryk4CTLoTjzoWFK0d/zLpXwNZnYOPjUJj+r/hlb47hkwVjBLEVa+F3P4thmNUK1yKzXl9PXMQpKc92S2QKTXchkrGeTyX/RUSypaAArnh39PQ07VBVyfFqb4b+PjjhggheYwU2iPf6ZW+O4iK9PfCSl0V1ybECG8Ci1RHW2vepeIyIxBzanZsiuEnemu7QVmpmfz3SDSieyMHM7OVm9kszazaznWb2NTOrzbj/Y2bWZ2btGbcj0vcVmtm304+93cyqMx53nZndPEmvWURk5igsgqveG+uK7dkaRTFkZKlkhLaSMjj90ok9ds4CuOomWH8NnPuqGDo5HsWlsO7yKFrS0jjRFotIvunvg1R/rAkpeWu6Q9sDwHmj3B6Y4PFqgE8Bi4hqlPOBm4fsW8PjTQAAshVJREFUc6u7V2bcnklvvwpoSD+mCXgHQDr0vR/4qwm2RUQkPxSXwjV/BvOXw+5NsHODwttQfb0RmPZsh/7eqMBZVTfx4yw5AtZfBQUTnK2w5gw44uS4wt7ZFssCiMjs4x7DIxMF0K3Qls+mdU6bu587ycf7z4xvO83sy8A/jPPhK4FfuXuvmd0DHJ/e/rfAp929bRKbKiIys5RVwnUfgbu/DU8+ALu3wJLVURVRoC29DltBUZT0X3fF9D6/GVz4hgjUjZvjhK2sKoZblpRPPASKyMyU7B8sStTfl+3WyBTKt7/qZwOPD9l2iZk1ATuAL7r7P6e3PwZ80MxKgXOA+83sNGCRu9862pOke+Nqh2xecohtFxHJLaXlUQXxhPPhO5+Flr1Q15DtVuWG3p6o7Pj2v4+CLeMd2jiZKmvhTZ+CR34BTz0UvaIdrYDHWm51DQdWnxSR/NLfF71tJaWa05bn8ia0mdn5wNuAMzM2fxf4MrALOA241cxa3P0/gB8D64GHgAeBW4A7gOvM7EbgGmArcIO7Nw95upuAj07VaxERySkLlkP94ujVkZhL1tcTc9KqD2JI5GQqLYfTL4tbXy88+7voGd3wh+gdXXRYdgKliEyP/t74WtcQv/Pu+p3PU9M9p+2QpAuEDBQUeTxj+2nAd4BXufuL2939CXff7u5Jd/8V8I9EGMPDh9z9OHd/B/Au4DaggpjfdgHwBPChYZpyMzG8MvO2fvJfsYhIDjCDo06NK7p93dluTfb19cQcsgXLs92S/RUVw5rT4er3wSveE9uatQi3SF7r7wNLwOIjAM+tIZLJflW4nUQzKrS5+zczCoqsBTCzE4EfAG939zvGOsRwG81sKRHmPgccA/zB3fuAh4HjhmlHs7tvzLwRvXIiIvlp5XFQUQPNe7Pdkuzr64kTkWVHZ7slI1t9YhQqaWuKoZwikp/6e2MO6/ylUFicOxUkO1thxwvQ0ZztluSNGRXahjKzY4DbgRvd/fvD3P8KM5tj4VTgRuB/hjnUzcAH0kFtA3CKmVUC5wIvTFHzRURmjjkLYP4y6OmIq6ezWV9vTPpfMI712LLFDM5/bazntmtjtFkOXX8ftOyJIbIiuaC/N9Z3nL88ihD15sBoiJ4u2Lcr/q9Q5eFJM6NDG/BnwDzgq5lrsWXc/xrgOaAN+Hfgs+5+S+YBzOwyYK+73w/g7g8BPwK2EMsQ/O2UvwoRkVxnBme+Mq7kbntudpeW7uuOK9t1C7LdktFV1cFV74uiJDs3zO7PbDK4w76dMeS0cUu2WyMSP5P9vTEKYs4CKC6BZJaLkfT3wt7tMYR8zgJd5JtEMzq0ufub3T0xZB22yoz7X+vuc9Pbj3L3fxrmGD9Mz2nL3HaTu89x99PdXcMeRUQAFq+GN34sStzv3jw7K5W5x3DD0oq45bqGFfCaD8VSALs2wq5NuTXnZSZpb45eg4qa6Elobcp2i2S26++LXt/a+VBSBpVzIDUFv999PeMLX6lkBLb+Xjj2XDjylMHqlnLIZnRoExGRaVa/GK54d5wgNDdmuzXTr78PUv1QP4NWeVmwHN7x/8Epl0CyD3Y8D93jHLI0W0623COQjbRIeX8vtO6JJRRe/Rew8tjoddv6DGx7FtpbZs97JbkjmQ5E89JFkeqXpEPSGMN3W/bEfNdxPUcyLtJtezYeN9Kx3aFpZ1zQWL4WXvoGqF0QRVI0PHtSKLSJiMjELDoMFq2GrrbZN7dnoAjJkiOy3ZKJKSmDC18Pb/lbmNMAuzZHefDujpHDRlc7bH8uCgrks4Fhj41bYOfG4XuQO1qjp+HUS2HBCnj522HVcbHkQ1kl7N0Ge7bOzt7nmSafwvVAuf8Fy+JrXcPYISmVgvam9BDGcbwXXW0RBCvnxNDgpp0H7uMOLY3xt2LuYrjyPVBYFKMyioqhV0OzJ4NCm4iITIwZnHQBYNDRku3WTK+ejnj9i1dnuyUHp24BvPlTcMJ5MTdv16YIZm1NB86F6WiJk7XGrdC+LzvtnWru0LQjhj6WV8cJ7Y4N0N+//z5dbTGf88QLYlvlHHj1B+Fdn4cb/gnOuDJ6GLY9p8ILucxT0WuU60theGowkA17v8cc1Y7WKIpUtzC218yL3uCerpEf29MZv+uWgJ4xipa4x9+BwqIYZr3y2OEDYUdz/A0pr4Zr/iwuZEAUQiouG709Mm4KbSIiMnErj4uhkq17Z+aV654u2LMtrja3NI7vNbQ3xzC4sqqo1DZTFZXAJW+D934Jzn1NzNFq2gnbnoG9O+KEMZmMXriKWlhxTGxvGya4uUfv42gnmLnKUxHYOlriZPeNH4817goKYOcLgyenfT0xj3HeUqisPfA4iQSccy284aNxkrp7c7xfs60XOle1NQ1eXGpvjtCS63+32luiXH53x/7bB4bxNm6Bxs3Q2xVDIusa4v7aeVBcGttH0tMZC2AVFkN32+jt6OuJY9UthLmLYqh1snf/9y7ZH0PlC4vhqptgzvzB+6rnxt+bsYZryrgotImIyMQVFsGZVwIevTXZOgHq74vgNZHKiL3dEdg62+IEqLkx5mqMprsjrs4XFMEr3wMV1YfW7lxQXArrLocb/hFe+39iHkpHcwSO7vY4GTv6dLj2A7Dq+Ag4rXvjxHffrsF5LjteiB6mzjFOAHNJKhlBtaMl5t287sNxwrvqOHj1h2I46c4XIqx1tQE+2Ms2koWr4O2fhePPjfdxxwsKbtmW7I+LMru3xM/sQPGYRMGBgSiXJNMFRvZsi6/u8fu1e3P0fPd0RYh65XvhTZ+Mn1eA6vqoIDnSz91A6CsqiuqyY80162yNx5x6cYwwqJ0P2P6P6+2O9/nYsw8cNl5cClVzsl/RMk8otImIyME54mS44A3RyzJScBs4aZqKIWPJZJzUtDdHZcTxTKzv7UmfCCUjsLzvy7B8TZxkj3Si09sTQQbgZW+CZWsmp/25ZMUxEdxOvDBO1NqbY1mDY86MgH7Ve2Mx8X07IyS3Nw+WGl91fJxA7tkWV+ZzXUdLzF1rb475fa/7y5h7M2DxanjdR6KXcecLMQStqAQOO2HsYxcWw6Vvh5e9Ob7P9/mAua6rLf5O1DXEBYf+3ggXFTXxueaqZH+EJLPoVdu1KeZM9vVERdhr/xze8pn4G1xQMPi4ouIIbskRKkj290bgmr883pOR9oPoHetsjeGNh58c2wZ6zjJ78nq7o52rTxj+OHMXxfPmcs/mDFGY7QaIiMgMdtIFUU3x59+Mq8Dzl8V/4BBXhpt3x4mGAYuPiCAwGVIpaNoeJw/L18bxNz4e8zSGG8IG0Y69W+NE5SUvg7OvjbaecnH0FHU0x9XnTMm+KDKR6ofTr4Bjzpqc9ueqM14Bz/0ueh6r62I4FMSJ2qv+An73szgxbFgVJ32l5XF/yx74xiciPM9dHMshDPwc5JK+nuhhSxTAceekh4cO02s6bwm8/qPw7c9ESF2+ZmK9q8vXQmVN9OaM9PMok6O/N4JZcemBP3OdbYMXHX51G+zeBOe/Dr73D3GRIVcl++MCwJp18Ojd0cO/9Kj4m7XkiNF/t+qXwIbHInTZkL6Z7o7YvuaMCLQb/hh/SxPD9OF0dcRIhqNfMri8SXV9vM89nYM/171d0b6RhozPSQ/d7O+Lvx1y0BTaRETk0Jz8sjjJuPs7cVV43tK4+tq0AzA48lTY8mT0Vs1feujPN1Dtr6sdFqyMeUiFxfCNj8fQoeFOkvt70z1BfXD8eXHiNnDis/K4OEnfsy0KTAxsT6Vgz/Y40T9qHay/KjeDyGSqmhMVEn/+TTjqtAg3A4qK4bRLh39cTT1ceSP89+cjvBeVQEl5nOCVlsfnkwvvXU9X9LKe82o4/eWj71tbH+sS/uI/o8dxImrmxesfq9CDHBr3+L3t6YpwVjknimEUFUePUk9XLPA8fzm88sb4O1VQGL3G25+Pn4XMn/GpkuyPnr5EQbSzoCj9tXD434v+vvjdeen1cYFk4UpoWDm+36E5CyKE9fXGMQb09QwWFVl1XATYwqIYWl5eeeBxOtNFTl5y0eC26rlQVAp96aHQnoqf8fKq6L0cTvXceJ7eLoW2Q6TQJiIih+60l8eJyX3fi+CU7I8Tqpe+AU66EO78D/jtT+NEYqL/cWdeMR4oLd3REvMrrv2zwfkcJ74Ubv9qXEEuq4p9zdIVELfFcx9zJlx0/f5XlguL4sTkJ1+J0Fm/OB63b2dcUV5yBLz8bdNzcpcLXvLSOPldcvjEHrd4NfzJzfDgj+DRX8Tww47m+BxKSqF+GRRm+bSjpytOlFcdN779y6vgsndO/HkKCqLHcbjy6DJ5utriAlH94rgw07w7biVlcaEglYyLNANhZ6Cnf/Hh8Xeosz16RKdaT+f+w7cHhgpaIuagzV82+PfFPf5+lldFG08aYy7lULXpCpLdnYOhrbM15vSlkjGcec6C+LtYWhHFSIaGtv6+uChWNSeWeBlQUhY9zgPVZPt6YxTCwlUjB8qa+sEKkiMFOxkXhTYREZkc666Ik437vx8nB0efNli84dRL4OlfR+/bghGG0QyntysCV2l5VDBr2zdYWvpVf7F/r9oRJ8ED86Blb1xVbm2KEyFLRHn7I0+NqokFw4SvtWdGQZIH/he2PB2hLpWK53zlTXESNFskCuKzOxiFRXDWlXHr64WdG+DxX8Fj98X8sIaVsU82uMfJc1EJzF049c+3YDk8/dBg745MLvf4e1BQCJe+Iy4a7NoMv/kpPPNwXNgpKhn+Z7lhZVzY6WiOEDLVvcADhTgufXsElz3pdf12bUovqdESw5EhQpCnYk7lwaiZH+GqtyuO07In3qdEQSxNccaV8XrnLIje4I5hqsJ2tsbf8BMuOPBi1dxFMZzcPf0cPvp8z9r50TvXNYMKFeUo/RUREZHJYQZnXRVXd59/BC5+2+DJUE09rD0Lfv2juCJeOEJvWyqZHupUDAmLIZX9vdDRF0FsYMjPNX82WOZ6QGlFzAG5/3/iZKK4LPbtbIXVJ8HlfzLyyXMiEcMfDzse7vluei5SHVzwuvyoFJkNRcWw9Mi4rT0j5hHt3DB8cHOPq/epZJzUjvTzcSj6e6MHYeFh0xOi6hamy6p36mdoKnR3RAhfdNhgb9CCZbHw+aVvgxf+GFVQq+ce+NjK2hgi+cd7IoDUzkuHtymqzzdQWGTBigjzAyGncUv8XvRnFPBJJuP3oWbewT1XdV2E1c72CITdHXGR6/IbYOUxg/sVFUcP2R/uiQtWNfXRRvf4m1lUMvyw4DkN6WVB+qOXs6Bw9HUrS8ri2Pm61uM0UmgTEZHJYxZDJU8bZr7QCedFj8u+3TGHbEAqFYtWd7bHSVZ/uqJZQWGcxB+7PgqEPPCD2Hb5DfsP2cl03Dnw1K/j5OuV740elZ70XIrxDG9cdFhUUZTJtfTIWIz6u38fpfAbVg4Okx0Y8trWFD8LzY1QNTcWAh9Of198lsMVTxhNT7rn4fCTDu21jFddQ5ywdncotE0298E5Yue86sCeMjM4bIwhsJe+PYY+3//9KDazb1f0ClXUTPxnayyp/vibVDZkGGJ5dcxvyyyhn0wv7D5nhJ//sRQURrDavTneh0Wr4cr3DB9eL3x9FBx57rdxoWv+svg96e2O39nhHvPiHLXuwQtscxoO3C9TwwrY9PjwxVFk3BTaRERkesxZAIedCH+8d/AqbVd73JJ98Z95aQUcvS6GMD73O6htgIveHCf4C1bEydTqE0d+jpp6ePPfxL8HenMG5rxJdg0E4u98dv+hks2NMXyrrDJOpH//8+ipLa8crFoH6SGve6MiYHHpxIbZQrrKXSGsWDupL2tEtfPTw8+ap+f5ZpOu9ggMDSsOfgkOs1hT77hz4IkH4Jf/HcO3m3fHHLmhAetQJNOhrXTIMUsr43dg6GLVWPT+HaxVx8Gmx+CY9XDea0ceklxSDte8L0YXPPiD6LnsbE1X1R2l6FBxWcz5TfbH/MCxhjzPXRwBu6d7sOKsTJhCm4iITJ+TLoj5Jtueje/N4sThyJOjJ25RxgnAi5P101fRjzp1fM+RrTlTMrYFy2Mh629/BnZsiBO47o6Yv/Oqv4jhbUuPhH//WPR8LFwVYa2tKdbV8lS65HhXnGCWjPME0D2GKRaVxJyc6VBYFL1tLY2D23o642LF0KUlZPxe7GVLwPnXHfp8NLMYvrv2DHjmN1EttHFLVG0snqS5rMn+KMIztAhTQUHMrWvZs/++RpTXP1gnnBdruJVVju/9OfniCK5Nu6JXsLQCVh47/L7Vc+N9aWmMHraL3zr28V/sdW5XaDsE6qMUEZHps2BFFP0orYyTimv/HN79f+GKd8cV88zANbC4rOSX+sWxeHV1XfSYNBwG1388AhvECePpl8UwyF2bBxfCLq+Gi94Eb/0M1MyNHrrxcIfmXTGnrWHF9BYFWbAiXkcyGUN9m3bEPM3M4XAyMR0t0Wu6+IgI+JPpiJPh9X8VgWn3pvjMJkN//8hrF1bNGRwSCRGaEgXx834oyqvG//ezojr+Lvd1x+/J0aePXOW3vDqKOi1fA2/46/2Huo9kTjq06ef+kKinTUREpo8ZvPSNcMF1s6eEvhyorgHe9DcxhGv1SQeeIK45A37/C9j+XCw/sO4VcNzZgz0fR54GD/04AtFoPaueirL7HS1xnAveMHWvaTjL10TxncYt0SvY2xM9RFqzauJSyeiRam+OzzxzrcXJVDknihZ99+9irtu8Q1xbMpUCT0aP2nCq6uL+gfleA0Mpy0fYf6ocf24UJWnfN1j1dzhmMY9wIsoqYp5qR+shNXG2U2gTEZHpp8Am5ZVxRX84hUVw7Qdi+YWVx+y/SDBEgHvsvugNqayDiqoo6JAplYxera42qF0QhVDmzJ+a1zKSJUfA+qtjyN3AcgNFJRHeKsZ+uKQl+2Kh+57OdI/rW2LB6amy9MgIMb+5Y7Da7cC6jxM1sGZl5Zzh7y9PV61MJqEwEb1yBQUH/sxPtZp6OOfa+J2rH0fv2UQtWA5bnpr4+9jdEUOl5y898Hd8ltHwSBEREck95VUx13G4k9f6xXDKxYDF0McdGw6swNe4NQLbvKVw3UemP7ANOPllcMYVEdbOujrm9CT7stOWmaivF3ZvjcC2bA285dNw1MlT/7wveVkMG2zaFfMhd7wAnS0TP04qHdpqRpijVl4NVhDhEOJnY6ShlFPt2LOjGNBUPHf9kginvd0Te1xXe/RMj3c4dB6b0aHNzI41s9+a2b707WdmtnbIPp8ysz1m1mxmXzSzovT2QjP7dnr77WZWnfGY68zs5ml+OSIiIjJe666A930FXv1/4iR354a4Kt/XE4GtpxOWHA6v/cuYN5QtZrD+GviTm+ElL43egsxqgTKy3q4YWtrfA0edFr2vlbXT89xz5sORp8TP1J5t8XPV0jTx4wwsrD1SNcjyquhZ7uuJ3uFU8tDns+WigWIkLY2Dy7qMR28XYJoPxwwPbcBW4GqgDqgHbgP+a+BOM3sb8BrgZGA1cALwkfTdVwENwHygCXhH+jG1wPuBv5qG9ouIiMjBKiiAlWvhNR+K4LZrY/SI9HbFAsav+uD0zw0aSUV1zGMrr5q8Ahf5rLsjwneyH064MNZnnO55gC+5KCowpvpjyGR/78Q/u1R6Ye2RqkGWVcXr6usdXFg7H6uLNqyEFcdEz9m252J9uLGkkjGUuLA4iqQkD+L3prdnsPLsDDej57S5+z5gH4CZGZAEDjMzc3cH3gx8zt03pvf5BPBl4KPASuBX7t5rZvcAx6cP+7fAp929bVpfjIiIiByc+cvgbZ+FP94Dm5+KNQFHW58qm6rnwvbnR99n6HIXs01naxSQATjrKjjjFdl5L+YugqveG2sDWgJ+8IUIHRU14z9GMglYFOIYTnl1/Jx2dw0OpazN0lDeqVRYBFfcAKe9HP7787EeXtkY8xJ7uiK4LV8LO56PNQ+HW/B7JKkk7N0WQzILCqJq8QwObzM6tA0ws2agkug5/Hg6sAEcAzyasesjwBIzqwEeAz5oZqXAOcD9ZnYasMjdbx3j+WqB2iGbp2DWpoiIiIxLRTWcfnnccll1fZxMDlQLHM6+9BIF85dNb9uyzT2qQzbvjpPsC98Ax5+X3fC69Kj42rInekmHC22eimBQXHZgW5P9UTF0pB7f8qr0MhSpwdL/2Zp/OR0WLIeTLoK7vxW9YEPXwuvriVtZVbynZnD8OdC2J3rMJhLaWvbEsZYeDe1N8bM1g4tg5UVoc/daM6sArgc2ZdxVCWTOGm1Of60CfgysBx4CHgRuAe4ArjOzG4FriOGXN7h7M/u7ieitExERERm/ytoIa319wy/enEpGT1NfTwyZKyoeLN4w3RUFp5M7tO6B1qYYDnf5u2LdtFxRPTd6y3ZvHtzmHp9Va1MM36udd+AwyFS6hH9Z5fDHLSyKHqC2fRFizKAmj0MbwNGnwcO3Q8vuKBSU7I+iQZ1tMRc1lYr3Otkbc0CXHBHr8j32ywhe7hGELRFfE4ko5lJQGP+GKB4zsL7jK2+McNy8a+TPYQaYUXPa0gVC2tO3xzPvc/cO4EvAv5vZwE97O5A5m3Pg0kibhw+5+3Hu/g7gXcScuApiftsFwBPAh4Zpys3E8MrM2/rJeI0iIiKSxypq4uSyf4TCCl3tcRJbUBTzuiB63nZu2H8R5nyR7I/KgLs2Rc9IaTm86s9zK7BBhKllR0WYTiYjYOzaFGu5pfojaPZ0Hfi45DhK+FfWRqn/zpborWuYwuUMckH1XFh1zGCRlx0vpBed74G5i2FZumespzNCVuUcWHVchLS922Dfznjf92yNz2DHC7Gm4/bnBucFtu6J53rp9dELbxaLfM9gM6qnzd2/CXxzlF0SQDmwGNhNDIE8HvhV+v4TgK3uvl/NVjNbSvSsnU0UKPmDu/eZ2cPAe4dpRzODvXYDx5jw6xEREZFZpqImvVZb9/BD5gbmT5WWR0GVVHX04rjHie38Q1zsOde07oG25uhRbFgFl74td4eFLjws2rlrY4TuRAEsORLOvw4e+F/Y+PiBj+nvj895tPPEqrr4jDFYe0qEjHx33Lnw1MPx815ZA2vPivUX6xbGhYt//2gEs0WHxXt3xMnwinfH3L/KmqhA2d0e+3a1R0/lMw9D0/YIhT2dsczAUadm+5VOmhkV2oYys5cBO4lwVgF8iihM8mR6l1uAPzezHwMdREXIrw1zqJuBD6SD2gbgFDOrBM4FXpjClyAiIiKzSUVNeshjz4H39fdF70P13CiP3p4eMpdKxYl9+77ojSgaZlhlrujtiWFoZunhagWDt6JiKCkf3Nc9TrhLyuAdfz+xAh/Z0LAyhtvt2w2LVkVYW3JEvNb5y+D5R+KzGhii56nohRtrSF5F7eBcq1MvncpXkDuWHAGv+ot4jxatjt7IAeVV0UN227/A4SfFtkTB2L2vPy2B3/8CBipbnHV1XhXzmdGhDZgD/BPRs9ZFzE+72N0HVu77KrAC+C1QBHyLCHYvMrPLgL3ufj+Auz9kZj8CtgBPEz1wIiIiIoeuoibmMfUMWWTYHTpaYk7b8efA7i1RkGOgl23dFfDAbdHLU1oRJ7GWMZ+nrHL6S+IPp31fBM+CIvCuOCkfqA/nHq9/7sJoe09nBNUVx+R+YINY7+/q98cwxmVr9g8EdQ3xmfR2Ry8pDA7VG2ttufIqKCyM4XsLlk9Z83POksNHvu+w42Ntw4lcoDjlEnj64fgZrF0Aq0841BbmlBkd2tz928C3R7nfgQ+nbyPt80Pgh0O23UQUGxERERGZPMWlEbram+N79wg5bU1RPKG4FNacATwAz/425kkVFsWcntJK+Pl/RNhxH7zhcaK66LAsvjAicHa1xeu74Z9iW09HrMnV1gTP/AYevTuCTcPKwbW6jjs3Wy2euHlLGLZgeO2C6DHsbs8IbekS/iOt0TZg4SqoWwTrLs+rnqFDVlo+9j6Z6hrg6NPht3fEe1kwo2POAfLr1YiIiIjkuqq6KKDQ3QGteyOsmUUvy/mvi3Xm6hripLOrPYpT1NTH9rXrIgj09cZQyd5uePIB+OV/pwNDFqvjdbZFz9mxZw9Wxiwuidc7f2n0nixfAz/+CuzeFEMJi0pj20w3Z36EtsxFo1PpwjFjrbtWvxje+LEZXY4+Z5z76phnmGe9bKDQJiIiIjK9qusjbO3ekp4PtRTOfS2sPGawp+XFnpsOWLx6/xN6swhDxSVRtOK4c+DRu6I3K6uhrTV6BU84f+R91qyLnsI7vg7JPlh5fLzOma6sCsprYi2xAcn+dNXCBWM/Ps96hbKmqCSWFMhD+gkRERERmU6LDos5aFVz4NzXwMrjBotXDJgzP3rYPAXL145+vMramGP1+C/3L4QxHVIp6GiOHraerggoY83LOuF8aNwKv/8ZnHDudLRy6pnFmmM7no+eULOY02YWa46JHCKFNhEREZHpdOQpUT2vrHLkIXGlFTGscO92WDFGaAM46jR46tdRzKRqzuS2dzSdrVFN0Sxey6kvH3telhlcdH0Mo5w3zPywmap+cVQu7O+LojDJvii4MhtK+MuUU2gTERERmW7jqZa4fE0sIFw/jmCz9KiY99bWNL2hrbs9evau/UD0sJUNs/bcSBbm2SLScxbEkNXujnRo64/QNtx6fCITNI395yIiIiIybme8Aq7/xNjrfEGEhaNOi6UE+nunvm0QoaS7IwLoimNiDbPZXP2wZl7Mz+vpiu8HetxyeV09mTEU2kRERERyVfUE5kOtOSOG4u3bPXXtydTdEfO2jjxtdoe1AdV1EdAG1qZLjmNhbZFxUmgTERERyQd1DTGksqcjCoRMta72qHq4dt3UP9dMUFQCFbWxXl0qGZ9BRW22WyV5QqFNREREJF8cfx4UFsf6b1MplYyetrJKmD9GtcjZpK4hhkX29wMeQyZFJoFCm4iIiEi+WHIkzFsG7c1T29vWujeG/x3+EijQotAvql0QQyP7e+Jr7TjWaBMZB4U2ERERkXxRUADrr4aCBOzbOTXP0dkKbfui8Mi6K6bmOWaq6roYMjpQjGTO/Oy2R/KGQpuIiIhIPlm+BtacGWu2DYSHyZBKRljbtyvWZLvi3bHMgAyqqotKnj0dUZylVu+PTA6t0yYiIiKST8zg7Gth42Ow4wUoLY9esbLKmO820UqPyf4IgO3N0NcTBTfOvBJWHjMVrZ/ZqudCcSl0NEOiUIVIZNIotImIiIjkm4pqeO3/gftuhRcejd6xfbti3bDymghwxaWjB7j+vghqHc3x7+IyOO5sWPeKKLghB6qoTa/LZrGw9kQWGxcZhUKbiIiISD6qnQ+X/0kUxNi1Cf5wLzz3O2jdAy2NMfeqsCjur54bi2RD9Ka174OO1liHrbQcTnopnHpJDP+TkRUUxHu5a1P8u6Qs2y2SPKHQJiIiIpLPzKBhRdwueiM0N8Jj98HTD0c4SyVhz7YIaKnk4LayKjj5IjjxQihXj9G41S0EHEortei4TBqFNhEREZHZpHYenHVV3CCGPt76+RhGCRHWznxlDIVUT9HE1cyDgqLBnkuRSaDQJiIiIjKbFRbBVTfBz/4dervg/Os0DPJQVNfFvLZqvYcyeWZ0yX8zO9bMfmtm+9K3n5nZ2oz7P2ZmfWbWnnE7In1foZl928yazex2M6vOeNx1ZnZzFl6SiIiIyPQrKoZL3gaveI8C26GauyiKttQvyXZLJI/M6NAGbAWuBuqAeuA24L+G7HOru1dm3J5Jb78KaADmA03AOwDMrBZ4P/BXU998EREREckrdQvhdR+Gky7Mdkskj8zo4ZHuvg/YB2BmBiSBw8zM3N3HePhK4Ffu3mtm9wDHp7f/LfBpd2+bqnaLiIiISB6bMz/bLZA8M6ND2wAzawYqiZ7Djw8JbJeYWROwA/iiu/9zevtjwAfNrBQ4B7jfzE4DFrn7rWM8Xy1QO2Sz+sBFRERERGTS5UVoc/daM6sArgc2Zdz1XeDLwC7gNOBWM2tx9/8AfgysBx4CHgRuAe4ArjOzG4FriOGXN7h785CnvAn46FS9HhERERERkQE29ijC3GFm1wH/L/3tJndfO+T+BNAIHO3uu4d5/IeAde7+imHu+zMixP4Q+A5wIvBBoNLdPzRk31qG72m7b8OGDaxYsWLCr01ERERERPLfxo0bWblyJcBKd984nsfMqJ42d/8m8M1RdkkA5cBi4IDQBgybUM1sKdGzdjZRoOQP7t5nZg8D7x2mHc1A85BjjP0CREREREREJmhGV480s5eZ2fFmVpAu2f85ojDJk+n7X2FmcyycCtwI/M8wh7oZ+IC79wEbgFPMrBI4F3hhGl6KiIiIiIjIsGZUT9sw5gD/RPSsdRHz0y529+70/a8BvgaUEPPTPuvut2QewMwuA/a6+/0A7v6Qmf0I2AI8TfTAiYiIiIiIZMWMmtOWy8zsMOC5++67jyVLVEhSREREREQOtHXrVtavXw+w2t2fH89jFNomiZmdBdyX7XaIiIiIiMiMsN7dfzmeHRXaJomZlQCnEOvBJbPcnHyxhAjC64nhrRBzDldmrUWSaTI+i+E+Y5mYmfA7MVs+55nwWUyFXPx8Z+tnMVUO9jPW55A7Mj+LXPydnU02AKuBhcDD7t4zngfN9DltOSP9ho8rKcv4ZFTk3DpQDtXMGG9pVJlak/FZDPcZy8TMhN+J2fI5z4TPYirk4uc7Wz+LqXKwn7E+h9yR+Vnk4u/sbJL+LJ4HxjUscsCMrh4pIiIiIiKS7xTaZKb5eLYbIC/SZ5Eb9DnkDn0WuUOfRW7Q55A79FnkjoP6LDSnTXKWma0gPQZb3ff5SZ/x7KDPOb/p881/+ozziz7PmUk9bZLLmomrEc3ZbYZMoWb0Gc8GzehzzmfN6PPNd83oM84nzejznHHU0yYiIiIiIpLD1NMmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMREREREclhCm0iIiIiIiI5TKFNREREREQkhym0iYiIiIiI5DCFNhERERERkRym0CYiIiIiIpLDFNpERERERERymEKbiIiIiIhIDlNoExERERERyWEKbSIiIiIiIjlMoU1ERERERCSHKbSJiIiIiIjkMIU2ERERERGRHKbQJiIiIiIiksMU2kRERERERHKYQpuIiIiIiEgOU2gTERERERHJYQptIiIiIiIiOUyhTUREREREJIcptImIiIiIiOQwhTYREREREZEcptAmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMREREREclhCm0iIiIiIiI5TKFNREREREQkhym0iYiIiIiI5DCFNhERERERkRym0CYiIiIiIpLDFNpERERERERymEKbiIiIiIhIDlNoExERERERyWEKbSIiIiIiIjlMoU1ERERERCSHKbSJiIiIiIjkMIU2ERERERGRHKbQJiIiIiIiksMU2kRERERERHKYQpuIiIiIiEgOU2gTERERERHJYQptIiIiIiIiOUyhTUREREREJIcptImIiIiIiOQwhTYREREREZEcptAmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMREREREclhCm0iIiIiIiI5TKFNREREREQkhym0iYiIiIiI5DCFNhERERERkRym0CYiIiIiIpLDFNpERERERERymEKbiIiIiIhIDlNoExERERERyWEKbSIiIiIiIjlMoU1ERERERCSHKbSJiIiIiIjkMIU2ERERERGRHKbQJiIiIiIiksMU2kRERERERHKYQpuIiIiIiEgOU2gTERERERHJYQptIiIiIiIiOUyhTUREREREJIcptImIiIiIiOQwhTYREREREZEcptAmIiIiIiKSwxTaREREREREcphCm4iIiIiISA5TaBMREREREclhCm0iIiIiIiI5TKFNJp2ZfczM7h5jHzezc6elQTOEmX3czP7xEB5/gpk9ZWbFk9kuERk//W0TmTgz+5KZfWmSj7nezNozvh/z3GQynidbzOyDZrbTzNrN7MJst2c0Zna3mX1slPvPNTOfxibNCApteSb9i+Bm9rYh22vSv8huZism+fk+NlnHm0pmdouZ3ZLtdgzHzBYDNwKfzNj2UTNrNLONZnb5kP3/18zekrnN3R8B/gi8exqaLDLtzOxd6b9hH8l2W6bTVJ1siky19DlCr5m1mVmLmW0ys+8OvbDh7u9y93eN85jjujDi7ve5e+XBtHuU5z7gd3EqnmeizGwJ8BngEnevdPefZbM9mWbShaz0+dabst2OkSi05afHgaF//N4IbJz+pkw9M0uYWcE0Pl/RFBz2BuAn7r4n/RwnAtcDRwGvAf7NzBLp+14PFLv714Y5zleA9w7sK5Jn/gTYC7w9X37Gp+jvSdafSyTDp929yt1rgNOB3wA/NbM/naonnIU/6ysAc/ffZ7shuWg6RyBN5TlpXvynJwf4X2CxmZ2cse2dwP8buqOZvd3MnjSzVjP7fWaPzkD3tJm90syeSe/zUzNbmL7/S8B64C/TvXg7hxz7o2a2w8yazOyLw/0Qm1mBmW01s9cN2f7Jka4sm9mKdLveamaPAZ3A0WZWm36eTWa218x+bGar0o/5S+A64Lp0W9vNbO5wV82G9silr7x81MzuNLM24J3pfb5pZv+cfq6dmT2O6bZ828z2pN+3Z8zsmuFeT9pVwE8zvj8c+LW773X3B4F+oN7MGoBPAO8Y4Tj3AA3AiaM8l8iMY2ZnAMcBrwOWAJcOuX+s38mBvxuvN7M/pK/8/8rMjsrY54CRA5lXXs2s1My+Z2bb049/zMxeNcHX4Wb2XjP7tZl1Ai9LH/fTZva8me0zs3vTF24ws+uAvwTWZ/ztOtHM3mRmG4cce7+/Z+nX80/pNjcDnxnYZ6S/z2ZWbGZfSL9/benX/56JvEaRkbj7Dnf/O+DTwGfNrAb2/3/XwifS5wZt6a+fTt/3ePpQP0n/LvxXevtwP+vDDbEzM/s7i1EsO83ss2ZWmL5j4G/EioydXzzGKL+L+z2PxXnNX5rZc2bWnP47c0bG/W9K/169y+J8pcXMvmNmVSO9b2ZWZmb/YIPnN3eY2Zr0fdcDd6b/3W5me0Y4xsfM7J7035rd6d/9PzezZWb2s/R7/TszWzue58045mh/T4b9vNKqzew/Lc6RtpjZsOc1ZnaUmfWb2dIh2++zEUZ6ZbzHN5nZZmBzxrF+aGb/P3t3Hh9Vdf5x/PMkYQ8kBEFBVBbFjbpbW1sV3K1W64LiymJRW21rtXWvorjV7Wdb9wXBrbhUq7YVV3CtFm1RERWVxQVQMAQIe8jz++PcwGSYSSbrnUm+79frvsjce865zx0yN/Pcc+6535jZ19G5rlO07Vlgc+COKNb/ROtr+7uQ7jvpbDO72Myejd7bT83siIQ2doz+P8osnPffNbOtUx1PFSVtLdMa4B7CVWnMbG+gM/DPxEIWvmxcR0gASgjJwONWPdkDOBLYnfDL3AW4EsJwBuA1wlW0QnffJKHOj4DFUZ0fEnqLqiVmURtrCb1D6z6s0Yd9JFDb+PZhwMFAIfAp8GT0885AL+B94B9m1sbdrwYeAh6KYi109+9qaT/R6cAl0fFX9XAdTUiSekQ/X2xme0Xbfk94z/sCRcABwPRUDZtZB0KP2rSE1R8Ae5hZ9+hkvwZYANxOeL+/TNWWu6+K3ovd63BsIrngF8Ab7v48MDF6naymz2SVkwmfx+7AfODWOsRgwDPAtkBX4HrgITPbtg5tQDifDAM6AS8RznW7AntHcT1C6IkodveHCF9wX0s4d9XlavpIwjm2BLg0WlfT+XlYtG6gu3cm9Iy8UcfjE6nNX4GOhN+1ZPsTfm/3jH4HdyB87nD3qoSiahjgkIR6qX7Xk+1J+FLdGxgMDAHOzSTgOnwWzyV8pzmS8Hl+CHg+KenYFNiS8Ld/W2A34Owadn9jFO/eUd3/Ai+YWWd3Hw8cEsVY6O4b1dDOnoQEphfhQvYfgfsIt2eUAJ8At2Sy34Qyac8ntfx/jQDuAooJ79ltZtY3OWB3/5jwXfPUqnXROfcHhO+66fQGBhDe335mtlHUzvNRrDsSLpDfHO3nkOi9OSOK9fs1tJ1K4nfSGdG6UYREvyg61vvNrGoo7W2E8/9GhN+TU4GymnagpK3lugsYYuEq1hmEE1llUplTgbuj8dgV7v4k4cT486RyF7j7YncvI5x8MvlFnuXuN7v7Gnf/hPCLma7e3cCeZjYgen0Y0AZ4opZ9XO7uX7l7BbA94WRxuruXRsnLxYQP5h4ZxFube939bQ+WR+tedffH3H2tu78BvMf6Y1wNdCOckM3d57h7yqSN8OUPwkkPAHf/iPDHYSJhnPqxwPGEP3KPmNk90RWauxNOAFWWEE6+Ii1C9Md2COv/QN8DHGxmWyQVrekzWeVyd//G3VcSLsBk/IfZ3Ve4+/jofFgRfVmaDgyq4yHd6O4fu7sTPtPDgF+6+9dRu7cShoEeVsd2U3nS3Z9z98qEc1dN5+fVhC8d20UXvOa7+38bIQ6RRFUXHlP9rVoNtAe2N7MO0d/0f2fQZqrf9WQLgCvcfVX0d/Z6QrLXmE4FrnP3D6LP2K3Ax4QkqcoawnerFe4+l3DROeW5yMJQ8BHAJdF3iZWE7zf5wKF1jG2mu98RnWeeBRYCL7r7dHdfQ0imd6vjfuvyfS/RY+4+Ofr/epSQsOySpuztwEhbP2LrNOBf7v5VDe1XAue4+7Lo9+EU4GN3/3P0/7+QcDH+FGuc4YzrvpO6++po3V3u/j93r4yOoQtQ1Zu2mvAddYuozlR3/6amHShpa6GinphJwO+Aw4F7UxTbDJiZtO4zwi9RYltzE16WE3qQajM36XXaelH7zxCuSBD9Oy7hlz6dWQk/bwW0BeZGXc1lhC89+YTjbKhZKdbVdIzXE67m3AMstHDjdb80bS+K/i1KXOnu97j7ru6+D+H/6UpCQn0B8E20vhQ4P6m9LtF6kZZiBLAKeDR6/QzwLaHHKlEm553k81nGEwiYWTsz+z8Lw56WROeZ7Qk9e3WReD7ZMvr33apzV9TuFoQrxQ1V13PXg4Sh9NcTzl3/smiopkgjqvq7vMGIF3d/BTiP8LdufjQ8bb8M2kz1u57si+gLdGKdxviOkCiT71bfRhecq9T03WojQhK7rk0Po5RmJ7WZiXlJr5cnrVvO+nNipvvN+PtekrrUe5LwHe9gM2tHGDGxwS0/SeZHiWaVrQgjmBLPs88DTritpKFqPNe6e9UMo1XHODza98vR8ND/qxqqmY6StpbtdsJVkWfdPfmDCuFKV3JXdH+isb8ZSu69q6/bgWFm1h84iNBTWJd9zwdWABu5e3HC0sHd/1pDrEsJQ5QS9aplX7Vy9+Xufqm770j4UraWMAQhVdkVhKv126faHrkduCZKxncGXo3WTyLhylR0MtuKcKO3SM4zMyMkZx2AmRbunf2K0EM90hp3woFq5wML97okJmTnEs5PBwNF7l5MmPjJ6rif5HMXwHZJ566O7n5tivIpY400xrlrrbvf4O57EIZDfQz8vS5tiGRgKCFBeCvVRncfG12Y7AE8DTxjZh2rNqdpM5Pf9c2t+iRGfQjnEwifKaj+uUr+TGWyj8b4bpVoIbAysc2oZ2iLBrTZnPtt8NT9US/gPYQetqOBZYSRSDVJ/r+aD0xOOs8WuXt7d/86TR2o/e9Cuv3VKOq9HOXuWxCGoB5IuFiRlpK2lu05wr0bv02zfSxhFrYfWbhx9ghCr1yqWQnTmU8YM9xQLxG6xh8FXnH3z+pY/3XgI8KY6B4AZtbVzI5OONHPB7ZM6gZ/B9jJzH4YvQdDCGO3G8TMDjez7aMP93JCQrm2hipPEL4MpmrreKDQ3e+OVn0KHBodx2GEK3hV9ga+IYw7F2kJDiR84RkM7JSwfJ8wBPmoRtzXO8DPzKxndK/ptYSh2lWKCD1+C4ECM/sFNV9sqZW7zyEkRbdVDfc0s85mdohFkz4Rzl1bRBdlqvwP6Gpmx1iYrWwQYQhpg5jZvma2m4XZ1lYSrn7XdO4SyZiZbWJm5xDu8znP3RenKPN9M9s7+gyuZn0yVfWleD7rh5jVVXfCva5to0kffk90QdXDfe6zCN+LCqKLyL9Lqp/qs5hsLHBe9B2gTXSe2A54uD4BRz2D44AxFiYNaU+Yg8BJmqugMTXifhvy/5XoLsIFs/MJt/bUtdPgPmA3CxPAdLRgMzP7WS2x1vZ3oV4sTJbSO7owuYQw4VyN51olbS2YBy+lG/Pr7o8QTpz3EoboXQ4c5+7/qcNubgQGRl3NNY0trjVWQlf3LtTe5Z2q/lpCgroSeNvCLI/vEW4ErrrKcxdhuOTCKN6SaBjGNYQZNxcQ7k35W32PI0FfwhexMuBrYGPWD/9M5XbgJ9G9O+tECehVVL/P8GrCF8VFhBtsr07YNgr4cz1OZiLZ6heE0QJvRPdXVS3vAxPY8PEmDfF/wFTCzfifEC6IfJ2w/UbCRZGvCFeae9M4k3ScEO23aobaTwif5aoevEeiWOZF566d3H0mcBbhJvoyQm9kyt78OupB+KJWSjgn7kO4p1akvqpmmF4K/Idw//kh0b1eqRQCNxGGQJcRTeqRMNTtQkLitcjMJtQxljcJw9O+JoxYeQK4IWH7KcB+0X4fYMOJLjb4LKbYx42E71VPEy7wnAIc7O4N6RU7lzCJxuuEIXd7AAe6+9IaazVcY+y3If9f60Tv3/OEBDjVLT+Z1N+TcIH8c8L/8XPA9xKKXQEcE8X6ZrSutr8L9TWY8HkoJ3xf/TdhWHpaFr4ri8TPzI4kzKLWO+oKb1XM7HKg2N1/U8/6OxG+xO6Qwf2AIiIiIjnDzP4EbObujTnCImcoaZOsYGEGxOeB59z98rjjEREREZHsYOFxAP8DjohGSbU6Gh4psTOzswjDIMqpPkxBRERERFqxaFjlB4R72VplwgbqaRMREREREclq6mkTERERERHJYgVxByAiIo0vmpJ6d8KDUzVlu7R2+UBPYIq7r4o7mNZI5ySRaup8TlLS1oicSTk/1rSisuGTDub/vd4zugJQ/tzsBtUvPH7HBtWfMPjZBtUHWPz+vg2qf/rnDft/KD14cIPqv9VjTIPqAxy25JO6PnBYGtfuhKmaRWS9vQjTl0vz0zlJZEMZn5OUtImItEzzAF577TV69+4ddyyt0k3PvFft9Tk/bdgFpVzQt2/fdT/PmjUrxkiq++qrr9hrr70g+lxILHROag6f963+un/DP4dDhw5d9/OECQ27MC9Bfc5JStpERFqmtQC9e/emT58+MYfSOhV3X1DtdWv7f8jS49WwvPjonNQcVia9boT3ukOHDgnNNbw9qSbjc5ImIhEREREREcliStpERERERESymJI2ERERkRbKzNqZ2b1mNsfMlprZe2Z2eA3lh5jZTDNbZmbPm9mmCdvamtmdZlZmZgvM7IrmOQoR0T1tIiIiIi1XAfAlsA/wBXAQ8JiZ7eLuMxILmtm2wFjgSOAN4Drg4aguwKXADsCWQCHwopnNcvf7muNAJH5r166ltLSUNWvWxB1K1svLy6Njx4507twZs4ZPqK2kTURERKSFcvdlwOiEVc+a2QzCFPwzkoqfBDzr7i8CmNklwLdm1t/dPwdGAKPcfSGw0MxuBEYCStpaidLSUtq3b89GG23UKIlIS+XurF27liVLllBaWkq3bt0a3KaGR4qIiIi0EmbWHdgW+DDF5oHAumdVuPtiYDYw0My6Ar0StwNTozrJ+yg2sz6JC6B5/luANWvWUFhYqIStFmZGQUEBXbt2ZdWqjJ6dXSv1tImIiIi0AmZWADwIPOLuU1MUKQQWJ60rAzpH20jaXrUt2dnAZfUK8szdai9z6zv1ajo2uXhMiTHP+GT9z2/9A2tXh3YOPa3RQspFjZncKmkTERFpAqcfuF3cIYisY2Z5wAPRy3TfpMuBLknrioCl0Tai7eVJ25LdDIxLWtcbeC3jgKV++mRZ8ieNRkmbiIhIE9i0pFPcIYgAYOFy/72E4Y2HuPvqNEWnATsm1OsC9AWmufsiM5sbbZ8bFdkpqlONu5cReuESY2jQMUiG2u8adwTSRHRPm4iIiEjLdjvhPrbD3H15DeUeBA4xs33NrAMwBngrmoQEQu/ZJWa2kZltAZxDmG1SJCsMGjQIM+Ptt9+utv6ss87CzBg3blw8gTUCJW0iIiIiLVSUXJ1O6BWbZ2bl0XJRtL3czPYCcPePgFOBe4DvCIneCQnNXU7oWfsceJdwb5xmjpSsMmDAAMaPH7/u9erVq3nsscfo379/jFE1nJI2ERERkRbK3ee4u7l7e3cvTFiujrYXuvtrCeUfc/d+7t7R3Q90968Ttq1299PdvcjdN3L3P8RxTJJl+p+efvnY0i+zahjKOWvX9eXq6MQTT+Txxx9fN2vj008/zW677cYmm2yyrsx9993HtttuS9euXdl///2ZOXPmum3nnHMOm222GV26dGG33XbjjTfeWLdt9OjRHH300YwaNYqioiL69+/Ps88+W+cY60NJm4iIiIiItAg9evRgjz324OmnnwZg3LhxDB8+fN32p556ijFjxvD444+zYMEC9ttvP4YMGYK7A7DrrrsydepUSktLGTJkCMcee2y1afv/8Y9/cMghh1BaWsrZZ5/NyJEjqaysbPLjUtImIiLSBKZ89m21RUSkyZXdVX1ppYYNG8b48eOZP38+U6ZM4fDDD1+37Y477uD8889n++23p6CggPPPP58ZM2YwY0Z41vyJJ55It27dKCgo4LzzzmPJkiV89tln6+r/8Ic/5KijjiI/P5+RI0cyf/585s6du0EMjU1Jm4iISBN45p051RYRkSY3//TqSyt1+OGHM2XKFG644QaOOeYY2rVb/3C5OXPmcO6551JcXExxcTElJSVUVFTw9ddhJPB1113HNttsQ1FREV27dmXZsmUsXLhwXf3EYZadOoVZgsvLy2lqmvJfRERERETq5/M702+r78O1+75bv3qRtm3bcswxx3DTTTdtMJPkZpttxvnnn8+wYcM2qPfqq69y3XXXMWnSJLbffnvMjKKionVDJ+OknjYREREREWlRLr30Ul566SV23333auvPOOMMrr32WqZNC48YXLx4MY8//jiVlZWUl5dTUFBA9+7dqaioYPTo0SxbtiyO8DegnjYREREREWlRNt54YzbeeOMN1h955JGUl5dz/PHHM2fOHIqKihg0aBBHH300Bx10ED/5yU8YMGAAhYWFnHvuufTs2TOG6DekpE1ERERERHLe5MmT0257/fXX1/188sknc/LJJ29QJj8/n7FjxzJ27Ppnxp977rnrfh49evQGdZpr6KSGR4qIiIiIiGQxJW0iIiIiIiJZTEmbiIiIiIhIFtM9bSIirdip46bEHUKLtXBBWbXXeq9FRKS+1NMmIiIiIiK180rif2JZ7mjMSUqUtImIiIiISK3alM6lvKCDErdauDsVFRUsWrSIdu3aNUqbGh4pIiIiIiK1KvnwZUqBpSW9wDLo+5k7t8ljylZ5eXl07NiRzp07N0p7StpEREREWigzOwsYAXwPeNjdh6cpdxFwUcKqfKAd0MPdF5rZOOAEYHVCmW7uvqop4pbslL9mJd2n/ivzCked1nTBtDIaHikiIiLScs0FxgD31lTI3a9298KqBfgjMNndFyYUuymxjBI2keajnjYREZEmUFjYIe4QRHD3JwDMbDegdyZ1zMyAU4DLmzA0aQqb3Bl3BNJElLSJiIg0gfYdGufmc5EY7AX0AP6WtP40MzsNmA1c6+6PpqpsZsVAcdLqjBJGaaBiDUdsqZS0iYiIiEiiYcDj7l6esO7PwLnAYuBA4FEzm+/ur6aofzZwWZNHKdKK6J42EREREQHAzDoCQ4Dxievd/b/u/p27V7j7v4AHgaPTNHMz0Ddp2avJghZpBdTTJiIiIiJVjgRKgcm1lEv7qC53LwPKEteF2+REpL7U0yYiIiLSQplZgZm1J0zhn29m7c2sTQ1VhgH3u3u1pMzMjjGzQjPLM7MDgZOAp5ouchFJpJ42ERGRJlCxpqLa64I2+pMrsbiE6veXnUQY+jjczMqBQ9z9NQAz2xTYF/hlinZ+Q3hsgAGzgFHu/nJTBi71sPLd6q/b7xpPHNLo9BdERESkCZSVlVd7vVH34ngCkVbN3UcDo9NsK0x6/TVpvhu6u+5JywWzd6v+epu0o1glx2h4pIiIiEiOMLO+ZrZ53HGISPNS0iYiIiKSpcxsrJn9OPp5CPApMNPMhsYbmYg0JyVtIiIiItnrEOC/0c/nAMcDhwIXxRaRiDQ73dMmIiIikr06uvtyM+sMbAP8zd0rzeyRuAMTkeajpE1EREQkey0ws22BgcBbUcLWiRqekyYiLY+SNhEREZHsdTPwTvRz1X1sewMfxhKNiMRCSZuIiIhIlnL3W8xsIlDh7rOj1Z8DZ8QXlYg0NyVtzeSJJ97k0Udfx4BL/jCU7bev+2y9DW2jrvX//uTbPPboG5gZF118DNttv9m6bf/657v89eHXyDOjU2F7rrvhFAoLO2zQxpq1lRz2f1P52S7d+cW+m1Xb9p+Zi7n5+S/IzzPyDK4dshU9i9tVK2OdutD+hLOxwiKoXMvyP51XbXv+1jvT7tBTQtkOncAdZt22bvt5Y99j/qKVLF9ZwWF79GL4/n03iPH1Dxdw73OzqHRn8A49aJ/ivdjhit/Q95QjWPrpHF4+YMS69YMn3kPXXbbnkz/dz4dX3Z7yfVw0dzkP/PZtjh69M5tuW7xu/TefLWHSvTPIb5NHm3b5/OSc7WnbIfVHcs3aSg678b/8bNce/GK/6v9vf3/3Gx5+cx5t2+TRo3Nbrj1uwLptvz3jIWZ8PJ8hJ3yf4adVf8TOB1O/5Lox/+SrL0p55B9n0WPjLin3XWXAJb+h99AjWPb5HN4+Yv170PuEI9l8xLHgMO33Y1jy3vQa22lpzKwdcBuwP1ACzAT+4O5PR9sHAvcAO0TbfpHwINthwK+BrYClwCPABe6+Otp+LHA2sBPwH3cf1FzHJSLZw90/S3o9I65YRCQeStqaweLFy3jwgUlMeOR8vv2mjPPOu4+H//r7Zm2jrvUXL17OQw+8wsMTzuGbbxdz4fkP8MBDZ6/bfsABO/KTQ3cF4JY//5NnnprC8SfuvUE7j779Df26b5jMAey0eWcePuN7APztnW948M15/P4nfaqVaXfcWaz6x/1Uzpudso21n/yP5Z/8D4C2Bw4FM9qWrN9+5Snfo21BHhVrKzl09GsM+fFmdGq//td+UflqHpw0hzt/vRttC8JkqhOu/niD/cy47WE+v+9v7HHXmGrr3zr1YjbZf0869t4kZXwAbz8+i023K95g/ZS/z+HHJ/Wn9/Zd+fcjM/no1fnseFDvlG08+vZ8+vVI/T7u2qeIn+7cg/w84/p/zeLp/37LvoeFbRde/lOmvDWLBd8s2aBe3/7dufOBkZz3qwlpY0805+6H+erBv/G9P61/D9oUd6HvGSfz+n7H0b7Xxux813W8edAJGbXXghQAXwL7AF8ABwGPmdkuwCzgGeCOaPsxwFNm1t/dFwEdCUnZfwgJ39OEGeFGR22XEoZGbQPs2yxHIyJZxcw2Bq4Evg90Ttzm7v1iCUpEmp2SthTMrA3wnLs3ypek99+fza67bknbtgX03mwjli1byerVa2jbtk2ztVHX+tM+mMMuu/WnTdsCevfutkH5Nm3X/+qsWLGa/lv13KCNZavW8uqMRRz8vY2Yv3jVBturkiSA8pVrGbBJx+oFLI/8Xn1pe8Cx5HXvxZp3JrHmlafSHmOb7+/H8lsvpu3B62Op2seqNZX06tqB9m3zq9V55YNvKerUhjNvfReA84Zsk7LtlfMX0GmLTTdYv+Lrb9LGAzBvxmI6FbfD8myDbd0268SqZRUhvmUVbLRFYco2lq1ay6ufpH8fN+u2vm+wbX4eBfnr91VT71lh51R9iumt+mYBHTav/h4U77oDpf9+F1+zhhVzvqKgsBN5bdtQuXpNndrOZe6+jPVJFsCzZjYD2B3YAugAXO/ulcBDZvZr4CjgXndP7J6dZ2YPAD9NaPtFADP7edMehYhksfFAF+AuoDzmWEQkJkraUssjXBVPycyKgeLk9aWLnqa4eMMv3mVly+hStD4h6dylI2Vly+nRoyjjgBraRl3rl5Uto0uX9T07XTp3YHHZcronlP/b4//mwfsn0659G04dtf8GbYx99WtO+VEvvl2yOm1ckz8u5ZYXv6R85VruHL5ttW3WuZi8TfuyYty1VM6bQ8dzbmLtJ/+jcv4XG7STt2k/fMUyfNG3QPUE8uw7/8eUT0sZuvfm5CclT9+WreKLb5cz/tw9mDmvnMsenMbhaaOtuylPzOGAM7fl1fGfbrBtyz168PS17/HmX2fStkM+ew/bMmUbY1/5qtb3EWDmt8t5fcYizth3B5Y1SvS1a1NSzJqyxeter1m8hDZdi1n1zYJmiiD7mFl3YFvCJAGDgQ+ihK3KVMIscKnUa3KBNOek1N22IpJrfgBs7u4bDpkQkVaj1SZtZvZyDZvza9gGYTjTZckrb775cUaPHr5B4eKiTixdsmLd6/KlKygu7rhBuZo0tI261i8q6lit/NLylRQllT/6mB9y9DE/ZOw9L3LfvS9z7u+P4OGHXuWFh6bRu6QdZcsr+NUBm/Pku9+m3c+gbUoYtE0Jz76/kJuf/4L/O2Fr2gz6GW122YfKBV/jZd9R+dXnAKydMZW8TfulTNra7HEAa95+AYCHJs3huf/OZ/PuHbnylO9x8+k7s2L1Wk6+/i0O2W0Ttuy1fnRJUac27LF1N9oW5LHNZl34bun6xGjAmSey2TEHsfSzL/jPqEvSHkM6s95dSI/+nenQOXVv5st3fcxPz9uBHv06858nZvPff3zJbkdsEY7hzbk898FCendtH97HA7fgyXfS9+rNL1vFhY/O4MYTtqZdm7xGS9r6nHYiPY84iGUzv+D9X234HqxZtJiCovW9eQVdOrNmUVkj7T33mFkB8CDwiLtPNbOfAouTipUB3VLUPQX4MeH+tbo6mxTnJBFpEb4BKmstJSItWqtN2oA9gGuAeSm2tSF8eUrnZmBc8sqzzz5mVqrCO+zYh5tvfoo1a9ayYMFiOnZsV6ehkY3RRl3rf2+HPvz5T/9kzZq1LExRftWqNbRrF1537tKBFStDsnPCiXtzcqe5vPlZGX9+/gtGjZ3ON0tWs7qikm16dmLwtutvOFu1ppJ2bcLwxS7tC2gf/bxm8t9ZM/nvAHQ892asa3d80QLyNx/Amv++tmGwZrTZeS/Krz4dgBMHb8GJg7fA3VldUUnbgjzaFeTRvm3+BsMjvz+ghGseC/ewzStdQeeE+91m3PoQM259KKP3N5UFs8v56sNFPPnJYhZ+Uc6ir5fzk3O2p0t0j58D7aOErmNRW8rmr0+ST9yzFyfu2Ys3Py3jz8/PYdS906q/j9ut/86/aNkafvPgR1x25JZs3i31fW/1Nfuuh5h9V/r3oOyd99j6krOxggLabdKdtcuWt6qhkYnMLA94IHp5WvRvOWFYU6IiwqQjiXUPB24ADnT3+fXY/c1seE7qDaT4wIhIjjkfuMXMznf3msfki0iL1ZqTtqnAx+7+ePKGhNngUnL3MsLV8urrmZSyfFFRJ044YR9OPvlGDLjo4uPqHGxD26hr/aKijgw9/scMP+VPmBkXXHQ0H3/0FW+++QkjT92P++59ibfemrGu7Jirqk8+seeWxey5ZTEAT777LfMXr2LwtiUsWLqasa9+zfmH9uXpqQt4+n8LyLNwL9boIze8n3rlI3+hw8iLIT8/DI38Mgwz7DDyYlaMvQqA/AE7sfarz2FF9f6likrn53+aAsCaikoO3nUTem8Uegt/f+9Urj91J/puUsj3B5Rw0vVvUbHWuei47Zjx4lsbxDHgzBPZfOihFG3bj31fuI//nH4p5TO/5Pt3jWGjPXcmv11bSnYbyGtHnrmuzveP7sP3j+4DwHO3TGfgfr0o/Wo5X08vY9t9evLjE/vzr5umkd8mD8uDg3+9/Qb73XOrYvbcKnof3/kmvI/bdQvv4ytfcf5h/bjlhS/4ZvFqrv3HTAAO37kH+x4c6l97+T/4YOqXrFmzlo+nz2XkGfsw5a2ZnDh8T76Y/R03Xv0sn33yDZed/wQH/mQgRx67W+pfCEKvW6+jD6Vw637s8dR9fHD2pSyf9SVz7nmYHz77ADh8eP5Vaeu3ZGZmwL1AL+CQqtkfgWnAeWaWlzBEcifg7oS6BwNjgcPcfWp99p/qnBRCkji1b9827hAkR5lZJdUfnm3Aycmfa3evbWSQtDZFo+KOQJqIuXvtpVogMxsCfOfuGwyTjK6Yn+zu4+vSpjMp59/Misqa75vKRP7fM5uNMJ3y52Y3qH7h8Ts2qP6Ewc82qD7A4vcbNofN6Z837P+h9ODBDar/Vo8xtReqxWFLPmk1WYOZ3UFIxg5w96UJ69sAMwgXgf5MmIDkVmBLdy81s32Bx4Cj3P2VFO3mE3r+hwMnAAcClQlJYU0x9QFmzZo1iz59+qQtd+q4KRkdo0gmxo74/rqfs+n7xezZs+nbty9A34RnnWUtM0t7X32iVOeNFG2dBYwAvgc87O7D05QbBLwMLE9Y/Rt3vzfa3hb4C3AcsAa43d0vzSTOqH4fMjgncWb6i4fr3PpO7WWySS4eU0LMg//+ybqfJ/1s67q1k23HlSXqc05qtT1t7v5YDdsqCbM1iYjUyMy2AE4HVhFmgKzadLW7Xx0NfbwHuILwnLafuXtpVOYPhOGS/0yoN8fdq7pdTwbuS9jdCuAVYFDTHI2IZIPEZMzMdnT395LLmNkOGTY3FxhDeBxJbWPov3X3dM+wuZTwvMktgULgRTOb5e73pSkvIo2o1SZtIiKNwd3nEIYupdv+AeEe2lTbauwSdfdxpLh/VkRaldfY8N5YgMmE5zvWyN2fADCz3WjYrLIjgFHuvhBYaGY3AiOpfmFJRJpIXu1FWiYzKzCzS83sOTO7ycx6JG3/IK7YRERERCIbXBSKhio2xfjTbmY238xmmdmfzKww2l9Xwj27iT1+U0nz+BIzKzazPokLegyJSIO05p62PwJ7EWZ72xuYamYHRVfFAfrEFZiIiIi0bmY2iWii4RSPKdoCaOybhT4Gdoz+3YJwm8ifgFMJwyGh+iNMyoDOpHY2egyJSKNqzUnbscBu0fS5f4mekfSCmf3U3afQNFewRERERDIxOfr3R4R7WatUAvOBRxpzZ9HjRqoeOTLLzM4DJhKStvJofZeEnzd4fEmCm9FjSEQaVWtO2roAVZMB4O73m1kZYUKAo2OLSkREWoSFC8qqvd6oe3EscUhucvfLAczsU3d/OI4QiIZmuvsiM5tL6ImbG23fifBYkw0r6jEk8fk46X3eRn0QLUWrvacN+BT4fuIKd38aOAV4EmgfR1AiIiIiVaoSNjPramabJy6Z1I/u4W8P5AP5ZtY+ehxJcrnBZraFBZsB1xK+D1UZB1xiZhtFs+aeQ3jGpIg0g9actP2ZFDfQuvtEwtDJ15s9IhEREZEEZvYDM/sMWAjMipbZ0b+ZuITwuJALgJOin++O2i43s72icjsDbwLLon8/AH6V0M7lhJ61z4F3gUc03b9I82m1wyPd/f4atr1MeMCkiIiISJzuAP4F3Mn6+8ky5u6jgdFpthUm/HwTcFMN7awmPJPy9LrGICIN12qTNgAzKwKOIvS4dSbcUDsNeDIajy0iIiISp/7ALu5eGXcgIhKfVjs80sx+DMwkXDHqRJiUpCNwGvCZmf0oxvBEREREAN4HMrp/TURartbc03Yb8KtUMzKZ2fGE4Qjfa/aoRERERNZ7EHjczK4H5iVucPdX4wlJRJpba07a+gOPpdn2N+CeZoxFREREJJVbo3//mrTeCTNCikgr0GqHRxKGG/wmzbZfEWZNEhEREYmNu+elWZSwibQirbmnbRTwtJmdQ0jQFhMeuP09YCVweIyxiYiIiIiIAK24p83dpwEDCA/TfpbQ8zYRGAZs7e4fxhieiIiICGaWZ2Znm9n06Llq083st2ZmcccmIs2nNfe0AfQBugMvu/v7iRvM7AJ3vzaWqERERESC3wO/BK4DPgO2jNa1A/Q9RaSVaLU9bWb2U+B/wO+Af5vZvWaWmMReFE9kIiIiIuucChzm7re6+3PufitwWLReRFqJVpu0AVcAQ9x9V0KP26bAM2bWLtquYQciIiISt+7A9KR1HwMbxRCLiMSkNSdt/dx9IoC7LwAOBcqAZ82sU5yBiYhI7isoyK+2iNTTdGBk0rrhwEfNH4pkvXa7VF+kxWjN97QtMrPN3P1LAHdfa2YnAPcCL6Bnn4iISAMUd+0cdwjSMpwPPGdmpwIzgb6Ema4PjjUqyU593407AmkirTlpexEYQRgmCYC7OzDSzO4AfhBXYCIizeXe4bvHHYK0IGNHxB1By+Pur5vZdsDxwGaE2a6HuvuceCMTkebUmpO2X5Lm+N39DDO7upnjEREREdlAlKBppkiRVqzV3tPm7qvdfXkN279oznhEREREUjGzvaJns12auGRY9ywze9fMVpvZuBrKHWpmr5tZmZnNN7OxZlacsH20ma2JnhVXtQxo+NGJSCZabdImIiIiku3M7BrCLR0nAQckLPtn2MRcYAzhnv2aFAFXAr2AbYAewM1JZf7m7oUJy4wMYxCRBmrNwyNFREREst0oYA93n1qfyu7+BICZ7Qb0rqHcwwkvl5vZXcCN9dmniDQ+JW0iIiJN4PbnPqz2+hcHbR9TJJLjlgHTYtjv3sCHSesOMbNSYB5wu7vfkqpiNKyyOGl12oRRGtGsXau/1mySLYaSNhERkSYwb1Ha26ZF6uIG4FIzuyya5brJmdm+wM+BHyWsfhS4C/gG2AP4m5ktdvcHUjRxNnBZU8cpKaz6b9wRSBPRPW0iIiIi2evvwHHAEjObmbg0xc7MbA/gEeBYd1/X0+bu0919rruvdfc3gT8Bx6Rp5mbC8+QSl72aIl6R1kI9bSIiIiLZ6xHgK0Ii1KTdt2a2M/AMMMrdn6+leNpeP3cvA8qS2m5oeCKtmpI2ERERkey1A7CRu6+sT2UzKyB838sH8s2sPbDW3dcklRsITAR+7e5/T9HOEcCrhGRsd+DXwMX1iUlE6k7DI0VERESy14dASQPqXwKsAC4gPDZgBXA3QPSstaphi+cC3YF7Ep/FltDOUOAzYClwP/BHdx/XgLhEpA7U0yYiIiKSvR4EnjCzm4D5iRvc/dXaKrv7aGB0mm2FCT+PAEbU0M7xmYUrIk0hJ5M2M8sjPPhxhrtXxB2PiOQmnUtEJAf8Kfp3QtJ6Jwx5FJFWICeTNsKJ6h2gsLaCIiI10LlERLKau+tWFhHJzXvaoueUfA5sHHcsIpK7dC4RERGRXJCrPW0A/wf81cxGA7OByqoN7v5FTDGJSO7RuURERESyWi4nbfdE/77M+meFGBrjLSJ1o3OJiIiIZLVcTtr6xh2AiLQIOpeIiIhIVsvZpM3d58Qdg4jkPp1LRCTbmNmL7r5/9PPZ7n5zzCGJSMxyNmkDMLMSYHegB2E4EwDufn9sQYlIztG5RESyzO4JP18B3BxTHCKSJXI2aTOzwcCThPtOOgNLCdN2fwnoi5aIZETnEmkqVwzdvfZCIql9YGaPA+8D7czs0lSF3P2K5g1Lst42XnsZyUk5m7QBfwSuc/erzWyRu3c1s6uAeXEHJiI5RecSEck2JwMXAHsRHs80OEUZJ/TCiUgrkMtJ2wDguujnquFMVwIfAbfEEpGI5CKdS0Qkq7j7LOB0ADP72N1TJW0i0ork5MO1I6tYn3QuMrNNop83iikeEclNOpeISNZy923ijkFE4pfLSdsU4KDo55eBh4DHgKlxBSQiOUnnEhHJWhacbWbTzaw8+ve3Zma11xaRliKXh0f+nPUPvv0d4b6ULsBv4wpolwfvaHAbE486pEH1e3zwcYPqt9m14SMw/KhTGlS/81ENDqFBjvcj4g0A4HsNq96tgbs/dEnDf5dzSNadS0REEpwH/JIwjPszYEvg90A74NoY4xKRZpSzSZu7z0/4eRFwWozhiEiO0rlEmspTU2ZXe33E7n1iiUNy3qnAYe7+QfT6OTN7hTDrba1Jm5mdBYwgXA582N2H11B2COHC1cbAG8AId/862tYW+AtwHLAGuN3dU85qKTGal/QnrOdd8cQhjS5nkzYAM9sTGA70dPefmtkuQEd3fz3eyEQkl+hcIk3h3c8XVHutpE3qqTswPWndx2R+3+1cYAxhGHiHdIXMbFtgLHAkIWG7DngY2CcqcimwA6GnrxB40cxmuft9GcYhzWHx3dVfK2lrMXL2njYzOw74J1DB+hNKHpr+VkTqQOcSEcly04GRSeuGE2a4rZW7P+Hufwe+q6XoScCz7v6iu68ALgF+YGb9o+0jgDHuvtDdZwM3pohLRJpILve0XQIc6u5vmtnx0boPgIExxiQiuUfnEhHJZucThkSeCswE+hKGOh7cyPsZCPyn6oW7Lzaz2cBAMysFegHvJZSfClydqiEzKwaKk1b3brxQRVqfXE7aNnP3N6Ofqx7/vprcPiYRaX46l4hI1nL316OhiycAmwHvA0PdfU4j76oQWJy0rgzoHG0jaXvVtlTOBi5rvNBidOZutZe59Z3m2U8mftU4zeSc5vp/au59JcjlLyWzzWwnd5+asG4XwlUoEZFM6VwiIlnN3b+g6WeKLCfMnJuoCFgabSPaXp60LZWbgXFJ63oDrzU0SJHWKufuaTOzx6Nu95uAJ8xsBFBgZkOBBwljrEVEaqRziYhINdOAHatemFkXwlDMadHMunMTtwM7RXU24O5l7j47cQG+aqrARVqDnEvagI6EcdQzgcsJXfAFhHHVt7v7X2OLTERyic4lItLimVmBmbUnPI8y38zam1mbFEUfBA4xs33NrANhxsm33P3zaPs44BIz28jMtgDOIcw2KSLNIOeGR7r7T6JnjjwL3ADs5O5eSzURkWp0LhGRVuISqt9fdhIwHhhuZuXAIe7+mrt/FE12cg+wCfA64T66KpcTHjPwOeuf06bp/kWaSc4lbQDufouZvQw8BBxqZtOStmsKWhGplc4lIpLNzKwAOA0Y6+4r69OGu48GRqfZVpj0+jHgsTRlVwOnR4uINLNcHB5ZxQhJp6VYREQypXOJiGQld68ArqlvwiYiLUdO9rSZ2a+BqwgTCFzu7pUxhyQiOUjnEhHJAW+b2W7u3vhziItIzsi5pM3M/kl4AOSh7v5q3PGISG7SuUREcsTrwN/N7B5gNrDu4pK73x9XUCLSvHIuaQNWESYMWBR3ICKS03QuEZFcMIIw8cewpPUOKGkTaSVyLmlz96PijkFEcp/OJSKSC9y9b9wxiEj8ci5pExERyQWnH7hd3CFIC2JmBmzi7vPijkWyWB/d+thSKWkTERFpApuWdIo7BGkBzKwjcDNwCrAW6GRmRwAD3f2qOGOTLNR+17gjkCaSy1P+i4iIiLR01wNbAPsQ7m0D+C9wfGwRiUizU0+biIiISPY6HNjR3UvNrBLA3b80s01jjktEmpF62kRERESyVxtgSeIKM+sArIgnHBGJg5I2ERERkew1BTg9ad0pwFsxxCIiMdHwSBERkSYw5bNvq73efcseMUUiOe73wKtmdixhEpKJwG7AnvGGJVmp7K7qr4tPiycOaXRK2kRERJrAM+/MqfZaSZvUh7t/bGbbEh6u/SEwHxjl7l/GG5lkpflJnbJK2loMJW0iIiIiWczdvwNuijsOEYmP7mkTERERyWJmNsTMnjWzaWY2MRoqWZf6xWb2qJktNbOvzeyXacrdYWblCcsqM1uasH2yma1M2P55Q49NRDKjnjYRERFpdKeOm9Js+7p3+O7Ntq/mZmbnABcDdwN/B/oAt5nZZu5+Y4bN3EL4ztcL6A+8YGYfufukxELufgZwRsK+xwGVSW2d7e531P1IRKQhlLSJiIiIZK9fAT9x97erVpjZk8BjQK1Jm5l1AoYAO7v7UmCqmY0FRgKTaql3NHBYw8IXkcag4ZEiIiIi2auYMO1/oneBLhnWHwCYu09PWDcVGFhLvaOBBcCrSeuvNLPvzOxNM9s3VcVoOGafxAXonWG8IpKCkjYRERGR7PUE4blsiU6K1meikKSHcwNlQOda6g0D7nd3T1h3PtCXMMzyTuAZM9sqRd2zgVlJy2sZxisiKWh4pIiIiEgWiYYvVmkP3GlmpxOSnz7ArsDjGTZXzoa9ckXA0hRlq/a/OTAIGJW4PnGIJjDezI4nDJ/8v6QmbgbGJa3rjRI3kXpT0iYiIiKSXSzh51XAwwmvP4mWTM0A3My2dfePonU7AdNqqHMy8Ia7z6ylbU+50r2M0Ju3jpmlKioiGVLSJiIiIpJF3H1EI7a1zMweB8aY2QjC8MaRwHE1VDsF+GPiCjMrBvYAXgEqovp7A79trFhFJD3d0yYiIiLSsp1J6BWbB0wERrv7JDPbPHre2uZVBc3sh4ShjI8ltdEGuJIwOclCwqyWP3P3j5vjAERaO/W0iYiIiGQpM9uW8Jy13QiTiqzj7vmZtBENVxySYv0XKdr8N9ApRdkFQMt9IJ5IllPSJiIiIpK9HiDcl3YSsDzmWEQkJkraRERERLLXAGAPd18bdyAiEh8lbSIiIk3gp7ttEXcI0jK8DWxJ3WaMlNZqkzvjjkCaiJI2ERGRJrD7lj3iDkFahpHAWDN7kTCRyDrufn88IUnWKj4t7gikiShpExEREclexwH7AjtQ/Z42B5S0ibQSStpEREREstcFwKHuPjHuQEQkPnpOm4iIiEj2Wgs8H3cQIhIvJW0iIiIi2ese4NS4gxCReGl4pIiISBP4unRZtdeblmzwvGKRTPwI+J2ZncOGE5HsG09IkrVWvlv9dftd44lDGp2SNhERkSZw5/PTq72+YujuMUUiOW5StIjUbvZu1V9v4/HEIY1OSZuIiIhIlnL3y+OOQUTip6StmZy/+wi2K+lHfl4+D370DybOfrPG8uf+cgIzPprPMSfszrBRP6q27aWJ03nikXcxMzoVtuXSq4+gU2G7Ddo47453mFe6guUrK/jpnpsx/OAtq20vX7GGU697g5nzyvnDyTtw+I82r7b9w+lfMuaqxwHn2GN+xFFH7lFt+6zZ33LhxQ/Spk0Ba9asZfQfjmWbbTZNe0xPPPEmjz76OgZc8oehbL/95mnLNlUbuV4/G2JojGMQERERkcxpIpJm0L9oM/oXbcaw5/7AaS9cwS93PK7WOudf9hN++dvUQ9X33m9rbr3vZG4ZexIDttmE5/45LWW5K3++Cw9ctBePXLYPf31pJuUr1lTb3r5tPrf85geccmD/lPXHXPU41//xFO6/79c88NArLF68vNr2zXp3468P/pYHxv2a3/zqUG6787m0x7N48TIefGAS999/DtdfP5KrrnykpsNvkjZyvX42xNAYx9DSmFk7M7vXzOaY2VIze8/MDk/YPtDM3jKz5WY2zcz2Stg2zMzeNbMlZva1md1kZm0Ttt9gZp9G7X5iZpqMQKSVMbNKM1ubaok7NhFpPkramsGCFaWsqaygwPLp1KYDS1Yvq7VOj427pN3Wpk3+up9XrFhD3/4bpSzXtiD8965aU0nPbh3p0K56x2pBfh7di9unrLt69RpWrFjNZr270bZtAbvu2p/3P5hTvX5BPmYGwLJlK9l6QK+0Mb///mx23XVL2rYtoPdmG7Fs2UpWr16TtnxTtJHr9bMhhsY4hhaoAPgS2AcoIjxT6WEzG2BmbYBngCeBrsA1wFNm1jWq2xE4G+gO7AbsBVyU0PYy4KdRuycB15vZ4KY+IBHJKoMJD9euWk4GpgJnxhiTiDSzVp20mdk+ZnZh4lXxhG23NdZ+lqxexhdL5/H3I25mwqF/5J4Pnmhwm/948j2GDbmH9//3JX37dU9b7jd/eZsDzn2OXQZ0Iz/PMm5/UdlyunTpsO51l84dNuhpA5j24Rccd8JNXH7lY/z4R9ukba+sbBldijque925S0fKyjZsryYNbSPX62dDDI1xDC2Nuy9z99HuPtvdK939WWAGsDswCOgAXO/uq9z9IeBT4Kio7u3u/lq0bR7wAGGmuKq2L3P3j6N2pwCTgT2b9QBFJFbu/krS8jBwLOFCTkbMrNjMHo167b82s1+mKTc86sUrT1j2r2s7ItL4Wm3SZmYjgScIV7dvNbMXzCyxeyvtyTA6afVJXiqWrU5Z/gc9d6BHhxIOf+rXHPn0bzlrp6G0yWvY7YSHHbkj4x/7OYP234a/3v/WuvUPvvA5J1/9Gpfc+18A/vSrPXjppoN4Zep8Pvt6Sa3tPvjQq5w8/M/8+ZZ/smTJinXrly5dQVHCl/UqA7ffnEcePodb//Tz6P631IqLOrE0ob3ypSsoLt6wvZo0tI1cr58NMTTGMbR0ZtYd2Bb4EBgIfODulQlFpkbrU9k7qpeq3XbA91NtT3VOAnrX+yBEJNvNBnaoQ/lbCKMCegGHApfX0Gs/xd0LE5YX69mOiDSiVpu0Ab8HDnL3o4EtgS+ASWZWEm2vqVvqbGBW8rLguRkpCxvGktXLqHRn+ZqVtMkrIN/q/9avWlWx7ufCzu1o177NutcnHdCfBy7aizEjd2Z1Rfie2K5NPu3bhqU2J524Nw+M+zVXXXECHTq0Ze7cUtasWcu7/5vJDt/bIimO9cPiOnfpQIcObZObW2eHHfvw7rufsWbNWubOLaVjx3a0bdsmbfmmaCPX62dDDI1xDC2ZmRUADwKPuPtUoBBYnFSsDOicou4pwI+Ba9M0fxuhB+/pFNvOZsNz0mt1jV9Eso+ZbZ60bAtcT0jcMqnfCRgCXOLuS6Nz01hgZB3jaJR2RKR+WvPskb3c/R0Ad18FnGpmfwReNbP9gJoebHEzMC55ZfeDBsxKVfjt+e9zcJ89GXvg5bTNb8OETyaycm3qXrkq113xL6a99zVr1lTwyfR5jDhjL955axbHD/sBE8a/xbv/CfeXdS5qzwWjD92gfsVa59Tr3gBgTUUlh3x/U3p3Dw92/d3tU7jhF+F5QWfc9G8++3oJHdrm8+6M77hi1/UXzC6+8GjO+f14wDlh6I/X9bSde954brxuGP9+awZ33/siedGwy4vOPyrt8RQVdeKEE/bh5JNvxICLLq59MpbGbiPX62dDDI1xDC2VmeURhjcCnBb9Ww4k36BaBCxNqns4cANwoLvPT9H2H4FdgMFJvXZVbmbDc1JvlLiJtASzqf6dxICZwCkZ1h8AmLsnPjhwKnBgmvI7mNlCoBR4CLjK3Svq0o6ZFQPFSavV+y/SAObeOh+6Z2YzgEPd/dOk9ZcDJwC93b1Dyspp7PzgcQ1+MycedUiD6vf44OMG1bddGz7KwQvS97hJ62EMzvwmyhxnYUaesUA/4BB3Xx6tPwC4H9i0Ktkys7eAu9393uj1wYTeucPc/a0UbV9OuLq9j7svqENMfYBZs2bNok+fPg04OqmvSydMqfa6NTxcu2pyKoCR9/2n2fZ77/Ca39vZs2fTt29fgL7uPrs5YmosZrZF0qql7l5ah/p7AU+6+0YJ6w4B/uLuWyaV7UdIEOcA2wOPAH919zF1bGc0cFmqeGo9J525W/ptVW59p/YyjaUx4smkjcbyq3erv67vw7UTYh7890/W/TzpZ1vXrZ3m+r9qzt+bRthXfc5JrXl45FOE5Kwad7+M8OVrwwefiYikdjvhPrbDqhK2yGRgJXBu9GiA4wlXq58EMLN9CVeyj06TsF0InAjsV5eETURaDnefk7RknLBFMurxj/Y1091nRZMffQBcARxT13YIvf99k5a9UpQTkQy12uGR7v77GrZdQ5iaW0SkRtFV8NOBVcC8hJ6Gq9396mjo4z2ELz8zgZ8lfOn6A+FLzz8T6s1x9+2r2gBWA58mbH/Q3c9owkMSkSxgZpfWVsbdr8igqRmAm9m27v5RtG4nIPVDXpN2UZ923L2McP/uOom9sCJSd602aRMRaQzuPocaJi6KrlbvkWZbjeOR3V3fckRar5rODwOBEsLFoBq5+zIzexwYY2YjCL1eI4ENbkqOhjv+192/MbNtCBeWHq9rOyLS+Fpt0hbN8nYR4ZlIHwLXuvu3Cds/cPfvxRWfiIiItF6pLupE96r+EehI6InP1JnA3cA8YAkw2t0nmdnmwHRgO3f/AtgPGGdmhcA3hPttr6qtnToemojUQ6tN2ggnvb0Is73tDUw1s4Oiq+IAfeIKTEREct+u/bvHHYK0EFESdTHwa8I9sdu4+5eZ1o+GKw5Jsf4LwqNJql7/DvhdXduRLFI0Ku4IpIm05qTtWGA3d/8G+Ev0jKQXzOyn7j6Fmqf8FxERqdERu/eJOwTJcdHMtKcRhkF+Duzr7m/HG5VktZ53xR2BNJHWnLR1ITyDBAB3v9/MyggTAhwdW1QiIiLS6pnZgYTnN3YGfu3uj8QckojEqDUnbZ8C3wfeqFrh7k9HPW5PAu3jCkxERERavYnAAsJjiLZONZtkhrNHikgL0JqTtj8TZl96I3Glu080s2OBS2KJSkRERAReJdyq8YM0250MZo8UkZah1SZt7n5/DdteBl5uxnBERERE1nH3QXHHICLZo9UmbQBmVgQcRehx6wwsJTwk8slohiQREREREZFYtdqkzcx+DDxFuLdtKmFSkiLCLE3Xm9kR7v5G+hZERETSu3TClGqvrxi6e0yRiEir8bFVf72NJkNvKVpt0gbcBvzK3R9O3mBmxwN3AHq4toiIiIiIxCov7gBi1B94LM22vwH9mjEWERERERGRlFpz0vY+8Js0234FfNCMsYiIiIiIiKTUmodHjgKeNrNzCAnaYsIDt78HrAQOjzE2ERERERERoBUnbe4+zcwGAIMIs0cWAuXADcBkd6+IMTwRERERERGgFSdtkT5Ad+Bld38/cYOZXeDu18YSlYiIiIiISKTVJm1m9lPgYWAGsI2ZTQBOT+hhuwhQ0iYiLdKKFStYsmQJa9eujTuUrNeuXTtKSkows9oLi4iINIFWm7QBVwBD3H2imXUHHgCeMbOfufsqQH+dRaRFWrFiBYsXL6akpIQ2bdooGamBu7No0SKWLl1Kly5d4g5HpF7MrBi4CzgEWAJc5e63pSg3DPg1sBWwFHgEuMDdV0fbxwEnAKsTqnWLvjeJSBNqzbNH9nP3iQDuvgA4FCgDnjWzTnEGJiLSlJYsWUJJSQlt27ZVwlYLM6NLly4sX7487lBEGuIWwoX6XoTvO5eb2eAU5ToCZxNuHdkN2Isw8ijRTe5emLAoYRNpBq05aVtkZptVvXD3tYSrR7OBF4D8mOISEWlSa9eupU2bNnGHkTPy8/OprKyMOwyReokuRA8BLnH3pe4+FRgLjEwu6+63u/tr7r7K3ecRRiH9qFkDFpGUWvPwyBeBEYRhkgC4uwMjzewO4AdxBSYi0tTUw5Y5vVf1c+/w3eMOQYIBgLn79IR1U4EDM6i7N/Bh0rrTzOw0wkXua9390eRK0XDM4qTVvTMLV0RSac1J2y9Jc/zufoaZXd3M8YiIiIg0tkLCfWyJyoDONVUys1OAHwM7Jaz+M3Au4dm2BwKPmtl8d381qfrZwGX1jlhENtBqh0e6+2p3T3uTgrt/0ZzxiIhIMGjQIMyMt99+u9r6s846CzNj3Lhx8QQmkpvKgeRZdIoIE42kZGaHE55be7C7z69a7+7/dffv3L3C3f8FPAgcnaKJm4G+ScteDTkIkdauNfe0iYhIlhowYADjx49njz32AGD16tU89thj9O/fP+bIMteza8e4QxCB8GgjN7Nt3f2jaN1OwLRUhc3sYMI9b4dF97/VxFOudC8j9OYltptxwNIA7XaJOwJpIq22p01ERLLXiSeeyOOPP86qVWFiuqeffprddtuNTTbZZF2Z++67j2233ZauXbuy//77M3PmzHXbzjnnHDbbbDO6dOnCbrvtxhtvvLFu2+jRozn66KMZNWoURUVF9O/fn2effbbRj+EXB21fbRGJg7svAx4HxphZZzPbgTAJydjksma2L/AQcLS7v5Vi+zFmVmhmeWZ2IHAS8FTTHoHUSd93qy/SYqinTUREuHTClHrV69m1Y9qE5PbnPmTeojAK/YqhdZuUokePHuyxxx48/fTTDBkyhHHjxjF8+HD+9Kc/AfDUU08xZswYnnnmGbbeemuuv/56hgwZwjvvvIOZseuuu3LxxRdTVFTEjTfeyLHHHsvMmTNp164dAP/4xz/461//yh133MFtt93GyJEj+frrr8nL07VMaZHOBO4G5hHubxvt7pPMbHNgOrBddFvIHwhDJ/+Z0DM2x92rPuS/Ae4lPMt2FjDK3V9uvsMQab3010lERLLSsGHDGD9+PPPnz2fKlCkcfvjh67bdcccdnH/++Wy//fYUFBRw/vnnM2PGDGbMmAGEnrpu3bpRUFDAeeedx5IlS/jss8/W1f/hD3/IUUcdRX5+PiNHjmT+/PnMnTu32Y9RpDm4e5m7D4meq9ar6sHa7v5FtO6L6PVgdy9Ieg7b9gnt7OXuRe7exd13dPcJcR2TSGujpE1ERLLS4YcfzpQpU7jhhhs45phj1vWSAcyZM4dzzz2X4uJiiouLKSkpoaKigq+//hqA6667jm222YaioiK6du3KsmXLWLhw4br6icMsO3XqBEB5eXkzHZmIiEjdaHikiIhkpbZt23LMMcdw0003bTCT5Gabbcb555/PsGHDNqj36quvct111zFp0iS23357zIyioiLCozhFRERyj5I2ERGp8z1nmWiMyTcuvfRSjjnmGHbfvXp8Z5xxBhdddBG77rorAwcOZPHixbzwwgscddRRlJeXU1BQQPfu3amoqOCqq65i2bJlDY5FREQkLkraREQka2288cZsvPHGG6w/8sgjKS8v5/jjj2fOnDkUFRUxaNAgjj76aA466CB+8pOfMGDAAAoLCzn33HPp2bNns8d++3MfVnutGSRFpMnN2rX6a80g2WIoaRMRkawyefLktNtef/31dT+ffPLJnHzyyRuUyc/PZ+zYsYwdu35G83PPPXfdz6NHj96gTlMMnayaOVNEpNms+m/cEUgT0UQkIiIiIiIiWUxJm4iIiIiISBZT0iYiIiIiIpLFlLSJiIiIiIhkMSVtIiIiIiIiWUxJm4hIK6QHTWdO75WIiMRNSZuISCvTrl07Fi1aREVFhRKSWrg75eXltGnTJu5QRESkFdNz2kREWpmSkhKWLl3KwoULqaysjDucrNemTRtKSkriDkNERFoxJW0iIq2MmdGlSxe6dOkSdygiIiKSAQ2PFBEREWnBzKzYzB41s6Vm9rWZ/bKGsmdFZZaa2SNm1qU+7YhI41LSJiIiItKy3UIYXdULOBS43MwGJxcyswOAy6IymwJtgL/UtR0RaXxK2kRERERaKDPrBAwBLnH3pe4+FRgLjExRfDhwn7tPdfclwMXAcWbWsY7tiEgj0z1tIiItUz7AV199FXccrVbZgrnVXs+ePTueQGKSTceb8DnIjzOOmAwAzN2nJ6ybChyYouxA4F9VL9z9IzMD2IpwoT+jdsysGChOWr0FZHBOWrKq5u0Azfm71RjxZNJGY/k66XX72fVrJyHmFRXrJ6yaXddjaa7/q+b8vWmEfdXrnOTuWpppIZzARgPFrbF+NsQQd/1siCEbjkFL0y/AjwHXokVLteXHcX82YzgX7AUsTFp3CPBZirKfA4clrfuGcD6pSzujs+D/WouWXFgyPidZ9OGSZmBmfYBZQF93n93a6mdDDHHXz4YYsuEYpOmZWTtgd2AesDZpc2/gNcKXsFzuimspxwEt51iy9TjygZ7AFHdvxm6P+JnZzsDb7t42Yd1Q4Hx33zmp7HvAH9394YR1K4AfEHraMm2nmA172toC/YBP2fCclIls/d3KVC7Hr9gbX53PSRoeKSLSAkV/BF5PtS0a7gTwVS4n3S3lOKDlHEuWH8fncQcQkxmAm9m27v5RtG4nYFqKstOAHYGHAcxsG8AIiZZl2o67lwFlaWKplyz/3apVLsev2JtMnc5JmohEREREpIVy92XA48AYM+tsZjsQJg8Zm6L4OGCEme1gZp2BK4FH3H15HdsRkUampE1ERESkZTuTcP/MPGAiMNrdJ5nZ5mZWbmabA7j7C8CYqMw8oBL4VW3tNN9hiLReGh4pIiIi0oJFwxWHpFj/BVCYtO4vVH82W63tiEjTU09b8yoDLif1OO/WUD8bYoi7fjbE0ND6jdWGxKeMlvH/V0bLOA5oOcdSRss4Dsk+ZeT271YZuRt/GYo9dpo9UkREREREJIupp01ERERERCSLKWkTERERERHJYkraREREREREspiStmZgZmeZ2btmttrMxtWjfjszu9fM5pjZUjN7z8wOr2MbN5rZl2a2JGrn4rrGEbWzkZktNLO36lF3spmtjKYXLjezOj/o1MyONrNpZrYsOo6jMqxXnrSsNbOUs2PV0MbmZvYPMys1s2/NbJyZFdZes1obW5nZ82ZWFsV/ai3l0/7umNlAM3vLzJZH78ledax/l5nNMLNKMxtel/2b2QAze8rMFpjZIjN7wcy2y/ydkKZgZt+L/r8WRcuLZrZ9Upkro89wmZndbmZtovUFZjYhWj/RzLok1DnRzG5uxuM41Mxej2KZb2Zjzaw4B4+jp5k9bWbzzMzNrE+KMll/HCliLjazR6O/R1+b2S+j9ZtF56RFZnZjUp27zexnsQQsWa0lfU7MbFD0NzXx+8apCdt/Hx3Hh2b2vYT1/aNzXn5zxpsolz/Xlub7ZS7EXhdK2prHXMJzT+6tZ/0C4EtgH6AIuAB42MwG1KGNu4Ft3L0LsCdwgpkdW49Yrgem16NelbPdvTBa+telopntC9wMnAF0BnYDpmZSN2GfhcAmwArgsbrsH7gDWARsCmwD9AX+kGllMysAngYmAxsBRwE3mtk+NVRL+bsT/cF6BngS6ApcAzxlZl0zqR95D/gF8N+67h8ojo5lG6A78DrwTzOzGtqSpvcVcDRQQvgde5qE33Mz+zkwlPDZ2RLYCbgk2nwU4bPRAygFTovqFAPnUIff9UZQRHioby/C71gPwmefKKZcOY5KwrOsUl5cyqHjSHYL4e9SL+BQ4HIzGwxcCLwEbA4cbma7AZjZj4Du7v73eMKVLNfSPiffJn7ncPd7o5h6AucB2xEeqXBNQp2/EL4frW3+cNfJ9c91qu+XuRJ7RpS0NQN3fyL6xfiunvWXuftod5/t7pXu/iwwA9i9Dm187O7LElZVEk5+GYuSi62A++pSrxFdAVzh7q9H78MCd59Zj3aOBr4FXqtjvb7AX919hbuXAk8AA+tQf2ugD3Ctu1e4+7uEpGtkugo1/O4MAjoA17v7Knd/CPiUpD96Nf3uufut7v4SsLKu+3f3/7j7ve7+nbtXAP8XHVuvdG1J03P3RdF5wgED1gL9E5LpEcBNUZmFhM9U1e9fX+BNd18NvAL0i9ZfC1zt7kub8TgedveJ7r48ei7UXcCPEorkynF84+63AVPSFMmJ40hkZp0Iz+m6xN2XuvtUYCwh7r7AK1Fs7wD9ootVNwC/jiNeyX4t8XOSxubAp+7+LTCJKFYzGwp87u7vxBVYC/5c53LsG1DSloPMrDuwLfBhHetdYGblhKvxhcCDdajblnAV5kygIc+JuNLMvjOzN6Oes0z3nw98HyixMKRvrpndZ2ZF9YhhGHC/1/15FzcTeig7Rf8HxwDP1qG+Jf1b9fMOdYwDQrL4gbtXJqybSt2SyMa0N+Eq57yY9i8JzKyMkIz/hfDFpep3fSChh7XKVKB39DmaBvzYzNoTevU/NLM9gF7u/rfmij2Nval+vsvV40iWi8cxgPC4oMQRF1MJxzIN2DcaorYr4f/sHOBv0UOcReoj1z4n3SwM655lZn+y9bdRfEZIGnoCg6NYuwC/A+p1y0ojagmf61TfL3Ml9owoacsx0RWCB4FHoishGXP3awnDCncB7icM9cvUBcCL7v5erSXTO59w1aMXcCfwjJltlWHdjYE2hCES+xKGF2xEwpCpTJjZFoQT+/i61Iu8ThiqtZjQU1cG3F6H+p8AXwMXm1nb6A/LkUDHesRSGMWRqIzw/9uszKwX4X34XVISKTFx92LCEMOzCFcXqyT/3pRF/3YG/gW8CfwHKAfGATcBvzazX5vZq2b2sCXdW9bUoj++P6f6l5qcO440cvE4CoElSevKCDFfQzjHvwbcRoj7Z8DtFu5DetXMrmy+UKWFyKXPycfAjoTvOfsCOwN/AnD374DfAv8EDicka1cDfwR2MbOXLdzzHsfF11z/XKf7fpkLsWdMSVsOMbM84IHo5Wn1acOD/xHu6bo8w/1uCQwHLqvPPhP2/XbU7b7K3ccTPkSHZVh9efTvLe7+VTRk6so61K9yMvC6u8+qS6Wop28i4T6yTkA3YA3RyTgT7r4GOIKQNM4l/GEZR+j5rKtyoEvSuiKgWYeCmNlGwAvAve4e17DZVsvCjfZVN15X63mPhkPfAdxvZj2i1cm/N1U91Uujc8MF7r6Du59GuHf0acLv+2nAfoT7WS9oruOILmw8Ahzr7onHl1PHUYOsPI5apD33uHupux/n7ju6+83An4FzCaMb8gnnvj3M7ODmDFiyS0v6nCQfi7vPd/fpHm7hmEW4h+3oqvLu/ld338Xdf0K4D68P8DfCd7sRhKGf9zRFrLXI6c91uu+XuRB7XShpyxHRPSn3Eq4iHBmN326IAiDTiUB+TLjRd4aZzSckKrtE3f/tGhBDxsMToyTty7rUSeMU6tfL1hXoTUgaV3m4p20sUKcPurt/6O77uftG7v4jQg9inWfiJHT5fy9K5KvsFK1vFhYmPXkB+Je7j26u/cp67v6Qr7/xevsURfIIPbmbRq+nEa4CV9kJ+Mrdq/XamtlmhOG/NxGGx7wfXXSYQv2G89Yo1XGY2c6EiySj3P35pCo5cxy1yMrjqMUMwM1s24R1O5F07jGzI4F57v5v4HvAO9Ew3Xdo/pgli7Skz0kGx1J1f3E10YXg/yPcV9UdyHf3OU0Zay1a2ud6g++KORR7WkramoGFKWnbE7L6fDNrb9F0tXVwO+E+tsPcfXlthZP238bMRlmYzjUvunp9JmFGnUw8QrhhdqdouRT4ANjJ3VdlGEOxmR0UHXuBmZ1IuE+lLveE3QOcZWabmFln4CLCFbWMmNmehC+vdZ01Eg83P88EzojezyJC7+P7dWnHwpTsHaL3YQThKuBNNZRP97szmXDP0rkWHglxPGFM+pMZ1icaotme8AelTbQtP5P60fjw5wg3gP++Lu+BNJ3oM7ajmeVH/0c3EYZBfxQVGQf81sy2iHpJ/0C4+JDsZsJw1zXALGB3C/dlDCJ8DppUNDxoIvBrTz271zhy4DgAos9P1cWtdtFnqOpL3Dhy5DiqRD24jwNjzKyzme1AmKxgXdxRbBexvndjFjDIwr3RP2rumCX7tZTPiZkNjuK0KIm8lqS/y5GzgH96mEztO6CDhcfmDG6uWBPl8uc6k++X2Rp7nbm7liZegNGErD9xGVeH+ltEdVYSurCrlosyrF9A+IJdGtWbQZgG1ep5PMOBt+pYpzvhCtJSwjjpt4AD6thGAaFru5RwT9l9QJc61L8TeKAB/487AC8TvgQvJAxp6FXHNq5J+H+YTEh86/W7Q7hS9DZhqOuHwN51rD85xbbhmdQnDC1wYFnS7+ReTflZ0lLr79dQwr2T5cACwr0TOyRsN+Cq6Pd3MWH4ZJukNg4D7kpad3P0e/8W0LsZjuM+wgy3ib9b5bl2HNE+kz8/DvTJteNI2n8x4eJXOWGo9y+Ttt8InJjwuojwN2gx8DChVyH2z4uW7FlayueEMMnF14RbOr4kfGfpnFSmF/DvxGMATiBM5DUbGBzT/0FOfq7J4PtltsZe18Wi4EVERERERCQLaXikiIiIiIhIFlPSJiIiIiIiksWUtImIiIiIiGQxJW0iIiIiIiJZTEmbiIiIiIhIFlPSJiIiIiIiksWUtEmrZ2ajzWxy3HGIiIiIiKSipE1iZ2aTzczN7OdJ64vMrDza1qcR9zW6MdoSkZYhOi+sjs43S8zsQzMbVYf6bmaDmi5CEWlNdE6SVJS0Sbb4EDgjad0pwOzmD0VEWqGr3b0QKAYuB+40s72ba+dmVmBm1lz7E5Gsp3OSVKOkTbLFU8CmZrZbwrrTgTsTC5nZKDP7KLry9D8z+2nCtkHR1aUjzWxGVOY5M+sZbb8D2Au4KLp6NT+p7cvMbJ6ZlZrZ7WaW32RHKyJZyd0r3f1RoBT4PoCZ7RFd+f7OzOaY2RgzK4i2fRhVfTY6rzwWrZ9tZsMT2068+p1wvhpqZp8By4FO0bpfmtmbUXvvm9meCW0MNrN3zGxxFM8bZta1ad8VEYmLzklSRUmbZIs1wD3ALwCiq0mdgX9WFTCzY4HrgNOAEuAK4PGkRA/gSGB3YHOgC3AlgLufAbxGdPXK3TdJqPMjYHFU54fAUOCExj1EEcl20dXlE4BuwCdmtjXwInArsDGwN/BT4HwAd98+qnpIdF4ZUsddHkP4ItYFWBat+zlwMuEK+yvAAwnlH4xiKQZ6Ar8DVtdxnyKSI3ROkipK2iSb3AUMMbMiwlDJu4HKhO2nAne7+2vuXuHuTwLPEE4miS5w98XuXgY8RHRlqhaz3P1md1/j7p8AL2VYT0RahgvMrAxYSfhCcpG7PwOcCfzd3R+LzjtzgGuAEY203/PdvdTdV7q7R+tucPfP3b2CMNqgn5l1i7atBvoDvdx9tbv/292XpWpYRHKazklSjZI2yRru/iUwiXCV5nDg3qQimwEzk9Z9RugdS2xnbsLLckKPXW3mJr3OtJ6ItAzXunsx0BW4D9g/Gm60FeFiUlnVQrigtEnalupmVop1yecwWH8+OhzoB7xrZp9Gw7o1lFuk5dE5SaopiDsAkSS3A/8C/ubu86z6rJFfAn2TyvcHvqhD+5W1FxGR1srdl5rZmcBHhCva84H73f20mqqlWLcU6FT1wsx6pdlfnc5J7v4B0dBtM9sJeI5wDryvLu2ISG7QOUmqqKdNss1zwAHAb1NsGwuMMrMfmVm+mR1BuMIztg7tzwcGNDxMEWmp3H0V4Z7ZS4BxwLFmdrSZtY3OPVua2cEJVeYDWyc18w5wgoVHlxQB1zY0rmj/I8yse7RqMbA2WkSkhdI5SUBJm2QZD15y969SbHsEuIgwbHIRYQrc49z9P3XYxY3AwGhIwQb7EBGJPECYrW1/4CDCbLZfA98BjwNbJJS9ELjYzBaZ2YRo3SWEm/i/InxZerKR4joG+NDMlhEmBBhHmAhARFo2nZNaOVt/j6GIiIiIiIhkG/W0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiLSwpnZiWb2YcLrcWY2LsaQRESkDpS0iYhIVjCzyWa22szKzWyJmX1oZqPq2Iab2aCmiTA3pErI3P0hd98+ppBERKSBlLSJiEg2udrdC4Fi4HLgTjPbuzkDMLMCM7Pm3KeIiEhNlLSJiEjWcfdKd38UKAW+X7XezPaIeuS+M7M5ZjbGzAqibVXD/56Neusei9bPNrPhie0n9siZ2aDo9VAz+wxYDnSK1v3SzN6M2nvfzPasKW4zO9nMPjWzpWb2hJn9ycwmJ2yvLZaeZvZPM/s26m2cYmb7JpTtE5U/KYpnaRTfNtH2i4ATgROjmMvNrJuZDTez2TXEXWxmt0fv6Xdm9i8z65ew/dio53OJmS00sxdreh9ERKRxKWkTEZGsE/V2nQB0Az6J1m0NvAjcCmwM7A38FDgfIGH43yHuXujuQ+q422MICWIXYFm07ufAyYSev1eAB2qIeU/gHuBsoCtwL1Cn4Z1AftRGX2Aj4CngSTPbKKncycABQHdgPuE9wd2vBh4CHoreg0J3/66mHUa9ik8ChcDOQC/gfeAfZtbGzDoCDwK/cvcuQG/g6joel4iINICSNhERySYXmFkZsJKQIF3k7s9E284E/u7uj7l7hbvPAa4BRjTSvs9391J3X+nuHq27wd0/d/cK4E6gn5l1S1N/RBTfP6P4/gk8k6ZsSu7+lbs/6e7L3H21u18JOLB7UtHL3f0bd18JjCWhN7IedgZ+CJweHf8q4GJgc2CPqMwaYFsz2yh6f15uwP5ERKSOlLSJiEg2udbdiwk9VfcB+1cNfwS2AoaYWVnVAtwNbNJI+56VYt3chJ/Lo387p6nfO0UbqdpMy8xKzGxsNIxySXSMXYAetcRVWJf9JNkKaAvMTXhfvyP0+m3m7suBg4H9gU+iYZlnNWB/IiJSRwW1FxEREWle7r7UzM4EPiL0sP2JMAzwfnc/raaqKdYtBTpVvTCzXmn2WVn/iAH4CuiTtC75dW2xXEsYGvkj1idmi4C6TIxSSd0uys4HVgAbRT2KG3D314DXoqGU+wATzexDd59Uh/2IiEg9qadNRESyUjRM7wrgEjPrAtwGHGtmR5tZWzPLN7MtzezghGrzga2TmnoHOMHMisysiJAYNYXxwJFmdkgU2yGEe+7qEksRIYFaBLQHrqTuvWjzgS3NLD/D8q8TkuPbzKwHgJl1jd7njma2iZkNMbPiaNhoGSE5XlvHuEREpJ6UtImISDZ7gDCD5O/dfQpwEHA68DVhCN/jwBYJ5S8ELjazRWY2IVp3CWFika8ISdOTTRGou78exfYXQmJzGmFSkUS1xfIHQuK2gDAByzdR2bq4izC0cWE03LGklrjXEiY1WQm8bWZLgfeAIwnJmQFnADPNrJzwnl/k7q/WMS4REaknW3+vtYiIiDQmMxsNDHL3QTGHIiIiOUw9bSIiIiIiIllMSZuIiIiIiEgW0/BIERERERGRLKaeNhERERERkSym57Q1EjNrB+wOzEPTIIuIiIiISGr5QE9gSvR4m1opaWs8uwOvxR2EiIiIiIjkhL0Iz8qslZK2xjMP4LXXXqN3795xxyIiIiIiIlnoq6++Yq+99oIof8iEkrbGsxagd+/e9OnTJ+ZQREREREQky2V8S5UmIhEREREREcliStpERERERESymJI2ERERERGRLKakTUREREREJIspaRMREREREclimj1SRERERLLO3XffzcyZM+MOo9HMmxdmd+/Zs2fMkTSefv36MWrUqLjDaBWUtImIiIiINLEVK1bEHYLksJxI2sysGLgLOARYAlzl7relKXsWcCHQBfgXMMrdl0TbypOKdwBuc/dfmVkfYBawLGH7je5+WSMeioiIiIhkoKX14Fx44YUAXHPNNTFHIrkoJ5I24BZCrL2A/sALZvaRu09KLGRmBwCXAQcAM4FxwF+AYQDuXphQthCYDzyWtK+N3H1l0xyGiIiIiIhI3WT9RCRm1gkYAlzi7kvdfSowFhiZovhw4D53nxr1rl0MHGdmHVOUPRr4FnitSQIXERERERFpBFmftAEDAHP36QnrpgIDU5QdCLxX9cLdP4p+3CpF2WHA/e7uSes/N7OvzGy8mfVIFZCZFZtZn8QF6J3Z4YiIiIiIiGQuF5K2QsJ9bInKgM5pyi5OWrc4uayZbQHsA4xPWL0Q2B3YAtgV6AT8NU1MZxPuf0tc1GMnIiIiIiKNLhfuaSsnTCqSqAhYmmHZLinKngy87u6zqla4eznwTvTym2hCk3lm1tXdFyXVv5lwv1yi3ihxExERERGRRpYLPW0zADezbRPW7QRMS1F2GrBj1Qsz2wYw4NOkcqdQvZctlaphk7bBBvcyd5+duABf1dKeiIiIiIhInWV90ubuy4DHgTFm1tnMdiBMQjI2RfFxwAgz28HMOgNXAo+4+/KqAma2J7ApSbNGmtkeZra1meWZWTfgz8Ar7l7aJAcmIiIiIiKSgaxP2iJnEnq+5gETgdHuPsnMNjezcjPbHMDdXwDGRGXmAZXAr5LaGgY84e7JQyb7RfWWEnrsVgFDm+h4REREREREMpIL97Th7mWEaf+T139BmHwkcd1fCM9mS9fW6WnW/5X0E4+IiIiIiIjEIld62kRERERERFolJW0iIiIiIiJZTEmbiIiIiIhIFlPSJiIiIiIiksWUtImIiIiIiGQxJW0iIiIiIiJZTEmbiIiIiIhIFlPSJiIiIiIiksWUtImIiIiIiGQxJW0iIiJNpLS0lAsuuIBFixbFHYqIiOQwJW0iIiJNZMKECUyfPp0JEybEHYqIiOQwJW0iIiJNoLS0lJdeegl358UXX1Rvm4iI1JuSNpFGpuFQIgKhl62yshKAyspK9baJiEi9KWkTaWQaDiUiAJMnT6aiogKAiooKJk2aFHNEIiKSq5S0iTQiDYcSkSqDBg2ioKAAgIKCAgYPHhxzRCIikqtyImkzs2Ize9TMlprZ12b2yxrKnhWVWWpmj5hZl4Rtk81spZmVR8vnSXX3MbNpZrbczN4ys+2b8rik5dFwKBGpMnToUPLywp/ZvLw8hg4dGnNEIiKSq3IiaQNuAQqAXsChwOVmtsElSzM7ALgsKrMp0Ab4S1Kxs929MFr6J9TtBjwFXAN0BZ4EnjKzgiY4HmmhNBxKRKqUlJSw3377YWbsv//+dO3aNe6QREQkR2V90mZmnYAhwCXuvtTdpwJjgZEpig8H7nP3qe6+BLgYOM7MOmawq6OAGe7+kLuvAq4HOgL7NMJhSCvxwx/+sNrrPffcM6ZIRCQbDB06lO222069bCIi0iBZn7QBAwBz9+kJ66YCA1OUHQi8V/XC3T+KftwqocyVZvadmb1pZvvWULcS+CDVfqLhmn0SF6B33Q5LWqKVK1dWe71q1aqYIhERERGRliIXkrZCYEnSujKgc5qyi5PWLU4oez7QlzDM8k7gGTPbqoa66fZzNjAraXmtxqOQVuHtt9+u9vrf//53TJGISDYYN24cH374IePHj487FBERyWG5kLSVA12S1hUBSzMs26WqrLu/HQ2xXOXu4wmJ1mH12M/NhOQvcdkrk4ORls3ManwtIq1HaWkpkydPBuDll1/WbLIiIlJvuZC0zQDczLZNWLcTMC1F2WnAjlUvzGwbwIBP07TtNdQ1YIdU+3H3MnefnbgAX2V0NNKi7b333tVe77OPbokUaa3GjRuHe/gz4+7qbRMRkXrL+qTN3ZcBjwNjzKyzme1AmIRkbIri44ARZraDmXUGrgQecffl0X1oB5lZezMrMLMTgb2BZ6O6TwBbm9nxZtYO+B2wHHilaY9QWpJhw4ZVm+J72LBhMUckInF55ZXqfz40m6yIiNRX1idtkTMJvWLzgInAaHefZGabR89b2xzA3V8AxkRl5gGVwK+iNtoQkrgFwMJo/c/c/eOo7nfAz4BLCPeyHQMc4e4VzXGA0jKUlJQwaNAgAAYPHqwpvkVasapetnSvRUREMpUTzyBz9zLCtP/J678gTCCSuO4vbPhsNtx9AbB7LfuZDOiB2tIgw4YN45tvvlEvm0grl5eXx9q1a6u9FhERqQ/9BREREWkCG2+8cbXXm2yySUyRiIhIrlPSJtLIJkyYwPTp05kwYULcoYhIjEpLS6u9/u6772KKREREcp2SNpFGVFpayksvvYS78+KLL2qKb5FWbPDgwese+2Fm7LvvvjFHJCIiuUpJm0gjmjBhApWVlQBUVlaqt02kFRs6dCgFBeHW8YKCAoYOHRpzRCIikquUtIk0osmTJ1NRESYcraio0BTfIq1YSUkJ+++/P2bGAQccoNlkRUSk3pS0iTSiQYMGVbuyPnjw4JgjEpE4DR06lO222069bCIi0iBK2kQa0dChQ6vdw6IvaiKtW0lJCddee6162UREpEGUtIk0opKSErp37w5Ajx499EVNRERERBpMSZtIIyotLWXevHkAzJ07V7NHioiIiEiDKWkTaUTjx4/H3QFwd8aPHx9zRCIiIiKS65S0iTSiV199tdrrV155JaZIRERERKSlKIg7AJGWpKqXLd1rEanZ3XffzcyZM+MOo9FUDZfu2bNnzJE0nn79+jFq1Ki4wxARaVXU0ybSiPbee+9qrwcNGhRPICKSFVasWMGKFSviDkNERHKcetpEGtHw4cN55ZVXqKysJC8vj2HDhsUdkkhOaWk9OBdeeCEA11xzTcyRiIhILsuJnjYzKzazR81sqZl9bWa/rKHsWVGZpWb2iJl1ida3M7N7zWxOtO09Mzs8qa6b2TIzK4+WcU18aNLClJSUsM8++wAwePBgTfkvIiIiIg2WKz1ttxBi7QX0B14ws4/cfVJiITM7ALgMOACYCYwD/gIMi+p/CewDfAEcBDxmZru4+4yEZnZ194+b9nCkJRs+fDjffvutetlEREREpFFkfdJmZp2AIcDO7r4UmGpmY4GRwKSk4sOB+9x9alT3YuB/ZvYLd18GjE4o+6yZzQB2B2YgsWmpEw9cd911MUfSeDTxgIiIiEh8cmF45ADA3H16wrqpwMAUZQcC71W9cPePoh+3Si5oZt2BbYEPkza9bGbzzexJM+uXKqBouGafxAXonekBScumiQdEREREpDFlfU8bUAgsSVpXBnROU3Zx0rrFyWXNrAB4EHikqlcusg/wFtARuBL4p5nt4O5rkto8mzAMUxpBS+vB0cQDIiIiItKYcqGnrRzokrSuCFiaYdkuiWXNLA94IHp5WmJBd3/V3Ve7exnwG2BzUvfo3Qz0TVr2qv1QRERERERE6iYXetpmAG5m2yYMd9wJmJai7DRgR+BhADPbBjDg0+i1AfcSJjQ5xN1X17LvlE9GjpK6ssR1oWkREREREZHGlfU9bdEEIo8DY8yss5ntQJiEZGyK4uOAEWa2g5l1JgxxfMTdl0fbbyfcx3ZYwjoAzGx7M9vJzPLNrBC4EZjLhve8iYiIiIiINJusT9oiZxJ6veYBE4HR7j7JzDaPnqe2OYC7vwCMicrMAyqBXwGY2RbA6YReunkJz2K7KNrHxsAjhPvnZgJ9gEMz6I0TERERERFpMrkwPLJqOOKQFOu/IEw+krjuL4RnsyWXnUMYKpluHy8DWzc0VhERERERkcaUKz1tIiIiIiIirZKSNhERERERkSympE1ERERERCSLKWkTERERERHJYkraREREREREspiSNhERERERkSyWE1P+i4iIiEjN7r77bmbOnBl3GJJG1f/NhRdeGHMkUpN+/foxatSouMPYgJI2ERERkRZg5syZfDrjI3p06xB3KJJCHmsAWPzd7HgDkbS+/W5F3CGkpaRNREREpIXo0a0DQw/fOu4wRHLShKc/iTuEtHRPm4iIiIiISBZT0iYiIiIiIpLFNDwyx+gm4+ynG42zX7beZCwiIiKSipK2HDNz5kymTf+E/PbFcYciaVSudgA+mvlNzJFIKmtXlsUdgoiIiEidKGnLQfnti+m4xX5xhyGSk5bPeSnuEBqVet+zm3res5963kUkF+RE0mZmxcBdwCHAEuAqd78tTdmzgAuBLsC/gFHuviSTdsxsH+BWoB/wPnCqu3/YNEclItJwM2fO5MNPppNf1DbuUCSFtZVhiu+P538WcySSytrFq+MOQUQkIzmRtAG3EGLtBfQHXjCzj9x9UmIhMzsAuAw4AJgJjAP+AgyrrR0z6wY8BZwJPA6cDTxlZtu4e0XTHp6ISP3lF7WlaO9ecYchknMWvzo37hBERDKS9bNHmlknYAhwibsvdfepwFhgZIriw4H73H1q1Lt2MXCcmXXMoJ2jgBnu/pC7rwKuBzoC+zTd0YmIiIiIiNQsF3raBgDm7tMT1k0FDkxRdiBhSCQA7v6RmQFsRUhQa2pnIPBeQt1KM/sgWl/tJphomGVx0r57Z3g8IiIiIiIiGcuFpK2QcP9ZojKgc5qyi5PWLY7KWi3tFAKLMtzP2YRhmCIiIiIiIk0qF5K2csKkIomKgKUZlu0Slc2rpZ267Odmwv1yiXoDr6Uo26jmzZvH2pVLWtwMeCLNZe3KMubNq4w7DBEREZGMZf09bcAMwM1s24R1OwHTUpSdBuxY9cLMtiH0sH2aQTvJdQ3YIdV+3L3M3WcnLsBXdT4yERERERGRWmR9T5u7LzOzx4ExZjYC6EuYPOS4FMXHAQ+Z2UPALOBK4BF3Xw5QSztPANeb2fHRz78GlgOvNNWx1UfPnj0pW5Gn57SJ1NPyOS/Rs+fGcYchIiIikrFc6GmDMA2/A/OAicDoaJr+zc2s3Mw2B3D3F4AxUZl5QCXwq9raiep+B/wMuIRwL9sxwBGa7l9EREREROKU9T1tEIYjEqbrT17/BWECkcR1fyE8my3jdhK2Twa2r3+kIiIiIiIijStXetpERERERERapZzoaRMRkdTmzZtHxeJVLH51btyhiOScirJVzPN5cYchIlIrJW05aO3KMk35n8UqV5cDkNe2sJaSEoe1K8sATUQiIiIiuUNJW47p169f3CFILWbOXAZAv35KDLLTxi3qc9SzZ08W2zKK9u4VdygiOWfxq3PpuUnPuMMQEamVkrYcM2rUqLhDkFpceOGFAFxzzTUxRyIiIiIiLYEmIhEREREREcliStpERERERESymJI2ERERERGRLKZ72kREctzaxas15X+WWlu+BoD8wjYxRyKprF28GjaJOwoRkdopaRMRyWEtaSbMlmjmzJkA9NtE/09ZaRN9hkQkNyhpExHJYZpRNrtpNlkREWkMuqdNREREREQkiylpExERERERyWJK2kRERERERLKYkjYREREREZEslvVJm5m1NbM7zazMzBaY2RW1lB9iZjPNbJmZPW9mmyZsu8HMPjWzpWb2iZmdmlR3tpmtMLPyaHm5qY5LREREREQkE1mftAGXAjsAWwK7AyeY2YhUBc1sW2AscBqwEfAJ8HBCkWXAT4Ei4CTgejMbnNTMke5eGC37NuqRiIiIiIiI1FEuJG0jgDHuvtDdZwM3AiPTlD0JeNbdX3T3FcAlwA/MrD+Au1/m7h+7e6W7TwEmA3s2+RGIiIiIiIjUU1YnbWbWFegFvJeweiowME2VgYll3X0xMDtVeTNrB3wf+DBp0/hoGOYLZrZzmriKzaxP4gL0zuigRERERERE6iCrkzagMPp3ccK6MqBzDeUXJ61LV/42YAbwdMK6E4E+wBbAy8BzZlaSou7ZwKyk5bU0MYmIiIiIiNRbrEmbmU00M0+zzAbKo6JdEqoVAUvTNFmeVDZleTP7I7ALcJS7V1atd/c33H2Fuy9392uAUmCfFPu5GeibtOxV+xGLiIiIiIjUTUGcO3f3g2srY2ZzgR2BudGqnYBpaYpPi8pW1e1CSKimJay7nDAZyT7uXlZbiGniLiP04CXGWUtTIiIiIiIidZftwyMBxgGXmNlGZrYFcA5hhshUHgQOMbN9zawDMAZ4y90/BzCzCwlDIPdz9wWJFc1sczP7UfSIgfZm9nugOxr2KCIiIiIiMYq1py1DlxOm7/8cWAPc7u73VW00s3LgEHd/zd0/ip69dg+wCfA6cEJCW1cDq4FPE3rGHnT3Mwj3vd0O9AdWEiY8OdjdFzbhsQlw9913M3PmzLjDaDSff/45q1at4ne/+x1t2rSJO5xG0a9fP0aNGhV3GCIiIiKtUtYnbe6+Gjg9WlJtL0x6/RjwWJqyaccwuvuHhOfBiTTI2rVrqays5JtvvqF3b00qKiIizWPevHmUL13OhKc/iTsUkZz07XfLWb56XtxhpJT1SZu0fC2pB6e0tJQRI8Kz35csWcJ5551H165dY45KRERERHKZkjaRRjRu3DgqK8OEpJWVlYwfP56zzz473qBERKRV6NmzJ4vbrmLo4VvHHYpITprw9CcUdesZdxgp5cJEJCI549VXX632evLkyfEEIiIiIiIthpI2kUaU/OgHPQpCRERERBpKSZtII9p7772rvd5nn1TPZhcRERERyZySNpFGNGzYMPLywscqLy+PYcOGxRyRiIiIiOQ6JW0ijaikpIRNNtkECDeEa+ZIEREREWkoJW0ijai0tJQFCxYA8O2337Jo0aKYIxIRERGRXKekTaQRTZgwAXcHwN2ZMGFCzBGJiIiISK5T0ibSiCZPnkxFRQUAFRUVTJo0KeaIRERERCTX6eHaIo1o0KBBTJw4EXfHzBg8eHDcIYmISCvy7XcrmPD0J3GHISksWrwKgK5F7WKORNL59rsVFHWLO4rUlLSJNKKDDz6YZ599FgjDIw8++OCYIxLJLXfffTczZ86MO4xGU3UsF154YcyRNJ5+/foxatSouMOQFPr16xd3CFKD7xaH80FRtz7xBiJpFXXL3s+RkjaRRjRx4kTMbF1P28SJE/nFL34Rd1giEpMOHTrEHYK0Ikqms1vVxZtrrrkm5kgkFylpE2lEkydPrjYRyaRJk5S0idSBvnSKiIhsKOsnIjGztmZ2p5mVmdkCM7uilvJDzGymmS0zs+fNbNOEbePMbLWZlScs7RK2DzSzt8xsuZlNM7O9mvLYpOUZNGgQBQXhWkhBQYHuaRMRERGRBsv6pA24FNgB2BLYHTjBzEakKmhm2wJjgdOAjYBPgIeTit3k7oUJy6qobhvgGeBJoCtwDfCUmenpyJKxoUOHkpcXPlZ5eXkMHTo05ohEJE6lpaVccMEFemajiIg0SC4kbSOAMe6+0N1nAzcCI9OUPQl41t1fdPcVwCXAD8ysfwb7GQR0AK5391Xu/hDwKXBUQw9AWo+SkhL2228/zIz999+frl2V84u0ZhMmTGD69Ol6ZqOIiDRIVidtUS9XL+C9hNVTgYFpqgxMLOvui4HZSeVPM7NSM/uvmR2bVPcDd6+sbV9mVmxmfRIXoHemxyUt29ChQ9luu+3UyybSypWWlvLSSy/h7rz44ovqbRMRkXrL6qQNKIz+XZywrgzoXEP5xUnrEsv/GdgK6EHohRtrZntnWDfR2cCspOW1dAchrUtJSQnXXnutetlEWrkJEyZQWRmuA1ZWVqq3TURE6i3WpM3MJpqZp1lmA+VR0S4J1YqApWmaLE8qW628u//X3b9z9wp3/xfwIHB0JnWT3Az0TVo0aYmIiKwzefJkKioqAKioqGDSpEkxRyQiIrkq1qTN3Q92d0uz9HH3RcBcYMeEajsB09I0OS2xrJl1ISRU6cp7Ut3vmVnie5JyX+5e5u6zExfgqxoPVkREWpUf/vCH1V7vueeeMUUiIiK5LtuHRwKMAy4xs43MbAvgHMIMkak8CBxiZvuaWQdgDPCWu38OYGbHmFmhmeWZ2YGEiUueiupOBlYC55pZOzM7HhhAmE1SRESkTqqe2SgiItJQuZC0XU7o7foceBd4xN3vq9oYPWttLwB3/wg4FbgH+A7YFjghoa3fAF8T7lW7Hhjl7i9HddcAhwPHRNsvAX7m7qVNeGwiItJCvfXWW9Vev/nmmzFFIiIiua4g7gBq4+6rgdOjJdX2wqTXjwGPpSlb431n7v4BsEf9IhUREVlv0KBBPP/886xdu5b8/HwGDx4cd0giIpKjcqGnTUREJOcMHTqU/Px8APLz8/UYEBERqTclbSIiIk2gpKSE/fbbDzNj//3312NARESk3rJ+eKSIiEiuGjp0KF988YV62UREpEGUtImIiDSRkpISrr322rjDEBGRHKfhkSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiIiIiIZDElbSIiIiIiIllMSZuIiIiIiEgWU9ImIiIiIiKSxZS0iYiINJHS0lIuuOACFi1aFHcoIiKSw5S0iYiINJEJEyYwffp0JkyYEHcoIiKSw5S0iYiINIHS0lJeeukl3J0XX3xRvW0iIlJvWZ+0mVlbM7vTzMrMbIGZXVFL+SFmNtPMlpnZ82a2acK2D82sPGGpMLNnErZ7VK9q+7gmPDQREWnBJkyYQGVlJQCVlZXqbRMRkXrL+qQNuBTYAdgS2B04wcxGpCpoZtsCY4HTgI2AT4CHq7a7+/buXujuhUBn4EvgsaRmdq0q4+7DG/tgRESkdZg8eTIVFRUAVFRUMGnSpJgjEhGRXJULSdsIYIy7L3T32cCNwMg0ZU8CnnX3F919BXAJ8AMz65+i7N6ExO5vTRCziIi0coMGDaKgoACAgoICBg8eHHNEIiKSq7I6aTOzrkAv4L2E1VOBgWmqDEws6+6Lgdlpyg8D/ubuy5LWv2xm883sSTPrlyauYjPrk7gAvTM4JBERaSWGDh1KXl74M5uXl8fQoUNjjkhERHLV/7d3/7F31Xcdx58vgbGy0tJKZAwYPyY/ZwZTQGEryEBHxSwLwaRDCYMNOjVxiMscGZvyww01Lp2SkVmEMoYDnUtEB+jIRulCmVDRpCqwlRXXlR8W/JYWcUx4+8c5X7lc7re9/fbb3lPv85Gc3O/5fD7nc96nyf30vO/53M/tdNIGzG5fN/aUTdBMbZyq/ca+ste0T7IXcA6wrK/tqcAhwFHA94GvJtljwHkuAb7bt62YIiZJ0hiaP38+p59+Okk444wzmDdv3qhDkiTtokaatCW5q138Y9C2FtjcNp3Tc9hcYNMUXW7uaztV+7OBZ4HlvYVVdW9VvVhVE8CHgTcz+CndEuDQvm3BlBcqSRpLixYt4phjjvEpmyRpu+w+ypNX1Zlba5NkPXAssL4tOg5YPUXz1W3byWPn0CRU/e3PB75QVbW1EAcWNkndRF+cW+lKkjRu5s+fzzXXXDPqMCRJu7iuT4+EZgrj5Un2TXIwcCnNCpGDfBFYmORdSWYBVwH3V9WayQZJDgROA27qPTDJW5Mcl2S3JLNpFjxZD/zLjF+RJEmSJA1pV0jarqB5UrYGWAXcVlU3Tla2v6e2AKCq/g34AHA98AxwNHBuX3/nASt7E7nWfsBtwHPAYzTfbTurql6c6QuSJEmSpGGNdHrkMNqkaXG7Daqf3bf/l7z2t9d66z8NfHpA+deBI7crWEmSJEmaYbvCkzZJkiRJGlsmbZIkSZLUYSZtkiRJktRhJm2SJEmS1GEmbZIkSZLUYSZtkiRJktRhJm2SJEmS1GEmbZIkSZLUYSZtkiRJktRhJm2SJEmS1GEmbZIkSZLUYSZtkiRJktRhJm2SJEmS1GEmbZIkSZLUYSZtkiRJktRhnU/akrwuyeeTTCT5jyRXbqHt/kluT/JEkkpyyIA2VyfZ0PZ3XZI9euoOSvL3SZ5PsibJ2TvosiRJkiRpKJ1P2oBPAm8Dfhw4ATg3yQVTtH0ZuAsYmGwl+SCwCDi+7e844PKeJl8CHgH2BRYDy5Icsf2XIEmSJEnTsyskbRcAV1XVhqpaC/wRcOGghlX1VFV9DnhgC319pqrWVtUG4MrJvpIcDpwIfKKqXqiqu4E7gfNm9GokSZIkaRvsPuoAtiTJPOBNwD/3FP8T8KlpdvkTA/o6MMnctu7xqproqz9xQFz7APv0FR84zZgkSZIkaUqdTtqA2e3rxp6yCWDv7eivvy/a/vrrtnSuS4DfmWYMkiRJkjS0kU6PTHJXu2DIoG0tsLltOqfnsLnApmmecvOAvmj766/b0rmWAIf2bQumGZMkSZIkTWmkT9qq6syttUmyHjgWWN8WHQesnuYpV7d93dfT17qq2phkNXBIkrlVtbGn/jXnaqdQTvTFOc2QJEmSJGlqu8JCJMuAy5Psm+Rg4FLghqkaJ3k9sGe7u2eS1+eVjGoZ8JtJDk6yL/CJyb6q6ts0C5hcmWRWkncBC4Gbd8A1SZIkSdJQuv6dNoAraJbgXwP8ELiuqm6crEyyGVhYVSvaohd6jn24fT0UWAtcDxwCrAL2oFni/+qe9otokrhngCeBC6vq0Zm9HEmSJEkaXueTtqp6keY30xZPUT+7b3/KeYpVVcDH221Q/feAn5t2sJIkSZI0wzqftEmSJGn8LF26lMcee2zUYcyYyWu57LLLRhzJzDnssMO46KKLRh3GWDBpkyRJknawWbNmjToE7cJM2iRJktQ5PsGRXrErrB4pSZIkSWPLpE2SJEmSOsykTZIkSZI6zKRNkiRJkjrMpE2SJEmSOsykTZIkSZI6zCX/Z85uAOvWrRt1HJIkSZI6qidf2G3YY1JVOyaaMZPkncCKUcchSZIkaZewoKq+OUxDk7YZkmRP4ATgCeClEYej0TqQJoFfAPjoVRpvjgeSJjkeaNJuwP7AA1X1g2EOcHrkDGn/wYfKlPX/W5LJP9dV1doRhiJpxBwPJE1yPFCfNdvS2IVIJEmSJKnDTNokSZIkqcNM2iRJkiSpw0zapJk3AVzRvkoabxM4HkhqTOB4oGly9UhJkiRJ6jCftEmSJElSh5m0SZIkSVKHmbRJO0iSzUmOaP9eluSaUcckqRuSrE1y5hR19yT50M6OSdLoJPndJLduod5xYcyZtElTaAfI/06yKclzSVYl+ViSPYc5vqpmV9WjOzpOSTOnfY9/ra/sgSQP9JV9I8nHdm50knaG9v//SvLTfeXXtuXv387+fzbJk9sVpMaOSZu0ZZdU1d7A/sBvAYuAO5JktGFJ2kGWAycl2R0gyd7AQcBB7d8keR3wM8A9owpS0g73KHD+5E77vv8lYM3IItJYM2mThlBVz1fVPcB7gJOAs5Icn2RlkokkTyT54yR7TB7Tfhp3VH9fSVYnObtn/0eSrEty2s64Fklb9CAQ4Ph2/53ASuB+4B1t2YnAS8BDSf4gyeNJnk5yfZI3THaU5KwkD7VjxP1JfnLQCZO8Jcm3k1zUV/66JM/0HpdkbpL/SnLYjF2xpEFuAc7pmV3zHprx4UmANH47yXeTbEjylSRvnDy4vQe4OMnDSTYmuTXJrHaMuBP4sfZrFJt73s97JFnatl+TZGF/UI4L48ukTdoGVfXvNIP2ApqbtkuBfWlu5s4EFg/RzU3AeT37p7V93TOTsUradlX1Q+A+4JS26BTg3nbrLbsPuAZ4K/BTwGE0Y8HVAEneTvNe/zVgPvAnwN8k2av3fEneBnwd+HhVLe2L5UXgVl49XpwDrKqqx2bgciVN7WngWzTJGsD7gWU99efT/J//bpqn8c8Af97Xxzk09wdvAd4OXFBVzwMLgafbr1HM7nk//yJNQjcfWALckORV9+qOC+PLpE3aduuB+VX1UFWtrKr/aQfKPwVOHeL4m4GfTzK/3T8P+GL5o4lSVyznlffyqcCKdpssO6VtczFwaVVtqKrNwO/RTKGmrVvajhEvV9UtND+ou6DnPCcDdwCLq+ovpohlGfC+JLu1++cBX9i+y5M0pJuA89snaCcAt/fU/QqwpKoeraoXgI8ApyY5sKfNp6rqmara0B478Gl7j5VV9ZWqegm4AXgj8KYB7ZbhuDB2TNqkbXcA8GySI5N8NcmTSZ4DrqT5pH2LqupJmqdqi5LMAs7GwVbqkuXAO9rvsB0JPAT8I3BUW3YyTRK3F/CtdvrjBHA3sE87Tfpg4MOTdW39obz6BmwxsAr4u6kCqaoHgA3Au5O8mWZq5lQJnqSZdTtNsvYR4MtV9YOeugOAxyd3qmoj8J9t+aTexUaeB2Zv5Xz/1759IsegYxwXxpNJm7QNkhxEMxVqBXAd8AhweFXNAT5J812YYSyj+WTsvcDDVfXIjAcrabr+AdgT+BDwYFW91H7yvQr4VWB3mu+4vQAcW1X7tNvcqprVTrH8HvD7PXX7VNVeVXVjz3l+HfhR4LqtLG40OaX6l4G/bW8OJe1g7VTEL9N8FWJZX/X3aT6cASDJHGBeW77VrmcgPMeFMWPSJg0hyV5JTgX+muaG7g6aT7+eAzYnOZrhvs826XbgCOAyfMomdUr7afr9NCvG3ttTdS/Nzdv97c3cUuAzSfYDSHJAkl9o2y4FLk5yUrvY0BuSLEwyr6e/zTTfbTkWuHYLId0MnAVciOOFtLNdCZzePt3qdQvN0/TD21kzfwisqKp1Q/T5FDCvbzzYVo4LY8akTdqyJUk20QywS4C/As6sqpdppku8D9gEfB64bdhO25vCW4GjgC/NcMyStt9yYD+ap+qTVrRly9v9jwIPAyvbKdJ3A0cDVNWDwAeAzwLPAt8BPth/kqraRLOI0QlJPjsokHZK9QpgDnDX9l6YpOFV1VNV9Y0BVTcBfwZ8DVhHMzacO2SfD9Mkfd9pp08fOo24HBfGTFz7QBqNJB8FTq6q9446FkndluRzwItVdcmoY5HUDY4L42X3UQcgjaMkc4GLgN8YdSySuq1djW4RzW/GSZLjwhhyeqS0k7U/oLse+GZV3TnqeCR1V5KraKZgXltV/zrqeCSNnuPCeHJ6pCRJkiR1mE/aJEmSJKnDTNokSZIkqcNM2iRJkiSpw0zaJEmSJKnDTNokSZIkqcNM2iRJkiSpw/4XtCU0G+ji0dkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "              baseline_ticker = '^GSPC', \n",
    "              baseline_start = df_account_value.loc[0,'date'],\n",
    "              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBQx4bVQFi-a"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "a1dc24e770f11933509167a1c29cdaaeb86ecb8b4614cc65da123615b71c0aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
